{"id": "56c1d16a-f2f1-47f7-928b-1e497a9533db", "fitness": 0.42416597216854585, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines particle swarm optimization (PSO) principles with differential evolution (DE) strategies for exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                new_pos_pso = pop[i] + v\n\n                # Differential Evolution update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                diff_vector = x1 + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_pos_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_pos_de[j] = diff_vector[j]\n\n                # Combined update\n                # 50% PSO, 50% DE\n                if np.random.rand() < 0.5:\n                    new_pos = new_pos_pso\n                else:\n                    new_pos = new_pos_de\n\n                # Clip to bounds\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_pos)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                if self.budget <= 0:\n                  break\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.424 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines particle swarm optimization (PSO) principles with differential evolution (DE) strategies for exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                new_pos_pso = pop[i] + v\n\n                # Differential Evolution update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                diff_vector = x1 + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_pos_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_pos_de[j] = diff_vector[j]\n\n                # Combined update\n                # 50% PSO, 50% DE\n                if np.random.rand() < 0.5:\n                    new_pos = new_pos_pso\n                else:\n                    new_pos = new_pos_de\n\n                # Clip to bounds\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_pos)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                if self.budget <= 0:\n                  break\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.15943733739742216, 0.30895491617367343, 0.4426460049000932, 0.27447028565838905, 0.27286049355380226, 0.5786111596479754, 0.30244197540927253, 0.4351494025322842, 0.41225504664135393, 0.19298334771646597, 0.4675954792418008, 0.9964879019241404, 0.31438855832461476, 0.47757411285802875, 0.7151949620862945, 0.49505521321815926, 0.38014776560030106, 0.5428966605718003, 0.21715198283216974, 0.4970168370828747], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "42ef278a-0272-49b3-8791-2e90eec2af0c", "fitness": 0.2780996971594553, "name": "CooperativeGaussianSearch", "description": "Cooperative Search with Gaussian Perturbations - Explores the search space with multiple cooperative agents, each perturbed by Gaussian noise, adapting their step size based on success.", "code": "import numpy as np\n\nclass CooperativeGaussianSearch:\n    def __init__(self, budget=10000, dim=10, num_agents=5, initial_step_size=0.5, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_agents = num_agents\n        self.initial_step_size = initial_step_size\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize agents\n        agents = np.random.uniform(self.lb, self.ub, size=(self.num_agents, self.dim))\n        fitnesses = np.array([func(agents[i]) for i in range(self.num_agents)])\n        eval_count = self.num_agents # Keep track of function evaluations\n\n        step_sizes = np.full(self.num_agents, self.initial_step_size)\n        \n        while eval_count < self.budget:\n            for i in range(self.num_agents):\n                if eval_count >= self.budget:\n                    break\n                \n                # Perturb agent with Gaussian noise\n                x_new = agents[i] + step_sizes[i] * np.random.normal(0, 1, size=self.dim)\n                \n                # Clip to bounds\n                x_new = np.clip(x_new, self.lb, self.ub)\n                \n                f_new = func(x_new)\n                eval_count += 1\n\n                # Update agent if better\n                if f_new < fitnesses[i]:\n                    fitnesses[i] = f_new\n                    agents[i] = x_new\n\n                    # Increase step size if successful\n                    step_sizes[i] *= (1 + self.success_threshold)\n                else:\n                    # Decrease step size if unsuccessful\n                    step_sizes[i] *= (1 - self.success_threshold)\n                    \n                # Keep track of the best solution found so far.\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                if fitnesses[i] < self.f_opt:\n                    self.f_opt = fitnesses[i]\n                    self.x_opt = agents[i]\n                    \n            # Global best update (optional, might help avoid premature convergence)\n            best_agent_index = np.argmin(fitnesses)\n            if fitnesses[best_agent_index] < self.f_opt:\n                self.f_opt = fitnesses[best_agent_index]\n                self.x_opt = agents[best_agent_index]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CooperativeGaussianSearch scored 0.278 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Cooperative Search with Gaussian Perturbations - Explores the search space with multiple cooperative agents, each perturbed by Gaussian noise, adapting their step size based on success.\n\n# Code:\n```python\nimport numpy as np\n\nclass CooperativeGaussianSearch:\n    def __init__(self, budget=10000, dim=10, num_agents=5, initial_step_size=0.5, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_agents = num_agents\n        self.initial_step_size = initial_step_size\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize agents\n        agents = np.random.uniform(self.lb, self.ub, size=(self.num_agents, self.dim))\n        fitnesses = np.array([func(agents[i]) for i in range(self.num_agents)])\n        eval_count = self.num_agents # Keep track of function evaluations\n\n        step_sizes = np.full(self.num_agents, self.initial_step_size)\n        \n        while eval_count < self.budget:\n            for i in range(self.num_agents):\n                if eval_count >= self.budget:\n                    break\n                \n                # Perturb agent with Gaussian noise\n                x_new = agents[i] + step_sizes[i] * np.random.normal(0, 1, size=self.dim)\n                \n                # Clip to bounds\n                x_new = np.clip(x_new, self.lb, self.ub)\n                \n                f_new = func(x_new)\n                eval_count += 1\n\n                # Update agent if better\n                if f_new < fitnesses[i]:\n                    fitnesses[i] = f_new\n                    agents[i] = x_new\n\n                    # Increase step size if successful\n                    step_sizes[i] *= (1 + self.success_threshold)\n                else:\n                    # Decrease step size if unsuccessful\n                    step_sizes[i] *= (1 - self.success_threshold)\n                    \n                # Keep track of the best solution found so far.\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                if fitnesses[i] < self.f_opt:\n                    self.f_opt = fitnesses[i]\n                    self.x_opt = agents[i]\n                    \n            # Global best update (optional, might help avoid premature convergence)\n            best_agent_index = np.argmin(fitnesses)\n            if fitnesses[best_agent_index] < self.f_opt:\n                self.f_opt = fitnesses[best_agent_index]\n                self.x_opt = agents[best_agent_index]\n                \n        return self.f_opt, self.x_opt\n```", "aucs": [0.10961259447607208, 0.1944434916092347, 0.3375687864513417, 0.1742802028545164, 0.1886653547652999, 0.14743491847766854, 0.23369339290557323, 0.2184105896659817, 0.1997863864533327, 0.11304966663769189, 0.1819592645451884, 0.2318522648888024, 0.2531357280854075, 0.18785933618706196, 0.6385714141690111, 0.3447970668667687, 0.31312017190451613, 0.8556617601992451, 0.195678429293362, 0.44241312275303035], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "8f0e252a-e716-42f4-abef-cbe1f9ac2d61", "fitness": 0.0, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a focus on maintaining diversity through adaptive parameter control and a novel selection mechanism.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.cr = cr  # Crossover rate for DE\n        self.f = f   # Scaling factor for DE\n        self.pop = None\n        self.fitness = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_x = None\n        self.gbest_fitness = np.inf\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.pbest_pop = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_x = self.pop[np.argmin(self.fitness)].copy()\n        self.gbest_fitness = np.min(self.fitness)\n\n    def update_gbest(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.gbest_fitness:\n            self.gbest_fitness = self.fitness[best_index]\n            self.gbest_x = self.pop[best_index].copy()\n            \n    def pso_update(self, func, velocities):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        \n        velocities = self.w * velocities + self.c1 * r1 * (self.pbest_pop - self.pop) + self.c2 * r2 * (self.gbest_x - self.pop)\n        new_pop = self.pop + velocities\n\n        # Handle boundaries\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        new_pop = np.clip(new_pop, lower_bound, upper_bound)\n\n        new_fitness = np.array([func(x) for x in new_pop])\n        self.eval_count += self.pop_size\n\n        # Update pbest\n        improved_indices = new_fitness < self.pbest_fitness\n        self.pbest_pop[improved_indices] = new_pop[improved_indices].copy()\n        self.pbest_fitness[improved_indices] = new_fitness[improved_indices].copy()\n        \n        return new_pop, new_fitness, velocities\n\n\n    def de_update(self, func):\n        new_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            # Ensure a, b, c are distinct and different from i\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            mutant = self.pbest_pop[a] + self.f * (self.pbest_pop[b] - self.pbest_pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            jrand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.cr or j == jrand:\n                    new_pop[i, j] = mutant[j]\n                else:\n                    new_pop[i, j] = self.pop[i, j]\n        \n        new_pop = np.clip(new_pop, func.bounds.lb, func.bounds.ub) # Ensure boundaries are respected again\n\n        new_fitness = np.array([func(x) for x in new_pop])\n        self.eval_count += self.pop_size\n\n        return new_pop, new_fitness\n\n    def selection(self, pso_pop, pso_fitness, de_pop, de_fitness):\n        # Combine populations and fitnesses\n        combined_pop = np.concatenate((pso_pop, de_pop), axis=0)\n        combined_fitness = np.concatenate((pso_fitness, de_fitness), axis=0)\n\n        # Sort by fitness (lower is better)\n        sorted_indices = np.argsort(combined_fitness)\n\n        # Select the best pop_size individuals\n        self.pop = combined_pop[sorted_indices[:self.pop_size]]\n        self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n        \n        #update pbest\n        for i in range(self.pop_size):\n             if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_pop[i] = self.pop[i].copy()\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        velocities = np.zeros((self.pop_size, self.dim))\n\n        while self.eval_count < self.budget:\n            # PSO update\n            pso_pop, pso_fitness, velocities = self.pso_update(func, velocities)\n\n            # DE update\n            de_pop, de_fitness = self.de_update(func)\n            \n            # Selection\n            self.selection(pso_pop, pso_fitness, de_pop, de_fitness)\n\n            self.update_gbest()\n\n        return self.gbest_fitness, self.gbest_x", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a focus on maintaining diversity through adaptive parameter control and a novel selection mechanism.\n\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.cr = cr  # Crossover rate for DE\n        self.f = f   # Scaling factor for DE\n        self.pop = None\n        self.fitness = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_x = None\n        self.gbest_fitness = np.inf\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.pbest_pop = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_x = self.pop[np.argmin(self.fitness)].copy()\n        self.gbest_fitness = np.min(self.fitness)\n\n    def update_gbest(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.gbest_fitness:\n            self.gbest_fitness = self.fitness[best_index]\n            self.gbest_x = self.pop[best_index].copy()\n            \n    def pso_update(self, func, velocities):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        \n        velocities = self.w * velocities + self.c1 * r1 * (self.pbest_pop - self.pop) + self.c2 * r2 * (self.gbest_x - self.pop)\n        new_pop = self.pop + velocities\n\n        # Handle boundaries\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        new_pop = np.clip(new_pop, lower_bound, upper_bound)\n\n        new_fitness = np.array([func(x) for x in new_pop])\n        self.eval_count += self.pop_size\n\n        # Update pbest\n        improved_indices = new_fitness < self.pbest_fitness\n        self.pbest_pop[improved_indices] = new_pop[improved_indices].copy()\n        self.pbest_fitness[improved_indices] = new_fitness[improved_indices].copy()\n        \n        return new_pop, new_fitness, velocities\n\n\n    def de_update(self, func):\n        new_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            # Ensure a, b, c are distinct and different from i\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            mutant = self.pbest_pop[a] + self.f * (self.pbest_pop[b] - self.pbest_pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            jrand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.cr or j == jrand:\n                    new_pop[i, j] = mutant[j]\n                else:\n                    new_pop[i, j] = self.pop[i, j]\n        \n        new_pop = np.clip(new_pop, func.bounds.lb, func.bounds.ub) # Ensure boundaries are respected again\n\n        new_fitness = np.array([func(x) for x in new_pop])\n        self.eval_count += self.pop_size\n\n        return new_pop, new_fitness\n\n    def selection(self, pso_pop, pso_fitness, de_pop, de_fitness):\n        # Combine populations and fitnesses\n        combined_pop = np.concatenate((pso_pop, de_pop), axis=0)\n        combined_fitness = np.concatenate((pso_fitness, de_fitness), axis=0)\n\n        # Sort by fitness (lower is better)\n        sorted_indices = np.argsort(combined_fitness)\n\n        # Select the best pop_size individuals\n        self.pop = combined_pop[sorted_indices[:self.pop_size]]\n        self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n        \n        #update pbest\n        for i in range(self.pop_size):\n             if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_pop[i] = self.pop[i].copy()\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        velocities = np.zeros((self.pop_size, self.dim))\n\n        while self.eval_count < self.budget:\n            # PSO update\n            pso_pop, pso_fitness, velocities = self.pso_update(func, velocities)\n\n            # DE update\n            de_pop, de_fitness = self.de_update(func)\n            \n            # Selection\n            self.selection(pso_pop, pso_fitness, de_pop, de_fitness)\n\n            self.update_gbest()\n\n        return self.gbest_fitness, self.gbest_x\n```", "aucs": [0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "cda6251f-8384-4386-8f74-6720253e1ccf", "fitness": 0.538808939115255, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a focus on exploration and local search.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        \"\"\"\n        Initializes the Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            if np.random.rand() < 0.5:  # Alternate between PSO and DE\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.539 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a focus on exploration and local search.\n\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        \"\"\"\n        Initializes the Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            if np.random.rand() < 0.5:  # Alternate between PSO and DE\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.1891653059123457, 0.40596983852838453, 0.5568849115440999, 0.8419875933766495, 0.5434964181312859, 0.6514594118364809, 0.37195077643226016, 0.481750139523351, 0.5768835679276747, 0.23275354887235955, 0.7966216867794302, 0.9931939555597465, 0.29888344298491576, 0.4846220294502305, 0.8000107144165916, 0.6212750517142083, 0.4558956534513422, 0.7677456062320399, 0.1976445377252528, 0.5079845919064487], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "42d5349e-ab31-49c8-b8ea-fafbd43169ac", "fitness": 0.0, "name": "LevyDifferentialEvolution", "description": "A population-based algorithm using a combination of Lévy flights and differential evolution with a dynamically adjusted exploration-exploitation balance.", "code": "import numpy as np\n\nclass LevyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, levy_exponent=1.5, de_rate=0.7, mutation_factor=0.5, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.de_rate = de_rate\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.exploration_rate = 0.9  # Initial exploration rate\n\n    def levy_flight(self, size):\n        numerator = np.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2)\n        denominator = np.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2))\n        sigma = (numerator / denominator) ** (1 / self.levy_exponent)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / abs(v) ** (1 / self.levy_exponent)\n        return step\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_rate:\n                    # Lévy Flight\n                    step_size = self.levy_flight(self.dim)\n                    new_individual = population[i] + step_size * (self.x_opt - population[i])\n\n                else:\n                    # Differential Evolution\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    new_individual = a + self.mutation_factor * (b - c)\n\n                    # Crossover\n                    cross_mask = np.random.rand(self.dim) < self.crossover_rate\n                    new_individual = np.where(cross_mask, new_individual, population[i])\n\n                # Clip to bounds\n                new_individual = np.clip(new_individual, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new individual\n                new_fitness = func(new_individual)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    new_population[i] = new_individual\n\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_individual\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n\n            # Adaptive Exploration Rate Adjustment\n            self.exploration_rate = 0.9 * np.exp(-generation / (self.budget / self.pop_size)) # Decay exploration rate over time\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'gamma'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm using a combination of Lévy flights and differential evolution with a dynamically adjusted exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass LevyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, levy_exponent=1.5, de_rate=0.7, mutation_factor=0.5, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.de_rate = de_rate\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.exploration_rate = 0.9  # Initial exploration rate\n\n    def levy_flight(self, size):\n        numerator = np.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2)\n        denominator = np.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2))\n        sigma = (numerator / denominator) ** (1 / self.levy_exponent)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / abs(v) ** (1 / self.levy_exponent)\n        return step\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_rate:\n                    # Lévy Flight\n                    step_size = self.levy_flight(self.dim)\n                    new_individual = population[i] + step_size * (self.x_opt - population[i])\n\n                else:\n                    # Differential Evolution\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    new_individual = a + self.mutation_factor * (b - c)\n\n                    # Crossover\n                    cross_mask = np.random.rand(self.dim) < self.crossover_rate\n                    new_individual = np.where(cross_mask, new_individual, population[i])\n\n                # Clip to bounds\n                new_individual = np.clip(new_individual, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new individual\n                new_fitness = func(new_individual)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    new_population[i] = new_individual\n\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_individual\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n\n            # Adaptive Exploration Rate Adjustment\n            self.exploration_rate = 0.9 * np.exp(-generation / (self.budget / self.pop_size)) # Decay exploration rate over time\n                \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.14067601264203627, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "a1745f16-47a1-462e-bd3c-3d6d2b291160", "fitness": 0.0, "name": "AdaptiveHybridPSODE", "description": "Combines PSO and DE with self-adaptive parameter control and a local search operator to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, cr_init=0.5, cr_end=0.9, f_init=0.5, f_end=0.9, local_search_prob=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_init (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            local_search_prob (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.local_search_prob = local_search_prob\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func, current_eval):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Adaptive inertia weight\n        w = self.w_init - (self.w_init - self.w_end) * (current_eval / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func, current_eval):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        # Adaptive crossover rate and scaling factor\n        cr = self.cr_init + (self.cr_end - self.cr_init) * (current_eval / self.budget)\n        f = self.f_init + (self.f_end - self.f_init) * (current_eval / self.budget)\n\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n\n    def local_search(self, func, x):\n        \"\"\"\n        Performs a simple local search around the given solution.\n        \"\"\"\n        sigma = 0.05 * (func.bounds.ub - func.bounds.lb)  # Standard deviation for Gaussian perturbation\n        x_new = x + np.random.normal(0, sigma, self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.func_evals += 1\n        return x_new, f_new\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        current_eval = self.pop_size\n        \n        while current_eval < self.budget:\n            if np.random.rand() < 0.5:  # Alternate between PSO and DE\n                self.pso_update(func, current_eval)\n            else:\n                self.de_update(func, current_eval)\n            current_eval += self.pop_size if np.random.rand() < 0.5 else self.pop_size #pso updates add pop_size evaluations, de updates add individual evaluations, but are done for the whole population\n\n            # Local search application\n            if np.random.rand() < self.local_search_prob:\n                index = np.random.randint(self.pop_size)\n                x_new, f_new = self.local_search(func, self.population[index])\n                if f_new < self.fitness[index]:\n                    self.population[index] = x_new\n                    self.fitness[index] = f_new\n                    if f_new < self.personal_best_fitness[index]:\n                        self.personal_best_fitness[index] = f_new\n                        self.personal_best_positions[index] = x_new.copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_position = x_new.copy()\n                current_eval += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSODE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cda6251f-8384-4386-8f74-6720253e1ccf"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines PSO and DE with self-adaptive parameter control and a local search operator to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, cr_init=0.5, cr_end=0.9, f_init=0.5, f_end=0.9, local_search_prob=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_init (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            local_search_prob (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.local_search_prob = local_search_prob\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func, current_eval):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Adaptive inertia weight\n        w = self.w_init - (self.w_init - self.w_end) * (current_eval / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func, current_eval):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        # Adaptive crossover rate and scaling factor\n        cr = self.cr_init + (self.cr_end - self.cr_init) * (current_eval / self.budget)\n        f = self.f_init + (self.f_end - self.f_init) * (current_eval / self.budget)\n\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n\n    def local_search(self, func, x):\n        \"\"\"\n        Performs a simple local search around the given solution.\n        \"\"\"\n        sigma = 0.05 * (func.bounds.ub - func.bounds.lb)  # Standard deviation for Gaussian perturbation\n        x_new = x + np.random.normal(0, sigma, self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.func_evals += 1\n        return x_new, f_new\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        current_eval = self.pop_size\n        \n        while current_eval < self.budget:\n            if np.random.rand() < 0.5:  # Alternate between PSO and DE\n                self.pso_update(func, current_eval)\n            else:\n                self.de_update(func, current_eval)\n            current_eval += self.pop_size if np.random.rand() < 0.5 else self.pop_size #pso updates add pop_size evaluations, de updates add individual evaluations, but are done for the whole population\n\n            # Local search application\n            if np.random.rand() < self.local_search_prob:\n                index = np.random.randint(self.pop_size)\n                x_new, f_new = self.local_search(func, self.population[index])\n                if f_new < self.fitness[index]:\n                    self.population[index] = x_new\n                    self.fitness[index] = f_new\n                    if f_new < self.personal_best_fitness[index]:\n                        self.personal_best_fitness[index] = f_new\n                        self.personal_best_positions[index] = x_new.copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_position = x_new.copy()\n                current_eval += 1\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.052364670217694746, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "ae66da83-ff9a-4af3-9261-55eddfb81c1f", "fitness": 0.5417485963065567, "name": "AdaptiveHybridPSO_DE", "description": "Hybrid PSO-DE with adaptive strategy selection and velocity clamping, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_de_ratio=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_de_ratio (float): Probability of selecting PSO vs DE update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_de_ratio = pso_de_ratio\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.iteration = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Adaptive inertia weight\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            if np.random.rand() < self.pso_de_ratio:  # Adaptive selection of PSO and DE\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.iteration += 1\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.542 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cda6251f-8384-4386-8f74-6720253e1ccf", "56c1d16a-f2f1-47f7-928b-1e497a9533db"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid PSO-DE with adaptive strategy selection and velocity clamping, enhancing exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_de_ratio=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_de_ratio (float): Probability of selecting PSO vs DE update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_de_ratio = pso_de_ratio\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.iteration = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Adaptive inertia weight\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            if np.random.rand() < self.pso_de_ratio:  # Adaptive selection of PSO and DE\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.iteration += 1\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.20447297458405256, 0.509897903998858, 0.49875163391108723, 0.769555969251346, 0.538048091777748, 0.6161832945943183, 0.4753853813278991, 0.5084411418205184, 0.5489595126911269, 0.22166373310495824, 0.7047153695548816, 0.9959985061408297, 0.3357393721958868, 0.49307330786316605, 0.8130984203568528, 0.6365508290056736, 0.45448812984284304, 0.7177057425705906, 0.2763628744642439, 0.5158797370742529], "operator": "crossover", "theta_sampled": 0.23396759719966298, "reward": 0.0029396571913017366, "generation": 1}, "task_prompt": ""}
{"id": "fb448003-a83b-4b79-ade4-c7c1c00aabb2", "fitness": 0.3506681006201271, "name": "AdaptiveHybridPSO_DE", "description": "Adaptively combines PSO and DE, biasing towards the algorithm that yields better improvements, and incorporates a mutation operator based on gbest.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.mutation_rate = mutation_rate # Add mutation rate\n        self.pso_success_rate = 0.5  # Initial belief in PSO\n        self.de_success_rate = 0.5   # Initial belief in DE\n        self.success_memory = []\n        self.memory_size = 10\n\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        while self.budget > 0:\n            pso_successes = 0\n            de_successes = 0\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                new_pos_pso = pop[i] + v\n                new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                fitness_pso = func(new_pos_pso)\n                self.budget -= 1\n\n\n                # Differential Evolution update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                diff_vector = x1 + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_pos_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_pos_de[j] = diff_vector[j]\n                new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                fitness_de = func(new_pos_de)\n                self.budget -= 1\n                \n                # Adaptive Selection\n                if fitness_pso < fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = fitness_pso\n                    pso_successes += 1\n\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = fitness_de\n                    de_successes += 1\n\n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)  # Gaussian mutation\n                    new_pos = np.clip(new_pos + mutation, func.bounds.lb, func.bounds.ub)\n                    new_fitness = func(new_pos)\n                    self.budget -= 1\n\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                if self.budget <= 0:\n                  break\n\n            # Update success rates\n            total_successes = pso_successes + de_successes\n            if total_successes > 0:\n                pso_rate = pso_successes / total_successes\n                de_rate = de_successes / total_successes\n            else:\n                pso_rate = 0.5\n                de_rate = 0.5\n\n            self.success_memory.append((pso_rate, de_rate))\n            if len(self.success_memory) > self.memory_size:\n              self.success_memory.pop(0)\n                \n            # Adjust PSO/DE based on memory\n\n            avg_pso = np.mean([pso for pso, de in self.success_memory]) if self.success_memory else 0.5\n            avg_de = np.mean([de for pso, de in self.success_memory]) if self.success_memory else 0.5\n\n            self.w = 0.7 + 0.2 * avg_pso #Adapt w to favor more succesful strat\n            self.f = 0.8 + 0.2* avg_de #Adapt f to favor more succesful strat\n              \n\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.351 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["56c1d16a-f2f1-47f7-928b-1e497a9533db"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE, biasing towards the algorithm that yields better improvements, and incorporates a mutation operator based on gbest.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.mutation_rate = mutation_rate # Add mutation rate\n        self.pso_success_rate = 0.5  # Initial belief in PSO\n        self.de_success_rate = 0.5   # Initial belief in DE\n        self.success_memory = []\n        self.memory_size = 10\n\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        while self.budget > 0:\n            pso_successes = 0\n            de_successes = 0\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                new_pos_pso = pop[i] + v\n                new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                fitness_pso = func(new_pos_pso)\n                self.budget -= 1\n\n\n                # Differential Evolution update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                diff_vector = x1 + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_pos_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_pos_de[j] = diff_vector[j]\n                new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                fitness_de = func(new_pos_de)\n                self.budget -= 1\n                \n                # Adaptive Selection\n                if fitness_pso < fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = fitness_pso\n                    pso_successes += 1\n\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = fitness_de\n                    de_successes += 1\n\n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)  # Gaussian mutation\n                    new_pos = np.clip(new_pos + mutation, func.bounds.lb, func.bounds.ub)\n                    new_fitness = func(new_pos)\n                    self.budget -= 1\n\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                if self.budget <= 0:\n                  break\n\n            # Update success rates\n            total_successes = pso_successes + de_successes\n            if total_successes > 0:\n                pso_rate = pso_successes / total_successes\n                de_rate = de_successes / total_successes\n            else:\n                pso_rate = 0.5\n                de_rate = 0.5\n\n            self.success_memory.append((pso_rate, de_rate))\n            if len(self.success_memory) > self.memory_size:\n              self.success_memory.pop(0)\n                \n            # Adjust PSO/DE based on memory\n\n            avg_pso = np.mean([pso for pso, de in self.success_memory]) if self.success_memory else 0.5\n            avg_de = np.mean([de for pso, de in self.success_memory]) if self.success_memory else 0.5\n\n            self.w = 0.7 + 0.2 * avg_pso #Adapt w to favor more succesful strat\n            self.f = 0.8 + 0.2* avg_de #Adapt f to favor more succesful strat\n              \n\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.21074912963792736, 0.3398818186059793, 0.8520414542366016, 0], "operator": "mutation", "theta_sampled": 0.2233203100950942, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "80e52b05-8bb9-4558-b094-6de755982aa6", "fitness": 0.5728909095090376, "name": "PerturbedDifferentialEvolution", "description": "Population-based algorithm that combines a simplified differential evolution (DE) variant with a local search based on perturbing the best solution found so far.", "code": "import numpy as np\n\nclass PerturbedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3) #Simplified version (current to best)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm PerturbedDifferentialEvolution scored 0.573 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines a simplified differential evolution (DE) variant with a local search based on perturbing the best solution found so far.\n# Code: \n```python\nimport numpy as np\n\nclass PerturbedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3) #Simplified version (current to best)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20577398521824275, 0.4546136948109468, 0.5987367602662899, 0.8575284410744374, 0.49266740543405585, 0.7430428290837039, 0.38728986013634725, 0.508954102395961, 0.6429984216536253, 0.20725493248929938, 0.818660897136195, 0.997921259658683, 0.40404337059616824, 0.49177624527084596, 0.8998803708275636, 0.6743547893159345, 0.43844671742846364, 0.8346979627674939, 0.29273078533665375, 0.5064453592798399], "operator": "random_new", "theta_sampled": -0.04625337765634817, "reward": 0.03408197039378269, "generation": 1}, "task_prompt": ""}
{"id": "1aa1b998-c2f7-4304-9a58-dbe9fee2b412", "fitness": 0.6048933640616465, "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with velocity clipping and local search, dynamically adjusting PSO/DE balance based on success rates and incorporating a local search to fine-tune solutions.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.605 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["56c1d16a-f2f1-47f7-928b-1e497a9533db"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with velocity clipping and local search, dynamically adjusting PSO/DE balance based on success rates and incorporating a local search to fine-tune solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.2379599636063272, 0.3163830580653667, 0.6670624128972547, 0.8679694980289749, 0.6990680537887484, 0.714569526578372, 0.5764133226825656, 0.5795925501201274, 0.7141132490330454, 0.1924512052557643, 0.8755516799421013, 0.996101911591316, 0.2968799338827657, 0.6718695114194233, 0.8655895260901731, 0.7132035155474038, 0.5465608944131628, 0.8422396353379333, 0.22375114717102695, 0.5005366857810782], "operator": "mutation", "theta_sampled": 0.19212458201990998, "reward": 0.06608442494639155, "generation": 1}, "task_prompt": ""}
{"id": "1d06737e-22d8-447a-bb9e-665dc2d94376", "fitness": 0.396983082673143, "name": "AdaptiveHybridPSO_DE", "description": "Integrates PSO and DE with a self-adaptive strategy to balance exploration and exploitation, coupled with a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, cr_init=0.5, cr_end=0.9, f=0.8, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f = f\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n        self.generation = 0\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        while self.budget > 0:\n            self.generation += 1\n\n            # Adaptive parameters\n            w = self.w_init - (self.w_init - self.w_end) * (self.generation / (self.budget/self.pop_size + self.generation))  # Linearly decreasing inertia weight\n            cr = self.cr_init + (self.cr_end - self.cr_init) * (self.generation / (self.budget/self.pop_size + self.generation)) # Linearly increasing crossover rate\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                new_pos_pso = pop[i] + v\n\n                # Differential Evolution update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                diff_vector = x1 + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_pos_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_pos_de[j] = diff_vector[j]\n\n                # Adaptive selection between PSO and DE\n                if np.random.rand() < 0.5:\n                    new_pos = new_pos_pso\n                else:\n                    new_pos = new_pos_de\n\n                # Clip to bounds\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_pos)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n                        self.last_improvement = self.generation\n                \n                pop[i] = new_pos\n                \n                if self.budget <= 0:\n                    break\n            \n            # Stagnation check and restart mechanism\n            if self.generation - self.last_improvement > self.stagnation_threshold:\n                self.stagnation_counter += 1\n                # Restart a portion of the population (e.g., 50%)\n                num_restart = int(self.pop_size * 0.5)\n                restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n                pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n                fitness[restart_indices] = np.array([func(x) for x in pop[restart_indices]])\n                self.budget -= num_restart\n                \n                # Update pbest and gbest\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(fitness)\n                gbest_pos = pop[gbest_index].copy()\n                gbest_fitness = fitness[gbest_index]\n\n                self.last_improvement = self.generation  # Reset last improvement\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.397 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["56c1d16a-f2f1-47f7-928b-1e497a9533db"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates PSO and DE with a self-adaptive strategy to balance exploration and exploitation, coupled with a restart mechanism when stagnation is detected.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, cr_init=0.5, cr_end=0.9, f=0.8, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f = f\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n        self.generation = 0\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        while self.budget > 0:\n            self.generation += 1\n\n            # Adaptive parameters\n            w = self.w_init - (self.w_init - self.w_end) * (self.generation / (self.budget/self.pop_size + self.generation))  # Linearly decreasing inertia weight\n            cr = self.cr_init + (self.cr_end - self.cr_init) * (self.generation / (self.budget/self.pop_size + self.generation)) # Linearly increasing crossover rate\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                new_pos_pso = pop[i] + v\n\n                # Differential Evolution update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                diff_vector = x1 + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_pos_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_pos_de[j] = diff_vector[j]\n\n                # Adaptive selection between PSO and DE\n                if np.random.rand() < 0.5:\n                    new_pos = new_pos_pso\n                else:\n                    new_pos = new_pos_de\n\n                # Clip to bounds\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_pos)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n                        self.last_improvement = self.generation\n                \n                pop[i] = new_pos\n                \n                if self.budget <= 0:\n                    break\n            \n            # Stagnation check and restart mechanism\n            if self.generation - self.last_improvement > self.stagnation_threshold:\n                self.stagnation_counter += 1\n                # Restart a portion of the population (e.g., 50%)\n                num_restart = int(self.pop_size * 0.5)\n                restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n                pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n                fitness[restart_indices] = np.array([func(x) for x in pop[restart_indices]])\n                self.budget -= num_restart\n                \n                # Update pbest and gbest\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(fitness)\n                gbest_pos = pop[gbest_index].copy()\n                gbest_fitness = fitness[gbest_index]\n\n                self.last_improvement = self.generation  # Reset last improvement\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.23060907275598008, 0.16806707894878814, 0.39494632073478786, 0.626221125183167, 0.32222704030589344, 0.45561018884992177, 0.29018083193439015, 0.35756567172506404, 0.36676633463685515, 0.26768648927938044, 0.6379381609952044, 0.9988902919021813, 0.3136385046476923, 0.30673034867148297, 0.6901548563598037, 0.3990945132203795, 0.3193686579656021, 0], "operator": "mutation", "theta_sampled": 0.03731109548425866, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "a119ce4a-1490-4d85-9545-2d89fdf5a5fc", "fitness": 0.0, "name": "VoronoiExploration", "description": "Adaptively samples points based on a Voronoi decomposition of the search space, prioritizing unexplored regions and exploiting promising areas.", "code": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\n\nclass VoronoiExploration:\n    def __init__(self, budget=10000, dim=10, exploration_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_factor = exploration_factor #Weighting for distance from known points when sampling\n\n        self.points = []\n        self.fitnesses = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        #Initial sample\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        f = func(x)\n        self.points.append(x)\n        self.fitnesses.append(f)\n        self.f_opt = f\n        self.x_opt = x\n        eval_count = 1\n\n\n        while eval_count < self.budget:\n            if len(self.points) < self.dim + 1:  # Initial exploration\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n            else:\n                # Voronoi-based sampling\n                vor = Voronoi(np.array(self.points))\n\n                # Calculate distances to nearest existing points for each region\n                distances = []\n                for i in range(len(vor.regions)):\n                    region = vor.regions[i]\n                    if not region or -1 in region:\n                        distances.append(0.0) #Handle unbounded regions\n                        continue\n                    vertices = vor.vertices[region]\n                    distances.append(np.mean(np.linalg.norm(vertices - self.points[i], axis=1)))\n\n\n                # Normalize distances to be between 0 and 1\n                normalized_distances = np.array(distances) / np.max(distances)\n\n                # Calculate fitness-based probabilities. Worse fitness => higher probability\n                fitnesses_array = np.array(self.fitnesses)\n                normalized_fitnesses = (np.max(fitnesses_array) - fitnesses_array) / (np.max(fitnesses_array) - np.min(fitnesses_array) + 1e-8) #Avoid div by zero\n\n                # Combined probability: Favor regions far from existing points, but also better fitness values\n                probabilities = self.exploration_factor * normalized_distances + (1 - self.exploration_factor) * normalized_fitnesses\n                probabilities /= np.sum(probabilities) # Normalize probabilities\n\n                # Select a region to sample from\n                selected_region_index = np.random.choice(len(self.points), p=probabilities)\n                selected_region = vor.regions[selected_region_index]\n\n                if not selected_region or -1 in selected_region:\n                    x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                else:\n                    # Sample within the selected Voronoi region\n                    vertices = vor.vertices[selected_region]\n                    \n                    # Simple sampling: take the mean of the vertices\n                    x = np.mean(vertices, axis=0)\n\n                    #Ensure it is within bounds\n                    x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n\n\n\n            f = func(x)\n            eval_count += 1\n\n            self.points.append(x)\n            self.fitnesses.append(f)\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: name 'Voronoi' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptively samples points based on a Voronoi decomposition of the search space, prioritizing unexplored regions and exploiting promising areas.\n# Code: \n```python\nimport numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\n\nclass VoronoiExploration:\n    def __init__(self, budget=10000, dim=10, exploration_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_factor = exploration_factor #Weighting for distance from known points when sampling\n\n        self.points = []\n        self.fitnesses = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        #Initial sample\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        f = func(x)\n        self.points.append(x)\n        self.fitnesses.append(f)\n        self.f_opt = f\n        self.x_opt = x\n        eval_count = 1\n\n\n        while eval_count < self.budget:\n            if len(self.points) < self.dim + 1:  # Initial exploration\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n            else:\n                # Voronoi-based sampling\n                vor = Voronoi(np.array(self.points))\n\n                # Calculate distances to nearest existing points for each region\n                distances = []\n                for i in range(len(vor.regions)):\n                    region = vor.regions[i]\n                    if not region or -1 in region:\n                        distances.append(0.0) #Handle unbounded regions\n                        continue\n                    vertices = vor.vertices[region]\n                    distances.append(np.mean(np.linalg.norm(vertices - self.points[i], axis=1)))\n\n\n                # Normalize distances to be between 0 and 1\n                normalized_distances = np.array(distances) / np.max(distances)\n\n                # Calculate fitness-based probabilities. Worse fitness => higher probability\n                fitnesses_array = np.array(self.fitnesses)\n                normalized_fitnesses = (np.max(fitnesses_array) - fitnesses_array) / (np.max(fitnesses_array) - np.min(fitnesses_array) + 1e-8) #Avoid div by zero\n\n                # Combined probability: Favor regions far from existing points, but also better fitness values\n                probabilities = self.exploration_factor * normalized_distances + (1 - self.exploration_factor) * normalized_fitnesses\n                probabilities /= np.sum(probabilities) # Normalize probabilities\n\n                # Select a region to sample from\n                selected_region_index = np.random.choice(len(self.points), p=probabilities)\n                selected_region = vor.regions[selected_region_index]\n\n                if not selected_region or -1 in selected_region:\n                    x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                else:\n                    # Sample within the selected Voronoi region\n                    vertices = vor.vertices[selected_region]\n                    \n                    # Simple sampling: take the mean of the vertices\n                    x = np.mean(vertices, axis=0)\n\n                    #Ensure it is within bounds\n                    x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n\n\n\n            f = func(x)\n            eval_count += 1\n\n            self.points.append(x)\n            self.fitnesses.append(f)\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.03460254483404816, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "d342d41d-6a62-43d4-8299-96fdfe1bc50b", "fitness": 0.0, "name": "AdaptiveCMA_NM", "description": "An adaptive algorithm that combines elements of CMA-ES and Nelder-Mead, switching between global exploration and local exploitation based on function evaluation performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveCMA_NM:\n    def __init__(self, budget=10000, dim=10, exploration_prob=0.5, cmaes_sigma=0.5, nm_adaptive=True):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_prob = exploration_prob  # Probability of CMA-ES exploration\n        self.cmaes_sigma = cmaes_sigma\n        self.nm_adaptive = nm_adaptive  # Adapt Nelder-Mead parameters based on performance\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.nm_scale_factor = 1.0\n\n    def cma_es_step(self, func, x0, sigma):\n        \"\"\"Performs a step of CMA-ES.\"\"\"\n        x = x0 + sigma * np.random.randn(self.dim)\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        f = func(x)\n        self.eval_count += 1\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x.copy()\n        return x, f\n\n    def nelder_mead_step(self, func, x0):\n        \"\"\"Performs a step of Nelder-Mead.\"\"\"\n        \n        def func_wrapper(x):\n            val = func(x)\n            self.eval_count += 1\n            return val\n\n        res = minimize(func_wrapper, x0, method='Nelder-Mead',\n                       bounds=np.stack((func.bounds.lb, func.bounds.ub), axis=-1),\n                       options={'maxfev': max(1, int(self.budget/100*self.nm_scale_factor)), 'adaptive': self.nm_adaptive}) # Limit function evaluations for Nelder-Mead\n\n        if res.fun < self.f_opt:\n            self.f_opt = res.fun\n            self.x_opt = res.x.copy()\n            \n        return res.x, res.fun\n        \n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.eval_count = 0\n        \n        # Initial evaluation\n        f = func(self.x_opt)\n        self.eval_count += 1\n        if f < self.f_opt:\n                self.f_opt = f\n                \n        while self.eval_count < self.budget:\n            if np.random.rand() < self.exploration_prob and self.eval_count < self.budget:\n                # Exploration: CMA-ES step\n                self.x_opt, f = self.cma_es_step(func, self.x_opt, self.cmaes_sigma)\n            elif self.eval_count < self.budget:\n                # Exploitation: Nelder-Mead step\n                \n                prev_f_opt = self.f_opt\n                self.x_opt, f = self.nelder_mead_step(func, self.x_opt)\n                \n                #Adapt Nelder-Mead's max function evaluations, reduce when improvement stagnation is detected.\n                if self.f_opt >= prev_f_opt:\n                  self.nm_scale_factor = max(0.1, self.nm_scale_factor * 0.9)\n                else:\n                  self.nm_scale_factor = min(1.0, self.nm_scale_factor * 1.1)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive algorithm that combines elements of CMA-ES and Nelder-Mead, switching between global exploration and local exploitation based on function evaluation performance.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveCMA_NM:\n    def __init__(self, budget=10000, dim=10, exploration_prob=0.5, cmaes_sigma=0.5, nm_adaptive=True):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_prob = exploration_prob  # Probability of CMA-ES exploration\n        self.cmaes_sigma = cmaes_sigma\n        self.nm_adaptive = nm_adaptive  # Adapt Nelder-Mead parameters based on performance\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.nm_scale_factor = 1.0\n\n    def cma_es_step(self, func, x0, sigma):\n        \"\"\"Performs a step of CMA-ES.\"\"\"\n        x = x0 + sigma * np.random.randn(self.dim)\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        f = func(x)\n        self.eval_count += 1\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x.copy()\n        return x, f\n\n    def nelder_mead_step(self, func, x0):\n        \"\"\"Performs a step of Nelder-Mead.\"\"\"\n        \n        def func_wrapper(x):\n            val = func(x)\n            self.eval_count += 1\n            return val\n\n        res = minimize(func_wrapper, x0, method='Nelder-Mead',\n                       bounds=np.stack((func.bounds.lb, func.bounds.ub), axis=-1),\n                       options={'maxfev': max(1, int(self.budget/100*self.nm_scale_factor)), 'adaptive': self.nm_adaptive}) # Limit function evaluations for Nelder-Mead\n\n        if res.fun < self.f_opt:\n            self.f_opt = res.fun\n            self.x_opt = res.x.copy()\n            \n        return res.x, res.fun\n        \n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.eval_count = 0\n        \n        # Initial evaluation\n        f = func(self.x_opt)\n        self.eval_count += 1\n        if f < self.f_opt:\n                self.f_opt = f\n                \n        while self.eval_count < self.budget:\n            if np.random.rand() < self.exploration_prob and self.eval_count < self.budget:\n                # Exploration: CMA-ES step\n                self.x_opt, f = self.cma_es_step(func, self.x_opt, self.cmaes_sigma)\n            elif self.eval_count < self.budget:\n                # Exploitation: Nelder-Mead step\n                \n                prev_f_opt = self.f_opt\n                self.x_opt, f = self.nelder_mead_step(func, self.x_opt)\n                \n                #Adapt Nelder-Mead's max function evaluations, reduce when improvement stagnation is detected.\n                if self.f_opt >= prev_f_opt:\n                  self.nm_scale_factor = max(0.1, self.nm_scale_factor * 0.9)\n                else:\n                  self.nm_scale_factor = min(1.0, self.nm_scale_factor * 1.1)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.024271049448309163, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "430f7ab1-3766-4389-9892-e6c71e43535b", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMAES", "description": "Combines PSO and DE with adaptive parameter control based on success rates and introduces a simplified covariance matrix adaptation evolution strategy (CMA-ES) inspired component for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, cmaes_ratio=0.1, cmaes_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.success_cmaes = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.total_cmaes = 0\n        self.local_search_probability = local_search_probability\n        self.cmaes_ratio = cmaes_ratio  # Ratio of CMA-ES updates\n        self.cmaes_step_size = cmaes_step_size # Step size for CMA-ES like updates\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            if self.budget <= 0:\n                return best_f, best_x\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        \n        # Initialize covariance matrix adaptation variables (simplified)\n        mean = np.mean(pop, axis=0)\n        covariance = np.eye(self.dim) * self.cmaes_step_size**2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio and np.random.rand() > self.cmaes_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # CMA-ES like update\n                new_pos_cmaes = pop[i].copy()\n                new_fitness_cmaes = np.inf\n                if np.random.rand() < self.cmaes_ratio:\n                    self.total_cmaes += 1\n                    # Generate a sample from a multivariate Gaussian distribution\n                    z = np.random.normal(0, 1, self.dim)\n                    new_pos_cmaes = mean + self.cmaes_step_size * np.dot(covariance,z)  #Simplified update\n\n                    # Clip to bounds\n                    new_pos_cmaes = np.clip(new_pos_cmaes, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_cmaes = func(new_pos_cmaes)\n                    self.budget -= 1\n\n                    if new_fitness_cmaes < pbest_fitness[i]:\n                        self.success_cmaes += 1\n\n                # Select the better update (PSO, DE or CMA-ES)\n                best_method = np.argmin([new_fitness_pso, new_fitness_de, new_fitness_cmaes])\n                if best_method == 0:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                elif best_method == 1:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                else:\n                    new_pos = new_pos_cmaes\n                    new_fitness = new_fitness_cmaes\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Adapt cmaes_ratio\n            total_updates = self.total_pso + self.total_de + self.total_cmaes\n            if total_updates > 0:\n              success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n              success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n              success_rate_cmaes = self.success_cmaes / self.total_cmaes if self.total_cmaes > 0 else 0\n\n              total_success = success_rate_pso + success_rate_de + success_rate_cmaes\n\n              if total_success > 0:\n                pso_proportion = success_rate_pso / total_success\n                de_proportion = success_rate_de / total_success\n                cmaes_proportion = success_rate_cmaes / total_success\n\n                self.pso_ratio = pso_proportion / (pso_proportion + de_proportion) if (pso_proportion + de_proportion) > 0 else 0.5  #avoid division by zero\n\n                self.cmaes_ratio = cmaes_proportion\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.success_cmaes = 0\n            self.total_pso = 0\n            self.total_de = 0\n            self.total_cmaes = 0\n            \n            if self.budget <= 0:\n              break\n            \n            mean = np.mean(pop, axis=0) #Update mean for CMA-ES like component\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines PSO and DE with adaptive parameter control based on success rates and introduces a simplified covariance matrix adaptation evolution strategy (CMA-ES) inspired component for enhanced exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, cmaes_ratio=0.1, cmaes_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.success_cmaes = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.total_cmaes = 0\n        self.local_search_probability = local_search_probability\n        self.cmaes_ratio = cmaes_ratio  # Ratio of CMA-ES updates\n        self.cmaes_step_size = cmaes_step_size # Step size for CMA-ES like updates\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            if self.budget <= 0:\n                return best_f, best_x\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        \n        # Initialize covariance matrix adaptation variables (simplified)\n        mean = np.mean(pop, axis=0)\n        covariance = np.eye(self.dim) * self.cmaes_step_size**2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio and np.random.rand() > self.cmaes_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # CMA-ES like update\n                new_pos_cmaes = pop[i].copy()\n                new_fitness_cmaes = np.inf\n                if np.random.rand() < self.cmaes_ratio:\n                    self.total_cmaes += 1\n                    # Generate a sample from a multivariate Gaussian distribution\n                    z = np.random.normal(0, 1, self.dim)\n                    new_pos_cmaes = mean + self.cmaes_step_size * np.dot(covariance,z)  #Simplified update\n\n                    # Clip to bounds\n                    new_pos_cmaes = np.clip(new_pos_cmaes, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_cmaes = func(new_pos_cmaes)\n                    self.budget -= 1\n\n                    if new_fitness_cmaes < pbest_fitness[i]:\n                        self.success_cmaes += 1\n\n                # Select the better update (PSO, DE or CMA-ES)\n                best_method = np.argmin([new_fitness_pso, new_fitness_de, new_fitness_cmaes])\n                if best_method == 0:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                elif best_method == 1:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                else:\n                    new_pos = new_pos_cmaes\n                    new_fitness = new_fitness_cmaes\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Adapt cmaes_ratio\n            total_updates = self.total_pso + self.total_de + self.total_cmaes\n            if total_updates > 0:\n              success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n              success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n              success_rate_cmaes = self.success_cmaes / self.total_cmaes if self.total_cmaes > 0 else 0\n\n              total_success = success_rate_pso + success_rate_de + success_rate_cmaes\n\n              if total_success > 0:\n                pso_proportion = success_rate_pso / total_success\n                de_proportion = success_rate_de / total_success\n                cmaes_proportion = success_rate_cmaes / total_success\n\n                self.pso_ratio = pso_proportion / (pso_proportion + de_proportion) if (pso_proportion + de_proportion) > 0 else 0.5  #avoid division by zero\n\n                self.cmaes_ratio = cmaes_proportion\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.success_cmaes = 0\n            self.total_pso = 0\n            self.total_de = 0\n            self.total_cmaes = 0\n            \n            if self.budget <= 0:\n              break\n            \n            mean = np.mean(pop, axis=0) #Update mean for CMA-ES like component\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.0156704802458355, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "bd21ce39-3bcf-4a0b-9b4a-76552e5cfe61", "fitness": 0.10149272541060045, "name": "AdaptiveHybridPSO_DE_CMAES", "description": "An adaptive hybrid algorithm that combines PSO, DE, and a CMA-ES-inspired mutation strategy, dynamically adjusting exploration/exploitation balance based on success rates and population diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_learning_rate = cma_learning_rate\n        self.mean = np.zeros(dim)\n        self.sigma = 0.5 # Initial step size\n        self.C = np.eye(dim) # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for C\n        self.ps = np.zeros(dim) # Evolution path for sigma\n        self.damps = 1 + (dim / 2)  # Damping factor for sigma\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2)) # Expectation of ||N(0,I)||\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n    \n    def cma_mutation(self, x):\n        z = np.random.normal(0, 1, self.dim)\n        return self.mean + self.sigma * np.dot(self.C**0.5, z)\n\n    def update_cma_parameters(self, x_k, fitness):\n        c_sigma = 0.3 # learning rate for sigma\n        c_c = 0.1 #learning rate for covariance matrix\n\n        self.mean = x_k #simple mean adaptation\n\n        z = (x_k - self.mean) / self.sigma\n        self.ps = (1 - c_sigma) * self.ps + (c_sigma * (2 - c_sigma))**0.5 * z\n        self.pc = (1 - c_c) * self.pc + (c_c * (2 - c_c))**0.5 * z\n        \n        norm_ps = np.linalg.norm(self.ps)\n        self.sigma *= np.exp((c_sigma / self.damps) * (norm_ps / self.chiN - 1))\n        \n        self.C = (1 - c_c) * self.C + c_c * np.outer(self.pc, self.pc)\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        self.mean = gbest_pos #initialize cmaes mean with gbest\n\n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # CMA-ES Mutation\n                new_pos_cmaes = self.cma_mutation(pop[i])\n                new_pos_cmaes = np.clip(new_pos_cmaes, func.bounds.lb, func.bounds.ub)\n                new_fitness_cmaes = func(new_pos_cmaes)\n                self.budget -= 1\n\n                # Select the best update (PSO, DE, or CMA-ES)\n                best_pos = pop[i].copy()\n                best_fitness = fitness[i]\n\n                if new_fitness_pso < best_fitness:\n                    best_pos = new_pos_pso\n                    best_fitness = new_fitness_pso\n                if new_fitness_de < best_fitness:\n                    best_pos = new_pos_de\n                    best_fitness = new_fitness_de\n                if new_fitness_cmaes < best_fitness:\n                    best_pos = new_pos_cmaes\n                    best_fitness = new_fitness_cmaes\n\n\n                if best_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = best_fitness\n                    pbest_pop[i] = best_pos.copy()\n                    \n                    if best_fitness < gbest_fitness:\n                        gbest_fitness = best_fitness\n                        gbest_pos = best_pos.copy()\n                        self.update_cma_parameters(gbest_pos, gbest_fitness)\n\n                pop[i] = best_pos\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                            self.update_cma_parameters(gbest_pos, gbest_fitness)\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMAES scored 0.101 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm that combines PSO, DE, and a CMA-ES-inspired mutation strategy, dynamically adjusting exploration/exploitation balance based on success rates and population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_learning_rate = cma_learning_rate\n        self.mean = np.zeros(dim)\n        self.sigma = 0.5 # Initial step size\n        self.C = np.eye(dim) # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for C\n        self.ps = np.zeros(dim) # Evolution path for sigma\n        self.damps = 1 + (dim / 2)  # Damping factor for sigma\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2)) # Expectation of ||N(0,I)||\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n    \n    def cma_mutation(self, x):\n        z = np.random.normal(0, 1, self.dim)\n        return self.mean + self.sigma * np.dot(self.C**0.5, z)\n\n    def update_cma_parameters(self, x_k, fitness):\n        c_sigma = 0.3 # learning rate for sigma\n        c_c = 0.1 #learning rate for covariance matrix\n\n        self.mean = x_k #simple mean adaptation\n\n        z = (x_k - self.mean) / self.sigma\n        self.ps = (1 - c_sigma) * self.ps + (c_sigma * (2 - c_sigma))**0.5 * z\n        self.pc = (1 - c_c) * self.pc + (c_c * (2 - c_c))**0.5 * z\n        \n        norm_ps = np.linalg.norm(self.ps)\n        self.sigma *= np.exp((c_sigma / self.damps) * (norm_ps / self.chiN - 1))\n        \n        self.C = (1 - c_c) * self.C + c_c * np.outer(self.pc, self.pc)\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        self.mean = gbest_pos #initialize cmaes mean with gbest\n\n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # CMA-ES Mutation\n                new_pos_cmaes = self.cma_mutation(pop[i])\n                new_pos_cmaes = np.clip(new_pos_cmaes, func.bounds.lb, func.bounds.ub)\n                new_fitness_cmaes = func(new_pos_cmaes)\n                self.budget -= 1\n\n                # Select the best update (PSO, DE, or CMA-ES)\n                best_pos = pop[i].copy()\n                best_fitness = fitness[i]\n\n                if new_fitness_pso < best_fitness:\n                    best_pos = new_pos_pso\n                    best_fitness = new_fitness_pso\n                if new_fitness_de < best_fitness:\n                    best_pos = new_pos_de\n                    best_fitness = new_fitness_de\n                if new_fitness_cmaes < best_fitness:\n                    best_pos = new_pos_cmaes\n                    best_fitness = new_fitness_cmaes\n\n\n                if best_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = best_fitness\n                    pbest_pop[i] = best_pos.copy()\n                    \n                    if best_fitness < gbest_fitness:\n                        gbest_fitness = best_fitness\n                        gbest_pos = best_pos.copy()\n                        self.update_cma_parameters(gbest_pos, gbest_fitness)\n\n                pop[i] = best_pos\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                            self.update_cma_parameters(gbest_pos, gbest_fitness)\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.2029854508212009, 0], "operator": "mutation", "theta_sampled": 0.014052768341695757, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "abaffeaf-09de-4661-a9a0-d03cf50970b5", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Adaptive hybrid algorithm that dynamically adjusts PSO and DE parameters based on their recent performance, and incorporates a local search step.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f=0.8, ls_prob=0.05):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial Crossover rate for DE.\n            cr_end (float): Final Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            ls_prob (float): Probability of performing local search on a particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f = f\n        self.ls_prob = ls_prob\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success_rate = 0.5  # Initial PSO success rate\n        self.de_success_rate = 0.5  # Initial DE success rate\n        self.pso_count = 0\n        self.de_count = 0\n        self.pso_success = 0\n        self.de_success = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func, iteration, total_iterations):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        w = self.w_init - (self.w_init - self.w_end) * (iteration / total_iterations)\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        delta_fitness = self.fitness - new_fitness\n        self.fitness = new_fitness\n        \n        improved = np.sum(delta_fitness > 0)\n        self.pso_success += improved\n        self.pso_count += self.pop_size\n        \n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func, iteration, total_iterations):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        cr = self.cr_init - (self.cr_init - self.cr_end) * (iteration / total_iterations)\n        \n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n            delta_fitness = self.fitness[i] - f_trial\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                self.de_success += 1\n            self.de_count += 1\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"\n        Performs a simple local search around a given point.\n        \"\"\"\n        x_new = x.copy()\n        for i in range(self.dim):\n            # Generate a random perturbation\n            perturbation = np.random.uniform(-radius, radius)\n            x_new[i] = x[i] + perturbation\n\n            # Clip to bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n        f_new = func(x_new)\n        self.func_evals += 1\n        return x_new, f_new\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        total_iterations = self.budget // self.pop_size  # rough estimate of iterations\n\n\n        iteration = 0\n        while self.func_evals < self.budget:\n\n            #Adaptive probability update\n            if self.pso_count > 0:\n                self.pso_success_rate = self.pso_success / self.pso_count\n            if self.de_count > 0:\n                self.de_success_rate = self.de_success / self.de_count\n            \n            pso_prob = self.pso_success_rate / (self.pso_success_rate + self.de_success_rate + 1e-9)\n            \n            if np.random.rand() < pso_prob:\n                self.pso_update(func, iteration, total_iterations)\n            else:\n                self.de_update(func, iteration, total_iterations)\n\n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.ls_prob:\n                    x_new, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = x_new\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = x_new.copy()\n                        if f_new < self.global_best_fitness:\n                            self.global_best_fitness = f_new\n                            self.global_best_position = x_new.copy()\n            iteration +=1\n            self.pso_count = 0\n            self.pso_success = 0\n            self.de_count = 0\n            self.de_success = 0\n\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cda6251f-8384-4386-8f74-6720253e1ccf"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive hybrid algorithm that dynamically adjusts PSO and DE parameters based on their recent performance, and incorporates a local search step.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f=0.8, ls_prob=0.05):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial Crossover rate for DE.\n            cr_end (float): Final Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            ls_prob (float): Probability of performing local search on a particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f = f\n        self.ls_prob = ls_prob\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success_rate = 0.5  # Initial PSO success rate\n        self.de_success_rate = 0.5  # Initial DE success rate\n        self.pso_count = 0\n        self.de_count = 0\n        self.pso_success = 0\n        self.de_success = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def pso_update(self, func, iteration, total_iterations):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        w = self.w_init - (self.w_init - self.w_end) * (iteration / total_iterations)\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        delta_fitness = self.fitness - new_fitness\n        self.fitness = new_fitness\n        \n        improved = np.sum(delta_fitness > 0)\n        self.pso_success += improved\n        self.pso_count += self.pop_size\n        \n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func, iteration, total_iterations):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        cr = self.cr_init - (self.cr_init - self.cr_end) * (iteration / total_iterations)\n        \n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n            delta_fitness = self.fitness[i] - f_trial\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                self.de_success += 1\n            self.de_count += 1\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"\n        Performs a simple local search around a given point.\n        \"\"\"\n        x_new = x.copy()\n        for i in range(self.dim):\n            # Generate a random perturbation\n            perturbation = np.random.uniform(-radius, radius)\n            x_new[i] = x[i] + perturbation\n\n            # Clip to bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n        f_new = func(x_new)\n        self.func_evals += 1\n        return x_new, f_new\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        total_iterations = self.budget // self.pop_size  # rough estimate of iterations\n\n\n        iteration = 0\n        while self.func_evals < self.budget:\n\n            #Adaptive probability update\n            if self.pso_count > 0:\n                self.pso_success_rate = self.pso_success / self.pso_count\n            if self.de_count > 0:\n                self.de_success_rate = self.de_success / self.de_count\n            \n            pso_prob = self.pso_success_rate / (self.pso_success_rate + self.de_success_rate + 1e-9)\n            \n            if np.random.rand() < pso_prob:\n                self.pso_update(func, iteration, total_iterations)\n            else:\n                self.de_update(func, iteration, total_iterations)\n\n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.ls_prob:\n                    x_new, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = x_new\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = x_new.copy()\n                        if f_new < self.global_best_fitness:\n                            self.global_best_fitness = f_new\n                            self.global_best_position = x_new.copy()\n            iteration +=1\n            self.pso_count = 0\n            self.pso_success = 0\n            self.de_count = 0\n            self.de_success = 0\n\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.025450718499606617, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "fe1bdc94-4c96-4a59-b9a7-983876c2f5d6", "fitness": 0.5315632483987217, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with self-adaptive parameters and a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptive F and Cr\n                F_i = np.random.normal(self.F, 0.1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n                Cr_i = np.random.normal(self.Cr, 0.1)\n                Cr_i = np.clip(Cr_i, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < Cr_i:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Stagnation Check and Restart\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:  #Stagnation detected\n                    self.stagnation_counter +=1\n\n                    # Restart strategy: Re-initialize a portion of the population around the best solution.\n                    restart_fraction = 0.3\n                    num_to_restart = int(self.pop_size * restart_fraction)\n                    for k in range(num_to_restart):\n                        population[k] = np.random.normal(self.x_opt, 0.1*(func.bounds.ub - func.bounds.lb), size=self.dim)\n                        population[k] = np.clip(population[k], func.bounds.lb, func.bounds.ub)\n                        fitness[k] = func(population[k])\n                        self.budget -=1\n                        if fitness[k] < self.f_opt:\n                           self.f_opt = fitness[k]\n                           self.x_opt = population[k]\n                    \n                    #Adjust F and Cr to escape stagnation\n                    self.F = np.clip(self.F * np.random.uniform(0.8, 1.2), 0.1, 1.0)\n                    self.Cr = np.clip(self.Cr * np.random.uniform(0.8, 1.2), 0.1, 1.0)\n                    print(\"Restarting population\")\n                    self.stagnation_counter = 0  #Reset stagnation counter\n            else:\n                self.stagnation_counter = 0\n            self.best_fitness_history.append(self.f_opt)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.532 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80e52b05-8bb9-4558-b094-6de755982aa6"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with self-adaptive parameters and a restart mechanism based on stagnation detection.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptive F and Cr\n                F_i = np.random.normal(self.F, 0.1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n                Cr_i = np.random.normal(self.Cr, 0.1)\n                Cr_i = np.clip(Cr_i, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < Cr_i:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Stagnation Check and Restart\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:  #Stagnation detected\n                    self.stagnation_counter +=1\n\n                    # Restart strategy: Re-initialize a portion of the population around the best solution.\n                    restart_fraction = 0.3\n                    num_to_restart = int(self.pop_size * restart_fraction)\n                    for k in range(num_to_restart):\n                        population[k] = np.random.normal(self.x_opt, 0.1*(func.bounds.ub - func.bounds.lb), size=self.dim)\n                        population[k] = np.clip(population[k], func.bounds.lb, func.bounds.ub)\n                        fitness[k] = func(population[k])\n                        self.budget -=1\n                        if fitness[k] < self.f_opt:\n                           self.f_opt = fitness[k]\n                           self.x_opt = population[k]\n                    \n                    #Adjust F and Cr to escape stagnation\n                    self.F = np.clip(self.F * np.random.uniform(0.8, 1.2), 0.1, 1.0)\n                    self.Cr = np.clip(self.Cr * np.random.uniform(0.8, 1.2), 0.1, 1.0)\n                    print(\"Restarting population\")\n                    self.stagnation_counter = 0  #Reset stagnation counter\n            else:\n                self.stagnation_counter = 0\n            self.best_fitness_history.append(self.f_opt)\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17249961218280008, 0.3336541779755313, 0.5562840891132109, 0.750017380199995, 0.5259067477539521, 0.7161371558009282, 0.33602358068584404, 0.4659254467554904, 0.5598905175874835, 0.20608429949742912, 0.794105152796617, 0.9800787379092792, 0.40030630420743507, 0.42102319677711775, 0.8700560763174567, 0.6412639754223605, 0.42667824670062715, 0.7862957898912257, 0.1910329052122377, 0.4980015751874147], "operator": "mutation", "theta_sampled": 0.0056463532951752556, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "5e7a0050-d169-4c89-9cd3-4defec887974", "fitness": 0.639169295748102, "name": "AdaptiveHybridPSO_DE", "description": "Adaptively switches between PSO and DE based on their recent success, and incorporates a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.639 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cda6251f-8384-4386-8f74-6720253e1ccf"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively switches between PSO and DE based on their recent success, and incorporates a restart mechanism to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.34124205793180273, 0.7242475634706506, 0.6802488574253909, 0.7622009486738792, 0.765916204338676, 0.7566998266257223, 0.33707556455044774, 0.5823500319362658, 0.750566431377284, 0.6593530537709547, 0.8445017350482035, 0.9945436283815969, 0.25085125036037526, 0.6737708520518553, 0.9133461838078968, 0.774115742440209, 0.2991875131561573, 0.8486653642446903, 0.28485969924114685, 0.5396434061288335], "operator": "mutation", "theta_sampled": 0.009972351555638317, "reward": 0.034275931686455485, "generation": 2}, "task_prompt": ""}
{"id": "31c63e6a-f4fb-49a5-a101-cf142e5a6f19", "fitness": 0.38726150973397144, "name": "AsynchronousMultiSwarm", "description": "An asynchronous multi-swarm approach with adaptive radius adjustment based on swarm performance and a repulsion mechanism to encourage diversity.", "code": "import numpy as np\n\nclass AsynchronousMultiSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=20, initial_radius=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.initial_radius = initial_radius\n        self.swarms = []\n        self.radii = np.full(num_swarms, initial_radius)\n        self.centers = []\n        self.fitnesses = []\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        center = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        swarm = np.random.uniform(\n            np.maximum(func.bounds.lb, center - self.initial_radius),\n            np.minimum(func.bounds.ub, center + self.initial_radius),\n            size=(self.swarm_size, self.dim)\n        )\n        fitnesses = np.array([func(x) for x in swarm])\n        self.eval_count += self.swarm_size\n        return center, swarm, fitnesses\n\n    def adjust_radius(self, swarm_index, improvement):\n        # Adaptive radius adjustment based on swarm performance\n        if improvement > 0:\n            self.radii[swarm_index] *= 1.1  # Expand if improving\n        else:\n            self.radii[swarm_index] *= 0.9  # Shrink if not improving\n        self.radii[swarm_index] = np.clip(self.radii[swarm_index], 0.001, 2.0) # Radius limits\n\n\n    def repulsion(self, swarm_index):\n        # Repulsion mechanism to encourage diversity\n        for i in range(self.num_swarms):\n            if i != swarm_index:\n                distance = np.linalg.norm(self.centers[swarm_index] - self.centers[i])\n                if distance < 0.5:\n                    # Repel the swarms from each other\n                    direction = self.centers[swarm_index] - self.centers[i]\n                    self.centers[swarm_index] += 0.1 * direction\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize swarms asynchronously\n        for i in range(self.num_swarms):\n            center, swarm, fitnesses = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            self.centers.append(center)\n            self.fitnesses.append(fitnesses)\n\n            best_index = np.argmin(fitnesses)\n            if fitnesses[best_index] < self.f_opt:\n                self.f_opt = fitnesses[best_index]\n                self.x_opt = swarm[best_index]\n\n        # Asynchronous evolution loop\n        while self.eval_count < self.budget:\n            for i in range(self.num_swarms):\n                # Select a swarm to update\n                if self.eval_count >= self.budget:\n                   break\n                \n                # Generate new particles around the current center\n                new_swarm = np.random.uniform(\n                    np.maximum(func.bounds.lb, self.centers[i] - self.radii[i]),\n                    np.minimum(func.bounds.ub, self.centers[i] + self.radii[i]),\n                    size=(self.swarm_size, self.dim)\n                )\n\n                new_fitnesses = np.array([func(x) for x in new_swarm])\n                self.eval_count += self.swarm_size\n\n                # Check for improvement in the swarm\n                best_index = np.argmin(self.fitnesses[i])\n                best_fitness = self.fitnesses[i][best_index]\n                new_best_index = np.argmin(new_fitnesses)\n                new_best_fitness = new_fitnesses[new_best_index]\n\n                improvement = best_fitness - new_best_fitness\n\n                # Update swarm and center if there's an improvement\n                if improvement > 0:\n                    self.swarms[i] = new_swarm\n                    self.fitnesses[i] = new_fitnesses\n                    self.centers[i] = new_swarm[new_best_index]\n\n\n                # Adjust radius\n                self.adjust_radius(i, improvement)\n\n                # Repulsion mechanism\n                self.repulsion(i)\n\n                # Update global best\n                best_index = np.argmin(self.fitnesses[i])\n                if self.fitnesses[i][best_index] < self.f_opt:\n                    self.f_opt = self.fitnesses[i][best_index]\n                    self.x_opt = self.swarms[i][best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AsynchronousMultiSwarm scored 0.387 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An asynchronous multi-swarm approach with adaptive radius adjustment based on swarm performance and a repulsion mechanism to encourage diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AsynchronousMultiSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=20, initial_radius=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.initial_radius = initial_radius\n        self.swarms = []\n        self.radii = np.full(num_swarms, initial_radius)\n        self.centers = []\n        self.fitnesses = []\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        center = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        swarm = np.random.uniform(\n            np.maximum(func.bounds.lb, center - self.initial_radius),\n            np.minimum(func.bounds.ub, center + self.initial_radius),\n            size=(self.swarm_size, self.dim)\n        )\n        fitnesses = np.array([func(x) for x in swarm])\n        self.eval_count += self.swarm_size\n        return center, swarm, fitnesses\n\n    def adjust_radius(self, swarm_index, improvement):\n        # Adaptive radius adjustment based on swarm performance\n        if improvement > 0:\n            self.radii[swarm_index] *= 1.1  # Expand if improving\n        else:\n            self.radii[swarm_index] *= 0.9  # Shrink if not improving\n        self.radii[swarm_index] = np.clip(self.radii[swarm_index], 0.001, 2.0) # Radius limits\n\n\n    def repulsion(self, swarm_index):\n        # Repulsion mechanism to encourage diversity\n        for i in range(self.num_swarms):\n            if i != swarm_index:\n                distance = np.linalg.norm(self.centers[swarm_index] - self.centers[i])\n                if distance < 0.5:\n                    # Repel the swarms from each other\n                    direction = self.centers[swarm_index] - self.centers[i]\n                    self.centers[swarm_index] += 0.1 * direction\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize swarms asynchronously\n        for i in range(self.num_swarms):\n            center, swarm, fitnesses = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            self.centers.append(center)\n            self.fitnesses.append(fitnesses)\n\n            best_index = np.argmin(fitnesses)\n            if fitnesses[best_index] < self.f_opt:\n                self.f_opt = fitnesses[best_index]\n                self.x_opt = swarm[best_index]\n\n        # Asynchronous evolution loop\n        while self.eval_count < self.budget:\n            for i in range(self.num_swarms):\n                # Select a swarm to update\n                if self.eval_count >= self.budget:\n                   break\n                \n                # Generate new particles around the current center\n                new_swarm = np.random.uniform(\n                    np.maximum(func.bounds.lb, self.centers[i] - self.radii[i]),\n                    np.minimum(func.bounds.ub, self.centers[i] + self.radii[i]),\n                    size=(self.swarm_size, self.dim)\n                )\n\n                new_fitnesses = np.array([func(x) for x in new_swarm])\n                self.eval_count += self.swarm_size\n\n                # Check for improvement in the swarm\n                best_index = np.argmin(self.fitnesses[i])\n                best_fitness = self.fitnesses[i][best_index]\n                new_best_index = np.argmin(new_fitnesses)\n                new_best_fitness = new_fitnesses[new_best_index]\n\n                improvement = best_fitness - new_best_fitness\n\n                # Update swarm and center if there's an improvement\n                if improvement > 0:\n                    self.swarms[i] = new_swarm\n                    self.fitnesses[i] = new_fitnesses\n                    self.centers[i] = new_swarm[new_best_index]\n\n\n                # Adjust radius\n                self.adjust_radius(i, improvement)\n\n                # Repulsion mechanism\n                self.repulsion(i)\n\n                # Update global best\n                best_index = np.argmin(self.fitnesses[i])\n                if self.fitnesses[i][best_index] < self.f_opt:\n                    self.f_opt = self.fitnesses[i][best_index]\n                    self.x_opt = self.swarms[i][best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.154348731561744, 0.19318973182722476, 0.3944771982013472, 0.5486239448708519, 0.3159341039638862, 0.3921097236630391, 0.3082859671220002, 0.32961240397329994, 0.32604203646990526, 0.18331724464782462, 0.5751657334905622, 0.9827790005044876, 0.20202573718799954, 0.2675148244360557, 0.7064906409228136, 0.3950694615695507, 0.32706093931206337, 0.44590464849792066, 0.2113077044293774, 0.485970418027476], "operator": "random_new", "theta_sampled": 0.031608831737157894, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "053d8645-0a4c-4d36-b74d-d33b99fb29a3", "fitness": 0.0, "name": "CauchyMutationDiversitySelection", "description": "Population-based algorithm utilizing a Cauchy mutation combined with a selection based on both fitness and diversity.", "code": "import numpy as np\n\nclass CauchyMutationDiversitySelection:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cauchy_scale=1.0, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cauchy_scale = cauchy_scale\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size  # Correctly initialize eval_count\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            # Cauchy mutation\n            cauchy_noise = self.cauchy_scale * np.random.standard_cauchy(size=(self.pop_size, self.dim))\n            mutated_population = population + cauchy_noise\n            mutated_population = np.clip(mutated_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate mutated population\n            mutated_fitness = np.array([func(x) for x in mutated_population])\n            eval_count += self.pop_size #Increment eval_count with the size of mutated_fitness\n\n            # Update best solution\n            best_index = np.argmin(mutated_fitness)\n            if mutated_fitness[best_index] < self.f_opt:\n                self.f_opt = mutated_fitness[best_index]\n                self.x_opt = mutated_population[best_index]\n\n            # Diversity Selection (replace worst individuals with mutated ones)\n            distances = np.linalg.norm(population[:, np.newaxis, :] - population[np.newaxis, :, :], axis=2)\n            np.fill_diagonal(distances, np.inf)  # Avoid self-comparison\n            min_distances = np.min(distances, axis=1)\n\n            # Identify poorly performing and undiverse individuals\n            combined_metric = fitness + (self.diversity_threshold / (min_distances + 1e-8)) # Add small value to prevent division by zero\n\n            # Indices of individuals to replace (worst combined metric)\n            replace_indices = np.argsort(combined_metric)[-self.pop_size // 4:]  # Replace 25% worst\n\n            # Replace with the *better* mutated individuals (fitness based selection, but only on the mutated set)\n            mutation_selection_indices = np.argsort(mutated_fitness)[:self.pop_size // 4]\n\n\n            population[replace_indices] = mutated_population[mutation_selection_indices]\n\n            fitness = np.array([func(x) for x in population])  # Re-evaluate fitness of updated population, important to ensure the fitness array represents the latest population\n            eval_count += len(replace_indices) # Account for re-evaluation within the loop\n\n            if eval_count > self.budget:\n                fitness = fitness[:self.pop_size - (eval_count-self.budget)]\n                population = population[:self.pop_size - (eval_count-self.budget)]\n                \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: shape mismatch: value array of shape (12,2) could not be broadcast to indexing result of shape (13,2)", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm utilizing a Cauchy mutation combined with a selection based on both fitness and diversity.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyMutationDiversitySelection:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cauchy_scale=1.0, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cauchy_scale = cauchy_scale\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size  # Correctly initialize eval_count\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            # Cauchy mutation\n            cauchy_noise = self.cauchy_scale * np.random.standard_cauchy(size=(self.pop_size, self.dim))\n            mutated_population = population + cauchy_noise\n            mutated_population = np.clip(mutated_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate mutated population\n            mutated_fitness = np.array([func(x) for x in mutated_population])\n            eval_count += self.pop_size #Increment eval_count with the size of mutated_fitness\n\n            # Update best solution\n            best_index = np.argmin(mutated_fitness)\n            if mutated_fitness[best_index] < self.f_opt:\n                self.f_opt = mutated_fitness[best_index]\n                self.x_opt = mutated_population[best_index]\n\n            # Diversity Selection (replace worst individuals with mutated ones)\n            distances = np.linalg.norm(population[:, np.newaxis, :] - population[np.newaxis, :, :], axis=2)\n            np.fill_diagonal(distances, np.inf)  # Avoid self-comparison\n            min_distances = np.min(distances, axis=1)\n\n            # Identify poorly performing and undiverse individuals\n            combined_metric = fitness + (self.diversity_threshold / (min_distances + 1e-8)) # Add small value to prevent division by zero\n\n            # Indices of individuals to replace (worst combined metric)\n            replace_indices = np.argsort(combined_metric)[-self.pop_size // 4:]  # Replace 25% worst\n\n            # Replace with the *better* mutated individuals (fitness based selection, but only on the mutated set)\n            mutation_selection_indices = np.argsort(mutated_fitness)[:self.pop_size // 4]\n\n\n            population[replace_indices] = mutated_population[mutation_selection_indices]\n\n            fitness = np.array([func(x) for x in population])  # Re-evaluate fitness of updated population, important to ensure the fitness array represents the latest population\n            eval_count += len(replace_indices) # Account for re-evaluation within the loop\n\n            if eval_count > self.budget:\n                fitness = fitness[:self.pop_size - (eval_count-self.budget)]\n                population = population[:self.pop_size - (eval_count-self.budget)]\n                \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.016608670541410693, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "75f88a08-8dda-4696-8a3a-e78d9d4515a6", "fitness": 0.5505058127541241, "name": "AdaptiveHybridPSO_DE_Restart", "description": "An adaptive hybrid PSO-DE algorithm with self-adjusting parameters, a restart mechanism, and improved boundary handling.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1_start=2.0, c1_end=1.0, c2_start=1.0, c2_end=2.0, cr_start=0.9, cr_end=0.2, f_start=0.5, f_end=0.9, pso_de_ratio=0.5, stagnation_threshold=50):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with parameter adaptation and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1_start (float): Initial cognitive coefficient for PSO.\n            c1_end (float): Final cognitive coefficient for PSO.\n            c2_start (float): Initial social coefficient for PSO.\n            c2_end (float): Final social coefficient for PSO.\n            cr_start (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_start (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_de_ratio (float): Probability of selecting PSO vs DE update.\n            stagnation_threshold (int): Number of iterations without improvement before restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1_start = c1_start\n        self.c1_end = c1_end\n        self.c2_start = c2_start\n        self.c2_end = c2_end\n        self.cr_start = cr_start\n        self.cr_end = cr_end\n        self.f_start = f_start\n        self.f_end = f_end\n        self.pso_de_ratio = pso_de_ratio\n        self.stagnation_threshold = stagnation_threshold\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.iteration = 0\n        self.stagnation_counter = 0\n        self.last_improvement_fitness = np.inf\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_improvement_fitness = self.global_best_fitness\n\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness and resets stagnation counter.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.stagnation_counter = 0\n            self.last_improvement_fitness = self.global_best_fitness\n        else:\n            self.stagnation_counter += 1\n\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Adaptive inertia weight\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget)\n\n        # Adaptive c1 and c2\n        c1 = self.c1_start - (self.c1_start - self.c1_end) * (self.func_evals / self.budget)\n        c2 = self.c2_start - (self.c2_start - self.c2_end) * (self.func_evals / self.budget)\n\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           c1 * r1 * (self.personal_best_positions - self.population) +\n                           c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (more robust bounce-back)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + np.abs(self.population[i, j] - func.bounds.lb[j])\n                    self.velocities[i,j] = -0.5*self.velocities[i,j] # Dampen velocity\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - np.abs(self.population[i, j] - func.bounds.ub[j])\n                    self.velocities[i,j] = -0.5*self.velocities[i,j]  # Dampen velocity\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n\n        #Adapt CR and F\n        cr = self.cr_start - (self.cr_start - self.cr_end) * (self.func_evals / self.budget)\n        f = self.f_start + (self.f_end - self.f_start) * (self.func_evals / self.budget)\n\n\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population if stagnation is detected.\n        \"\"\"\n        print(\"Restarting population...\")\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        #Keep the previous global best\n        for i in range(self.pop_size):\n          if np.random.rand() < 0.1: # 10% chance to keep the global best\n            self.population[i] = self.global_best_position.copy()\n            self.fitness[i] = self.global_best_fitness\n            self.personal_best_positions[i] = self.global_best_position.copy()\n            self.personal_best_fitness[i] = self.global_best_fitness\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.stagnation_counter = 0 # Reset stagnation counter\n        self.last_improvement_fitness = self.global_best_fitness\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            if self.stagnation_counter >= self.stagnation_threshold:\n                self.restart_population(func)\n\n            if np.random.rand() < self.pso_de_ratio:  # Adaptive selection of PSO and DE\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.iteration += 1\n            self.update_global_best()\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE_Restart scored 0.551 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ae66da83-ff9a-4af3-9261-55eddfb81c1f"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with self-adjusting parameters, a restart mechanism, and improved boundary handling.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1_start=2.0, c1_end=1.0, c2_start=1.0, c2_end=2.0, cr_start=0.9, cr_end=0.2, f_start=0.5, f_end=0.9, pso_de_ratio=0.5, stagnation_threshold=50):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with parameter adaptation and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1_start (float): Initial cognitive coefficient for PSO.\n            c1_end (float): Final cognitive coefficient for PSO.\n            c2_start (float): Initial social coefficient for PSO.\n            c2_end (float): Final social coefficient for PSO.\n            cr_start (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_start (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_de_ratio (float): Probability of selecting PSO vs DE update.\n            stagnation_threshold (int): Number of iterations without improvement before restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1_start = c1_start\n        self.c1_end = c1_end\n        self.c2_start = c2_start\n        self.c2_end = c2_end\n        self.cr_start = cr_start\n        self.cr_end = cr_end\n        self.f_start = f_start\n        self.f_end = f_end\n        self.pso_de_ratio = pso_de_ratio\n        self.stagnation_threshold = stagnation_threshold\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.iteration = 0\n        self.stagnation_counter = 0\n        self.last_improvement_fitness = np.inf\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_improvement_fitness = self.global_best_fitness\n\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness and resets stagnation counter.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.stagnation_counter = 0\n            self.last_improvement_fitness = self.global_best_fitness\n        else:\n            self.stagnation_counter += 1\n\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Adaptive inertia weight\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget)\n\n        # Adaptive c1 and c2\n        c1 = self.c1_start - (self.c1_start - self.c1_end) * (self.func_evals / self.budget)\n        c2 = self.c2_start - (self.c2_start - self.c2_end) * (self.func_evals / self.budget)\n\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           c1 * r1 * (self.personal_best_positions - self.population) +\n                           c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (more robust bounce-back)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + np.abs(self.population[i, j] - func.bounds.lb[j])\n                    self.velocities[i,j] = -0.5*self.velocities[i,j] # Dampen velocity\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - np.abs(self.population[i, j] - func.bounds.ub[j])\n                    self.velocities[i,j] = -0.5*self.velocities[i,j]  # Dampen velocity\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n\n        #Adapt CR and F\n        cr = self.cr_start - (self.cr_start - self.cr_end) * (self.func_evals / self.budget)\n        f = self.f_start + (self.f_end - self.f_start) * (self.func_evals / self.budget)\n\n\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population if stagnation is detected.\n        \"\"\"\n        print(\"Restarting population...\")\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        #Keep the previous global best\n        for i in range(self.pop_size):\n          if np.random.rand() < 0.1: # 10% chance to keep the global best\n            self.population[i] = self.global_best_position.copy()\n            self.fitness[i] = self.global_best_fitness\n            self.personal_best_positions[i] = self.global_best_position.copy()\n            self.personal_best_fitness[i] = self.global_best_fitness\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.stagnation_counter = 0 # Reset stagnation counter\n        self.last_improvement_fitness = self.global_best_fitness\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            if self.stagnation_counter >= self.stagnation_threshold:\n                self.restart_population(func)\n\n            if np.random.rand() < self.pso_de_ratio:  # Adaptive selection of PSO and DE\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.iteration += 1\n            self.update_global_best()\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.21675855497090468, 0.3637039387779387, 0.5530077315320081, 0.8363522062986743, 0.517090314207864, 0.6344166301965137, 0.32798849999252633, 0.47940864834917163, 0.543347469268034, 0.5529438230670825, 0.7223898847244872, 0.9995718784765261, 0.32626703702563176, 0.5204386525311424, 0.8527791994108553, 0.6372629602678539, 0.48682035097970333, 0.7059955253301835, 0.2280211745308207, 0.5055517751445597], "operator": "mutation", "theta_sampled": 0.008267755605509026, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "4382c451-ed5a-403f-969d-0e18fa6488d9", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_OL", "description": "Adaptive Hybrid PSO-DE with aging mechanism, dynamic parameter adaptation, and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, aging_probability=0.01, ol_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.aging_probability = aging_probability\n        self.ol_probability = ol_probability\n        self.age = np.zeros(pop_size) # Age of each particle\n        self.max_age = 50\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def orthogonal_learning(self, func, x):\n        \"\"\"Performs orthogonal learning around x.\"\"\"\n        levels = 3 # Number of levels for each dimension\n        candidates = []\n        \n        # Create orthogonal array (simplified for demonstration)\n        array = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\n\n        for row in array:\n            new_x = x.copy()\n            for i in range(self.dim):\n                step = (func.bounds.ub - func.bounds.lb) / (levels - 1)\n                level_value = x[i] + row[i%2] * step #Only vary 2 dimensions at a time in the simple array.\n                new_x[i] = np.clip(level_value, func.bounds.lb, func.bounds.ub)\n            candidates.append(new_x)\n        \n        # Evaluate candidates\n        fitnesses = []\n        for candidate in candidates:\n          f = func(candidate)\n          self.budget -= 1\n          if self.budget <= 0:\n            return func(x), x #Early return if budget is exhausted\n          fitnesses.append(f)\n\n        # Select the best\n        best_index = np.argmin(fitnesses)\n        return fitnesses[best_index], candidates[best_index]\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            # Adaptive Parameter Control (Example: Linear decrease of inertia weight)\n            self.w = 0.7 - (0.7 - 0.2) * (1 - self.budget / 10000) if self.budget < 10000 else 0.7\n\n            for i in range(self.pop_size):\n                # Aging mechanism\n                if np.random.rand() < self.aging_probability:\n                    self.age[i] += 1\n                    if self.age[i] > self.max_age:\n                        pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                        fitness[i] = func(pop[i])\n                        self.budget -= 1\n                        pbest_pop[i] = pop[i].copy()\n                        pbest_fitness[i] = fitness[i]\n                        self.age[i] = 0\n\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                # Orthogonal Learning\n                if np.random.rand() < self.ol_probability:\n                    ol_f, ol_x = self.orthogonal_learning(func, pop[i].copy())\n                    if ol_f < pbest_fitness[i]:\n                        pbest_fitness[i] = ol_f\n                        pbest_pop[i] = ol_x.copy()\n                        if ol_f < gbest_fitness:\n                            gbest_fitness = ol_f\n                            gbest_pos = ol_x.copy()\n                    pop[i] = ol_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with aging mechanism, dynamic parameter adaptation, and orthogonal learning to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, aging_probability=0.01, ol_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.aging_probability = aging_probability\n        self.ol_probability = ol_probability\n        self.age = np.zeros(pop_size) # Age of each particle\n        self.max_age = 50\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def orthogonal_learning(self, func, x):\n        \"\"\"Performs orthogonal learning around x.\"\"\"\n        levels = 3 # Number of levels for each dimension\n        candidates = []\n        \n        # Create orthogonal array (simplified for demonstration)\n        array = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\n\n        for row in array:\n            new_x = x.copy()\n            for i in range(self.dim):\n                step = (func.bounds.ub - func.bounds.lb) / (levels - 1)\n                level_value = x[i] + row[i%2] * step #Only vary 2 dimensions at a time in the simple array.\n                new_x[i] = np.clip(level_value, func.bounds.lb, func.bounds.ub)\n            candidates.append(new_x)\n        \n        # Evaluate candidates\n        fitnesses = []\n        for candidate in candidates:\n          f = func(candidate)\n          self.budget -= 1\n          if self.budget <= 0:\n            return func(x), x #Early return if budget is exhausted\n          fitnesses.append(f)\n\n        # Select the best\n        best_index = np.argmin(fitnesses)\n        return fitnesses[best_index], candidates[best_index]\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            # Adaptive Parameter Control (Example: Linear decrease of inertia weight)\n            self.w = 0.7 - (0.7 - 0.2) * (1 - self.budget / 10000) if self.budget < 10000 else 0.7\n\n            for i in range(self.pop_size):\n                # Aging mechanism\n                if np.random.rand() < self.aging_probability:\n                    self.age[i] += 1\n                    if self.age[i] > self.max_age:\n                        pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                        fitness[i] = func(pop[i])\n                        self.budget -= 1\n                        pbest_pop[i] = pop[i].copy()\n                        pbest_fitness[i] = fitness[i]\n                        self.age[i] = 0\n\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                # Orthogonal Learning\n                if np.random.rand() < self.ol_probability:\n                    ol_f, ol_x = self.orthogonal_learning(func, pop[i].copy())\n                    if ol_f < pbest_fitness[i]:\n                        pbest_fitness[i] = ol_f\n                        pbest_pop[i] = ol_x.copy()\n                        if ol_f < gbest_fitness:\n                            gbest_fitness = ol_f\n                            gbest_pos = ol_x.copy()\n                    pop[i] = ol_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "operator": "mutation", "theta_sampled": 0.00823129366193421, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "b934d285-32e9-4aba-ae39-95ec9671c706", "fitness": 0.0, "name": "AdaptiveHybridPSO_DELocalSearch", "description": "An adaptive hybrid PSO-DE algorithm with success-based probability adjustment, velocity clamping, boundary reflection, and a local search component.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DELocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, local_search_radius=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search on a particle.\n            local_search_radius (float): Radius for the local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            # Local search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.fitness[i] = local_f  # Update fitness after local search\n                    self.population[i] = local_x.copy() # Update population after local search\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DELocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with success-based probability adjustment, velocity clamping, boundary reflection, and a local search component.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DELocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, local_search_radius=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search on a particle.\n            local_search_radius (float): Radius for the local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            # Local search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.fitness[i] = local_f  # Update fitness after local search\n                    self.population[i] = local_x.copy() # Update population after local search\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.006942097766728902, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "7d4891ac-838f-42e3-bcb1-7fc60abca5e7", "fitness": 0.5542734248118003, "name": "AdaptiveStochasticDE", "description": "Adaptive Differential Evolution with stochastic ranking and local search for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveStochasticDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.7, local_search_rate=0.1, local_search_radius=0.1, ranking_probability=0.45):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial  # Scaling factor for DE\n        self.Cr = Cr_initial  # Crossover rate for DE\n        self.local_search_rate = local_search_rate\n        self.local_search_radius = local_search_radius\n        self.ranking_probability = ranking_probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive F and Cr (adjust based on success)\n            success_indices = []\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic Ranking\n                if (fitness[i] < self.f_opt or f_trial < self.f_opt) and np.random.rand() < self.ranking_probability:\n                    if f_trial < fitness[i]:\n                        fitness[i] = f_trial\n                        population[i] = x_trial\n                        success_indices.append(i)\n\n                        # Update best solution\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n                else:\n                    if f_trial < fitness[i]:\n                         fitness[i] = f_trial\n                         population[i] = x_trial\n                         success_indices.append(i)\n\n                         # Update best solution\n                         if f_trial < self.f_opt:\n                             self.f_opt = f_trial\n                             self.x_opt = x_trial\n            \n            #Adapt F and Cr\n            if len(success_indices) > 0:\n                self.F = np.clip(np.mean(np.random.normal(0.5, 0.3, len(success_indices))), 0.1, 1.0)\n                self.Cr = np.clip(np.mean(np.random.normal(0.7, 0.2, len(success_indices))), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n\n            # Local Search around the best solution\n            if np.random.rand() < self.local_search_rate and self.budget > 0:\n                x_local = self.x_opt + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                    \n                    #Potentially replace a worse member with the improved one\n                    worst_index = np.argmax(fitness)\n                    if f_local < fitness[worst_index]:\n                        fitness[worst_index] = f_local\n                        population[worst_index] = x_local\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveStochasticDE scored 0.554 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80e52b05-8bb9-4558-b094-6de755982aa6"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with stochastic ranking and local search for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveStochasticDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.7, local_search_rate=0.1, local_search_radius=0.1, ranking_probability=0.45):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial  # Scaling factor for DE\n        self.Cr = Cr_initial  # Crossover rate for DE\n        self.local_search_rate = local_search_rate\n        self.local_search_radius = local_search_radius\n        self.ranking_probability = ranking_probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive F and Cr (adjust based on success)\n            success_indices = []\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic Ranking\n                if (fitness[i] < self.f_opt or f_trial < self.f_opt) and np.random.rand() < self.ranking_probability:\n                    if f_trial < fitness[i]:\n                        fitness[i] = f_trial\n                        population[i] = x_trial\n                        success_indices.append(i)\n\n                        # Update best solution\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n                else:\n                    if f_trial < fitness[i]:\n                         fitness[i] = f_trial\n                         population[i] = x_trial\n                         success_indices.append(i)\n\n                         # Update best solution\n                         if f_trial < self.f_opt:\n                             self.f_opt = f_trial\n                             self.x_opt = x_trial\n            \n            #Adapt F and Cr\n            if len(success_indices) > 0:\n                self.F = np.clip(np.mean(np.random.normal(0.5, 0.3, len(success_indices))), 0.1, 1.0)\n                self.Cr = np.clip(np.mean(np.random.normal(0.7, 0.2, len(success_indices))), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n\n            # Local Search around the best solution\n            if np.random.rand() < self.local_search_rate and self.budget > 0:\n                x_local = self.x_opt + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                    \n                    #Potentially replace a worse member with the improved one\n                    worst_index = np.argmax(fitness)\n                    if f_local < fitness[worst_index]:\n                        fitness[worst_index] = f_local\n                        population[worst_index] = x_local\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19265329775480045, 0.4196965811698694, 0.5583094160092601, 0.8300618503247086, 0.4575840059387455, 0.7542416830439, 0.3388771962655026, 0.4919462356998724, 0.5216935885978673, 0.19210450773014376, 0.8413884976408268, 0.9938346642590997, 0.45664750153677347, 0.4410847267762259, 0.9136142405293738, 0.7123398568700415, 0.4312232127632514, 0.8058034046759723, 0.21008988835541698, 0.5222741402943527], "operator": "mutation", "theta_sampled": 0.022728394450386165, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "4ef17d15-f271-4b78-9cbc-8ba9ad1846fd", "fitness": 0.41828003226119054, "name": "SelfAdaptiveRestartDE", "description": "Differential Evolution with self-adaptive parameters and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass SelfAdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_base=0.5, Cr_base=0.7, restart_prob=0.05, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base\n        self.Cr_base = Cr_base\n        self.restart_prob = restart_prob\n        self.stagnation_limit = stagnation_limit  # Number of iterations without improvement before restart\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        # Initialize population and parameters\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize DE parameters for each individual\n        F = np.random.normal(self.F_base, 0.1, size=self.pop_size)\n        F = np.clip(F, 0.1, 1.0)  # Ensure F is within [0.1, 1.0]\n        Cr = np.random.normal(self.Cr_base, 0.1, size=self.pop_size)\n        Cr = np.clip(Cr, 0.1, 1.0) # Ensure Cr is within [0.1, 1.0]\n\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptation of DE parameters\n                F_i = F[i]\n                Cr_i = Cr[i]\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < Cr_i:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    \n                    # Adapt parameters if the trial vector is better\n                    F[i] = np.random.normal(self.F_base, 0.1)\n                    F[i] = np.clip(F[i], 0.1, 1.0)\n                    Cr[i] = np.random.normal(self.Cr_base, 0.1)\n                    Cr[i] = np.clip(Cr[i], 0.1, 1.0)\n\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1  # Increment stagnation counter\n\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_limit and self.budget > 0:\n                if np.random.rand() < self.restart_prob:\n                    # Restart a portion of the population\n                    num_restart = int(self.pop_size * 0.25)  # Restart 25% of population\n                    restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n                    population[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n                    fitness[restart_indices] = np.array([func(x) for x in population[restart_indices]])\n                    self.budget -= num_restart\n                    \n                    # Reinitialize DE parameters for restarted individuals\n                    F[restart_indices] = np.random.normal(self.F_base, 0.1, size=num_restart)\n                    F[restart_indices] = np.clip(F[restart_indices], 0.1, 1.0)\n                    Cr[restart_indices] = np.random.normal(self.Cr_base, 0.1, size=num_restart)\n                    Cr[restart_indices] = np.clip(Cr[restart_indices], 0.1, 1.0)\n\n\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0  # Reset stagnation counter after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SelfAdaptiveRestartDE scored 0.418 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80e52b05-8bb9-4558-b094-6de755982aa6"], "operator": "mutation", "metadata": {"llm_response": "# Description: Differential Evolution with self-adaptive parameters and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_base=0.5, Cr_base=0.7, restart_prob=0.05, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base\n        self.Cr_base = Cr_base\n        self.restart_prob = restart_prob\n        self.stagnation_limit = stagnation_limit  # Number of iterations without improvement before restart\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        # Initialize population and parameters\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize DE parameters for each individual\n        F = np.random.normal(self.F_base, 0.1, size=self.pop_size)\n        F = np.clip(F, 0.1, 1.0)  # Ensure F is within [0.1, 1.0]\n        Cr = np.random.normal(self.Cr_base, 0.1, size=self.pop_size)\n        Cr = np.clip(Cr, 0.1, 1.0) # Ensure Cr is within [0.1, 1.0]\n\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptation of DE parameters\n                F_i = F[i]\n                Cr_i = Cr[i]\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < Cr_i:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    \n                    # Adapt parameters if the trial vector is better\n                    F[i] = np.random.normal(self.F_base, 0.1)\n                    F[i] = np.clip(F[i], 0.1, 1.0)\n                    Cr[i] = np.random.normal(self.Cr_base, 0.1)\n                    Cr[i] = np.clip(Cr[i], 0.1, 1.0)\n\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1  # Increment stagnation counter\n\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_limit and self.budget > 0:\n                if np.random.rand() < self.restart_prob:\n                    # Restart a portion of the population\n                    num_restart = int(self.pop_size * 0.25)  # Restart 25% of population\n                    restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n                    population[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n                    fitness[restart_indices] = np.array([func(x) for x in population[restart_indices]])\n                    self.budget -= num_restart\n                    \n                    # Reinitialize DE parameters for restarted individuals\n                    F[restart_indices] = np.random.normal(self.F_base, 0.1, size=num_restart)\n                    F[restart_indices] = np.clip(F[restart_indices], 0.1, 1.0)\n                    Cr[restart_indices] = np.random.normal(self.Cr_base, 0.1, size=num_restart)\n                    Cr[restart_indices] = np.clip(Cr[restart_indices], 0.1, 1.0)\n\n\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0  # Reset stagnation counter after restart\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16039608098084013, 0.260417495701633, 0.41072541274637075, 0.45276296967489504, 0.29380519203423006, 0.6328807338281559, 0.29706999732545336, 0.3669246133766324, 0.303615231572283, 0.19686674666127668, 0.4589652256089619, 0.9885181042754464, 0.3162696219106409, 0.3157449105412249, 0.7767843013368219, 0.5017318760015992, 0.324017081900298, 0.6189542280062768, 0.2038404295378281, 0.48531039220294336], "operator": "mutation", "theta_sampled": 0.005232795108862453, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "1d04b255-d6b1-4807-ab79-0ed1ac77c9bf", "fitness": 0.3430099522953505, "name": "AdaptiveDE_SA_OL", "description": "Adaptive Differential Evolution with Simulated Annealing-inspired acceptance criterion and orthogonal learning.", "code": "import numpy as np\n\nclass AdaptiveDE_SA_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_base=0.5, Cr_base=0.7, temp_init=1.0, temp_decay=0.995, orthogonal_learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base  # Base Scaling factor for DE, will be adapted\n        self.Cr_base = Cr_base  # Base Crossover rate for DE, will be adapted\n        self.temp = temp_init  # Initial temperature for SA\n        self.temp_decay = temp_decay # Decay rate for SA\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Adaptive Parameter Control\n            F = self.F_base * (1 + 0.1 * np.random.randn())\n            Cr = self.Cr_base * (1 + 0.1 * np.random.randn())\n            F = np.clip(F, 0.1, 0.9)\n            Cr = np.clip(Cr, 0.1, 0.9)\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Simulated Annealing-based Acceptance\n                delta_f = f_trial - fitness[i]\n                if delta_f < 0:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                else:\n                    acceptance_prob = np.exp(-delta_f / self.temp)\n                    if np.random.rand() < acceptance_prob:\n                        fitness[i] = f_trial\n                        population[i] = x_trial\n\n            # Orthogonal Learning\n            if self.budget > 0 and np.random.rand() < self.orthogonal_learning_rate:\n                # Select a random individual\n                idx = np.random.randint(self.pop_size)\n                x_current = population[idx].copy()\n                f_current = fitness[idx]\n\n                # Generate a random direction\n                d = np.random.randn(self.dim)\n                d /= np.linalg.norm(d) # Normalize\n\n                # Define a search range around the current individual\n                alpha = np.linspace(-0.1, 0.1, 5) # Reduced the number of points for faster evaluation\n\n                # Evaluate points along the direction\n                x_candidates = np.array([x_current + a * d for a in alpha])\n                x_candidates = np.clip(x_candidates, func.bounds.lb, func.bounds.ub)\n                f_candidates = np.zeros(len(alpha))\n\n                for k in range(len(alpha)):\n                    f_candidates[k] = func(x_candidates[k])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                \n                if self.budget <= 0:\n                    break\n\n                # Select the best point\n                best_candidate_idx = np.argmin(f_candidates)\n                f_best_candidate = f_candidates[best_candidate_idx]\n                x_best_candidate = x_candidates[best_candidate_idx]\n\n                # Replace the current individual if the candidate is better\n                if f_best_candidate < f_current:\n                    fitness[idx] = f_best_candidate\n                    population[idx] = x_best_candidate\n                    if f_best_candidate < self.f_opt:\n                        self.f_opt = f_best_candidate\n                        self.x_opt = x_best_candidate\n\n            #Cooling\n            self.temp *= self.temp_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE_SA_OL scored 0.343 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80e52b05-8bb9-4558-b094-6de755982aa6"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Simulated Annealing-inspired acceptance criterion and orthogonal learning.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_SA_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_base=0.5, Cr_base=0.7, temp_init=1.0, temp_decay=0.995, orthogonal_learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base  # Base Scaling factor for DE, will be adapted\n        self.Cr_base = Cr_base  # Base Crossover rate for DE, will be adapted\n        self.temp = temp_init  # Initial temperature for SA\n        self.temp_decay = temp_decay # Decay rate for SA\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Adaptive Parameter Control\n            F = self.F_base * (1 + 0.1 * np.random.randn())\n            Cr = self.Cr_base * (1 + 0.1 * np.random.randn())\n            F = np.clip(F, 0.1, 0.9)\n            Cr = np.clip(Cr, 0.1, 0.9)\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Simulated Annealing-based Acceptance\n                delta_f = f_trial - fitness[i]\n                if delta_f < 0:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                else:\n                    acceptance_prob = np.exp(-delta_f / self.temp)\n                    if np.random.rand() < acceptance_prob:\n                        fitness[i] = f_trial\n                        population[i] = x_trial\n\n            # Orthogonal Learning\n            if self.budget > 0 and np.random.rand() < self.orthogonal_learning_rate:\n                # Select a random individual\n                idx = np.random.randint(self.pop_size)\n                x_current = population[idx].copy()\n                f_current = fitness[idx]\n\n                # Generate a random direction\n                d = np.random.randn(self.dim)\n                d /= np.linalg.norm(d) # Normalize\n\n                # Define a search range around the current individual\n                alpha = np.linspace(-0.1, 0.1, 5) # Reduced the number of points for faster evaluation\n\n                # Evaluate points along the direction\n                x_candidates = np.array([x_current + a * d for a in alpha])\n                x_candidates = np.clip(x_candidates, func.bounds.lb, func.bounds.ub)\n                f_candidates = np.zeros(len(alpha))\n\n                for k in range(len(alpha)):\n                    f_candidates[k] = func(x_candidates[k])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                \n                if self.budget <= 0:\n                    break\n\n                # Select the best point\n                best_candidate_idx = np.argmin(f_candidates)\n                f_best_candidate = f_candidates[best_candidate_idx]\n                x_best_candidate = x_candidates[best_candidate_idx]\n\n                # Replace the current individual if the candidate is better\n                if f_best_candidate < f_current:\n                    fitness[idx] = f_best_candidate\n                    population[idx] = x_best_candidate\n                    if f_best_candidate < self.f_opt:\n                        self.f_opt = f_best_candidate\n                        self.x_opt = x_best_candidate\n\n            #Cooling\n            self.temp *= self.temp_decay\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1662916830787422, 0.29633840039977544, 0.29277082639307495, 0.3406311354766567, 0.2624291610561712, 0.3115822593553822, 0.2665510767857997, 0.27088205648526165, 0.25841962976218746, 0.2053223955438368, 0.35380069276498893, 0.9891298970482088, 0.31295649648197654, 0.2802907520798683, 0.6520257548446069, 0.31492348302269724, 0.2803928368839579, 0.35250572076569286, 0.187465748386767, 0.46548903929135654], "operator": "mutation", "theta_sampled": 0.013940369339999446, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "a40ef82b-c2e7-45d4-b0cf-85f1b2e3a14e", "fitness": 0.0, "name": "CauchyShrinkingWalk", "description": "Population-based algorithm using a Cauchy mutation and a shrinking random walk for exploitation, with a restart mechanism for exploration.", "code": "import numpy as np\n\nclass CauchyShrinkingWalk:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cauchy_scale=1.0, walk_decay=0.99, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cauchy_scale = cauchy_scale\n        self.walk_decay = walk_decay\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        walk_step = (func.bounds.ub - func.bounds.lb) / 10.0  # Initial step size for the random walk\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutated_individual = population[i] + cauchy_mutation\n\n                # Shrinking random walk\n                rand_dir = np.random.uniform(-1, 1, size=self.dim)\n                rand_dir = rand_dir / np.linalg.norm(rand_dir) # Normalize direction\n                walk_mutation = walk_step * rand_dir\n                mutated_individual += walk_mutation\n                \n                # Clip to bounds\n                mutated_individual = np.clip(mutated_individual, func.bounds.lb, func.bounds.ub)\n                \n                f_mutated = func(mutated_individual)\n                self.budget -= 1\n                \n                if f_mutated < fitness[i]:\n                    fitness[i] = f_mutated\n                    population[i] = mutated_individual\n                    \n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_individual.copy()\n\n                # Restart mechanism: occasionally replace an individual with a random one\n                if np.random.rand() < self.restart_prob:\n                    population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(population[i])\n                    self.budget -=1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i].copy()\n            \n            walk_step *= self.walk_decay # Reduce the random walk step size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CauchyShrinkingWalk scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a Cauchy mutation and a shrinking random walk for exploitation, with a restart mechanism for exploration.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyShrinkingWalk:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cauchy_scale=1.0, walk_decay=0.99, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cauchy_scale = cauchy_scale\n        self.walk_decay = walk_decay\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        walk_step = (func.bounds.ub - func.bounds.lb) / 10.0  # Initial step size for the random walk\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutated_individual = population[i] + cauchy_mutation\n\n                # Shrinking random walk\n                rand_dir = np.random.uniform(-1, 1, size=self.dim)\n                rand_dir = rand_dir / np.linalg.norm(rand_dir) # Normalize direction\n                walk_mutation = walk_step * rand_dir\n                mutated_individual += walk_mutation\n                \n                # Clip to bounds\n                mutated_individual = np.clip(mutated_individual, func.bounds.lb, func.bounds.ub)\n                \n                f_mutated = func(mutated_individual)\n                self.budget -= 1\n                \n                if f_mutated < fitness[i]:\n                    fitness[i] = f_mutated\n                    population[i] = mutated_individual\n                    \n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_individual.copy()\n\n                # Restart mechanism: occasionally replace an individual with a random one\n                if np.random.rand() < self.restart_prob:\n                    population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(population[i])\n                    self.budget -=1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i].copy()\n            \n            walk_step *= self.walk_decay # Reduce the random walk step size\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.024333890724413994, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "8f066986-9fe7-4de8-b29c-5caff5554c1c", "fitness": 0.0, "name": "CosineNichingProbabilisticSearch", "description": "A population-based algorithm with a niching strategy using cosine similarity to maintain diversity, coupled with a probabilistic local search based on gradient estimation.", "code": "import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nclass CosineNichingProbabilisticSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, niche_radius=0.2, local_search_prob=0.1, local_search_step=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.niche_radius = niche_radius\n        self.local_search_prob = local_search_prob\n        self.local_search_step = local_search_step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Niching based on cosine similarity\n            similarities = cosine_similarity(self.population)\n            for i in range(self.pop_size):\n                for j in range(i + 1, self.pop_size):\n                    if similarities[i, j] > 1 - self.niche_radius:  # Cosine similarity close to 1 indicates similarity\n                        # Replace the worse individual with a new random one\n                        if self.fitness[i] > self.fitness[j]:\n                            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                            self.fitness[i] = func(self.population[i])\n                            self.budget -= 1\n                            if self.budget <= 0:\n                                break\n                        else:\n                            self.population[j] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                            self.fitness[j] = func(self.population[j])\n                            self.budget -= 1\n                            if self.budget <= 0:\n                                break\n                if self.budget <= 0:\n                    break\n\n\n            # Probabilistic local search with gradient estimation\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_prob:\n                    # Estimate gradient (simple finite difference)\n                    gradient = np.zeros(self.dim)\n                    for d in range(self.dim):\n                        x_plus = self.population[i].copy()\n                        x_minus = self.population[i].copy()\n\n                        x_plus[d] = min(func.bounds.ub[d], x_plus[d] + self.local_search_step)\n                        x_minus[d] = max(func.bounds.lb[d], x_minus[d] - self.local_search_step)\n\n                        f_plus = func(x_plus)\n                        self.budget -=1 \n                        f_minus = func(x_minus)\n                        self.budget -= 1\n\n                        if self.budget <=0 :\n                            return self.f_opt, self.x_opt\n\n                        gradient[d] = (f_plus - f_minus) / (2 * self.local_search_step)\n\n                    # Move in the opposite direction of the gradient\n                    new_x = self.population[i] - self.local_search_step * gradient\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n\n                    if new_f < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = new_f\n\n            # Update best solution\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: name 'cosine_similarity' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with a niching strategy using cosine similarity to maintain diversity, coupled with a probabilistic local search based on gradient estimation.\n# Code: \n```python\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nclass CosineNichingProbabilisticSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, niche_radius=0.2, local_search_prob=0.1, local_search_step=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.niche_radius = niche_radius\n        self.local_search_prob = local_search_prob\n        self.local_search_step = local_search_step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Niching based on cosine similarity\n            similarities = cosine_similarity(self.population)\n            for i in range(self.pop_size):\n                for j in range(i + 1, self.pop_size):\n                    if similarities[i, j] > 1 - self.niche_radius:  # Cosine similarity close to 1 indicates similarity\n                        # Replace the worse individual with a new random one\n                        if self.fitness[i] > self.fitness[j]:\n                            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                            self.fitness[i] = func(self.population[i])\n                            self.budget -= 1\n                            if self.budget <= 0:\n                                break\n                        else:\n                            self.population[j] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                            self.fitness[j] = func(self.population[j])\n                            self.budget -= 1\n                            if self.budget <= 0:\n                                break\n                if self.budget <= 0:\n                    break\n\n\n            # Probabilistic local search with gradient estimation\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_prob:\n                    # Estimate gradient (simple finite difference)\n                    gradient = np.zeros(self.dim)\n                    for d in range(self.dim):\n                        x_plus = self.population[i].copy()\n                        x_minus = self.population[i].copy()\n\n                        x_plus[d] = min(func.bounds.ub[d], x_plus[d] + self.local_search_step)\n                        x_minus[d] = max(func.bounds.lb[d], x_minus[d] - self.local_search_step)\n\n                        f_plus = func(x_plus)\n                        self.budget -=1 \n                        f_minus = func(x_minus)\n                        self.budget -= 1\n\n                        if self.budget <=0 :\n                            return self.f_opt, self.x_opt\n\n                        gradient[d] = (f_plus - f_minus) / (2 * self.local_search_step)\n\n                    # Move in the opposite direction of the gradient\n                    new_x = self.population[i] - self.local_search_step * gradient\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n\n                    if new_f < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = new_f\n\n            # Update best solution\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.004124016062270856, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "80db541f-7a79-49c4-b29f-0c41117ee012", "fitness": 0.26332868684907706, "name": "AdaptiveGaussianSearch", "description": "Population-based algorithm with Gaussian perturbation and adaptive step size control, focusing on exploitation around promising solutions.", "code": "import numpy as np\n\nclass AdaptiveGaussianSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        step_size = np.full(self.pop_size, self.initial_step_size) # Individual step sizes\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Generate Gaussian perturbation\n                x_new = population[i] + step_size[i] * np.random.normal(0, 1, size=self.dim)\n\n                # Clip to bounds\n                x_new = np.clip(x_new, self.lb, self.ub)\n\n                f_new = func(x_new)\n                eval_count += 1\n\n                if f_new < fitness[i]:\n                    # Accept the new solution\n                    fitness[i] = f_new\n                    population[i] = x_new\n                    # Reduce step size\n                    step_size[i] *= 1.1\n                    \n                else:\n                    # Reject the new solution and shrink step size\n                    step_size[i] *= 0.85\n\n                # Update best solution\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianSearch scored 0.263 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with Gaussian perturbation and adaptive step size control, focusing on exploitation around promising solutions.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGaussianSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        step_size = np.full(self.pop_size, self.initial_step_size) # Individual step sizes\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Generate Gaussian perturbation\n                x_new = population[i] + step_size[i] * np.random.normal(0, 1, size=self.dim)\n\n                # Clip to bounds\n                x_new = np.clip(x_new, self.lb, self.ub)\n\n                f_new = func(x_new)\n                eval_count += 1\n\n                if f_new < fitness[i]:\n                    # Accept the new solution\n                    fitness[i] = f_new\n                    population[i] = x_new\n                    # Reduce step size\n                    step_size[i] *= 1.1\n                    \n                else:\n                    # Reject the new solution and shrink step size\n                    step_size[i] *= 0.85\n\n                # Update best solution\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.10879910102907797, 0.2426180051009369, 0.27069945497156556, 0.2566076060109218, 0.1560204943983894, 0.17792151832565284, 0.23024587823487586, 0.22362050204867046, 0.15894119758011382, 0.1688389030356202, 0.22218712267239293, 0.1990058817811312, 0.2904310019690093, 0.2793249706441736, 0.6398458214978614, 0.32069933018827557, 0.22055085312691902, 0.464160351672801, 0.14481657599409115, 0.49123916669906265], "operator": "random_new", "theta_sampled": 0.0029695076715859263, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "25345ecb-bd00-44c2-a4b7-0db3e9c40dce", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE", "description": "An adaptive hybrid PSO-DE algorithm with a self-adaptive local search radius and population diversity maintenance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, initial_local_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.local_radius = initial_local_radius\n        self.initial_local_radius = initial_local_radius\n        self.diversity_threshold = 0.1  # Threshold for triggering diversity maintenance\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        if self.budget <= 0:\n            return best_f, best_x\n\n        evaluations = min(5, self.budget) #Limit evaluations based on remaining budget.\n        for _ in range(evaluations): \n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n            if self.budget <= 0:\n                break\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        \n        generation = 0 # Keep track of generations.\n\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search with adaptive radius\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy(), self.local_radius)\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # Adjust local search radius adaptively\n            if generation % 10 == 0:\n              if gbest_fitness == pbest_fitness[np.argmin(pbest_fitness)]: #If gbest not changing much\n                self.local_radius *= 0.9  # Reduce radius if stuck\n              else:\n                self.local_radius = self.initial_local_radius\n\n            # Diversity maintenance\n            if self.calculate_diversity(pop) < self.diversity_threshold:\n                self.maintain_diversity(pop, func)\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(fitness)\n                gbest_pos = pop[gbest_index].copy()\n                gbest_fitness = fitness[gbest_index]\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n\n    def calculate_diversity(self, pop):\n        \"\"\"Calculates the diversity of the population.\"\"\"\n        centroid = np.mean(pop, axis=0)\n        distances = np.linalg.norm(pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity / (func.bounds.ub - func.bounds.lb)  # Normalize diversity\n\n    def maintain_diversity(self, pop, func):\n        \"\"\"Maintains diversity by re-initializing a portion of the population.\"\"\"\n        num_to_reinitialize = int(self.pop_size * 0.25)  # Re-initialize 25% of population\n        indices_to_reinitialize = np.random.choice(self.pop_size, num_to_reinitialize, replace=False)\n        for i in indices_to_reinitialize:\n            pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with a self-adaptive local search radius and population diversity maintenance.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, initial_local_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.local_radius = initial_local_radius\n        self.initial_local_radius = initial_local_radius\n        self.diversity_threshold = 0.1  # Threshold for triggering diversity maintenance\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        if self.budget <= 0:\n            return best_f, best_x\n\n        evaluations = min(5, self.budget) #Limit evaluations based on remaining budget.\n        for _ in range(evaluations): \n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n            if self.budget <= 0:\n                break\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        \n        generation = 0 # Keep track of generations.\n\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search with adaptive radius\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy(), self.local_radius)\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # Adjust local search radius adaptively\n            if generation % 10 == 0:\n              if gbest_fitness == pbest_fitness[np.argmin(pbest_fitness)]: #If gbest not changing much\n                self.local_radius *= 0.9  # Reduce radius if stuck\n              else:\n                self.local_radius = self.initial_local_radius\n\n            # Diversity maintenance\n            if self.calculate_diversity(pop) < self.diversity_threshold:\n                self.maintain_diversity(pop, func)\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(fitness)\n                gbest_pos = pop[gbest_index].copy()\n                gbest_fitness = fitness[gbest_index]\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n\n    def calculate_diversity(self, pop):\n        \"\"\"Calculates the diversity of the population.\"\"\"\n        centroid = np.mean(pop, axis=0)\n        distances = np.linalg.norm(pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity / (func.bounds.ub - func.bounds.lb)  # Normalize diversity\n\n    def maintain_diversity(self, pop, func):\n        \"\"\"Maintains diversity by re-initializing a portion of the population.\"\"\"\n        num_to_reinitialize = int(self.pop_size * 0.25)  # Re-initialize 25% of population\n        indices_to_reinitialize = np.random.choice(self.pop_size, num_to_reinitialize, replace=False)\n        for i in indices_to_reinitialize:\n            pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n```", "operator": "mutation", "theta_sampled": 0.005666196151166201, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "9a76ad9f-b0ef-4b73-a201-e031d2f316a5", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS_Diversity", "description": "Adaptively combines PSO and DE with a local search component and population diversity enhancement for robust global optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS_Diversity:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, diversity_threshold=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with local search and diversity control.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            diversity_threshold (float): Threshold for population diversity, used for restarting.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.diversity_threshold = diversity_threshold\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100  # Restart every 100 iterations if no improvement\n        self.v_max = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        self.velocities = np.clip(self.velocities, -self.v_max, self.v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                # Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        #self.func_evals += 1 #The fitness has already been calculated\n        \n        for _ in range(3):  # Reduced local search evaluations further\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)  # Keep probabilities away from 0 or 1\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the diversity of the population.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima and increase diversity.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with local search and diversity control.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n\n            # Adaptive PSO/DE Selection\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability and self.func_evals < self.budget:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.population[i] = local_x.copy()\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            # Diversity Check and Restart\n            diversity = self.calculate_diversity()\n            if diversity < self.diversity_threshold or self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n            if self.func_evals >= self.budget:\n                break\n                \n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS_Diversity scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with a local search component and population diversity enhancement for robust global optimization.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS_Diversity:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, diversity_threshold=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with local search and diversity control.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            diversity_threshold (float): Threshold for population diversity, used for restarting.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.diversity_threshold = diversity_threshold\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100  # Restart every 100 iterations if no improvement\n        self.v_max = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        self.velocities = np.clip(self.velocities, -self.v_max, self.v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                # Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        #self.func_evals += 1 #The fitness has already been calculated\n        \n        for _ in range(3):  # Reduced local search evaluations further\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)  # Keep probabilities away from 0 or 1\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the diversity of the population.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima and increase diversity.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with local search and diversity control.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n\n            # Adaptive PSO/DE Selection\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability and self.func_evals < self.budget:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.population[i] = local_x.copy()\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            # Diversity Check and Restart\n            diversity = self.calculate_diversity()\n            if diversity < self.diversity_threshold or self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n            if self.func_evals >= self.budget:\n                break\n                \n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "crossover", "theta_sampled": -0.0006833007233113441, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "dcf9de44-1522-4dbd-854e-024dfaefb7ff", "fitness": 0.5798701330495841, "name": "AdaptivePerturbedDE", "description": "Adaptive Perturbed Differential Evolution with velocity and archive to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePerturbedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.velocities = np.zeros((self.pop_size, self.dim))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Initialize Archive\n        self.archive = list(population)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Velocity update\n                self.velocities[i] = self.F * (x_r2 - x_r3)\n                x_mutated = population[i] + self.velocities[i]\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n                    #Update archive\n                    self.update_archive(x_trial)\n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n                    self.update_archive(x_perturbed)\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n                    self.update_archive(x_perturbed)\n\n            # Adaptive F and Cr (optional - can be enabled/disabled)\n            self.F = np.random.normal(0.5, 0.1)\n            self.Cr = np.random.normal(0.7, 0.1)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        return self.f_opt, self.x_opt\n\n    def update_archive(self, x):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n        else:\n            # Replace a random element in archive\n            index = np.random.randint(self.archive_size)\n            self.archive[index] = x", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptivePerturbedDE scored 0.580 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80e52b05-8bb9-4558-b094-6de755982aa6"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Perturbed Differential Evolution with velocity and archive to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePerturbedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.velocities = np.zeros((self.pop_size, self.dim))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Initialize Archive\n        self.archive = list(population)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Velocity update\n                self.velocities[i] = self.F * (x_r2 - x_r3)\n                x_mutated = population[i] + self.velocities[i]\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n                    #Update archive\n                    self.update_archive(x_trial)\n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n                    self.update_archive(x_perturbed)\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n                    self.update_archive(x_perturbed)\n\n            # Adaptive F and Cr (optional - can be enabled/disabled)\n            self.F = np.random.normal(0.5, 0.1)\n            self.Cr = np.random.normal(0.7, 0.1)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        return self.f_opt, self.x_opt\n\n    def update_archive(self, x):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n        else:\n            # Replace a random element in archive\n            index = np.random.randint(self.archive_size)\n            self.archive[index] = x\n```", "aucs": [0.19706000628614595, 0.4960855770260968, 0.607899898357855, 0.8301311188354248, 0.5847541961865589, 0.7353560662382601, 0.34555873492241906, 0.5005163712289493, 0.6147742192188191, 0.4204882780100655, 0.821669537164022, 0.9972084420931074, 0.4388699697586772, 0.4567748913858781, 0.8865652587460086, 0.6846190398986791, 0.45084551132106065, 0.8064082030056966, 0.21480109477326548, 0.5070162465346901], "operator": "mutation", "theta_sampled": 0.005333693609734926, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "50c8026e-61ee-45ab-9ad0-b18f71a4a627", "fitness": 0.0, "name": "AdaptiveExplorationExploitation", "description": "This algorithm combines a simplified CMA-ES strategy for global exploration with a local search using Nelder-Mead simplex for exploitation, adaptively switching between them based on success rates.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveExplorationExploitation:\n    def __init__(self, budget=10000, dim=10, exploration_ratio=0.5, local_search_iterations=10):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_ratio = exploration_ratio\n        self.local_search_iterations = local_search_iterations\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.zeros(dim)\n        self.sigma = 1.0\n        self.success_rate = 0.0\n        self.success_history = []\n        self.history_length = 10\n        self.exploration_count = 0\n        self.exploitation_count = 0\n\n    def sample(self):\n        return self.mean + self.sigma * np.random.randn(self.dim)\n\n    def local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead',\n                       bounds=[(self.lb, self.ub)] * self.dim,\n                       options={'maxiter': self.local_search_iterations})\n        return res.fun, res.x\n\n    def update_success_rate(self, success):\n        self.success_history.append(success)\n        if len(self.success_history) > self.history_length:\n            self.success_history.pop(0)\n        self.success_rate = np.mean(self.success_history)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            if np.random.rand() < self.exploration_ratio:\n                # Exploration (Simplified CMA-ES)\n                self.exploration_count += 1\n                x = self.sample()\n                x = np.clip(x, self.lb, self.ub)\n                f = func(x)\n                eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    self.mean = x\n                    self.sigma *= 0.9  # Reduce step size if successful\n                    self.update_success_rate(True)\n                else:\n                    self.sigma *= 1.1  # Increase step size if unsuccessful\n                    self.update_success_rate(False)\n                    \n            else:\n                # Exploitation (Local Search)\n                self.exploitation_count += 1\n                x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f_local, x_local = self.local_search(func, x0)\n                eval_count += self.local_search_iterations # Account for local search evals\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                    self.update_success_rate(True)\n                else:\n                    self.update_success_rate(False)\n            \n            # Budget Check (Crucial after local search iterations)\n            if eval_count >= self.budget:\n                break\n\n\n            # Adapt exploration ratio based on success\n            self.exploration_ratio = 0.5 + 0.3 * np.tanh(5 * (self.success_rate - 0.5))\n\n            self.sigma = np.clip(self.sigma, 0.01, 2.0) # keep sigma in bounds\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: This algorithm combines a simplified CMA-ES strategy for global exploration with a local search using Nelder-Mead simplex for exploitation, adaptively switching between them based on success rates.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveExplorationExploitation:\n    def __init__(self, budget=10000, dim=10, exploration_ratio=0.5, local_search_iterations=10):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_ratio = exploration_ratio\n        self.local_search_iterations = local_search_iterations\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.zeros(dim)\n        self.sigma = 1.0\n        self.success_rate = 0.0\n        self.success_history = []\n        self.history_length = 10\n        self.exploration_count = 0\n        self.exploitation_count = 0\n\n    def sample(self):\n        return self.mean + self.sigma * np.random.randn(self.dim)\n\n    def local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead',\n                       bounds=[(self.lb, self.ub)] * self.dim,\n                       options={'maxiter': self.local_search_iterations})\n        return res.fun, res.x\n\n    def update_success_rate(self, success):\n        self.success_history.append(success)\n        if len(self.success_history) > self.history_length:\n            self.success_history.pop(0)\n        self.success_rate = np.mean(self.success_history)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            if np.random.rand() < self.exploration_ratio:\n                # Exploration (Simplified CMA-ES)\n                self.exploration_count += 1\n                x = self.sample()\n                x = np.clip(x, self.lb, self.ub)\n                f = func(x)\n                eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    self.mean = x\n                    self.sigma *= 0.9  # Reduce step size if successful\n                    self.update_success_rate(True)\n                else:\n                    self.sigma *= 1.1  # Increase step size if unsuccessful\n                    self.update_success_rate(False)\n                    \n            else:\n                # Exploitation (Local Search)\n                self.exploitation_count += 1\n                x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f_local, x_local = self.local_search(func, x0)\n                eval_count += self.local_search_iterations # Account for local search evals\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                    self.update_success_rate(True)\n                else:\n                    self.update_success_rate(False)\n            \n            # Budget Check (Crucial after local search iterations)\n            if eval_count >= self.budget:\n                break\n\n\n            # Adapt exploration ratio based on success\n            self.exploration_ratio = 0.5 + 0.3 * np.tanh(5 * (self.success_rate - 0.5))\n\n            self.sigma = np.clip(self.sigma, 0.01, 2.0) # keep sigma in bounds\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.003226560564432838, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "780a44a1-46ca-4aea-8754-b0e943f6a41a", "fitness": 0.5212999476184185, "name": "AdaptiveStochasticDE", "description": "Adaptive Stochastic DE with velocity-based mutation, enhanced adaptation of F and Cr, and population-based local search.", "code": "import numpy as np\n\nclass AdaptiveStochasticDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.7, local_search_rate=0.1, local_search_radius=0.1, ranking_probability=0.45, velocity_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial  # Scaling factor for DE\n        self.Cr = Cr_initial  # Crossover rate for DE\n        self.local_search_rate = local_search_rate\n        self.local_search_radius = local_search_radius\n        self.ranking_probability = ranking_probability\n        self.velocity_weight = velocity_weight\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities for velocity-based mutation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        generation = 0\n        success_F = []\n        success_Cr = []\n        while self.budget > 0:\n            generation += 1\n            # Adaptive F and Cr (adjust based on success)\n            success_indices = []\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation with Velocity\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Update velocity\n                self.velocities[i] = self.velocity_weight * self.velocities[i] + self.F * (x_r2 - x_r3)\n                \n                x_mutated = population[i] + self.velocities[i] # self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic Ranking\n                if (fitness[i] < self.f_opt or f_trial < self.f_opt) and np.random.rand() < self.ranking_probability:\n                    if f_trial < fitness[i]:\n                        fitness[i] = f_trial\n                        population[i] = x_trial\n                        success_indices.append(i)\n                        success_F.append(self.F)\n                        success_Cr.append(self.Cr)\n\n                        # Update best solution\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n                else:\n                    if f_trial < fitness[i]:\n                         fitness[i] = f_trial\n                         population[i] = x_trial\n                         success_indices.append(i)\n                         success_F.append(self.F)\n                         success_Cr.append(self.Cr)\n\n                         # Update best solution\n                         if f_trial < self.f_opt:\n                             self.f_opt = f_trial\n                             self.x_opt = x_trial\n            \n            #Adapt F and Cr\n            if len(success_indices) > 0:\n                #Lehmer Mean adaptation\n                F_mean = np.sum(np.array(success_F)**2) / np.sum(np.array(success_F)) if len(success_F) > 0 else np.random.uniform(0.1, 0.9)\n                Cr_mean = np.sum(np.array(success_Cr)**2) / np.sum(np.array(success_Cr)) if len(success_Cr) > 0 else np.random.uniform(0.1, 0.9)\n\n                self.F = np.clip(np.random.normal(F_mean, 0.3), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(Cr_mean, 0.2), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n            success_F = []\n            success_Cr = []\n\n            # Population-based Local Search\n            if np.random.rand() < self.local_search_rate and self.budget > self.pop_size:\n                # Select individuals for local search (e.g., top 20%)\n                num_local_search = int(self.pop_size * 0.2)\n                indices_to_search = np.argsort(fitness)[:num_local_search]\n\n                for idx in indices_to_search:\n                    x_local = population[idx] + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < fitness[idx]:\n                        fitness[idx] = f_local\n                        population[idx] = x_local\n\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveStochasticDE scored 0.521 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d4891ac-838f-42e3-bcb1-7fc60abca5e7"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Stochastic DE with velocity-based mutation, enhanced adaptation of F and Cr, and population-based local search.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveStochasticDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.7, local_search_rate=0.1, local_search_radius=0.1, ranking_probability=0.45, velocity_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial  # Scaling factor for DE\n        self.Cr = Cr_initial  # Crossover rate for DE\n        self.local_search_rate = local_search_rate\n        self.local_search_radius = local_search_radius\n        self.ranking_probability = ranking_probability\n        self.velocity_weight = velocity_weight\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities for velocity-based mutation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        generation = 0\n        success_F = []\n        success_Cr = []\n        while self.budget > 0:\n            generation += 1\n            # Adaptive F and Cr (adjust based on success)\n            success_indices = []\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation with Velocity\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Update velocity\n                self.velocities[i] = self.velocity_weight * self.velocities[i] + self.F * (x_r2 - x_r3)\n                \n                x_mutated = population[i] + self.velocities[i] # self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic Ranking\n                if (fitness[i] < self.f_opt or f_trial < self.f_opt) and np.random.rand() < self.ranking_probability:\n                    if f_trial < fitness[i]:\n                        fitness[i] = f_trial\n                        population[i] = x_trial\n                        success_indices.append(i)\n                        success_F.append(self.F)\n                        success_Cr.append(self.Cr)\n\n                        # Update best solution\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n                else:\n                    if f_trial < fitness[i]:\n                         fitness[i] = f_trial\n                         population[i] = x_trial\n                         success_indices.append(i)\n                         success_F.append(self.F)\n                         success_Cr.append(self.Cr)\n\n                         # Update best solution\n                         if f_trial < self.f_opt:\n                             self.f_opt = f_trial\n                             self.x_opt = x_trial\n            \n            #Adapt F and Cr\n            if len(success_indices) > 0:\n                #Lehmer Mean adaptation\n                F_mean = np.sum(np.array(success_F)**2) / np.sum(np.array(success_F)) if len(success_F) > 0 else np.random.uniform(0.1, 0.9)\n                Cr_mean = np.sum(np.array(success_Cr)**2) / np.sum(np.array(success_Cr)) if len(success_Cr) > 0 else np.random.uniform(0.1, 0.9)\n\n                self.F = np.clip(np.random.normal(F_mean, 0.3), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(Cr_mean, 0.2), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n            success_F = []\n            success_Cr = []\n\n            # Population-based Local Search\n            if np.random.rand() < self.local_search_rate and self.budget > self.pop_size:\n                # Select individuals for local search (e.g., top 20%)\n                num_local_search = int(self.pop_size * 0.2)\n                indices_to_search = np.argsort(fitness)[:num_local_search]\n\n                for idx in indices_to_search:\n                    x_local = population[idx] + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < fitness[idx]:\n                        fitness[idx] = f_local\n                        population[idx] = x_local\n\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19729832249405277, 0.3206750852148442, 0.47816212291936433, 0.7904019399008583, 0.4844928187852158, 0.6117496033295103, 0.3278529291462541, 0.4410276946105838, 0.45961040691842037, 0.26299044879309197, 0.7948052371102025, 0.9941971183103985, 0.4685566896978315, 0.3964308249882246, 0.8497743773234159, 0.6227502399435425, 0.40908523009202413, 0.7759043832338319, 0.24527449340147212, 0.49495898615522904], "operator": "mutation", "theta_sampled": 0.007654203711897725, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "89945d36-a299-4fd4-b795-a086e73ddc5c", "fitness": 0.5410187522200676, "name": "AdaptiveHybridPSO_DE_SA_CMA", "description": "An adaptive hybrid algorithm that dynamically adjusts PSO/DE probabilities and parameters based on their success and population diversity, incorporating a Simulated Annealing-inspired acceptance criterion for DE to escape local optima, and a CMA-ES-based parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_SA_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, initial_temp=1.0, temp_decay=0.95, cma_learning_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Simulated Annealing and CMA-ES.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            initial_temp (float): Initial temperature for Simulated Annealing.\n            temp_decay (float): Temperature decay rate for Simulated Annealing.\n            cma_learning_rate (float): Learning rate for CMA-ES parameter adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.initial_temp = initial_temp\n        self.temp = initial_temp\n        self.temp_decay = temp_decay\n        self.cma_learning_rate = cma_learning_rate\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.diversity = 0.0 # Track population diversity\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.update_diversity()\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with Simulated Annealing.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection with Simulated Annealing\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            delta_f = f_trial - self.fitness[i]\n            if delta_f < 0:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n            else:\n                # Simulated Annealing acceptance criterion\n                acceptance_prob = np.exp(-delta_f / self.temp)\n                if np.random.rand() < acceptance_prob:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n            \n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n        self.temp *= self.temp_decay #Cooling\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success and population diversity.\n        Also adapts DE's F and CR parameters using CMA-ES principles.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n        \n        # Parameter adaptation for DE (Simplified CMA-ES)\n        if avg_de_success > 0.5:  # If DE is performing well\n            self.f *= (1 + self.cma_learning_rate)\n            self.cr *= (1 + self.cma_learning_rate)\n        else:\n            self.f *= (1 - self.cma_learning_rate)\n            self.cr *= (1 - self.cma_learning_rate)\n\n        self.f = np.clip(self.f, 0.1, 1.0)\n        self.cr = np.clip(self.cr, 0.1, 1.0)\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.update_diversity()\n\n    def update_diversity(self):\n        \"\"\"\n        Calculates and updates the population diversity.\n        \"\"\"\n        center = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - center, axis=1)\n        self.diversity = np.mean(distances)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with SA and CMA-ES.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        self.temp = self.initial_temp #Reset temperature\n\n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE_SA_CMA scored 0.541 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm that dynamically adjusts PSO/DE probabilities and parameters based on their success and population diversity, incorporating a Simulated Annealing-inspired acceptance criterion for DE to escape local optima, and a CMA-ES-based parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_SA_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, initial_temp=1.0, temp_decay=0.95, cma_learning_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Simulated Annealing and CMA-ES.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            initial_temp (float): Initial temperature for Simulated Annealing.\n            temp_decay (float): Temperature decay rate for Simulated Annealing.\n            cma_learning_rate (float): Learning rate for CMA-ES parameter adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.initial_temp = initial_temp\n        self.temp = initial_temp\n        self.temp_decay = temp_decay\n        self.cma_learning_rate = cma_learning_rate\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.diversity = 0.0 # Track population diversity\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.update_diversity()\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with Simulated Annealing.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection with Simulated Annealing\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            delta_f = f_trial - self.fitness[i]\n            if delta_f < 0:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n            else:\n                # Simulated Annealing acceptance criterion\n                acceptance_prob = np.exp(-delta_f / self.temp)\n                if np.random.rand() < acceptance_prob:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n            \n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n        self.temp *= self.temp_decay #Cooling\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success and population diversity.\n        Also adapts DE's F and CR parameters using CMA-ES principles.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n        \n        # Parameter adaptation for DE (Simplified CMA-ES)\n        if avg_de_success > 0.5:  # If DE is performing well\n            self.f *= (1 + self.cma_learning_rate)\n            self.cr *= (1 + self.cma_learning_rate)\n        else:\n            self.f *= (1 - self.cma_learning_rate)\n            self.cr *= (1 - self.cma_learning_rate)\n\n        self.f = np.clip(self.f, 0.1, 1.0)\n        self.cr = np.clip(self.cr, 0.1, 1.0)\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.update_diversity()\n\n    def update_diversity(self):\n        \"\"\"\n        Calculates and updates the population diversity.\n        \"\"\"\n        center = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - center, axis=1)\n        self.diversity = np.mean(distances)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with SA and CMA-ES.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        self.temp = self.initial_temp #Reset temperature\n\n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.23449752259388146, 0.39799210920198735, 0.4491607819483806, 0.8710707869805667, 0.5577851108416667, 0.532976570281005, 0.41890365529125007, 0.5256749078184682, 0.676565171075347, 0.321150105697494, 0.72134266836285, 0.9996525036501023, 0.3219257769133822, 0.6002791270130521, 0.8659390362477382, 0.48369626396780974, 0.4663033066826592, 0.655214001831501, 0.20341467561735194, 0.5168309623848556], "operator": "mutation", "theta_sampled": 0.006618023875873373, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "bd989e82-7167-4717-8dd7-35de2f210ffb", "fitness": 0.0, "name": "AdaptiveDE_NM", "description": "An enhanced Differential Evolution with adaptive parameters and a local search component using Nelder-Mead simplex method.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.local_search_prob = local_search_prob # Probability of performing local search\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Adaptive Parameter Control\n            self.F = 0.5 + 0.4 * np.exp(-generation / 100) #Decaying F\n            self.Cr = 0.1 + 0.8 * np.exp(-generation / 150) #Decaying Cr\n\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Local Search using Nelder-Mead\n            if np.random.rand() < self.local_search_prob and self.budget > self.dim + 1:  # Ensure enough budget for Nelder-Mead\n                \n                # Define a wrapper for the objective function that decrements the budget\n                def func_wrapper(x):\n                    nonlocal self\n                    if self.budget > 0:\n                        self.budget -= 1\n                        return func(x)\n                    else:\n                        return np.inf  # Return a high value if the budget is exhausted\n\n                result = minimize(func_wrapper, self.x_opt, method='Nelder-Mead',\n                                   bounds=np.array(list(zip(func.bounds.lb, func.bounds.ub))),\n                                   options={'maxfev': self.budget // 20, 'adaptive': True}) # Limit the number of function evaluations\n                \n                if result.fun < self.f_opt:\n                    self.f_opt = result.fun\n                    self.x_opt = result.x\n                    \n                    # Replace a poorly performing individual with the result of the local search\n                    worst_index = np.argmax(fitness)\n                    fitness[worst_index] = self.f_opt\n                    population[worst_index] = self.x_opt\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["80e52b05-8bb9-4558-b094-6de755982aa6"], "operator": "mutation", "metadata": {"llm_response": "# Description: An enhanced Differential Evolution with adaptive parameters and a local search component using Nelder-Mead simplex method.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.local_search_prob = local_search_prob # Probability of performing local search\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Adaptive Parameter Control\n            self.F = 0.5 + 0.4 * np.exp(-generation / 100) #Decaying F\n            self.Cr = 0.1 + 0.8 * np.exp(-generation / 150) #Decaying Cr\n\n\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Local Search using Nelder-Mead\n            if np.random.rand() < self.local_search_prob and self.budget > self.dim + 1:  # Ensure enough budget for Nelder-Mead\n                \n                # Define a wrapper for the objective function that decrements the budget\n                def func_wrapper(x):\n                    nonlocal self\n                    if self.budget > 0:\n                        self.budget -= 1\n                        return func(x)\n                    else:\n                        return np.inf  # Return a high value if the budget is exhausted\n\n                result = minimize(func_wrapper, self.x_opt, method='Nelder-Mead',\n                                   bounds=np.array(list(zip(func.bounds.lb, func.bounds.ub))),\n                                   options={'maxfev': self.budget // 20, 'adaptive': True}) # Limit the number of function evaluations\n                \n                if result.fun < self.f_opt:\n                    self.f_opt = result.fun\n                    self.x_opt = result.x\n                    \n                    # Replace a poorly performing individual with the result of the local search\n                    worst_index = np.argmax(fitness)\n                    fitness[worst_index] = self.f_opt\n                    population[worst_index] = self.x_opt\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.010464991856736787, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "682d64ab-4ee5-42d1-8197-8edf869426d2", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_Ortho", "description": "Implements a self-adaptive hybrid PSO-DE with dynamic parameter control and a novel population diversity maintenance strategy using orthogonal learning.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Ortho:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_range=(0.4, 0.9), c_range=(1.5, 2.5), cr_range=(0.3, 0.9), f_range=(0.3, 1.0), pso_prob=0.5, success_memory=10, ortho_group_size=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE with Orthogonal Learning algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_range (tuple): Range for inertia weight for PSO.\n            c_range (tuple): Range for cognitive and social coefficients for PSO.\n            cr_range (tuple): Range for Crossover rate for DE.\n            f_range (tuple): Range for Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            ortho_group_size (int): Size of the group for orthogonal learning.  Must divide pop_size evenly.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_range = w_range\n        self.c_range = c_range\n        self.cr_range = cr_range\n        self.f_range = f_range\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.ortho_group_size = ortho_group_size\n        assert self.pop_size % self.ortho_group_size == 0, \"pop_size must be divisible by ortho_group_size\"\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n        # Initialize dynamic parameters\n        self.w = np.random.uniform(self.w_range[0], self.w_range[1])\n        self.c1 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.c2 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.cr = np.random.uniform(self.cr_range[0], self.cr_range[1])\n        self.f = np.random.uniform(self.f_range[0], self.f_range[1])\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def orthogonal_learning(self, func):\n        \"\"\"\n        Applies orthogonal learning to improve population diversity.\n        \"\"\"\n        group_size = self.ortho_group_size\n        num_groups = self.pop_size // group_size\n\n        for g in range(num_groups):\n            group_indices = range(g * group_size, (g + 1) * group_size)\n            group = self.population[group_indices]\n            \n            # Select dimensions for orthogonal design\n            num_factors = min(self.dim, group_size -1)  # Factors cannot exceed the number of individuals in a group.\n            selected_dims = np.random.choice(self.dim, num_factors, replace=False)\n\n            # Create orthogonal array (simplified for demonstration - replace with a proper OA generator)\n            oa = np.array([[ -1, -1],\n                           [ 1, -1],\n                           [-1,  1],\n                           [ 1,  1]]) # Example OA(4, 2, 2)\n            \n            if group_size == 5:\n                oa = np.array([[-1, -1, -1], [1, -1, -1], [-1, 1, -1], [1, 1, -1], [-1, -1, 1]])\n            elif group_size > 5:\n                continue # Skip for demonstration; needs larger OA\n\n            oa_size = oa.shape[0]\n            \n            trial_solutions = np.zeros((oa_size, self.dim))\n            \n            for i in range(oa_size):\n                trial = group[0].copy()\n                for j, dim_index in enumerate(selected_dims):\n                    factor_level = oa[i, j]\n                    \n                    #Map factor level to search space range.  Scale and shift.\n                    dim_range = func.bounds.ub[dim_index] - func.bounds.lb[dim_index]\n                    trial[dim_index] = group[0, dim_index] + factor_level * 0.25 * dim_range  #Explore around centroid. Can adaptive adjust multiplier.\n\n                    trial[dim_index] = np.clip(trial[dim_index], func.bounds.lb[dim_index], func.bounds.ub[dim_index])\n\n                trial_solutions[i] = trial\n            \n            trial_fitnesses = np.array([func(x) for x in trial_solutions])\n            self.func_evals += oa_size\n\n            best_trial_index = np.argmin(trial_fitnesses)\n            best_trial_solution = trial_solutions[best_trial_index]\n            best_trial_fitness = trial_fitnesses[best_trial_index]\n\n            # Replace the worst member of the group with the best trial solution\n            worst_group_index = group_indices[np.argmax(self.fitness[group_indices])]\n            if best_trial_fitness < self.fitness[worst_group_index]:\n                self.population[worst_group_index] = best_trial_solution\n                self.fitness[worst_group_index] = best_trial_fitness\n                \n                #Update pbest and gbest\n                if best_trial_fitness < self.personal_best_fitness[worst_group_index]:\n                  self.personal_best_fitness[worst_group_index] = best_trial_fitness\n                  self.personal_best_positions[worst_group_index] = best_trial_solution.copy()\n                \n                if best_trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = best_trial_fitness\n                    self.global_best_position = best_trial_solution.copy()\n            \n            \n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def update_dynamic_parameters(self):\n        \"\"\"\n        Dynamically adjusts PSO and DE parameters.\n        \"\"\"\n        self.w = np.random.uniform(self.w_range[0], self.w_range[1])\n        self.c1 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.c2 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.cr = np.random.uniform(self.cr_range[0], self.cr_range[1])\n        self.f = np.random.uniform(self.f_range[0], self.f_range[1])\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n                \n            # Apply Orthogonal Learning for diversity maintenance\n            if self.func_evals < 0.8 * self.budget: # Apply before running out of budget.\n                self.orthogonal_learning(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.update_dynamic_parameters()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: index 3 is out of bounds for axis 1 with size 3", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements a self-adaptive hybrid PSO-DE with dynamic parameter control and a novel population diversity maintenance strategy using orthogonal learning.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Ortho:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_range=(0.4, 0.9), c_range=(1.5, 2.5), cr_range=(0.3, 0.9), f_range=(0.3, 1.0), pso_prob=0.5, success_memory=10, ortho_group_size=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE with Orthogonal Learning algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_range (tuple): Range for inertia weight for PSO.\n            c_range (tuple): Range for cognitive and social coefficients for PSO.\n            cr_range (tuple): Range for Crossover rate for DE.\n            f_range (tuple): Range for Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            ortho_group_size (int): Size of the group for orthogonal learning.  Must divide pop_size evenly.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_range = w_range\n        self.c_range = c_range\n        self.cr_range = cr_range\n        self.f_range = f_range\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.ortho_group_size = ortho_group_size\n        assert self.pop_size % self.ortho_group_size == 0, \"pop_size must be divisible by ortho_group_size\"\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n        # Initialize dynamic parameters\n        self.w = np.random.uniform(self.w_range[0], self.w_range[1])\n        self.c1 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.c2 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.cr = np.random.uniform(self.cr_range[0], self.cr_range[1])\n        self.f = np.random.uniform(self.f_range[0], self.f_range[1])\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def orthogonal_learning(self, func):\n        \"\"\"\n        Applies orthogonal learning to improve population diversity.\n        \"\"\"\n        group_size = self.ortho_group_size\n        num_groups = self.pop_size // group_size\n\n        for g in range(num_groups):\n            group_indices = range(g * group_size, (g + 1) * group_size)\n            group = self.population[group_indices]\n            \n            # Select dimensions for orthogonal design\n            num_factors = min(self.dim, group_size -1)  # Factors cannot exceed the number of individuals in a group.\n            selected_dims = np.random.choice(self.dim, num_factors, replace=False)\n\n            # Create orthogonal array (simplified for demonstration - replace with a proper OA generator)\n            oa = np.array([[ -1, -1],\n                           [ 1, -1],\n                           [-1,  1],\n                           [ 1,  1]]) # Example OA(4, 2, 2)\n            \n            if group_size == 5:\n                oa = np.array([[-1, -1, -1], [1, -1, -1], [-1, 1, -1], [1, 1, -1], [-1, -1, 1]])\n            elif group_size > 5:\n                continue # Skip for demonstration; needs larger OA\n\n            oa_size = oa.shape[0]\n            \n            trial_solutions = np.zeros((oa_size, self.dim))\n            \n            for i in range(oa_size):\n                trial = group[0].copy()\n                for j, dim_index in enumerate(selected_dims):\n                    factor_level = oa[i, j]\n                    \n                    #Map factor level to search space range.  Scale and shift.\n                    dim_range = func.bounds.ub[dim_index] - func.bounds.lb[dim_index]\n                    trial[dim_index] = group[0, dim_index] + factor_level * 0.25 * dim_range  #Explore around centroid. Can adaptive adjust multiplier.\n\n                    trial[dim_index] = np.clip(trial[dim_index], func.bounds.lb[dim_index], func.bounds.ub[dim_index])\n\n                trial_solutions[i] = trial\n            \n            trial_fitnesses = np.array([func(x) for x in trial_solutions])\n            self.func_evals += oa_size\n\n            best_trial_index = np.argmin(trial_fitnesses)\n            best_trial_solution = trial_solutions[best_trial_index]\n            best_trial_fitness = trial_fitnesses[best_trial_index]\n\n            # Replace the worst member of the group with the best trial solution\n            worst_group_index = group_indices[np.argmax(self.fitness[group_indices])]\n            if best_trial_fitness < self.fitness[worst_group_index]:\n                self.population[worst_group_index] = best_trial_solution\n                self.fitness[worst_group_index] = best_trial_fitness\n                \n                #Update pbest and gbest\n                if best_trial_fitness < self.personal_best_fitness[worst_group_index]:\n                  self.personal_best_fitness[worst_group_index] = best_trial_fitness\n                  self.personal_best_positions[worst_group_index] = best_trial_solution.copy()\n                \n                if best_trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = best_trial_fitness\n                    self.global_best_position = best_trial_solution.copy()\n            \n            \n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def update_dynamic_parameters(self):\n        \"\"\"\n        Dynamically adjusts PSO and DE parameters.\n        \"\"\"\n        self.w = np.random.uniform(self.w_range[0], self.w_range[1])\n        self.c1 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.c2 = np.random.uniform(self.c_range[0], self.c_range[1])\n        self.cr = np.random.uniform(self.cr_range[0], self.cr_range[1])\n        self.f = np.random.uniform(self.f_range[0], self.f_range[1])\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n                \n            # Apply Orthogonal Learning for diversity maintenance\n            if self.func_evals < 0.8 * self.budget: # Apply before running out of budget.\n                self.orthogonal_learning(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.update_dynamic_parameters()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "mutation", "theta_sampled": 0.004593879705767871, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "5f9bbb57-8043-4563-8659-af0ba9263c71", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMAES", "description": "An adaptive hybrid algorithm that dynamically adjusts the PSO/DE ratio based on their respective success rates, incorporates a CMA-ES-based mutation operator, and employs a Cauchy mutation-based local search for enhanced exploration and exploitation.", "code": "import numpy as np\nimport cma\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, cma_sigma = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma #Initial CMA-ES sigma\n        self.cma_es = None  # CMA-ES optimizer (initialized later)\n\n    def cauchy_mutation(self, x, scale=0.1):\n        \"\"\"Performs Cauchy mutation on x.\"\"\"\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def local_search(self, func, x, scale=0.1):\n        \"\"\"Performs a local search around x using Cauchy mutation.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = self.cauchy_mutation(x, scale)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        # Initialize CMA-ES\n        self.cma_es = cma.purecma.CMAES(gbest_pos, self.cma_sigma,\n                                           {'bounds': [func.bounds.lb, func.bounds.ub],\n                                            'verbose': -9})\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update with CMA-ES mutation\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    # CMA-ES mutation\n                    solutions = self.cma_es.ask(1)\n                    mutated_vector = solutions[0]\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = mutated_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                        # Tell CMA-ES about the new best solution\n                        self.cma_es.tell([(gbest_pos, gbest_fitness)])\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                            # Tell CMA-ES about the new best solution\n                            self.cma_es.tell([(gbest_pos, gbest_fitness)])\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: No module named 'cma'", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm that dynamically adjusts the PSO/DE ratio based on their respective success rates, incorporates a CMA-ES-based mutation operator, and employs a Cauchy mutation-based local search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nimport cma\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, cma_sigma = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma #Initial CMA-ES sigma\n        self.cma_es = None  # CMA-ES optimizer (initialized later)\n\n    def cauchy_mutation(self, x, scale=0.1):\n        \"\"\"Performs Cauchy mutation on x.\"\"\"\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def local_search(self, func, x, scale=0.1):\n        \"\"\"Performs a local search around x using Cauchy mutation.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = self.cauchy_mutation(x, scale)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        # Initialize CMA-ES\n        self.cma_es = cma.purecma.CMAES(gbest_pos, self.cma_sigma,\n                                           {'bounds': [func.bounds.lb, func.bounds.ub],\n                                            'verbose': -9})\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update with CMA-ES mutation\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    # CMA-ES mutation\n                    solutions = self.cma_es.ask(1)\n                    mutated_vector = solutions[0]\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = mutated_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                        # Tell CMA-ES about the new best solution\n                        self.cma_es.tell([(gbest_pos, gbest_fitness)])\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                            # Tell CMA-ES about the new best solution\n                            self.cma_es.tell([(gbest_pos, gbest_fitness)])\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "operator": "mutation", "theta_sampled": 0.002341733094578282, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "9566e25e-8203-4bbd-a900-b7197ee9c496", "fitness": 0.0, "name": "GradientEnhancedDE", "description": "A population-based algorithm that combines aspects of differential evolution with a local search strategy based on gradient estimation.", "code": "import numpy as np\n\nclass GradientEnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, f=0.5, cr=0.9, grad_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.grad_steps = grad_steps\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.cr\n                trial = np.where(cross_mask, mutant, population[i])\n\n                # Gradient Estimation and Local Search\n                grad_est = np.zeros(self.dim)\n                f_center = func(trial)\n                self.budget -= 1\n                if f_center < self.f_opt:\n                    self.f_opt = f_center\n                    self.x_opt = trial\n                    \n                for d in range(self.dim):\n                    delta = np.zeros(self.dim)\n                    delta[d] = 1e-4  # Small perturbation\n                    x_plus = trial + delta\n                    x_minus = trial - delta\n                    x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                    x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n                    \n                    f_plus = func(x_plus)\n                    self.budget -= 1\n                    if f_plus < self.f_opt:\n                        self.f_opt = f_plus\n                        self.x_opt = x_plus\n                        \n                    f_minus = func(x_minus)\n                    self.budget -= 1\n                    if f_minus < self.f_opt:\n                        self.f_opt = f_minus\n                        self.x_opt = x_minus\n                    grad_est[d] = (f_plus - f_minus) / (2 * 1e-4)\n\n                # Move in the direction of the estimated gradient\n                step_size = 0.01  # Learning rate for gradient descent\n                new_trial = trial - step_size * grad_est\n                new_trial = np.clip(new_trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(new_trial)\n                self.budget -= 1\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = new_trial\n                    \n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = new_trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = new_trial\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm GradientEnhancedDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution with a local search strategy based on gradient estimation.\n# Code: \n```python\nimport numpy as np\n\nclass GradientEnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, f=0.5, cr=0.9, grad_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.grad_steps = grad_steps\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.cr\n                trial = np.where(cross_mask, mutant, population[i])\n\n                # Gradient Estimation and Local Search\n                grad_est = np.zeros(self.dim)\n                f_center = func(trial)\n                self.budget -= 1\n                if f_center < self.f_opt:\n                    self.f_opt = f_center\n                    self.x_opt = trial\n                    \n                for d in range(self.dim):\n                    delta = np.zeros(self.dim)\n                    delta[d] = 1e-4  # Small perturbation\n                    x_plus = trial + delta\n                    x_minus = trial - delta\n                    x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                    x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n                    \n                    f_plus = func(x_plus)\n                    self.budget -= 1\n                    if f_plus < self.f_opt:\n                        self.f_opt = f_plus\n                        self.x_opt = x_plus\n                        \n                    f_minus = func(x_minus)\n                    self.budget -= 1\n                    if f_minus < self.f_opt:\n                        self.f_opt = f_minus\n                        self.x_opt = x_minus\n                    grad_est[d] = (f_plus - f_minus) / (2 * 1e-4)\n\n                # Move in the direction of the estimated gradient\n                step_size = 0.01  # Learning rate for gradient descent\n                new_trial = trial - step_size * grad_est\n                new_trial = np.clip(new_trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(new_trial)\n                self.budget -= 1\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = new_trial\n                    \n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = new_trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = new_trial\n                    \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.006044373471762677, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "1b804195-a9c3-4fda-9a0d-242e768749c7", "fitness": 0.5842052195323686, "name": "AdaptivePerturbedDE", "description": "An Adaptive Perturbed DE with a more robust adaptation of F and Cr, using a weighted average based on success rate, and also an additional mutation strategy using archive members to enhance exploration.", "code": "import numpy as np\n\nclass AdaptivePerturbedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05, archive_size=10, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.adapt_rate = adapt_rate # Rate to adapt F and Cr\n        self.success_F = []\n        self.success_Cr = []\n        self.sf_memory = []\n        self.scr_memory = []\n        self.sf_memsize = 10\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Initialize Archive\n        self.archive = list(population)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Velocity update\n                self.velocities[i] = self.F * (x_r2 - x_r3)\n                x_mutated = population[i] + self.velocities[i]\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Additional Mutation using Archive\n                if len(self.archive) > 2 and np.random.rand() < 0.2:\n                    x_archive = self.archive[np.random.randint(len(self.archive))]\n                    x_mutated = population[i] + self.F * (x_archive - x_r1)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    \n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n                    #Update archive\n                    self.update_archive(x_trial)\n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n                    self.update_archive(x_perturbed)\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n                    self.update_archive(x_perturbed)\n\n            # Adaptive F and Cr \n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt\n\n    def update_archive(self, x):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n        else:\n            # Replace a random element in archive\n            index = np.random.randint(self.archive_size)\n            self.archive[index] = x\n\n    def adapt_parameters(self):\n        if self.success_F:\n            self.sf_memory.extend(self.success_F)\n            self.scr_memory.extend(self.success_Cr)\n            if len(self.sf_memory) > self.sf_memsize:\n                self.sf_memory = self.sf_memory[-self.sf_memsize:]\n                self.scr_memory = self.scr_memory[-self.sf_memsize:]\n            \n            mean_F = np.mean(self.sf_memory)\n            mean_Cr = np.mean(self.scr_memory)\n\n            self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * mean_F\n            self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * mean_Cr\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n            \n            self.success_F = []\n            self.success_Cr = []\n        else:\n            # If no successful updates, explore more\n            self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n            self.Cr = np.clip(np.random.normal(0.7, 0.2), 0.1, 1.0)", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptivePerturbedDE scored 0.584 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dcf9de44-1522-4dbd-854e-024dfaefb7ff"], "operator": "mutation", "metadata": {"llm_response": "# Description: An Adaptive Perturbed DE with a more robust adaptation of F and Cr, using a weighted average based on success rate, and also an additional mutation strategy using archive members to enhance exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePerturbedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05, archive_size=10, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.adapt_rate = adapt_rate # Rate to adapt F and Cr\n        self.success_F = []\n        self.success_Cr = []\n        self.sf_memory = []\n        self.scr_memory = []\n        self.sf_memsize = 10\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Initialize Archive\n        self.archive = list(population)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Velocity update\n                self.velocities[i] = self.F * (x_r2 - x_r3)\n                x_mutated = population[i] + self.velocities[i]\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Additional Mutation using Archive\n                if len(self.archive) > 2 and np.random.rand() < 0.2:\n                    x_archive = self.archive[np.random.randint(len(self.archive))]\n                    x_mutated = population[i] + self.F * (x_archive - x_r1)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    \n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n                    #Update archive\n                    self.update_archive(x_trial)\n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n                    self.update_archive(x_perturbed)\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n                    self.update_archive(x_perturbed)\n\n            # Adaptive F and Cr \n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt\n\n    def update_archive(self, x):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n        else:\n            # Replace a random element in archive\n            index = np.random.randint(self.archive_size)\n            self.archive[index] = x\n\n    def adapt_parameters(self):\n        if self.success_F:\n            self.sf_memory.extend(self.success_F)\n            self.scr_memory.extend(self.success_Cr)\n            if len(self.sf_memory) > self.sf_memsize:\n                self.sf_memory = self.sf_memory[-self.sf_memsize:]\n                self.scr_memory = self.scr_memory[-self.sf_memsize:]\n            \n            mean_F = np.mean(self.sf_memory)\n            mean_Cr = np.mean(self.scr_memory)\n\n            self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * mean_F\n            self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * mean_Cr\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n            \n            self.success_F = []\n            self.success_Cr = []\n        else:\n            # If no successful updates, explore more\n            self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n            self.Cr = np.clip(np.random.normal(0.7, 0.2), 0.1, 1.0)\n```", "aucs": [0.20672506299676097, 0.500648655859317, 0.5871874249150494, 0.8617597591838764, 0.5786487889192604, 0.6865221076277355, 0.3463470333840182, 0.5292764290994276, 0.5982596235666805, 0.1801184214550423, 0.8345401239384286, 0.9908775051434364, 0.6579941566642684, 0.4869590126915966, 0.9048529157291226, 0.7221917622894642, 0.4552880687835845, 0.8140370390774503, 0.23788870958052777, 0.5039817897423264], "operator": "mutation", "theta_sampled": 0.004035281695159294, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "4d152350-8a49-4921-83c4-1145d6399b7a", "fitness": 0.4951646465750807, "name": "AdaptiveHybridPSO_DE_Orthogonal", "description": "Adaptive hybrid PSO-DE with orthogonal learning, population diversity maintenance, and dynamic parameter adjustment to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Orthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, diversity_threshold = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.diversity_threshold = diversity_threshold\n        self.archive = []\n        self.archive_fitness = []\n        self.archive_size = 20\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n    \n    def orthogonal_learning(self, func, x, n_samples=5):\n        \"\"\"Performs orthogonal learning around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        # Generate orthogonal array (simplified for demonstration)\n        oa = np.random.choice([-1, 1], size=(n_samples, self.dim))\n\n        for i in range(n_samples):\n            new_x = x + 0.05 * oa[i]  # Scale the orthogonal vector\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_archive(self, x, fitness):\n        \"\"\"Updates the archive with diverse solutions.\"\"\"\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n            self.archive_fitness.append(fitness)\n        else:\n            # Replace the worst solution in the archive\n            max_index = np.argmax(self.archive_fitness)\n            if fitness < self.archive_fitness[max_index]:\n                self.archive[max_index] = x\n                self.archive_fitness[max_index] = fitness\n    \n    def calculate_diversity(self, pop):\n        \"\"\"Calculates the diversity of the population.\"\"\"\n        centroid = np.mean(pop, axis=0)\n        distances = np.linalg.norm(pop - centroid, axis=1)\n        mean_distance = np.mean(distances)\n        return mean_distance\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity(pop)\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                #Apply orthogonal learning\n                if np.random.rand() < self.local_search_probability:\n                     local_f, local_x = self.orthogonal_learning(func, pop[i].copy())\n                     if local_f < pbest_fitness[i]:\n                         pbest_fitness[i] = local_f\n                         pbest_pop[i] = local_x.copy()\n                         if local_f < gbest_fitness:\n                             gbest_fitness = local_f\n                             gbest_pos = local_x.copy()\n                     pop[i] = local_x.copy()\n                \n                self.update_archive(pop[i].copy(), fitness[i]) # Update archive\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Dynamic parameter adjustment based on diversity\n            if diversity < self.diversity_threshold:\n                # Increase exploration: higher mutation factor, exploration bias\n                self.f = min(self.f + 0.05, 1.0)  # Increase mutation\n                self.cr = max(self.cr - 0.05, 0.1)\n                self.w = max(self.w - 0.02, 0.4)\n            else:\n                # Increase exploitation\n                self.f = max(self.f - 0.05, 0.5)\n                self.cr = min(self.cr + 0.05, 0.9)\n                self.w = min(self.w + 0.02, 0.8)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE_Orthogonal scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive hybrid PSO-DE with orthogonal learning, population diversity maintenance, and dynamic parameter adjustment to balance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Orthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, diversity_threshold = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.diversity_threshold = diversity_threshold\n        self.archive = []\n        self.archive_fitness = []\n        self.archive_size = 20\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n    \n    def orthogonal_learning(self, func, x, n_samples=5):\n        \"\"\"Performs orthogonal learning around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        # Generate orthogonal array (simplified for demonstration)\n        oa = np.random.choice([-1, 1], size=(n_samples, self.dim))\n\n        for i in range(n_samples):\n            new_x = x + 0.05 * oa[i]  # Scale the orthogonal vector\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_archive(self, x, fitness):\n        \"\"\"Updates the archive with diverse solutions.\"\"\"\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n            self.archive_fitness.append(fitness)\n        else:\n            # Replace the worst solution in the archive\n            max_index = np.argmax(self.archive_fitness)\n            if fitness < self.archive_fitness[max_index]:\n                self.archive[max_index] = x\n                self.archive_fitness[max_index] = fitness\n    \n    def calculate_diversity(self, pop):\n        \"\"\"Calculates the diversity of the population.\"\"\"\n        centroid = np.mean(pop, axis=0)\n        distances = np.linalg.norm(pop - centroid, axis=1)\n        mean_distance = np.mean(distances)\n        return mean_distance\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity(pop)\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                #Apply orthogonal learning\n                if np.random.rand() < self.local_search_probability:\n                     local_f, local_x = self.orthogonal_learning(func, pop[i].copy())\n                     if local_f < pbest_fitness[i]:\n                         pbest_fitness[i] = local_f\n                         pbest_pop[i] = local_x.copy()\n                         if local_f < gbest_fitness:\n                             gbest_fitness = local_f\n                             gbest_pos = local_x.copy()\n                     pop[i] = local_x.copy()\n                \n                self.update_archive(pop[i].copy(), fitness[i]) # Update archive\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Dynamic parameter adjustment based on diversity\n            if diversity < self.diversity_threshold:\n                # Increase exploration: higher mutation factor, exploration bias\n                self.f = min(self.f + 0.05, 1.0)  # Increase mutation\n                self.cr = max(self.cr - 0.05, 0.1)\n                self.w = max(self.w - 0.02, 0.4)\n            else:\n                # Increase exploitation\n                self.f = max(self.f - 0.05, 0.5)\n                self.cr = min(self.cr + 0.05, 0.9)\n                self.w = min(self.w + 0.02, 0.8)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.19310881718810502, 0.21663596564882548, 0.5772856354366671, 0.19608586048625276, 0.5824279931396306, 0.5919353874841519, 0.3386355560839813, 0.4850857641111628, 0.5520244980439714, 0.4173239433110366, 0.8014925615737027, 0.9937272619228684, 0.2627318413387557, 0.5341718133540552, 0.6965554387097951, 0.5645886602915646, 0.45571007090423954, 0.7066842092714267, 0.2376041741914482, 0.4994774790099742], "operator": "mutation", "theta_sampled": 5.101193287741692e-06, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "2c104505-1223-41e3-9c9e-bf7588f59373", "fitness": 0.0, "name": "AdaptiveGaussianCrossover", "description": "A population-based algorithm that uses a combination of Gaussian mutation and crossover to explore the search space, dynamically adjusting the mutation strength based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveGaussianCrossover:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n        return self.fitness.sum()  # return sum of fitness, needed for budget management. Prevents unnecessary calls to func\n\n    def gaussian_mutation(self, sigma):\n        mutated_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            mutation = np.random.normal(0, sigma, self.dim)\n            mutated_population[i] = self.population[i] + mutation\n            mutated_population[i] = np.clip(mutated_population[i], self.lb, self.ub)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            j = np.random.randint(self.pop_size)\n            crossover_point = np.random.randint(self.dim)\n            crossed_population[i, :crossover_point] = mutated_population[i, :crossover_point]\n            crossed_population[i, crossover_point:] = self.population[j, crossover_point:]\n            crossed_population[i] = np.clip(crossed_population[i], self.lb, self.ub)\n        return crossed_population\n\n    def selection(self, crossed_population, func):\n        crossed_fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            crossed_fitness[i] = func(crossed_population[i])\n\n        for i in range(self.pop_size):\n            if crossed_fitness[i] < self.fitness[i]:\n                self.population[i] = crossed_population[i]\n                self.fitness[i] = crossed_fitness[i]\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.initialize_population()\n        initial_fitness_sum = self.evaluate_population(func)\n        eval_count = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        sigma = 0.1 * (self.ub - self.lb)  # Initial mutation strength\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            # Adjust sigma based on diversity. If the population is too similar, increase mutation.\n            sigma = 0.1 * (self.ub - self.lb) * (1 - diversity / (0.5*(self.ub - self.lb)))\n            sigma = max(sigma, 0.0001) #Ensure sigma does not become zero or negative\n\n            mutated_population = self.gaussian_mutation(sigma)\n            crossed_population = self.crossover(mutated_population)\n            \n            fitness_sum_before = np.sum(self.fitness)\n            self.selection(crossed_population, func)\n            fitness_sum_after = np.sum(self.fitness)\n            eval_count += self.pop_size\n            \n            current_best_fitness = np.min(self.fitness)\n            current_best_index = np.argmin(self.fitness)\n\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[current_best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of Gaussian mutation and crossover to explore the search space, dynamically adjusting the mutation strength based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveGaussianCrossover:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n        return self.fitness.sum()  # return sum of fitness, needed for budget management. Prevents unnecessary calls to func\n\n    def gaussian_mutation(self, sigma):\n        mutated_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            mutation = np.random.normal(0, sigma, self.dim)\n            mutated_population[i] = self.population[i] + mutation\n            mutated_population[i] = np.clip(mutated_population[i], self.lb, self.ub)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            j = np.random.randint(self.pop_size)\n            crossover_point = np.random.randint(self.dim)\n            crossed_population[i, :crossover_point] = mutated_population[i, :crossover_point]\n            crossed_population[i, crossover_point:] = self.population[j, crossover_point:]\n            crossed_population[i] = np.clip(crossed_population[i], self.lb, self.ub)\n        return crossed_population\n\n    def selection(self, crossed_population, func):\n        crossed_fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            crossed_fitness[i] = func(crossed_population[i])\n\n        for i in range(self.pop_size):\n            if crossed_fitness[i] < self.fitness[i]:\n                self.population[i] = crossed_population[i]\n                self.fitness[i] = crossed_fitness[i]\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.initialize_population()\n        initial_fitness_sum = self.evaluate_population(func)\n        eval_count = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        sigma = 0.1 * (self.ub - self.lb)  # Initial mutation strength\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            # Adjust sigma based on diversity. If the population is too similar, increase mutation.\n            sigma = 0.1 * (self.ub - self.lb) * (1 - diversity / (0.5*(self.ub - self.lb)))\n            sigma = max(sigma, 0.0001) #Ensure sigma does not become zero or negative\n\n            mutated_population = self.gaussian_mutation(sigma)\n            crossed_population = self.crossover(mutated_population)\n            \n            fitness_sum_before = np.sum(self.fitness)\n            self.selection(crossed_population, func)\n            fitness_sum_after = np.sum(self.fitness)\n            eval_count += self.pop_size\n            \n            current_best_fitness = np.min(self.fitness)\n            current_best_index = np.argmin(self.fitness)\n\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[current_best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0026631667434249317, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "e75ca451-ca83-43b6-8e21-0aea7d693a97", "fitness": 0.0, "name": "SobolSimplex", "description": "A hybrid algorithm combining the exploration of a Sobol sequence with the exploitation of a Nelder-Mead simplex method, adaptively adjusting the simplex size based on function evaluation success.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolSimplex:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.sobol_engine = np.random.default_rng().sobol(dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_rate = 0.2  # Initial success rate for simplex size adaptation\n\n    def generate_sobol_point(self, lb, ub):\n        \"\"\"Generates a Sobol sequence point scaled to the bounds.\"\"\"\n        p = self.sobol_engine.random()\n        return lb + p * (ub - lb)\n    \n    def nelder_mead(self, func, x0, bounds, max_evals):\n        \"\"\"Applies Nelder-Mead locally with a limited evaluation budget.\"\"\"\n        \n        local_budget = min(max_evals, self.budget - self.eval_count)\n        if local_budget <= 0:\n            return self.f_opt, self.x_opt  # No budget left, return current best\n        \n        res = minimize(func, x0, method='Nelder-Mead', \n                       bounds=bounds,\n                       options={'maxfev': local_budget, 'disp': False, 'adaptive':True})\n        \n        self.eval_count += res.nfev\n        return res.fun, res.x\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        success_count = 0\n        total_iterations = 0\n\n        while self.eval_count < self.budget:\n            total_iterations += 1\n            # 1. Generate a Sobol sequence point.\n            x = self.generate_sobol_point(lb, ub)\n            \n            # 2. Evaluate the function at the Sobol point.\n            f = func(x)\n            self.eval_count += 1\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                success_count += 1\n\n            # 3. Apply Nelder-Mead simplex around the Sobol point or the best point found so far.\n            if np.random.rand() < 0.5: # Apply Nelder-Mead around Sobol point with 50% probability\n                x0 = x.copy()\n            else:\n                x0 = self.x_opt.copy() if self.x_opt is not None else x.copy() # Use best point as center if available\n            \n            # Perturb x0 to create an initial simplex\n            initial_simplex = np.zeros((self.dim + 1, self.dim))\n            initial_simplex[0] = x0\n            for i in range(self.dim):\n                x_new = x0.copy()\n                x_new[i] += self.initial_simplex_size # Simple perturbation\n                initial_simplex[i+1] = x_new\n                \n            f_nm, x_nm = self.nelder_mead(func, x0, bounds=[(lb[i], ub[i]) for i in range(self.dim)], max_evals=max(10,int(self.budget/100))) # dynamically adjusted max_evals\n            \n            if f_nm < self.f_opt:\n                self.f_opt = f_nm\n                self.x_opt = x_nm\n                success_count += 1\n\n            # 4. Adaptively adjust the simplex size based on the success rate.\n            self.success_rate = success_count / total_iterations if total_iterations > 0 else 0.2\n            if self.success_rate > 0.3:\n                self.initial_simplex_size *= 1.1  # Increase simplex size if successful\n            elif self.success_rate < 0.1:\n                self.initial_simplex_size *= 0.9  # Decrease simplex size if unsuccessful\n            self.initial_simplex_size = np.clip(self.initial_simplex_size, 1e-4, 1.0) # Bound simplex size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: 'numpy.random._generator.Generator' object has no attribute 'sobol'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A hybrid algorithm combining the exploration of a Sobol sequence with the exploitation of a Nelder-Mead simplex method, adaptively adjusting the simplex size based on function evaluation success.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolSimplex:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.sobol_engine = np.random.default_rng().sobol(dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_rate = 0.2  # Initial success rate for simplex size adaptation\n\n    def generate_sobol_point(self, lb, ub):\n        \"\"\"Generates a Sobol sequence point scaled to the bounds.\"\"\"\n        p = self.sobol_engine.random()\n        return lb + p * (ub - lb)\n    \n    def nelder_mead(self, func, x0, bounds, max_evals):\n        \"\"\"Applies Nelder-Mead locally with a limited evaluation budget.\"\"\"\n        \n        local_budget = min(max_evals, self.budget - self.eval_count)\n        if local_budget <= 0:\n            return self.f_opt, self.x_opt  # No budget left, return current best\n        \n        res = minimize(func, x0, method='Nelder-Mead', \n                       bounds=bounds,\n                       options={'maxfev': local_budget, 'disp': False, 'adaptive':True})\n        \n        self.eval_count += res.nfev\n        return res.fun, res.x\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        success_count = 0\n        total_iterations = 0\n\n        while self.eval_count < self.budget:\n            total_iterations += 1\n            # 1. Generate a Sobol sequence point.\n            x = self.generate_sobol_point(lb, ub)\n            \n            # 2. Evaluate the function at the Sobol point.\n            f = func(x)\n            self.eval_count += 1\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                success_count += 1\n\n            # 3. Apply Nelder-Mead simplex around the Sobol point or the best point found so far.\n            if np.random.rand() < 0.5: # Apply Nelder-Mead around Sobol point with 50% probability\n                x0 = x.copy()\n            else:\n                x0 = self.x_opt.copy() if self.x_opt is not None else x.copy() # Use best point as center if available\n            \n            # Perturb x0 to create an initial simplex\n            initial_simplex = np.zeros((self.dim + 1, self.dim))\n            initial_simplex[0] = x0\n            for i in range(self.dim):\n                x_new = x0.copy()\n                x_new[i] += self.initial_simplex_size # Simple perturbation\n                initial_simplex[i+1] = x_new\n                \n            f_nm, x_nm = self.nelder_mead(func, x0, bounds=[(lb[i], ub[i]) for i in range(self.dim)], max_evals=max(10,int(self.budget/100))) # dynamically adjusted max_evals\n            \n            if f_nm < self.f_opt:\n                self.f_opt = f_nm\n                self.x_opt = x_nm\n                success_count += 1\n\n            # 4. Adaptively adjust the simplex size based on the success rate.\n            self.success_rate = success_count / total_iterations if total_iterations > 0 else 0.2\n            if self.success_rate > 0.3:\n                self.initial_simplex_size *= 1.1  # Increase simplex size if successful\n            elif self.success_rate < 0.1:\n                self.initial_simplex_size *= 0.9  # Decrease simplex size if unsuccessful\n            self.initial_simplex_size = np.clip(self.initial_simplex_size, 1e-4, 1.0) # Bound simplex size\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.003456563555990345, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "5ec3e3c8-75ab-459e-8601-2711989066ed", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_Enhanced", "description": "An adaptive hybrid PSO-DE algorithm with a success-history based adaptation of PSO/DE probabilities, velocity clamping, boundary reflection, local search, and population restart mechanisms.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            restart_interval (int): Number of iterations before a population restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.last_best_fitness = np.inf\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n            \n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n\n        for _ in range(5):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n\n            # Choose PSO or DE\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n                \n            #Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability and self.func_evals < self.budget:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        self.population[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n            \n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE_Enhanced scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with a success-history based adaptation of PSO/DE probabilities, velocity clamping, boundary reflection, local search, and population restart mechanisms.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            restart_interval (int): Number of iterations before a population restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.last_best_fitness = np.inf\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n            \n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n\n        for _ in range(5):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n\n            # Choose PSO or DE\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n                \n            #Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability and self.func_evals < self.budget:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        self.population[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n            \n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.0021735387698114225, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "1eb91ba4-15a8-4019-a4f6-8f74ae8a67bd", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Adaptive hybrid PSO-DE with success-based parameter adaptation, local search, and velocity clamping for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            restart_interval (int): Interval for restarting the population.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.ls_evals = 5  # Number of evaluations in local search\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n            \n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        for _ in range(self.ls_evals):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n\n            # Choose PSO or DE\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            # Local search application\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_x.copy()\n                        if local_f < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = local_f\n                            self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive hybrid PSO-DE with success-based parameter adaptation, local search, and velocity clamping for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            restart_interval (int): Interval for restarting the population.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.ls_evals = 5  # Number of evaluations in local search\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n            \n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        for _ in range(self.ls_evals):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n\n            # Choose PSO or DE\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            # Local search application\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_x.copy()\n                        if local_f < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = local_f\n                            self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.00021805076023968182, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "9057b751-fba8-4934-ae81-4c8efc1fcafb", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE2", "description": "Adaptively combines PSO and DE with a self-adjusting balance, velocity clamping, and a periodic population-wide local search to escape local optima and maintain diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, local_search_radius=0.1, reset_probability=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n        self.reset_probability = reset_probability\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        # no budget reduction here, since its called within a loop and it gets tracked there\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            \n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy(), radius=self.local_search_radius)\n                    \n                    #reduce budget according to the number of evaluations in local_search\n                    self.budget -= 5\n                    if self.budget <= 0:\n                      return gbest_fitness, gbest_pos\n\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n                \n                # Random Resetting\n                if np.random.rand() < self.reset_probability:\n                    pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                      return gbest_fitness, gbest_pos\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Adapt Local Search Radius\n            self.local_search_radius = 0.1 + 0.4 * (self.budget / 10000) #linearly decrease radius\n            self.local_search_radius = np.clip(self.local_search_radius, 0.01, 0.5)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE2 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with a self-adjusting balance, velocity clamping, and a periodic population-wide local search to escape local optima and maintain diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, local_search_radius=0.1, reset_probability=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n        self.reset_probability = reset_probability\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        # no budget reduction here, since its called within a loop and it gets tracked there\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            \n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy(), radius=self.local_search_radius)\n                    \n                    #reduce budget according to the number of evaluations in local_search\n                    self.budget -= 5\n                    if self.budget <= 0:\n                      return gbest_fitness, gbest_pos\n\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n                \n                # Random Resetting\n                if np.random.rand() < self.reset_probability:\n                    pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                      return gbest_fitness, gbest_pos\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Adapt Local Search Radius\n            self.local_search_radius = 0.1 + 0.4 * (self.budget / 10000) #linearly decrease radius\n            self.local_search_radius = np.clip(self.local_search_radius, 0.01, 0.5)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.0035385628133470827, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "1ca38c17-43b0-499d-846b-5af3e3c5834d", "fitness": 0.3179954395286483, "name": "AdaptiveCauchyGaussian", "description": "Population-based algorithm that combines a global exploration phase using a Cauchy distribution and a local exploitation phase using a Gaussian distribution, with adaptive scaling based on the success rate of each phase.", "code": "import numpy as np\n\nclass AdaptiveCauchyGaussian:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cauchy_scale=1.0, gaussian_scale=0.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cauchy_scale = cauchy_scale\n        self.gaussian_scale = gaussian_scale\n        self.success_threshold = success_threshold\n        self.population = None\n        self.fitness = None\n        self.cauchy_success_rate = 0.5\n        self.gaussian_success_rate = 0.5\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size  # Account for initial evaluations\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, func, x):\n        z = np.random.standard_cauchy(size=self.dim)\n        new_x = x + self.cauchy_scale * z\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def gaussian_mutation(self, func, x):\n        z = np.random.normal(size=self.dim)\n        new_x = x + self.gaussian_scale * z\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        cauchy_successes = 0\n        gaussian_successes = 0\n        total_iterations = 0\n\n        while self.budget > 0:\n            total_iterations += 1\n\n            # Select individuals based on fitness (e.g., tournament selection or random selection)\n            indices = np.random.choice(self.pop_size, size=self.pop_size, replace=True)\n            parents = self.population[indices]\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.cauchy_success_rate / (self.cauchy_success_rate + self.gaussian_success_rate):\n                    # Cauchy mutation (exploration)\n                    new_x = self.cauchy_mutation(func, parents[i])\n                    f = func(new_x)\n                    self.budget -= 1\n                    if f < self.fitness[indices[i]]:\n                        cauchy_successes += 1\n                        new_population.append(new_x)\n                        new_fitness.append(f)\n                    else:\n                        new_population.append(parents[i])\n                        new_fitness.append(self.fitness[indices[i]])\n                else:\n                    # Gaussian mutation (exploitation)\n                    new_x = self.gaussian_mutation(func, parents[i])\n                    f = func(new_x)\n                    self.budget -= 1\n                    if f < self.fitness[indices[i]]:\n                        gaussian_successes += 1\n                        new_population.append(new_x)\n                        new_fitness.append(f)\n                    else:\n                        new_population.append(parents[i])\n                        new_fitness.append(self.fitness[indices[i]])\n\n                if self.budget <= 0:\n                    break\n\n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n\n            # Update Cauchy and Gaussian success rates adaptively\n            self.cauchy_success_rate = 0.9 * self.cauchy_success_rate + 0.1 * (cauchy_successes / self.pop_size)\n            self.gaussian_success_rate = 0.9 * self.gaussian_success_rate + 0.1 * (gaussian_successes / self.pop_size)\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n            cauchy_successes = 0\n            gaussian_successes = 0\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveCauchyGaussian scored 0.318 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines a global exploration phase using a Cauchy distribution and a local exploitation phase using a Gaussian distribution, with adaptive scaling based on the success rate of each phase.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCauchyGaussian:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cauchy_scale=1.0, gaussian_scale=0.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cauchy_scale = cauchy_scale\n        self.gaussian_scale = gaussian_scale\n        self.success_threshold = success_threshold\n        self.population = None\n        self.fitness = None\n        self.cauchy_success_rate = 0.5\n        self.gaussian_success_rate = 0.5\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size  # Account for initial evaluations\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, func, x):\n        z = np.random.standard_cauchy(size=self.dim)\n        new_x = x + self.cauchy_scale * z\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def gaussian_mutation(self, func, x):\n        z = np.random.normal(size=self.dim)\n        new_x = x + self.gaussian_scale * z\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        cauchy_successes = 0\n        gaussian_successes = 0\n        total_iterations = 0\n\n        while self.budget > 0:\n            total_iterations += 1\n\n            # Select individuals based on fitness (e.g., tournament selection or random selection)\n            indices = np.random.choice(self.pop_size, size=self.pop_size, replace=True)\n            parents = self.population[indices]\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.cauchy_success_rate / (self.cauchy_success_rate + self.gaussian_success_rate):\n                    # Cauchy mutation (exploration)\n                    new_x = self.cauchy_mutation(func, parents[i])\n                    f = func(new_x)\n                    self.budget -= 1\n                    if f < self.fitness[indices[i]]:\n                        cauchy_successes += 1\n                        new_population.append(new_x)\n                        new_fitness.append(f)\n                    else:\n                        new_population.append(parents[i])\n                        new_fitness.append(self.fitness[indices[i]])\n                else:\n                    # Gaussian mutation (exploitation)\n                    new_x = self.gaussian_mutation(func, parents[i])\n                    f = func(new_x)\n                    self.budget -= 1\n                    if f < self.fitness[indices[i]]:\n                        gaussian_successes += 1\n                        new_population.append(new_x)\n                        new_fitness.append(f)\n                    else:\n                        new_population.append(parents[i])\n                        new_fitness.append(self.fitness[indices[i]])\n\n                if self.budget <= 0:\n                    break\n\n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n\n            # Update Cauchy and Gaussian success rates adaptively\n            self.cauchy_success_rate = 0.9 * self.cauchy_success_rate + 0.1 * (cauchy_successes / self.pop_size)\n            self.gaussian_success_rate = 0.9 * self.gaussian_success_rate + 0.1 * (gaussian_successes / self.pop_size)\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n            cauchy_successes = 0\n            gaussian_successes = 0\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1320859909376142, 0.17353365914225194, 0.3773455016434888, 0.16911731522521745, 0.23659313991956332, 0.39871837881451533, 0.22754965931336324, 0.19706933576089392, 0.21222708136739898, 0.16461693197490335, 0.3004148471524033, 0.9916291680824891, 0.24962621384412964, 0.2936742438866857, 0.6466731354783737, 0.3134614346300201, 0.21170803704200103, 0.4460987051387719, 0.14908320393369612, 0.46868280728518574], "operator": "random_new", "theta_sampled": 0.001139338361768454, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "897eb561-52a4-41ae-878b-f5a12e560e9b", "fitness": 0.0, "name": "AdaptiveHybridPSODE_SOM_CMAES", "description": "An adaptive hybrid PSO-DE algorithm with a self-organizing map (SOM) to cluster individuals and apply tailored PSO/DE strategies, along with a CMA-ES based local search and adaptive parameter control.", "code": "import numpy as np\nfrom minisom import MiniSom\nfrom cma import CMAEvolutionStrategy\n\nclass AdaptiveHybridPSODE_SOM_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=60, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, som_grid_size=5, local_search_probability=0.05, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.som_grid_size = som_grid_size\n        self.local_search_probability = local_search_probability\n        self.local_search_iterations = local_search_iterations\n        self.som = MiniSom(som_grid_size, som_grid_size, dim, sigma=0.3, learning_rate=0.7)\n        self.pso_ratio_map = np.full((som_grid_size, som_grid_size), 0.5)\n        self.success_pso_map = np.zeros((som_grid_size, som_grid_size))\n        self.success_de_map = np.zeros((som_grid_size, som_grid_size))\n        self.total_pso_map = np.zeros((som_grid_size, som_grid_size))\n        self.total_de_map = np.zeros((som_grid_size, som_grid_size))\n        self.learning_rate_pso_ratio = 0.1\n\n    def local_search_cmaes(self, func, x):\n        \"\"\"Local search using CMA-ES.\"\"\"\n        es = CMAEvolutionStrategy(x, 0.5, {'bounds': [func.bounds.lb, func.bounds.ub], 'verbose': -9})\n        \n        evals = 0\n        while evals < self.local_search_iterations and self.budget > 0 and not es.stop():\n            solutions = es.ask()\n            fitness_values = [func(xi) for xi in solutions]\n            self.budget -= len(solutions)\n            evals += len(solutions)\n            es.tell(solutions, fitness_values)\n\n        return es.result.fbest, es.result.xbest\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n\n        # Train SOM\n        self.som.train(pop, 1000)  # Train SOM initially\n\n        while self.budget > 0:\n            # Re-train SOM periodically to adapt to population movement\n            if self.budget % (self.pop_size * 10) == 0:\n                self.som.train(pop, 200, verbose=False) # Reduced training\n\n            for i in range(self.pop_size):\n                winner = self.som.winner(pop[i])\n                row, col = winner\n\n                pso_ratio = self.pso_ratio_map[row, col]\n\n                new_pos_pso = pop[i].copy()\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < pso_ratio:\n                    self.total_pso_map[row, col] += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso_map[row, col] += 1\n\n                new_pos_de = pop[i].copy()\n                new_fitness_de = np.inf\n\n                if np.random.rand() > pso_ratio:\n                    self.total_de_map[row, col] += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de_map[row, col] += 1\n\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                # Local search with CMA-ES\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search_cmaes(func, pop[i].copy())\n                    if self.budget <= 0:\n                      break\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy() #Replace the current particle with the result from CMAES\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt PSO ratio for each SOM node\n            for row in range(self.som_grid_size):\n                for col in range(self.som_grid_size):\n                    total_pso = self.total_pso_map[row, col]\n                    total_de = self.total_de_map[row, col]\n\n                    if total_pso + total_de > 0:\n                        success_rate_pso = self.success_pso_map[row, col] / total_pso if total_pso > 0 else 0\n                        success_rate_de = self.success_de_map[row, col] / total_de if total_de > 0 else 0\n\n                        if success_rate_pso + success_rate_de > 0:\n                            new_pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n                            self.pso_ratio_map[row, col] += self.learning_rate_pso_ratio * (new_pso_ratio - self.pso_ratio_map[row, col])\n                            self.pso_ratio_map[row, col] = np.clip(self.pso_ratio_map[row, col], 0.1, 0.9)  # Keep ratios within reasonable bounds\n\n            # Reset success counters for the next generation\n            self.success_pso_map = np.zeros((self.som_grid_size, self.som_grid_size))\n            self.success_de_map = np.zeros((self.som_grid_size, self.som_grid_size))\n            self.total_pso_map = np.zeros((self.som_grid_size, self.som_grid_size))\n            self.total_de_map = np.zeros((self.som_grid_size, self.som_grid_size))\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: No module named 'minisom'", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with a self-organizing map (SOM) to cluster individuals and apply tailored PSO/DE strategies, along with a CMA-ES based local search and adaptive parameter control.\n# Code: \n```python\nimport numpy as np\nfrom minisom import MiniSom\nfrom cma import CMAEvolutionStrategy\n\nclass AdaptiveHybridPSODE_SOM_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=60, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, som_grid_size=5, local_search_probability=0.05, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.som_grid_size = som_grid_size\n        self.local_search_probability = local_search_probability\n        self.local_search_iterations = local_search_iterations\n        self.som = MiniSom(som_grid_size, som_grid_size, dim, sigma=0.3, learning_rate=0.7)\n        self.pso_ratio_map = np.full((som_grid_size, som_grid_size), 0.5)\n        self.success_pso_map = np.zeros((som_grid_size, som_grid_size))\n        self.success_de_map = np.zeros((som_grid_size, som_grid_size))\n        self.total_pso_map = np.zeros((som_grid_size, som_grid_size))\n        self.total_de_map = np.zeros((som_grid_size, som_grid_size))\n        self.learning_rate_pso_ratio = 0.1\n\n    def local_search_cmaes(self, func, x):\n        \"\"\"Local search using CMA-ES.\"\"\"\n        es = CMAEvolutionStrategy(x, 0.5, {'bounds': [func.bounds.lb, func.bounds.ub], 'verbose': -9})\n        \n        evals = 0\n        while evals < self.local_search_iterations and self.budget > 0 and not es.stop():\n            solutions = es.ask()\n            fitness_values = [func(xi) for xi in solutions]\n            self.budget -= len(solutions)\n            evals += len(solutions)\n            es.tell(solutions, fitness_values)\n\n        return es.result.fbest, es.result.xbest\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n\n        # Train SOM\n        self.som.train(pop, 1000)  # Train SOM initially\n\n        while self.budget > 0:\n            # Re-train SOM periodically to adapt to population movement\n            if self.budget % (self.pop_size * 10) == 0:\n                self.som.train(pop, 200, verbose=False) # Reduced training\n\n            for i in range(self.pop_size):\n                winner = self.som.winner(pop[i])\n                row, col = winner\n\n                pso_ratio = self.pso_ratio_map[row, col]\n\n                new_pos_pso = pop[i].copy()\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < pso_ratio:\n                    self.total_pso_map[row, col] += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso_map[row, col] += 1\n\n                new_pos_de = pop[i].copy()\n                new_fitness_de = np.inf\n\n                if np.random.rand() > pso_ratio:\n                    self.total_de_map[row, col] += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de_map[row, col] += 1\n\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                # Local search with CMA-ES\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search_cmaes(func, pop[i].copy())\n                    if self.budget <= 0:\n                      break\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy() #Replace the current particle with the result from CMAES\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt PSO ratio for each SOM node\n            for row in range(self.som_grid_size):\n                for col in range(self.som_grid_size):\n                    total_pso = self.total_pso_map[row, col]\n                    total_de = self.total_de_map[row, col]\n\n                    if total_pso + total_de > 0:\n                        success_rate_pso = self.success_pso_map[row, col] / total_pso if total_pso > 0 else 0\n                        success_rate_de = self.success_de_map[row, col] / total_de if total_de > 0 else 0\n\n                        if success_rate_pso + success_rate_de > 0:\n                            new_pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n                            self.pso_ratio_map[row, col] += self.learning_rate_pso_ratio * (new_pso_ratio - self.pso_ratio_map[row, col])\n                            self.pso_ratio_map[row, col] = np.clip(self.pso_ratio_map[row, col], 0.1, 0.9)  # Keep ratios within reasonable bounds\n\n            # Reset success counters for the next generation\n            self.success_pso_map = np.zeros((self.som_grid_size, self.som_grid_size))\n            self.success_de_map = np.zeros((self.som_grid_size, self.som_grid_size))\n            self.total_pso_map = np.zeros((self.som_grid_size, self.som_grid_size))\n            self.total_de_map = np.zeros((self.som_grid_size, self.som_grid_size))\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos\n```", "operator": "mutation", "theta_sampled": 0.0017303761034956036, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "42d95073-e3a8-4574-b166-496ea2243a3b", "fitness": 0.5011334875307487, "name": "AdaptiveHybridPSO_DE_LS_Restart", "description": "An adaptive hybrid PSO-DE algorithm with dynamic probability adjustments, velocity clamping, boundary reflection, local search, and periodic population restarts for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_prob=0.05, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search and Restarts.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_prob (float): Probability of performing local search.\n            restart_interval (int): Number of iterations before a population restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_prob = local_search_prob\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.last_best_fitness = np.inf\n        self.v_max_ratio = 0.1\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * self.v_max_ratio  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(3): # Reduce number of local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n              return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Local Search and Restarts.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO update on individual\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n\n                    velocity = (self.w * self.velocities[i] +\n                               self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                               self.c2 * r2 * (self.global_best_position - self.population[i]))\n\n                    # Velocity clamping\n                    v_max = (func.bounds.ub - func.bounds.lb) * self.v_max_ratio\n                    velocity = np.clip(velocity, -v_max, v_max)\n                    \n                    new_position = self.population[i] + velocity\n\n                    # Boundary handling (reflecting boundaries)\n                    for j in range(self.dim):\n                        if new_position[j] < func.bounds.lb[j]:\n                            new_position[j] = func.bounds.lb[j] + (func.bounds.lb[j] - new_position[j])\n                            velocity[j] = -velocity[j]\n                        elif new_position[j] > func.bounds.ub[j]:\n                            new_position[j] = func.bounds.ub[j] - (new_position[j] - func.bounds.ub[j])\n                            velocity[j] = -velocity[j]\n                            \n                    self.velocities[i] = velocity #Update Velocity\n                    self.population[i] = new_position\n\n                    new_fitness = func(self.population[i])\n                    self.func_evals += 1\n\n                    if new_fitness < self.fitness[i]:\n                        self.fitness[i] = new_fitness\n                        # Update personal best if needed\n                        if new_fitness < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = new_fitness\n                            self.personal_best_positions[i] = self.population[i].copy()\n\n                        if new_fitness < self.global_best_fitness:\n                            self.global_best_fitness = new_fitness\n                            self.global_best_position = self.population[i].copy()\n                    self.pso_success[self.success_index] = 1 #mark success\n                    self.de_success[self.success_index] = 0\n\n                else:\n                    # DE update on individual\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[indices]\n                    v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n\n                    # Ensure mutated vector is within bounds (clip)\n                    v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    u_crossover = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() <= self.cr or j == j_rand:\n                            u_crossover[j] = v_mutation[j]\n                        else:\n                            u_crossover[j] = self.population[i, j]\n\n                    # Selection\n                    f_trial = func(u_crossover)\n                    self.func_evals += 1\n\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = u_crossover\n                        self.fitness[i] = f_trial\n                        # Update personal best if needed\n                        if f_trial < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_trial\n                            self.personal_best_positions[i] = u_crossover.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = u_crossover.copy()\n                    self.pso_success[self.success_index] = 0\n                    self.de_success[self.success_index] = 1 # Mark success\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.population[i] = local_x.copy()\n\n                if self.func_evals >= self.budget:\n                    break\n\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                self.v_max_ratio = min(0.5, self.v_max_ratio * 1.1) #Increase Exploration\n\n            else:\n                self.v_max_ratio = max(0.01, self.v_max_ratio * 0.99) # Reduce exploration\n\n            if self.func_evals >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS_Restart scored 0.501 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with dynamic probability adjustments, velocity clamping, boundary reflection, local search, and periodic population restarts for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_prob=0.05, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search and Restarts.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_prob (float): Probability of performing local search.\n            restart_interval (int): Number of iterations before a population restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_prob = local_search_prob\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.last_best_fitness = np.inf\n        self.v_max_ratio = 0.1\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * self.v_max_ratio  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(3): # Reduce number of local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n              return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Local Search and Restarts.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO update on individual\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n\n                    velocity = (self.w * self.velocities[i] +\n                               self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                               self.c2 * r2 * (self.global_best_position - self.population[i]))\n\n                    # Velocity clamping\n                    v_max = (func.bounds.ub - func.bounds.lb) * self.v_max_ratio\n                    velocity = np.clip(velocity, -v_max, v_max)\n                    \n                    new_position = self.population[i] + velocity\n\n                    # Boundary handling (reflecting boundaries)\n                    for j in range(self.dim):\n                        if new_position[j] < func.bounds.lb[j]:\n                            new_position[j] = func.bounds.lb[j] + (func.bounds.lb[j] - new_position[j])\n                            velocity[j] = -velocity[j]\n                        elif new_position[j] > func.bounds.ub[j]:\n                            new_position[j] = func.bounds.ub[j] - (new_position[j] - func.bounds.ub[j])\n                            velocity[j] = -velocity[j]\n                            \n                    self.velocities[i] = velocity #Update Velocity\n                    self.population[i] = new_position\n\n                    new_fitness = func(self.population[i])\n                    self.func_evals += 1\n\n                    if new_fitness < self.fitness[i]:\n                        self.fitness[i] = new_fitness\n                        # Update personal best if needed\n                        if new_fitness < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = new_fitness\n                            self.personal_best_positions[i] = self.population[i].copy()\n\n                        if new_fitness < self.global_best_fitness:\n                            self.global_best_fitness = new_fitness\n                            self.global_best_position = self.population[i].copy()\n                    self.pso_success[self.success_index] = 1 #mark success\n                    self.de_success[self.success_index] = 0\n\n                else:\n                    # DE update on individual\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[indices]\n                    v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n\n                    # Ensure mutated vector is within bounds (clip)\n                    v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    u_crossover = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() <= self.cr or j == j_rand:\n                            u_crossover[j] = v_mutation[j]\n                        else:\n                            u_crossover[j] = self.population[i, j]\n\n                    # Selection\n                    f_trial = func(u_crossover)\n                    self.func_evals += 1\n\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = u_crossover\n                        self.fitness[i] = f_trial\n                        # Update personal best if needed\n                        if f_trial < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_trial\n                            self.personal_best_positions[i] = u_crossover.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = u_crossover.copy()\n                    self.pso_success[self.success_index] = 0\n                    self.de_success[self.success_index] = 1 # Mark success\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.population[i] = local_x.copy()\n\n                if self.func_evals >= self.budget:\n                    break\n\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                self.v_max_ratio = min(0.5, self.v_max_ratio * 1.1) #Increase Exploration\n\n            else:\n                self.v_max_ratio = max(0.01, self.v_max_ratio * 0.99) # Reduce exploration\n\n            if self.func_evals >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.13544707762233066, 0.4803383120311011, 0.5025428724935399, 0.7474232296271761, 0.6071461911695579, 0.537849289203195, 0.4782146697466816, 0.3502607865236932, 0.5774502492743965, 0.28600455867932595, 0.8542775811506615, 0.9998253737150291, 0.29332446400926104, 0.3807414237445238, 0.7872897215015067, 0], "operator": "crossover", "theta_sampled": 0.0011520509834932352, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "2a821800-9fb5-47d1-9212-ff60f1973804", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_OL", "description": "An adaptive hybrid PSO-DE algorithm with self-adaptive parameter control, orthogonal learning, and a diversity-enhancing restart strategy.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.5, f_end=0.9, pso_prob=0.5, success_memory=10, orthogonal_learning_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with orthogonal learning and adaptive parameters.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_init (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            orthogonal_learning_rate (float): probability to perform orthogonal learning.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.iteration = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n\n        # Adaptive inertia weight\n        w = self.w_init - (self.w_init - self.w_end) * (self.iteration / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n\n            #Adaptive cr and f\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (self.iteration / self.budget)\n            f = self.f_init + (self.f_end - self.f_init) * (self.iteration / self.budget)\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n    \n    def orthogonal_learning(self, func):\n        \"\"\"\n        Implements orthogonal learning to enhance population diversity and convergence.\n        \"\"\"\n        if np.random.rand() < self.orthogonal_learning_rate:\n            # Select a random individual from the population\n            idx = np.random.randint(self.pop_size)\n            x = self.population[idx].copy()\n\n            # Generate orthogonal array (simplified for demonstration)\n            oa = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n\n            # Scale and shift the orthogonal array to fit the search space\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            scaled_oa = (oa * 0.5 + 0.5) * (ub - lb) + lb\n\n            # Evaluate the function at each point in the scaled orthogonal array\n            fitness_values = np.array([func(scaled_oa[i]) for i in range(oa.shape[0])])\n            self.func_evals += oa.shape[0]\n\n            # Select the best point from the orthogonal array\n            best_idx = np.argmin(fitness_values)\n            best_point = scaled_oa[best_idx]\n\n            # Replace the original individual with the best point from OA\n            if fitness_values[best_idx] < self.fitness[idx]:\n                self.population[idx] = best_point\n                self.fitness[idx] = fitness_values[best_idx]\n                self.personal_best_fitness[idx] = fitness_values[best_idx]\n                self.personal_best_positions[idx] = best_point.copy()\n                if fitness_values[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = fitness_values[best_idx]\n                    self.global_best_position = best_point.copy()\n    \n    def diversity_restart(self, func):\n        \"\"\"\n        Restarts a portion of the population with diverse individuals.\n        \"\"\"\n        # Calculate the mean position of the population\n        mean_position = np.mean(self.population, axis=0)\n\n        # Calculate the distance of each individual from the mean\n        distances = np.linalg.norm(self.population - mean_position, axis=1)\n\n        # Identify the individuals closest to the mean (least diverse)\n        num_to_restart = int(0.2 * self.pop_size)  # Restart 20% of the population\n        worst_indices = np.argsort(distances)[:num_to_restart]\n\n        # Replace the least diverse individuals with new random individuals\n        for i in worst_indices:\n            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            self.fitness[i] = func(self.population[i])\n            self.func_evals += 1\n            self.personal_best_positions[i] = self.population[i].copy()\n            self.personal_best_fitness[i] = self.fitness[i]\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.diversity_restart(func)\n        #self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        #self.fitness = np.array([func(x) for x in self.population])\n        #self.func_evals += self.pop_size\n        #self.personal_best_positions = self.population.copy()\n        #self.personal_best_fitness = self.fitness.copy()\n\n        #self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        #self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Orthogonal Learning and Diversity Restart.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.iteration += 1\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n            \n            # Apply orthogonal learning\n            self.orthogonal_learning(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (4,2) (5,) ", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with self-adaptive parameter control, orthogonal learning, and a diversity-enhancing restart strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.5, f_end=0.9, pso_prob=0.5, success_memory=10, orthogonal_learning_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with orthogonal learning and adaptive parameters.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_init (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            orthogonal_learning_rate (float): probability to perform orthogonal learning.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.iteration = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n\n        # Adaptive inertia weight\n        w = self.w_init - (self.w_init - self.w_end) * (self.iteration / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n\n            #Adaptive cr and f\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (self.iteration / self.budget)\n            f = self.f_init + (self.f_end - self.f_init) * (self.iteration / self.budget)\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n    \n    def orthogonal_learning(self, func):\n        \"\"\"\n        Implements orthogonal learning to enhance population diversity and convergence.\n        \"\"\"\n        if np.random.rand() < self.orthogonal_learning_rate:\n            # Select a random individual from the population\n            idx = np.random.randint(self.pop_size)\n            x = self.population[idx].copy()\n\n            # Generate orthogonal array (simplified for demonstration)\n            oa = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n\n            # Scale and shift the orthogonal array to fit the search space\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            scaled_oa = (oa * 0.5 + 0.5) * (ub - lb) + lb\n\n            # Evaluate the function at each point in the scaled orthogonal array\n            fitness_values = np.array([func(scaled_oa[i]) for i in range(oa.shape[0])])\n            self.func_evals += oa.shape[0]\n\n            # Select the best point from the orthogonal array\n            best_idx = np.argmin(fitness_values)\n            best_point = scaled_oa[best_idx]\n\n            # Replace the original individual with the best point from OA\n            if fitness_values[best_idx] < self.fitness[idx]:\n                self.population[idx] = best_point\n                self.fitness[idx] = fitness_values[best_idx]\n                self.personal_best_fitness[idx] = fitness_values[best_idx]\n                self.personal_best_positions[idx] = best_point.copy()\n                if fitness_values[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = fitness_values[best_idx]\n                    self.global_best_position = best_point.copy()\n    \n    def diversity_restart(self, func):\n        \"\"\"\n        Restarts a portion of the population with diverse individuals.\n        \"\"\"\n        # Calculate the mean position of the population\n        mean_position = np.mean(self.population, axis=0)\n\n        # Calculate the distance of each individual from the mean\n        distances = np.linalg.norm(self.population - mean_position, axis=1)\n\n        # Identify the individuals closest to the mean (least diverse)\n        num_to_restart = int(0.2 * self.pop_size)  # Restart 20% of the population\n        worst_indices = np.argsort(distances)[:num_to_restart]\n\n        # Replace the least diverse individuals with new random individuals\n        for i in worst_indices:\n            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            self.fitness[i] = func(self.population[i])\n            self.func_evals += 1\n            self.personal_best_positions[i] = self.population[i].copy()\n            self.personal_best_fitness[i] = self.fitness[i]\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.diversity_restart(func)\n        #self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        #self.fitness = np.array([func(x) for x in self.population])\n        #self.func_evals += self.pop_size\n        #self.personal_best_positions = self.population.copy()\n        #self.personal_best_fitness = self.fitness.copy()\n\n        #self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        #self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Orthogonal Learning and Diversity Restart.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.iteration += 1\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n            \n            # Apply orthogonal learning\n            self.orthogonal_learning(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "mutation", "theta_sampled": 0.0030562947985710524, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "42d9f438-3d1f-4316-bfee-95cff1177b44", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LocalSearch", "description": "An adaptive hybrid algorithm that dynamically adjusts PSO/DE probabilities based on success rate and introduces a local search component using Nelder-Mead simplex method when stagnation is detected, along with a Cauchy mutation operator for DE.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSO_DE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, stagnation_threshold=1e-5, local_search_prob = 0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            stagnation_threshold (float): Threshold for detecting stagnation.\n            local_search_prob (float): Probability of performing local search on the global best.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_prob = local_search_prob\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.stagnation_counter = 0\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation - Cauchy mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                # v_mutation = x_r1 + self.f * (x_r2 - x_r3) #original mutation\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3) + 0.01 * np.random.standard_cauchy(size=self.dim)\n\n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def local_search(self, func):\n        \"\"\"\n        Performs local search around the global best position using Nelder-Mead.\n        \"\"\"\n        bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        result = minimize(func, self.global_best_position, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.budget - self.func_evals})\n        if result.success:\n           if result.fun < self.global_best_fitness:\n                self.global_best_fitness = result.fun\n                self.global_best_position = result.x\n        self.func_evals += result.nfev\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            self.stagnation_counter += 1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation and np.random.rand() < self.local_search_prob:\n                self.local_search(func)\n                self.stagnation_counter = 0\n\n            if abs(self.global_best_fitness - self.last_best_fitness) < self.stagnation_threshold:\n              self.stagnation_counter+=1\n            else:\n              self.stagnation_counter = 0\n              self.last_best_fitness = self.global_best_fitness\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm that dynamically adjusts PSO/DE probabilities based on success rate and introduces a local search component using Nelder-Mead simplex method when stagnation is detected, along with a Cauchy mutation operator for DE.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSO_DE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, stagnation_threshold=1e-5, local_search_prob = 0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            stagnation_threshold (float): Threshold for detecting stagnation.\n            local_search_prob (float): Probability of performing local search on the global best.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_prob = local_search_prob\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.stagnation_counter = 0\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation - Cauchy mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                # v_mutation = x_r1 + self.f * (x_r2 - x_r3) #original mutation\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3) + 0.01 * np.random.standard_cauchy(size=self.dim)\n\n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def local_search(self, func):\n        \"\"\"\n        Performs local search around the global best position using Nelder-Mead.\n        \"\"\"\n        bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        result = minimize(func, self.global_best_position, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.budget - self.func_evals})\n        if result.success:\n           if result.fun < self.global_best_fitness:\n                self.global_best_fitness = result.fun\n                self.global_best_position = result.x\n        self.func_evals += result.nfev\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            self.stagnation_counter += 1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation and np.random.rand() < self.local_search_prob:\n                self.local_search(func)\n                self.stagnation_counter = 0\n\n            if abs(self.global_best_fitness - self.last_best_fitness) < self.stagnation_threshold:\n              self.stagnation_counter+=1\n            else:\n              self.stagnation_counter = 0\n              self.last_best_fitness = self.global_best_fitness\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "mutation", "theta_sampled": 0.000790904262761649, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "7b3ff7e9-fff5-4575-a2a8-90fe1f0b6e29", "fitness": 0.0, "name": "AdaptiveCMAES_LocalSearch", "description": "An adaptive algorithm that combines a simplified CMA-ES-like exploration with local search using Nelder-Mead simplex, dynamically adjusting exploration range.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveCMAES_LocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.mu = None\n        self.history_x = []\n        self.history_f = []\n        self.exploration_factor = 1.0  # Adjust exploration range\n        self.adaptation_rate = 0.05\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Simplified CMA-ES Sampling\n            x = self.mu + self.sigma * np.random.randn(self.dim) * self.exploration_factor\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = func(x)\n            eval_count += 1\n\n            self.history_x.append(x)\n            self.history_f.append(f)\n\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n\n\n            # Local Search (Nelder-Mead) every few iterations\n            if eval_count % (self.dim * 5) == 0:\n                local_search_budget = min(self.budget - eval_count, self.dim * 10) # Reduced local search budget\n                result = minimize(func, self.x_opt, method='Nelder-Mead',\n                                  bounds=list(zip([func.bounds.lb] * self.dim, [func.bounds.ub] * self.dim)),\n                                  options={'maxfev': local_search_budget}) # Pass bounds and reduced budget\n\n\n                if result.success:\n                    x_local = result.x\n                    f_local = result.fun\n                    eval_count += result.nfev\n\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = x_local.copy()\n\n\n            # Adaptive Sigma and Exploration Factor\n            if len(self.history_f) > self.dim * 10:  # Wait before adapting\n                recent_improvements = [self.history_f[i] < self.history_f[i - self.dim] for i in range(len(self.history_f) - self.dim, len(self.history_f))]\n                success_rate = sum(recent_improvements) / self.dim\n\n                if success_rate > 0.6:\n                    self.sigma *= (1 - self.adaptation_rate) # Reduce sigma if improving well\n                    self.exploration_factor *= (1 - self.adaptation_rate) # Reduce exploration factor\n                elif success_rate < 0.4:\n                    self.sigma *= (1 + self.adaptation_rate) # Increase sigma if not improving\n                    self.exploration_factor *= (1 + self.adaptation_rate) # Increase exploration factor\n\n                self.sigma = min(self.sigma, self.initial_sigma * 2.0)\n                self.sigma = max(self.sigma, self.initial_sigma * 0.1)\n                self.exploration_factor = min(self.exploration_factor, 2.0)\n                self.exploration_factor = max(self.exploration_factor, 0.5)\n\n            # Update Mean using best point so far\n            self.mu = self.x_opt.copy() # Simple mean adaptation\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive algorithm that combines a simplified CMA-ES-like exploration with local search using Nelder-Mead simplex, dynamically adjusting exploration range.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveCMAES_LocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.mu = None\n        self.history_x = []\n        self.history_f = []\n        self.exploration_factor = 1.0  # Adjust exploration range\n        self.adaptation_rate = 0.05\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Simplified CMA-ES Sampling\n            x = self.mu + self.sigma * np.random.randn(self.dim) * self.exploration_factor\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = func(x)\n            eval_count += 1\n\n            self.history_x.append(x)\n            self.history_f.append(f)\n\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n\n\n            # Local Search (Nelder-Mead) every few iterations\n            if eval_count % (self.dim * 5) == 0:\n                local_search_budget = min(self.budget - eval_count, self.dim * 10) # Reduced local search budget\n                result = minimize(func, self.x_opt, method='Nelder-Mead',\n                                  bounds=list(zip([func.bounds.lb] * self.dim, [func.bounds.ub] * self.dim)),\n                                  options={'maxfev': local_search_budget}) # Pass bounds and reduced budget\n\n\n                if result.success:\n                    x_local = result.x\n                    f_local = result.fun\n                    eval_count += result.nfev\n\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = x_local.copy()\n\n\n            # Adaptive Sigma and Exploration Factor\n            if len(self.history_f) > self.dim * 10:  # Wait before adapting\n                recent_improvements = [self.history_f[i] < self.history_f[i - self.dim] for i in range(len(self.history_f) - self.dim, len(self.history_f))]\n                success_rate = sum(recent_improvements) / self.dim\n\n                if success_rate > 0.6:\n                    self.sigma *= (1 - self.adaptation_rate) # Reduce sigma if improving well\n                    self.exploration_factor *= (1 - self.adaptation_rate) # Reduce exploration factor\n                elif success_rate < 0.4:\n                    self.sigma *= (1 + self.adaptation_rate) # Increase sigma if not improving\n                    self.exploration_factor *= (1 + self.adaptation_rate) # Increase exploration factor\n\n                self.sigma = min(self.sigma, self.initial_sigma * 2.0)\n                self.sigma = max(self.sigma, self.initial_sigma * 0.1)\n                self.exploration_factor = min(self.exploration_factor, 2.0)\n                self.exploration_factor = max(self.exploration_factor, 0.5)\n\n            # Update Mean using best point so far\n            self.mu = self.x_opt.copy() # Simple mean adaptation\n\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0007273826240052887, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "987c2b6f-95be-4f67-9f5a-a4ce9235ed76", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Adaptively combines PSO and DE with local search, leveraging success rates and a memory-based probability adjustment for exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, local_search_radius=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            local_search_radius (float): Radius for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100  # Restart every 100 iterations if no improvement\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n\n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                # Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(5):  # Reduced local search evaluations\n            new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)  # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with local search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n\n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO update\n                    old_fitness = self.fitness[i]\n                    old_position = self.population[i].copy()\n                    self.pso_update(func)  # Update all population by PSO internally\n                    if self.fitness[i] < old_fitness:\n                        self.pso_success[self.success_index] = 1\n                    else:\n                        self.pso_success[self.success_index] = 0\n                else:\n                    # DE update\n                    old_fitness = self.fitness[i]\n                    old_position = self.population[i].copy()\n                    self.de_update(func)  # Update all population by DE internally\n                    if self.fitness[i] < old_fitness:\n                        self.de_success[self.success_index] = 1\n                    else:\n                        self.de_success[self.success_index] = 0\n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        self.population[i] = local_x.copy()\n                        self.fitness[i] = local_f\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                \n                if self.func_evals >= self.budget:\n                    break\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with local search, leveraging success rates and a memory-based probability adjustment for exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, local_search_radius=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            local_search_radius (float): Radius for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100  # Restart every 100 iterations if no improvement\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n\n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                # Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(5):  # Reduced local search evaluations\n            new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)  # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with local search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n\n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO update\n                    old_fitness = self.fitness[i]\n                    old_position = self.population[i].copy()\n                    self.pso_update(func)  # Update all population by PSO internally\n                    if self.fitness[i] < old_fitness:\n                        self.pso_success[self.success_index] = 1\n                    else:\n                        self.pso_success[self.success_index] = 0\n                else:\n                    # DE update\n                    old_fitness = self.fitness[i]\n                    old_position = self.population[i].copy()\n                    self.de_update(func)  # Update all population by DE internally\n                    if self.fitness[i] < old_fitness:\n                        self.de_success[self.success_index] = 1\n                    else:\n                        self.de_success[self.success_index] = 0\n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        self.population[i] = local_x.copy()\n                        self.fitness[i] = local_f\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                \n                if self.func_evals >= self.budget:\n                    break\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "crossover", "theta_sampled": -0.0002609644570169759, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "036e7772-8ea0-4341-b1be-1940256b0272", "fitness": 0.0, "name": "AdaptivePerturbedDE_OL", "description": "Adaptive Perturbed DE with orthogonal learning to enhance diversity and exploitation.", "code": "import numpy as np\n\nclass AdaptivePerturbedDE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05, archive_size=10, orthogonal_learning_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Initialize Archive\n        self.archive = list(population)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Velocity update\n                self.velocities[i] = self.F * (x_r2 - x_r3)\n                x_mutated = population[i] + self.velocities[i]\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n                    #Update archive\n                    self.update_archive(x_trial)\n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n                    self.update_archive(x_perturbed)\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n                    self.update_archive(x_perturbed)\n\n            # Adaptive F and Cr (optional - can be enabled/disabled)\n            self.F = np.random.normal(0.5, 0.1)\n            self.Cr = np.random.normal(0.7, 0.1)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n            # Orthogonal Learning Strategy\n            if np.random.rand() < self.orthogonal_learning_rate and self.budget > 0:\n                self.orthogonal_learning(population, fitness, func)\n\n        return self.f_opt, self.x_opt\n\n    def update_archive(self, x):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n        else:\n            # Replace a random element in archive\n            index = np.random.randint(self.archive_size)\n            self.archive[index] = x\n\n    def orthogonal_learning(self, population, fitness, func):\n        # Select two random individuals\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = population[idxs]\n\n        # Create orthogonal array (L9 array for 3 factors and 3 levels)\n        # Simple example using two points; more sophisticated orthogonal arrays can be used.\n        levels = np.array([x1, x2, (x1 + x2)/2.0]) # Create three levels\n\n        # Generate combinations based on the levels for each dimension (simplified)\n        combinations = []\n        for i in range(self.dim):\n            comb = levels[np.random.choice(3, size=1)]\n            combinations.append(comb)\n            \n        x_new = np.array([c[0] for c in combinations])\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        \n        f_new = func(x_new)\n        self.budget -= 1\n\n        if f_new < self.f_opt:\n            self.f_opt = f_new\n            self.x_opt = x_new\n            self.update_archive(x_new)\n\n        #Potentially replace a random solution\n        replace_index = np.random.randint(self.pop_size)\n        if f_new < fitness[replace_index]:\n            fitness[replace_index] = f_new\n            population[replace_index] = x_new\n            self.update_archive(x_new)", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: '<' not supported between instances of 'list' and 'float'", "parent_ids": ["dcf9de44-1522-4dbd-854e-024dfaefb7ff"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Perturbed DE with orthogonal learning to enhance diversity and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePerturbedDE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, perturbation_rate=0.1, perturbation_size=0.05, archive_size=10, orthogonal_learning_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_size = perturbation_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Initialize Archive\n        self.archive = list(population)\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Velocity update\n                self.velocities[i] = self.F * (x_r2 - x_r3)\n                x_mutated = population[i] + self.velocities[i]\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n                    #Update archive\n                    self.update_archive(x_trial)\n\n            # Perturbation of the best solution\n            if np.random.rand() < self.perturbation_rate and self.budget > 0:\n                perturbation = np.random.normal(0, self.perturbation_size, size=self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = x_perturbed\n                    self.update_archive(x_perturbed)\n\n                # Potentially replace a random member with the perturbed solution\n                replace_index = np.random.randint(self.pop_size)\n                if f_perturbed < fitness[replace_index]:\n                    fitness[replace_index] = f_perturbed\n                    population[replace_index] = x_perturbed\n                    self.update_archive(x_perturbed)\n\n            # Adaptive F and Cr (optional - can be enabled/disabled)\n            self.F = np.random.normal(0.5, 0.1)\n            self.Cr = np.random.normal(0.7, 0.1)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n            # Orthogonal Learning Strategy\n            if np.random.rand() < self.orthogonal_learning_rate and self.budget > 0:\n                self.orthogonal_learning(population, fitness, func)\n\n        return self.f_opt, self.x_opt\n\n    def update_archive(self, x):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n        else:\n            # Replace a random element in archive\n            index = np.random.randint(self.archive_size)\n            self.archive[index] = x\n\n    def orthogonal_learning(self, population, fitness, func):\n        # Select two random individuals\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = population[idxs]\n\n        # Create orthogonal array (L9 array for 3 factors and 3 levels)\n        # Simple example using two points; more sophisticated orthogonal arrays can be used.\n        levels = np.array([x1, x2, (x1 + x2)/2.0]) # Create three levels\n\n        # Generate combinations based on the levels for each dimension (simplified)\n        combinations = []\n        for i in range(self.dim):\n            comb = levels[np.random.choice(3, size=1)]\n            combinations.append(comb)\n            \n        x_new = np.array([c[0] for c in combinations])\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        \n        f_new = func(x_new)\n        self.budget -= 1\n\n        if f_new < self.f_opt:\n            self.f_opt = f_new\n            self.x_opt = x_new\n            self.update_archive(x_new)\n\n        #Potentially replace a random solution\n        replace_index = np.random.randint(self.pop_size)\n        if f_new < fitness[replace_index]:\n            fitness[replace_index] = f_new\n            population[replace_index] = x_new\n            self.update_archive(x_new)\n```", "operator": "mutation", "theta_sampled": 0.002115101450238392, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "6aff0e6b-636c-486c-8b09-b648861b8b65", "fitness": 0.5262897592667826, "name": "AdaptiveHybridPSO_DE", "description": "Dynamically adjusts PSO/DE ratio based on success rates, incorporates a dynamically scaled local search, and uses a simplified velocity update with adaptive inertia weight for better exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, local_search_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.local_search_scale = local_search_scale #Initial scale for local search\n        self.generation = 0 # Generation counter\n\n    def local_search(self, func, x, radius):\n        \"\"\"Performs a local search around x with dynamically scaled radius.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5):  # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)  # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            self.generation += 1\n            #Adaptive Inertia Weight\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget // self.pop_size + self.generation)) # Linear decrease\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()  # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    # Simplified Velocity Update\n                    velocity[i] = w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n\n                    # Velocity clipping\n                    velocity[i] = np.clip(velocity[i], -v_max, v_max)\n                    new_pos_pso = pop[i] + velocity[i]\n\n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()  # Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n\n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                # Local search with adaptive scaling\n                if np.random.rand() < self.local_search_probability:\n                    # Reduce scale as search progresses\n                    current_scale = self.local_search_scale * (1 - (self.generation / (self.budget // self.pop_size + self.generation)))\n                    local_f, local_x = self.local_search(func, pop[i].copy(), current_scale)\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.526 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO/DE ratio based on success rates, incorporates a dynamically scaled local search, and uses a simplified velocity update with adaptive inertia weight for better exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, local_search_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.local_search_scale = local_search_scale #Initial scale for local search\n        self.generation = 0 # Generation counter\n\n    def local_search(self, func, x, radius):\n        \"\"\"Performs a local search around x with dynamically scaled radius.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5):  # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)  # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            self.generation += 1\n            #Adaptive Inertia Weight\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget // self.pop_size + self.generation)) # Linear decrease\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()  # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    # Simplified Velocity Update\n                    velocity[i] = w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n\n                    # Velocity clipping\n                    velocity[i] = np.clip(velocity[i], -v_max, v_max)\n                    new_pos_pso = pop[i] + velocity[i]\n\n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()  # Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n\n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                # Local search with adaptive scaling\n                if np.random.rand() < self.local_search_probability:\n                    # Reduce scale as search progresses\n                    current_scale = self.local_search_scale * (1 - (self.generation / (self.budget // self.pop_size + self.generation)))\n                    local_f, local_x = self.local_search(func, pop[i].copy(), current_scale)\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.2371978771429608, 0.22446312054523465, 0.5802892284561378, 0.8092066411540113, 0.26535338197503566, 0.6588966933891143, 0.3325781526961463, 0.5325240487299673, 0.6238671832986253, 0.20219639600358963, 0.7778155338286563, 0.9908784744751017, 0.2955306002585295, 0.521252872789244, 0.8449205364925921, 0.6397283699670011, 0.39389148390204165, 0.7243933100382176, 0.35933954009025093, 0.5114717401031936], "operator": "mutation", "theta_sampled": 0.0020230046745039277, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "5e555e64-64bb-43df-bf45-a341a9eeacbb", "fitness": 0.0, "name": "AdaptiveHybridPSO_DELocal", "description": "An adaptive hybrid PSO-DE algorithm with local search and dynamic strategy adaptation based on success rates and population diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DELocal:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, diversity_threshold=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search and Diversity Check.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            diversity_threshold (float): Threshold for population diversity to trigger restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.diversity_threshold = diversity_threshold\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100\n        self.pso_total = 0\n        self.de_total = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"Updates the global best position and fitness.\"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"Updates the population using PSO.\"\"\"\n        self.pso_total += self.pop_size\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        self.population += self.velocities\n\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])\n                    self.velocities[i, j] = -self.velocities[i, j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])\n                    self.velocities[i, j] = -self.velocities[i, j]\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        improved = False\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n                improved = True\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n        return improved\n\n\n    def de_update(self, func):\n        \"\"\"Updates the population using DE.\"\"\"\n        self.de_total += self.pop_size\n        improved = False\n        for i in range(self.pop_size):\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                improved = True\n\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n        return improved\n    \n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        num_evals = min(5, self.budget - self.func_evals) # Reduce evaluations if budget is low\n        if num_evals <= 0:\n            return best_f, best_x\n\n        for _ in range(num_evals):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n            if self.func_evals >= self.budget:\n                break\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"Updates the probabilities of using PSO or DE.\"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)\n\n    def restart_population(self, func):\n        \"\"\"Restarts the population.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        \n\n    def check_diversity(self):\n        \"\"\"Checks the diversity of the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        if distances:\n            avg_distance = np.mean(distances)\n            range_size = np.linalg.norm(np.array(func.bounds.ub) - np.array(func.bounds.lb))\n            normalized_distance = avg_distance / range_size\n            return normalized_distance < self.diversity_threshold\n        return False  # If distances is empty, return False to avoid errors\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n            \n            # Choose between PSO and DE\n            if np.random.rand() < self.pso_prob:\n                improved = self.pso_update(func)\n            else:\n                improved = self.de_update(func)\n            \n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        self.population[i] = local_x.copy() #Update population\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            \n            if self.check_diversity():\n                self.restart_population(func)\n                self.restart_counter = 0\n            elif self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with local search and dynamic strategy adaptation based on success rates and population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DELocal:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, diversity_threshold=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search and Diversity Check.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            diversity_threshold (float): Threshold for population diversity to trigger restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.diversity_threshold = diversity_threshold\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100\n        self.pso_total = 0\n        self.de_total = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"Updates the global best position and fitness.\"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"Updates the population using PSO.\"\"\"\n        self.pso_total += self.pop_size\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        self.population += self.velocities\n\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])\n                    self.velocities[i, j] = -self.velocities[i, j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])\n                    self.velocities[i, j] = -self.velocities[i, j]\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        improved = False\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n                improved = True\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n        return improved\n\n\n    def de_update(self, func):\n        \"\"\"Updates the population using DE.\"\"\"\n        self.de_total += self.pop_size\n        improved = False\n        for i in range(self.pop_size):\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                improved = True\n\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n        return improved\n    \n    def local_search(self, func, x, radius=0.05):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        num_evals = min(5, self.budget - self.func_evals) # Reduce evaluations if budget is low\n        if num_evals <= 0:\n            return best_f, best_x\n\n        for _ in range(num_evals):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n            if self.func_evals >= self.budget:\n                break\n        return best_f, best_x\n\n    def update_probabilities(self):\n        \"\"\"Updates the probabilities of using PSO or DE.\"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)\n\n    def restart_population(self, func):\n        \"\"\"Restarts the population.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        \n\n    def check_diversity(self):\n        \"\"\"Checks the diversity of the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        if distances:\n            avg_distance = np.mean(distances)\n            range_size = np.linalg.norm(np.array(func.bounds.ub) - np.array(func.bounds.lb))\n            normalized_distance = avg_distance / range_size\n            return normalized_distance < self.diversity_threshold\n        return False  # If distances is empty, return False to avoid errors\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter += 1\n            \n            # Choose between PSO and DE\n            if np.random.rand() < self.pso_prob:\n                improved = self.pso_update(func)\n            else:\n                improved = self.de_update(func)\n            \n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        self.population[i] = local_x.copy() #Update population\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            \n            if self.check_diversity():\n                self.restart_population(func)\n                self.restart_counter = 0\n            elif self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "crossover", "theta_sampled": 0.002622161532776499, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "45a74d20-a070-43f7-a641-9696fe6cf414", "fitness": 0.5927246051011882, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive Differential Evolution algorithm that uses a pool of mutation strategies and dynamically adjusts their probabilities based on their recent success in improving the solution.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.593 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution algorithm that uses a pool of mutation strategies and dynamically adjusts their probabilities based on their recent success in improving the solution.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20427662246788003, 0.38834462589371965, 0.55445059298417, 0.8367205494689944, 0.6564559632691851, 0.7362868273366068, 0.43490293957974313, 0.5621842045366168, 0.6412454713640177, 0.5780286672881062, 0.7695697768028699, 0.9951718868641796, 0.32581344509257193, 0.6296383489107171, 0.8602476222568941, 0.7353110587119935, 0.44231299398618085, 0.8129266972075804, 0.1867609486906039, 0.503842859311133], "operator": "random_new", "theta_sampled": 0.0015690106066886128, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "280c5639-7564-48e8-86bb-920f24350b86", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMA", "description": "Dynamically adjusts PSO/DE ratio based on their individual success rates and incorporates a covariance matrix adaptation (CMA) inspired mutation for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, cma_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_lr = cma_lr  # Learning rate for CMA-like adaptation\n        self.covariance = np.eye(dim)  # Initialize covariance matrix\n        self.mean = np.zeros(dim)  # Initialize mean for CMA-like mutation\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        if self.budget <= 0:\n            return best_f, best_x\n\n        num_evals = min(5, self.budget)\n        for _ in range(num_evals):  # Reduced local search evaluations based on budget\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            f = func(new_x)\n            self.budget -= 1\n            if f < best_f:\n                best_f = f\n                best_x = new_x.copy()\n            if self.budget <= 0:\n                break\n        return best_f, best_x\n\n    def cma_mutation(self):\n        \"\"\"Performs a CMA-like mutation.\"\"\"\n        return np.random.multivariate_normal(self.mean, self.covariance)\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # CMA-like mutation\n                new_pos_cma = pop[i] + self.cma_mutation()\n                new_pos_cma = np.clip(new_pos_cma, func.bounds.lb, func.bounds.ub)\n                new_fitness_cma = func(new_pos_cma)\n                self.budget -= 1\n\n                # Select the better update (PSO, DE, or CMA)\n                best_pos = pop[i].copy()\n                best_fitness = fitness[i]\n\n                if new_fitness_pso < best_fitness:\n                    best_pos = new_pos_pso\n                    best_fitness = new_fitness_pso\n\n                if new_fitness_de < best_fitness:\n                    best_pos = new_pos_de\n                    best_fitness = new_fitness_de\n\n                if new_fitness_cma < best_fitness:\n                    best_pos = new_pos_cma\n                    best_fitness = new_fitness_cma\n                \n                if best_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = best_fitness\n                    pbest_pop[i] = best_pos.copy()\n\n                    if best_fitness < gbest_fitness:\n                        gbest_fitness = best_fitness\n                        gbest_pos = best_pos.copy()\n\n                pop[i] = best_pos.copy()\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            # Adapt pso ratio\n            if self.total_pso > 0 or self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # Update CMA parameters\n            self.mean = gbest_pos.copy()  # Use gbest as the mean\n\n            #Adapt covariance matrix\n            diff = pop - self.mean\n            self.covariance = (1 - self.cma_lr) * self.covariance + self.cma_lr * (diff.T @ diff) / self.pop_size #approximation of rank-mu update\n\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO/DE ratio based on their individual success rates and incorporates a covariance matrix adaptation (CMA) inspired mutation for enhanced exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, cma_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_lr = cma_lr  # Learning rate for CMA-like adaptation\n        self.covariance = np.eye(dim)  # Initialize covariance matrix\n        self.mean = np.zeros(dim)  # Initialize mean for CMA-like mutation\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        if self.budget <= 0:\n            return best_f, best_x\n\n        num_evals = min(5, self.budget)\n        for _ in range(num_evals):  # Reduced local search evaluations based on budget\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            f = func(new_x)\n            self.budget -= 1\n            if f < best_f:\n                best_f = f\n                best_x = new_x.copy()\n            if self.budget <= 0:\n                break\n        return best_f, best_x\n\n    def cma_mutation(self):\n        \"\"\"Performs a CMA-like mutation.\"\"\"\n        return np.random.multivariate_normal(self.mean, self.covariance)\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # CMA-like mutation\n                new_pos_cma = pop[i] + self.cma_mutation()\n                new_pos_cma = np.clip(new_pos_cma, func.bounds.lb, func.bounds.ub)\n                new_fitness_cma = func(new_pos_cma)\n                self.budget -= 1\n\n                # Select the better update (PSO, DE, or CMA)\n                best_pos = pop[i].copy()\n                best_fitness = fitness[i]\n\n                if new_fitness_pso < best_fitness:\n                    best_pos = new_pos_pso\n                    best_fitness = new_fitness_pso\n\n                if new_fitness_de < best_fitness:\n                    best_pos = new_pos_de\n                    best_fitness = new_fitness_de\n\n                if new_fitness_cma < best_fitness:\n                    best_pos = new_pos_cma\n                    best_fitness = new_fitness_cma\n                \n                if best_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = best_fitness\n                    pbest_pop[i] = best_pos.copy()\n\n                    if best_fitness < gbest_fitness:\n                        gbest_fitness = best_fitness\n                        gbest_pos = best_pos.copy()\n\n                pop[i] = best_pos.copy()\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            # Adapt pso ratio\n            if self.total_pso > 0 or self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # Update CMA parameters\n            self.mean = gbest_pos.copy()  # Use gbest as the mean\n\n            #Adapt covariance matrix\n            diff = pop - self.mean\n            self.covariance = (1 - self.cma_lr) * self.covariance + self.cma_lr * (diff.T @ diff) / self.pop_size #approximation of rank-mu update\n\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0], "operator": "mutation", "theta_sampled": -6.212763591413939e-05, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "5e6e2fe9-1bb7-4ff9-88e9-8c6ec97199e5", "fitness": 0.0, "name": "GradientGuidedGaussianMutation", "description": "This algorithm combines a Gaussian mutation-based exploration strategy with a local search component that leverages gradient estimation for refinement.", "code": "import numpy as np\n\nclass GradientGuidedGaussianMutation:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, mutation_rate=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.mutation_rate = mutation_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)  # Initialize randomly\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Gaussian Mutation\n            x_mutated = self.x_opt + self.mutation_rate * np.random.normal(0, 1, size=self.dim)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            f_mutated = func(x_mutated)\n            eval_count += 1\n            if eval_count >= self.budget:\n                if f_mutated < self.f_opt:\n                    self.f_opt = f_mutated\n                    self.x_opt = x_mutated\n                break\n            \n            if f_mutated < self.f_opt:\n                self.f_opt = f_mutated\n                self.x_opt = x_mutated\n                \n                # Local Search with Gradient Estimation\n                x_local = self.x_opt.copy()\n                f_local = self.f_opt\n                for _ in range(self.local_search_iterations):\n                    # Estimate Gradient (simplified finite difference)\n                    gradient = np.zeros(self.dim)\n                    for i in range(self.dim):\n                        x_plus = x_local.copy()\n                        x_minus = x_local.copy()\n                        x_plus[i] += self.step_size\n                        x_minus[i] -= self.step_size\n                        x_plus[i] = np.clip(x_plus[i], func.bounds.lb, func.bounds.ub)\n                        x_minus[i] = np.clip(x_minus[i], func.bounds.lb, func.bounds.ub)\n                        \n                        f_plus = func(x_plus)\n                        eval_count += 1\n                        if eval_count >= self.budget:\n                            break\n                        f_minus = func(x_minus)\n                        eval_count += 1\n                        if eval_count >= self.budget:\n                            break\n\n                        gradient[i] = (f_plus - f_minus) / (2 * self.step_size)\n\n                    if eval_count >= self.budget:\n                        break\n\n                    # Move against the gradient\n                    x_new = x_local - self.step_size * gradient\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                    f_new = func(x_new)\n                    eval_count += 1\n                    \n                    if eval_count >= self.budget:\n                        break\n\n                    if f_new < f_local:\n                        f_local = f_new\n                        x_local = x_new\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: This algorithm combines a Gaussian mutation-based exploration strategy with a local search component that leverages gradient estimation for refinement.\n\n# Code:\n```python\nimport numpy as np\n\nclass GradientGuidedGaussianMutation:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, mutation_rate=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.mutation_rate = mutation_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)  # Initialize randomly\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Gaussian Mutation\n            x_mutated = self.x_opt + self.mutation_rate * np.random.normal(0, 1, size=self.dim)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            f_mutated = func(x_mutated)\n            eval_count += 1\n            if eval_count >= self.budget:\n                if f_mutated < self.f_opt:\n                    self.f_opt = f_mutated\n                    self.x_opt = x_mutated\n                break\n            \n            if f_mutated < self.f_opt:\n                self.f_opt = f_mutated\n                self.x_opt = x_mutated\n                \n                # Local Search with Gradient Estimation\n                x_local = self.x_opt.copy()\n                f_local = self.f_opt\n                for _ in range(self.local_search_iterations):\n                    # Estimate Gradient (simplified finite difference)\n                    gradient = np.zeros(self.dim)\n                    for i in range(self.dim):\n                        x_plus = x_local.copy()\n                        x_minus = x_local.copy()\n                        x_plus[i] += self.step_size\n                        x_minus[i] -= self.step_size\n                        x_plus[i] = np.clip(x_plus[i], func.bounds.lb, func.bounds.ub)\n                        x_minus[i] = np.clip(x_minus[i], func.bounds.lb, func.bounds.ub)\n                        \n                        f_plus = func(x_plus)\n                        eval_count += 1\n                        if eval_count >= self.budget:\n                            break\n                        f_minus = func(x_minus)\n                        eval_count += 1\n                        if eval_count >= self.budget:\n                            break\n\n                        gradient[i] = (f_plus - f_minus) / (2 * self.step_size)\n\n                    if eval_count >= self.budget:\n                        break\n\n                    # Move against the gradient\n                    x_new = x_local - self.step_size * gradient\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                    f_new = func(x_new)\n                    eval_count += 1\n                    \n                    if eval_count >= self.budget:\n                        break\n\n                    if f_new < f_local:\n                        f_local = f_new\n                        x_local = x_new\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0010755886219816603, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "869af858-f3ed-4db8-98c4-67c6fc47efca", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Adaptively combines PSO and DE with local search, using a success memory to dynamically adjust PSO probability and incorporates velocity clamping and boundary reflection for PSO.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, local_search_radius=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            local_search_radius (float): Radius for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.velocity_clamp_factor = 0.1\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * self.velocity_clamp_factor  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n    \n    def local_search(self, func, x):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    self.pso_update(func)\n                else:\n                    self.de_update(func)\n                    \n                # Local search\n                if np.random.rand() < self.local_search_probability and self.func_evals < self.budget:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.population[i] = local_x.copy()\n                if self.func_evals >= self.budget:\n                    break\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974", "1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with local search, using a success memory to dynamically adjust PSO probability and incorporates velocity clamping and boundary reflection for PSO.\n\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, local_search_probability=0.05, local_search_radius=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            local_search_probability (float): Probability of performing local search.\n            local_search_radius (float): Radius for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.velocity_clamp_factor = 0.1\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * self.velocity_clamp_factor  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n    \n    def local_search(self, func, x):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.func_evals += 1\n        if self.func_evals >= self.budget:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    self.pso_update(func)\n                else:\n                    self.de_update(func)\n                    \n                # Local search\n                if np.random.rand() < self.local_search_probability and self.func_evals < self.budget:\n                    local_f, local_x = self.local_search(func, self.population[i].copy())\n                    if local_f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = local_f\n                        self.personal_best_positions[i] = local_x.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_x.copy()\n                    self.population[i] = local_x.copy()\n                if self.func_evals >= self.budget:\n                    break\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.0005111192154343324, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "2dbbb9f9-66cb-4a90-80ce-da515872de2e", "fitness": 0.27888435902994235, "name": "AdaptiveStepSizeSearch", "description": "An adaptive algorithm that combines global exploration with local refinement using a dynamically adjusted step size based on the success rate of the search.", "code": "import numpy as np\n\nclass AdaptiveStepSizeSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_threshold=0.1, step_size_reduction_factor=0.5, step_size_increase_factor=1.2):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_threshold = success_threshold\n        self.step_size_reduction_factor = step_size_reduction_factor\n        self.step_size_increase_factor = step_size_increase_factor\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        \n        # Initialization\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        \n        success_count = 0\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Generate a candidate solution by perturbing the current best\n            x_new = x + np.random.normal(0, self.step_size, size=self.dim)\n\n            # Clip the solution to the bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            eval_count += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                success_count += 1\n                \n\n            # Adjust step size based on success rate\n            if eval_count % 100 == 0: # Evaluate every 100 iterations\n                success_rate = success_count / 100\n                if success_rate > self.success_threshold:\n                    self.step_size *= self.step_size_increase_factor\n                    self.step_size = min(self.step_size, (func.bounds.ub[0] - func.bounds.lb[0])/2)  # Cap step size\n                else:\n                    self.step_size *= self.step_size_reduction_factor\n                    self.step_size = max(self.step_size, 1e-6) # Ensure step size doesn't become too small\n                success_count = 0\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveStepSizeSearch scored 0.279 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive algorithm that combines global exploration with local refinement using a dynamically adjusted step size based on the success rate of the search.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveStepSizeSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_threshold=0.1, step_size_reduction_factor=0.5, step_size_increase_factor=1.2):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_threshold = success_threshold\n        self.step_size_reduction_factor = step_size_reduction_factor\n        self.step_size_increase_factor = step_size_increase_factor\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        \n        # Initialization\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        \n        success_count = 0\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Generate a candidate solution by perturbing the current best\n            x_new = x + np.random.normal(0, self.step_size, size=self.dim)\n\n            # Clip the solution to the bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            eval_count += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                success_count += 1\n                \n\n            # Adjust step size based on success rate\n            if eval_count % 100 == 0: # Evaluate every 100 iterations\n                success_rate = success_count / 100\n                if success_rate > self.success_threshold:\n                    self.step_size *= self.step_size_increase_factor\n                    self.step_size = min(self.step_size, (func.bounds.ub[0] - func.bounds.lb[0])/2)  # Cap step size\n                else:\n                    self.step_size *= self.step_size_reduction_factor\n                    self.step_size = max(self.step_size, 1e-6) # Ensure step size doesn't become too small\n                success_count = 0\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.035266423060529406, 0.1668657940302053, 0.20410614189875886, 0.13644221586101557, 0.09110454417516989, 0.18805676798514692, 0.21742215291273548, 0.1124689667250135, 0.1470374503074079, 0.1362436367830876, 0.8870550252638697, 0.17257244630182356, 0.24688321034971628, 0.19518401689106135, 0.9351257828796206, 0.33407642519934166, 0.17843931167870763, 0.9408204016526123, 0.07646479908329662, 0.17605166755972657], "operator": "random_new", "theta_sampled": 0.0010010578369109015, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "c735ff04-b525-4168-ba06-79c83b7ad6b8", "fitness": 0.0, "name": "CauchySearch", "description": "Population-based algorithm using a Cauchy mutation operator and a shrinking search space based on the best solution found so far.", "code": "import numpy as np\n\nclass CauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, shrink_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within the bounds\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        \n        f_vals = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(f_vals)\n        self.f_opt = f_vals[best_idx]\n        self.x_opt = population[best_idx]\n\n        current_lb = lb\n        current_ub = ub\n\n        while self.budget > 0:\n            # Cauchy mutation\n            cauchy_samples = np.random.standard_cauchy(size=(self.pop_size, self.dim))\n            mutated_population = population + 0.1 * cauchy_samples  # Scaling factor for Cauchy distribution\n\n            # Reflect boundary handling\n            mutated_population = np.clip(mutated_population, current_lb, current_ub)\n\n            # Evaluate mutated population\n            mutated_f_vals = np.array([func(x) for x in mutated_population])\n            self.budget -= self.pop_size\n\n            # Update population and best solution\n            for i in range(self.pop_size):\n                if mutated_f_vals[i] < f_vals[i]:\n                    population[i] = mutated_population[i]\n                    f_vals[i] = mutated_f_vals[i]\n\n                    if mutated_f_vals[i] < self.f_opt:\n                        self.f_opt = mutated_f_vals[i]\n                        self.x_opt = mutated_population[i]\n\n            # Shrink the search space around the best solution\n            current_range = current_ub - current_lb\n            new_range = self.shrink_factor * current_range\n\n            current_lb = np.maximum(lb, self.x_opt - new_range/2)\n            current_ub = np.minimum(ub, self.x_opt + new_range/2)\n\n            if (current_ub - current_lb) < 1e-9:\n              # Break if search space becomes too small to avoid numerical issues\n              break\n           \n            # Reflect to avoid going out of original bounds.\n            if np.any(current_lb < lb):\n              shift = lb - current_lb\n              current_lb += shift\n              current_ub += shift\n            if np.any(current_ub > ub):\n              shift = current_ub - ub\n              current_lb -= shift\n              current_ub -= shift\n\n            current_lb = np.clip(current_lb, lb, ub)\n            current_ub = np.clip(current_ub, lb, ub)\n              \n\n            if self.budget <= 0:\n                break\n            \n            # Ensure population stays within the shrunk bounds after shrinking.\n            population = np.clip(population, current_lb, current_ub)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a Cauchy mutation operator and a shrinking search space based on the best solution found so far.\n# Code: \n```python\nimport numpy as np\n\nclass CauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, shrink_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within the bounds\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        \n        f_vals = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(f_vals)\n        self.f_opt = f_vals[best_idx]\n        self.x_opt = population[best_idx]\n\n        current_lb = lb\n        current_ub = ub\n\n        while self.budget > 0:\n            # Cauchy mutation\n            cauchy_samples = np.random.standard_cauchy(size=(self.pop_size, self.dim))\n            mutated_population = population + 0.1 * cauchy_samples  # Scaling factor for Cauchy distribution\n\n            # Reflect boundary handling\n            mutated_population = np.clip(mutated_population, current_lb, current_ub)\n\n            # Evaluate mutated population\n            mutated_f_vals = np.array([func(x) for x in mutated_population])\n            self.budget -= self.pop_size\n\n            # Update population and best solution\n            for i in range(self.pop_size):\n                if mutated_f_vals[i] < f_vals[i]:\n                    population[i] = mutated_population[i]\n                    f_vals[i] = mutated_f_vals[i]\n\n                    if mutated_f_vals[i] < self.f_opt:\n                        self.f_opt = mutated_f_vals[i]\n                        self.x_opt = mutated_population[i]\n\n            # Shrink the search space around the best solution\n            current_range = current_ub - current_lb\n            new_range = self.shrink_factor * current_range\n\n            current_lb = np.maximum(lb, self.x_opt - new_range/2)\n            current_ub = np.minimum(ub, self.x_opt + new_range/2)\n\n            if (current_ub - current_lb) < 1e-9:\n              # Break if search space becomes too small to avoid numerical issues\n              break\n           \n            # Reflect to avoid going out of original bounds.\n            if np.any(current_lb < lb):\n              shift = lb - current_lb\n              current_lb += shift\n              current_ub += shift\n            if np.any(current_ub > ub):\n              shift = current_ub - ub\n              current_lb -= shift\n              current_ub -= shift\n\n            current_lb = np.clip(current_lb, lb, ub)\n            current_ub = np.clip(current_ub, lb, ub)\n              \n\n            if self.budget <= 0:\n                break\n            \n            # Ensure population stays within the shrunk bounds after shrinking.\n            population = np.clip(population, current_lb, current_ub)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": -0.00019988155485604835, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "b560cb53-c04f-4c2b-a476-50b6c9483c25", "fitness": 0.6716055014906605, "name": "AdaptiveAgingDE", "description": "Adaptive Differential Evolution with aging, dynamically adjusted CR/F parameters and a repair mechanism to handle out-of-bound individuals, aiming for a better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveAgingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveAgingDE scored 0.672 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45a74d20-a070-43f7-a641-9696fe6cf414"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with aging, dynamically adjusted CR/F parameters and a repair mechanism to handle out-of-bound individuals, aiming for a better exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1981453456831107, 0.464017318888992, 0.6630950574862853, 0.8368292076142992, 0.7606551089638532, 0.837373824206319, 0.635507455369301, 0.6685788149844429, 0.7637127134079693, 0.6980549326823895, 0.8187125618426727, 0.9992361814559579, 0.33000798769096584, 0.7161059480485212, 0.9028227115359397, 0.8114923000451418, 0.5063634738862176, 0.8425584996957343, 0.4459633429149803, 0.5328772434101149], "operator": "mutation", "theta_sampled": 0.0003093219976439617, "reward": 0.032436205742558455, "generation": 8}, "task_prompt": ""}
{"id": "abec3175-2196-4db0-a2d5-c665f3bc9230", "fitness": 0.5825998419606917, "name": "AdaptiveHybridPSO_DE_CMA", "description": "An adaptive hybrid algorithm that combines PSO and DE with a CMA-ES inspired adaptation of the covariance matrix for mutation, enhancing exploration and exploitation capabilities.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.learning_rate = learning_rate #Learning Rate for CMA update\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES-like mutation\n        self.eigen_decomposition()\n        self.mueff = pop_size / 4 #mu effective\n\n    def eigen_decomposition(self):\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(np.diag(self.D))\n\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            sorted_indices = np.argsort(fitness)\n            elite_individuals = pop[sorted_indices[:self.pop_size // 4]]\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update with CMA-ES-inspired mutation\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    # CMA-ES-like mutation\n                    z = np.random.normal(0, 1, self.dim)\n                    diff_vector = x1 + self.f * (x2 - x3) + self.f * (self.B @ self.D @ z)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # CMA-ES-like Covariance Matrix Adaptation\n            delta = elite_individuals - np.mean(elite_individuals, axis=0)\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * (delta.T @ delta) / (self.mueff * np.var(fitness))\n\n            self.eigen_decomposition() #Update B and D\n\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMA scored 0.583 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm that combines PSO and DE with a CMA-ES inspired adaptation of the covariance matrix for mutation, enhancing exploration and exploitation capabilities.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.learning_rate = learning_rate #Learning Rate for CMA update\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES-like mutation\n        self.eigen_decomposition()\n        self.mueff = pop_size / 4 #mu effective\n\n    def eigen_decomposition(self):\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(np.diag(self.D))\n\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            sorted_indices = np.argsort(fitness)\n            elite_individuals = pop[sorted_indices[:self.pop_size // 4]]\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update with CMA-ES-inspired mutation\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    # CMA-ES-like mutation\n                    z = np.random.normal(0, 1, self.dim)\n                    diff_vector = x1 + self.f * (x2 - x3) + self.f * (self.B @ self.D @ z)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # CMA-ES-like Covariance Matrix Adaptation\n            delta = elite_individuals - np.mean(elite_individuals, axis=0)\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * (delta.T @ delta) / (self.mueff * np.var(fitness))\n\n            self.eigen_decomposition() #Update B and D\n\n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.10753503419683952, 0.5800478731845802, 0.6402468832346815, 0.7223507969373745, 0.6824085675048457, 0.7433752755951778, 0.346632945873214, 0.46946001686483374, 0.6996514885869121, 0.18058635207517149, 0.8481419295750895, 0.9989248286388858, 0.293777047498337, 0.42690456645342967, 0.8533102104710713, 0.7156360119066512, 0.5863205620478602, 0.7990499814172813, 0.4214995138120182, 0.536136953339579], "operator": "mutation", "theta_sampled": 0.01778912409483984, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "f349b329-b53c-4f44-b7a4-30d9c6a56280", "fitness": 0.40307221934858894, "name": "AdaptiveHybridPSO_DE_CMA", "description": "An adaptive hybrid PSO-DE algorithm with a self-adjusting PSO/DE ratio based on success rates, combined with a CMA-ES-inspired mutation strategy to enhance exploration around the current best solution.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, cma_mu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_mu = cma_mu #mutation strength\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def cma_mutation(self, x, gbest_pos, sigma):\n        \"\"\"Applies a CMA-ES inspired mutation around gbest.\"\"\"\n        z = np.random.normal(0, 1, self.dim)\n        new_x = gbest_pos + sigma * z\n        return new_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        sigma = 0.1 * (func.bounds.ub - func.bounds.lb)  # Mutation strength, adapted from CMA-ES\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                # CMA-ES-inspired mutation on gbest\n                if np.random.rand() < self.cma_mu:\n                    mutated_x = self.cma_mutation(pop[i], gbest_pos, sigma)\n                    mutated_x = np.clip(mutated_x, func.bounds.lb, func.bounds.ub)\n                    mutated_f = func(mutated_x)\n                    self.budget -= 1\n                    if self.budget > 0 and mutated_f < pbest_fitness[i]:\n                        pbest_fitness[i] = mutated_f\n                        pbest_pop[i] = mutated_x.copy()\n                        if mutated_f < gbest_fitness:\n                            gbest_fitness = mutated_f\n                            gbest_pos = mutated_x.copy()\n                    pop[i] = mutated_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMA scored 0.403 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with a self-adjusting PSO/DE ratio based on success rates, combined with a CMA-ES-inspired mutation strategy to enhance exploration around the current best solution.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, cma_mu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.cma_mu = cma_mu #mutation strength\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def cma_mutation(self, x, gbest_pos, sigma):\n        \"\"\"Applies a CMA-ES inspired mutation around gbest.\"\"\"\n        z = np.random.normal(0, 1, self.dim)\n        new_x = gbest_pos + sigma * z\n        return new_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        sigma = 0.1 * (func.bounds.ub - func.bounds.lb)  # Mutation strength, adapted from CMA-ES\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                # CMA-ES-inspired mutation on gbest\n                if np.random.rand() < self.cma_mu:\n                    mutated_x = self.cma_mutation(pop[i], gbest_pos, sigma)\n                    mutated_x = np.clip(mutated_x, func.bounds.lb, func.bounds.ub)\n                    mutated_f = func(mutated_x)\n                    self.budget -= 1\n                    if self.budget > 0 and mutated_f < pbest_fitness[i]:\n                        pbest_fitness[i] = mutated_f\n                        pbest_pop[i] = mutated_x.copy()\n                        if mutated_f < gbest_fitness:\n                            gbest_fitness = mutated_f\n                            gbest_pos = mutated_x.copy()\n                    pop[i] = mutated_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.19936971645293367, 0.44590312328605586, 0.4609199696476425, 0.8438175814337382, 0.4287666574724107, 0.528808445922325, 0.31699226057360574, 0], "operator": "mutation", "theta_sampled": 0.007966062601736953, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "0516dbcb-12cc-4dfd-aa5a-b3a302cdc870", "fitness": 0.0, "name": "OrthogonalShrinkingHypersphere", "description": "A population-based algorithm using orthogonal learning to estimate promising regions and a shrinking hypersphere to focus search.", "code": "import numpy as np\n\nclass OrthogonalShrinkingHypersphere:\n    def __init__(self, budget=10000, dim=10, pop_size=20, sphere_reduction_rate=0.95, orthogonal_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sphere_reduction_rate = sphere_reduction_rate\n        self.orthogonal_trials = orthogonal_trials\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        radius = (ub - lb) / 2.0  # Initial radius\n\n        # Initialize population within the bounds\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find the best individual in the initial population\n        best_index = np.argmin(fitness)\n        self.x_opt = population[best_index]\n        self.f_opt = fitness[best_index]\n        center = self.x_opt # Initialize the center of the hypersphere\n\n        while self.budget > 0 and radius > 1e-6:  # Stop if budget is exhausted or radius is too small\n            # Orthogonal Learning Phase: Create orthogonal designs around the best solution\n            orthogonal_points = []\n            for _ in range(self.orthogonal_trials):\n                # Generate random orthogonal vectors\n                orthogonal_vector = np.random.normal(0, 1, size=self.dim)\n                orthogonal_vector /= np.linalg.norm(orthogonal_vector)\n\n                # Generate points along orthogonal vector\n                new_point = center + radius * orthogonal_vector\n                new_point = np.clip(new_point, lb, ub)  # Ensure within bounds\n                orthogonal_points.append(new_point)\n\n                new_point2 = center - radius * orthogonal_vector\n                new_point2 = np.clip(new_point2, lb, ub)  # Ensure within bounds\n                orthogonal_points.append(new_point2)\n\n\n            # Evaluate orthogonal points\n            orthogonal_fitness = []\n            for point in orthogonal_points:\n                if self.budget > 0:\n                    f = func(point)\n                    orthogonal_fitness.append(f)\n                    self.budget -= 1\n                else:\n                    break\n            orthogonal_fitness = np.array(orthogonal_fitness)\n\n\n            # Update best solution if orthogonal points are better\n            if len(orthogonal_fitness) > 0 and np.min(orthogonal_fitness) < self.f_opt:\n                best_orthogonal_index = np.argmin(orthogonal_fitness)\n                self.f_opt = orthogonal_fitness[best_orthogonal_index]\n                self.x_opt = orthogonal_points[best_orthogonal_index]\n                center = self.x_opt\n\n            # Hypersphere shrinking\n            radius *= self.sphere_reduction_rate\n\n            # Sample new points within the shrinking hypersphere around the current best\n            new_population = []\n            while len(new_population) < self.pop_size and self.budget > 0:\n                  \n                x = np.random.normal(center, radius/3, self.dim)\n                x = np.clip(x, lb, ub)  # Ensure within bounds\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    center = self.x_opt\n                new_population.append(x)\n            new_population = np.array(new_population)\n\n\n            # If we run out of budget when creating the new population, we have to terminate\n            if len(new_population) == 0:\n              break\n\n\n            # Update population with the new samples\n            population = new_population\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm using orthogonal learning to estimate promising regions and a shrinking hypersphere to focus search.\n# Code:\n```python\nimport numpy as np\n\nclass OrthogonalShrinkingHypersphere:\n    def __init__(self, budget=10000, dim=10, pop_size=20, sphere_reduction_rate=0.95, orthogonal_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sphere_reduction_rate = sphere_reduction_rate\n        self.orthogonal_trials = orthogonal_trials\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        radius = (ub - lb) / 2.0  # Initial radius\n\n        # Initialize population within the bounds\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find the best individual in the initial population\n        best_index = np.argmin(fitness)\n        self.x_opt = population[best_index]\n        self.f_opt = fitness[best_index]\n        center = self.x_opt # Initialize the center of the hypersphere\n\n        while self.budget > 0 and radius > 1e-6:  # Stop if budget is exhausted or radius is too small\n            # Orthogonal Learning Phase: Create orthogonal designs around the best solution\n            orthogonal_points = []\n            for _ in range(self.orthogonal_trials):\n                # Generate random orthogonal vectors\n                orthogonal_vector = np.random.normal(0, 1, size=self.dim)\n                orthogonal_vector /= np.linalg.norm(orthogonal_vector)\n\n                # Generate points along orthogonal vector\n                new_point = center + radius * orthogonal_vector\n                new_point = np.clip(new_point, lb, ub)  # Ensure within bounds\n                orthogonal_points.append(new_point)\n\n                new_point2 = center - radius * orthogonal_vector\n                new_point2 = np.clip(new_point2, lb, ub)  # Ensure within bounds\n                orthogonal_points.append(new_point2)\n\n\n            # Evaluate orthogonal points\n            orthogonal_fitness = []\n            for point in orthogonal_points:\n                if self.budget > 0:\n                    f = func(point)\n                    orthogonal_fitness.append(f)\n                    self.budget -= 1\n                else:\n                    break\n            orthogonal_fitness = np.array(orthogonal_fitness)\n\n\n            # Update best solution if orthogonal points are better\n            if len(orthogonal_fitness) > 0 and np.min(orthogonal_fitness) < self.f_opt:\n                best_orthogonal_index = np.argmin(orthogonal_fitness)\n                self.f_opt = orthogonal_fitness[best_orthogonal_index]\n                self.x_opt = orthogonal_points[best_orthogonal_index]\n                center = self.x_opt\n\n            # Hypersphere shrinking\n            radius *= self.sphere_reduction_rate\n\n            # Sample new points within the shrinking hypersphere around the current best\n            new_population = []\n            while len(new_population) < self.pop_size and self.budget > 0:\n                  \n                x = np.random.normal(center, radius/3, self.dim)\n                x = np.clip(x, lb, ub)  # Ensure within bounds\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    center = self.x_opt\n                new_population.append(x)\n            new_population = np.array(new_population)\n\n\n            # If we run out of budget when creating the new population, we have to terminate\n            if len(new_population) == 0:\n              break\n\n\n            # Update population with the new samples\n            population = new_population\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": -0.00010864910809561408, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "c549f739-9427-485f-b91e-61a339a7588b", "fitness": 0.6498655577470496, "name": "AdaptiveDifferentialEvolutionArchive", "description": "Adaptive Differential Evolution with dynamic parameter control and archive for stagnation avoidance.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDifferentialEvolutionArchive scored 0.650 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45a74d20-a070-43f7-a641-9696fe6cf414"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with dynamic parameter control and archive for stagnation avoidance.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.24321223043785212, 0.46375060688773606, 0.6463134111604962, 0.8778462312046247, 0.699480865158076, 0.778919206199516, 0.49076878025282167, 0.6526943236983563, 0.7060245112863963, 0.6647738619945287, 0.8311674553365316, 0.9925059341730603, 0.406194565871386, 0.7333202432489518, 0.9028246279590029, 0.796732728331784, 0.4990974425132525, 0.8567033871056897, 0.23324437724561253, 0.5217363648753158], "operator": "mutation", "theta_sampled": 0.007011654703689836, "reward": 0.010696261998947576, "generation": 8}, "task_prompt": ""}
{"id": "03727654-89a0-497a-89e7-d7dde5591816", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMA", "description": "An adaptive hybrid algorithm that dynamically adjusts the PSO/DE ratio and incorporates a self-adaptive mutation strategy and covariance matrix adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for C\n        self.ps = np.zeros(dim) # Evolution path for step size\n        self.c_sigma = 1/np.sqrt(dim)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((dim-1)/(dim+1)) - 1) + self.c_sigma\n        self.mu = pop_size // 2 # number of parents/selected individuals\n        self.weights = np.log(self.mu+1) - np.log(np.arange(1, self.mu+1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_c = (4 + self.mueff/self.dim) / (dim + 4 + 2*self.mueff/self.dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mueff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mueff - 2 + 1/self.mueff) / ((dim + 2)**2 + self.mueff))\n        self.chiN = dim**0.5*(1-1/(4*dim)+1/(21*dim**2))\n        self.mutation_scaling = 0.1 # Scaling factor for the mutation parameter\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        mean = gbest_pos.copy()\n\n        while self.budget > 0:\n            # Generate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n            offspring = mean + self.step_size * z\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n            \n            # Selection and Recombination\n            indices = np.argsort(fitness)\n            selected_offspring = offspring[indices[:self.mu]]\n            selected_fitness = fitness[indices[:self.mu]]\n            \n            # Update mean\n            old_mean = mean.copy()\n            mean = np.sum(self.weights[:, None] * selected_offspring, axis=0)\n\n            # Update evolution paths\n            y = (mean - old_mean) / self.step_size\n            z = (selected_offspring - old_mean) / self.step_size\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)*self.mueff) * np.linalg.solve(self.C**0.5, (mean - old_mean) / self.step_size)\n            \n            if np.linalg.norm(self.ps)/np.sqrt(1-(1-self.c_sigma)**(2*(self.budget//self.pop_size)))/self.chiN < 1.1:\n              hsig = 1\n            else:\n              hsig = 0\n            self.pc = (1-self.c_c)*self.pc + hsig*np.sqrt(self.c_c*(2-self.c_c)*self.mueff) * y\n            \n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            self.C += self.c_mu * np.sum(self.weights[:, None, None] * (z[:, :, None] @ z[:, None, :]), axis=0)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            mineig = np.min(np.linalg.eigvalsh(self.C))\n            if mineig < 1e-10:\n              self.C += (1e-10 - mineig) * np.eye(self.dim)\n\n            # Update step size\n            self.step_size = self.step_size * np.exp((self.c_sigma/self.d_sigma)*(np.linalg.norm(self.ps)/self.chiN - 1))\n                \n            # Local search on the best offspring\n            best_index = np.argmin(fitness)\n            local_f, local_x = self.local_search(func, offspring[best_index].copy())\n            if local_f < gbest_fitness:\n                gbest_fitness = local_f\n                gbest_pos = local_x.copy()\n\n            if fitness[best_index] < gbest_fitness:\n              gbest_fitness = fitness[best_index]\n              gbest_pos = offspring[best_index]\n\n            if self.budget <= 0:\n              break\n            \n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: Eigenvalues did not converge", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm that dynamically adjusts the PSO/DE ratio and incorporates a self-adaptive mutation strategy and covariance matrix adaptation for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability = 0.05, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.pso_ratio = pso_ratio  # Initial ratio of PSO updates\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for C\n        self.ps = np.zeros(dim) # Evolution path for step size\n        self.c_sigma = 1/np.sqrt(dim)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((dim-1)/(dim+1)) - 1) + self.c_sigma\n        self.mu = pop_size // 2 # number of parents/selected individuals\n        self.weights = np.log(self.mu+1) - np.log(np.arange(1, self.mu+1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_c = (4 + self.mueff/self.dim) / (dim + 4 + 2*self.mueff/self.dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mueff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mueff - 2 + 1/self.mueff) / ((dim + 2)**2 + self.mueff))\n        self.chiN = dim**0.5*(1-1/(4*dim)+1/(21*dim**2))\n        self.mutation_scaling = 0.1 # Scaling factor for the mutation parameter\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n        mean = gbest_pos.copy()\n\n        while self.budget > 0:\n            # Generate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n            offspring = mean + self.step_size * z\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n            \n            # Selection and Recombination\n            indices = np.argsort(fitness)\n            selected_offspring = offspring[indices[:self.mu]]\n            selected_fitness = fitness[indices[:self.mu]]\n            \n            # Update mean\n            old_mean = mean.copy()\n            mean = np.sum(self.weights[:, None] * selected_offspring, axis=0)\n\n            # Update evolution paths\n            y = (mean - old_mean) / self.step_size\n            z = (selected_offspring - old_mean) / self.step_size\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)*self.mueff) * np.linalg.solve(self.C**0.5, (mean - old_mean) / self.step_size)\n            \n            if np.linalg.norm(self.ps)/np.sqrt(1-(1-self.c_sigma)**(2*(self.budget//self.pop_size)))/self.chiN < 1.1:\n              hsig = 1\n            else:\n              hsig = 0\n            self.pc = (1-self.c_c)*self.pc + hsig*np.sqrt(self.c_c*(2-self.c_c)*self.mueff) * y\n            \n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            self.C += self.c_mu * np.sum(self.weights[:, None, None] * (z[:, :, None] @ z[:, None, :]), axis=0)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            mineig = np.min(np.linalg.eigvalsh(self.C))\n            if mineig < 1e-10:\n              self.C += (1e-10 - mineig) * np.eye(self.dim)\n\n            # Update step size\n            self.step_size = self.step_size * np.exp((self.c_sigma/self.d_sigma)*(np.linalg.norm(self.ps)/self.chiN - 1))\n                \n            # Local search on the best offspring\n            best_index = np.argmin(fitness)\n            local_f, local_x = self.local_search(func, offspring[best_index].copy())\n            if local_f < gbest_fitness:\n                gbest_fitness = local_f\n                gbest_pos = local_x.copy()\n\n            if fitness[best_index] < gbest_fitness:\n              gbest_fitness = fitness[best_index]\n              gbest_pos = offspring[best_index]\n\n            if self.budget <= 0:\n              break\n            \n        return gbest_fitness, gbest_pos\n```", "operator": "mutation", "theta_sampled": 0.005973043474837456, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "cdf1257e-1e47-4bd9-978b-760cce745a8c", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMA", "description": "An adaptive hybrid PSO-DE algorithm with a self-adaptive mutation strategy and velocity update and covariance matrix adaptation (CMA) to further enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, mutation_strategy=\"rand1\"):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with CMA.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            mutation_strategy (str): DE mutation strategy (e.g., \"rand1\", \"best1\").\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.mutation_strategy = mutation_strategy\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.learning_rate = 0.1  # Learning rate for CMA\n\n        # CMA parameters\n        self.mean = None\n        self.covariance = None\n        self.step_size = 1.0  # Overall step size\n\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n        # Initialize CMA parameters\n        self.mean = self.global_best_position.copy()\n        self.covariance = np.eye(self.dim)\n\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        # Adaptive inertia weight\n        self.w = 0.9 - (self.func_evals / self.budget) * 0.7 # Linearly decrease w\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with adaptive mutation and CMA.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            if self.mutation_strategy == \"rand1\":\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            elif self.mutation_strategy == \"best1\":\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.population[indices]\n                v_mutation = self.global_best_position + self.f * (x_r1 - x_r2)\n            else: # Self-adaptive mutation\n                if np.random.rand() < 0.5:\n                   indices = np.random.choice(self.pop_size, 3, replace=False)\n                   x_r1, x_r2, x_r3 = self.population[indices]\n                   v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                else:\n                   indices = np.random.choice(self.pop_size, 2, replace=False)\n                   x_r1, x_r2 = self.population[indices]\n                   v_mutation = self.global_best_position + self.f * (x_r1 - x_r2)\n\n\n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n        # CMA Update (simplified version)\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.covariance)\n        x = self.mean + self.step_size * z\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        f_x = func(x)\n        self.func_evals += 1\n\n        if f_x < self.global_best_fitness:\n            self.global_best_fitness = f_x\n            self.global_best_position = x.copy()\n            self.mean = x.copy()\n            self.covariance = (1 - self.learning_rate) * self.covariance + self.learning_rate * np.outer(z, z)\n            self.step_size *= np.exp(0.5 * (1.0 - f_x/self.global_best_fitness))\n\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.mean = self.global_best_position.copy() # Reset CMA mean too\n        self.covariance = np.eye(self.dim)\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with CMA.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with a self-adaptive mutation strategy and velocity update and covariance matrix adaptation (CMA) to further enhance exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, mutation_strategy=\"rand1\"):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with CMA.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            mutation_strategy (str): DE mutation strategy (e.g., \"rand1\", \"best1\").\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.mutation_strategy = mutation_strategy\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.learning_rate = 0.1  # Learning rate for CMA\n\n        # CMA parameters\n        self.mean = None\n        self.covariance = None\n        self.step_size = 1.0  # Overall step size\n\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n        # Initialize CMA parameters\n        self.mean = self.global_best_position.copy()\n        self.covariance = np.eye(self.dim)\n\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        # Adaptive inertia weight\n        self.w = 0.9 - (self.func_evals / self.budget) * 0.7 # Linearly decrease w\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with adaptive mutation and CMA.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            if self.mutation_strategy == \"rand1\":\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            elif self.mutation_strategy == \"best1\":\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.population[indices]\n                v_mutation = self.global_best_position + self.f * (x_r1 - x_r2)\n            else: # Self-adaptive mutation\n                if np.random.rand() < 0.5:\n                   indices = np.random.choice(self.pop_size, 3, replace=False)\n                   x_r1, x_r2, x_r3 = self.population[indices]\n                   v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                else:\n                   indices = np.random.choice(self.pop_size, 2, replace=False)\n                   x_r1, x_r2 = self.population[indices]\n                   v_mutation = self.global_best_position + self.f * (x_r1 - x_r2)\n\n\n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n        # CMA Update (simplified version)\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.covariance)\n        x = self.mean + self.step_size * z\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        f_x = func(x)\n        self.func_evals += 1\n\n        if f_x < self.global_best_fitness:\n            self.global_best_fitness = f_x\n            self.global_best_position = x.copy()\n            self.mean = x.copy()\n            self.covariance = (1 - self.learning_rate) * self.covariance + self.learning_rate * np.outer(z, z)\n            self.step_size *= np.exp(0.5 * (1.0 - f_x/self.global_best_fitness))\n\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.mean = self.global_best_position.copy() # Reset CMA mean too\n        self.covariance = np.eye(self.dim)\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with CMA.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.003745892577744512, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "1bf85a87-9198-4f10-b1ab-1bde02faffb8", "fitness": 0.580874521668105, "name": "AdaptiveHybridPSO_DE_Niching", "description": "Dynamically adjusts PSO and DE parameters based on success rates and employs a niching strategy to maintain diversity and avoid premature convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Niching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1_init=1.5, c1_end=2.0, c2_init=1.5, c2_end=0.5, cr_init=0.7, cr_end=0.9, f_init=0.8, f_end=0.6, pso_prob=0.5, success_memory=10, niching_radius=0.5, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching and dynamic parameter adjustments.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1_init (float): Initial cognitive coefficient for PSO.\n            c1_end (float): Final cognitive coefficient for PSO.\n            c2_init (float): Initial social coefficient for PSO.\n            c2_end (float): Final social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_init (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            niching_radius (float): Radius of the niche.\n            restart_interval (int): Frequency of population restarts.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1_init = c1_init\n        self.c1_end = c1_end\n        self.c2_init = c2_init\n        self.c2_end = c2_end\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.niching_radius = niching_radius\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func, current_eval):\n        \"\"\"\n        Updates the population using PSO principles with dynamic parameter adjustment.\n        \"\"\"\n        # Dynamic parameter adjustment\n        w = self.w_init - (self.w_init - self.w_end) * (current_eval / self.budget)\n        c1 = self.c1_init + (self.c1_end - self.c1_init) * (current_eval / self.budget)\n        c2 = self.c2_init + (self.c2_end - self.c2_init) * (current_eval / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           c1 * r1 * (self.personal_best_positions - self.population) +\n                           c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func, current_eval):\n            \"\"\"\n            Updates the population using Differential Evolution principles with dynamic parameter adjustment.\n            \"\"\"\n            # Dynamic parameter adjustment\n            cr = self.cr_init + (self.cr_end - self.cr_init) * (current_eval / self.budget)\n            f = self.f_init - (self.f_init - self.f_end) * (current_eval / self.budget)\n\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def apply_niching(self):\n        \"\"\"\n        Applies niching to maintain diversity.\n        \"\"\"\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distance = np.linalg.norm(self.population[i] - self.population[j])\n                if distance < self.niching_radius:\n                    # Replace the particle with worse fitness with a random one\n                    if self.fitness[i] > self.fitness[j]:\n                        self.population[i] = self.personal_best_positions[i].copy() #back to best pos\n                        self.fitness[i] = self.personal_best_fitness[i]\n                    else:\n                        self.population[j] = self.personal_best_positions[j].copy() #back to best pos\n                        self.fitness[j] = self.personal_best_fitness[j]\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        current_eval = self.pop_size\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func, current_eval)\n            else:\n                self.de_update(func, current_eval)\n            \n            self.apply_niching() # Apply niching after each update\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n            current_eval = self.func_evals\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridPSO_DE_Niching scored 0.581 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO and DE parameters based on success rates and employs a niching strategy to maintain diversity and avoid premature convergence.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Niching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1_init=1.5, c1_end=2.0, c2_init=1.5, c2_end=0.5, cr_init=0.7, cr_end=0.9, f_init=0.8, f_end=0.6, pso_prob=0.5, success_memory=10, niching_radius=0.5, restart_interval=100):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching and dynamic parameter adjustments.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1_init (float): Initial cognitive coefficient for PSO.\n            c1_end (float): Final cognitive coefficient for PSO.\n            c2_init (float): Initial social coefficient for PSO.\n            c2_end (float): Final social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_init (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            niching_radius (float): Radius of the niche.\n            restart_interval (int): Frequency of population restarts.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1_init = c1_init\n        self.c1_end = c1_end\n        self.c2_init = c2_init\n        self.c2_end = c2_end\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.niching_radius = niching_radius\n        self.restart_interval = restart_interval\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func, current_eval):\n        \"\"\"\n        Updates the population using PSO principles with dynamic parameter adjustment.\n        \"\"\"\n        # Dynamic parameter adjustment\n        w = self.w_init - (self.w_init - self.w_end) * (current_eval / self.budget)\n        c1 = self.c1_init + (self.c1_end - self.c1_init) * (current_eval / self.budget)\n        c2 = self.c2_init + (self.c2_end - self.c2_init) * (current_eval / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           c1 * r1 * (self.personal_best_positions - self.population) +\n                           c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func, current_eval):\n            \"\"\"\n            Updates the population using Differential Evolution principles with dynamic parameter adjustment.\n            \"\"\"\n            # Dynamic parameter adjustment\n            cr = self.cr_init + (self.cr_end - self.cr_init) * (current_eval / self.budget)\n            f = self.f_init - (self.f_init - self.f_end) * (current_eval / self.budget)\n\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n    def apply_niching(self):\n        \"\"\"\n        Applies niching to maintain diversity.\n        \"\"\"\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distance = np.linalg.norm(self.population[i] - self.population[j])\n                if distance < self.niching_radius:\n                    # Replace the particle with worse fitness with a random one\n                    if self.fitness[i] > self.fitness[j]:\n                        self.population[i] = self.personal_best_positions[i].copy() #back to best pos\n                        self.fitness[i] = self.personal_best_fitness[i]\n                    else:\n                        self.population[j] = self.personal_best_positions[j].copy() #back to best pos\n                        self.fitness[j] = self.personal_best_fitness[j]\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        current_eval = self.pop_size\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func, current_eval)\n            else:\n                self.de_update(func, current_eval)\n            \n            self.apply_niching() # Apply niching after each update\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n            current_eval = self.func_evals\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.23187090563110402, 0.5321820588358808, 0.6723250252013914, 0.8306688875008449, 0.6499614101428006, 0.6699313141226226, 0.34311940332893087, 0.5797481729637965, 0.4775501397516556, 0.22002378909091214, 0.7953055750063212, 0.9982640241520641, 0.37198318554302545, 0.36782812045107827, 0.8601718940288975, 0.7102718938266819, 0.6059819721467858, 0.792382862677746, 0.37565774306687905, 0.5322620558926829], "operator": "mutation", "theta_sampled": 0.009438987102685632, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "1009b740-e0c5-4559-a935-bb6ab7bfb8f9", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_Niching", "description": "Combines PSO and DE with dynamic parameter adaptation based on population diversity and individual success rates. Includes a niching strategy using k-means clustering to maintain diversity and avoid premature convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveHybridPSO_DE_Niching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_start=0.9, cr_end=0.1, f_start=0.5, f_end=0.9, pso_prob=0.5, success_memory=10, num_clusters=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_start (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_start (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            num_clusters (int): Number of clusters for niching.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_start = cr_start\n        self.cr_end = cr_end\n        self.f_start = f_start\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.num_clusters = num_clusters\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.iteration = 0\n        self.cluster_labels = None\n        self.cluster_centers = None\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.stagnation_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget) # Linearly decreasing inertia weight\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            cr = self.cr_start - (self.cr_start - self.cr_end) * (self.func_evals / self.budget) # Linearly decreasing CR\n            f = self.f_start + (self.f_end - self.f_start) * (self.func_evals / self.budget)  # Linearly increasing F\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n\n    def perform_niching(self):\n        \"\"\"\n        Performs niching using k-means clustering.\n        \"\"\"\n        kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init = 'auto') #explicitly declare n_init\n        self.cluster_labels = kmeans.fit_predict(self.population)\n        self.cluster_centers = kmeans.cluster_centers_\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population, biased towards the best individuals from each niche.\n        \"\"\"\n        new_population = np.zeros_like(self.population)\n        for i in range(self.num_clusters):\n            cluster_indices = np.where(self.cluster_labels == i)[0]\n            if len(cluster_indices) > 0:\n                # Select best individual from the cluster\n                best_index_in_cluster = cluster_indices[np.argmin(self.fitness[cluster_indices])]\n                best_individual_in_cluster = self.population[best_index_in_cluster]\n                \n                # Generate new individuals around the best one, ensuring diversity\n                for j in range(len(cluster_indices)):\n                    new_population[cluster_indices[j]] = best_individual_in_cluster + np.random.normal(0, 0.1, self.dim) # Gaussian perturbation\n                    new_population[cluster_indices[j]] = np.clip(new_population[cluster_indices[j]], func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n        # Replace old population with the new one\n        self.population = new_population\n\n        # Re-evaluate fitness\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n\n        #Update personal Bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n        self.update_global_best() #Update Global best\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.iteration += 1\n            self.stagnation_counter +=1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.iteration % 20 == 0: # Perform niching every 20 iterations\n                 self.perform_niching()\n           \n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.perform_niching()\n                self.restart_population(func)\n                self.stagnation_counter = 0\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: name 'KMeans' is not defined", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines PSO and DE with dynamic parameter adaptation based on population diversity and individual success rates. Includes a niching strategy using k-means clustering to maintain diversity and avoid premature convergence.\n# Code: \n```python\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveHybridPSO_DE_Niching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_start=0.9, cr_end=0.1, f_start=0.5, f_end=0.9, pso_prob=0.5, success_memory=10, num_clusters=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_start (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_start (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            num_clusters (int): Number of clusters for niching.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_start = cr_start\n        self.cr_end = cr_end\n        self.f_start = f_start\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.num_clusters = num_clusters\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.iteration = 0\n        self.cluster_labels = None\n        self.cluster_centers = None\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.stagnation_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget) # Linearly decreasing inertia weight\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            cr = self.cr_start - (self.cr_start - self.cr_end) * (self.func_evals / self.budget) # Linearly decreasing CR\n            f = self.f_start + (self.f_end - self.f_start) * (self.func_evals / self.budget)  # Linearly increasing F\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + f * (x_r2 - x_r3)\n                \n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n\n    def perform_niching(self):\n        \"\"\"\n        Performs niching using k-means clustering.\n        \"\"\"\n        kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init = 'auto') #explicitly declare n_init\n        self.cluster_labels = kmeans.fit_predict(self.population)\n        self.cluster_centers = kmeans.cluster_centers_\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population, biased towards the best individuals from each niche.\n        \"\"\"\n        new_population = np.zeros_like(self.population)\n        for i in range(self.num_clusters):\n            cluster_indices = np.where(self.cluster_labels == i)[0]\n            if len(cluster_indices) > 0:\n                # Select best individual from the cluster\n                best_index_in_cluster = cluster_indices[np.argmin(self.fitness[cluster_indices])]\n                best_individual_in_cluster = self.population[best_index_in_cluster]\n                \n                # Generate new individuals around the best one, ensuring diversity\n                for j in range(len(cluster_indices)):\n                    new_population[cluster_indices[j]] = best_individual_in_cluster + np.random.normal(0, 0.1, self.dim) # Gaussian perturbation\n                    new_population[cluster_indices[j]] = np.clip(new_population[cluster_indices[j]], func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n        # Replace old population with the new one\n        self.population = new_population\n\n        # Re-evaluate fitness\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n\n        #Update personal Bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n        self.update_global_best() #Update Global best\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.iteration += 1\n            self.stagnation_counter +=1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.iteration % 20 == 0: # Perform niching every 20 iterations\n                 self.perform_niching()\n           \n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.perform_niching()\n                self.restart_population(func)\n                self.stagnation_counter = 0\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "mutation", "theta_sampled": 0.004858102118701614, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "ec43a554-c7d2-4b22-93df-7e00552a113a", "fitness": 0.31442811987774866, "name": "AdaptiveDEOrthogonalLearning", "description": "An adaptive DE with archive and self-adaptive parameters, incorporates orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n        self.success_memory_CR = []\n        self.success_memory_F = []\n        self.memory_size = 10\n\n\n    def orthogonal_design(self, num_factors, levels):\n        if num_factors == 2 and levels == 3:\n            return np.array([[1, 1], [2, 3], [3, 2]]) - 1 # Subtract 1 to make it 0-indexed\n        elif num_factors == 3 and levels == 3:\n             return np.array([[1, 1, 1], [1, 2, 2], [1, 3, 3], [2, 1, 2], [2, 2, 3], [2, 3, 1], [3, 1, 3], [3, 2, 1], [3, 3, 2]]) - 1\n\n        else:\n            raise ValueError(\"Orthogonal design not implemented for these parameters.\")\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            if self.success_memory_CR:\n                self.CR = np.random.choice(self.success_memory_CR)\n            else:\n                self.CR = 0.5 + 0.4 * np.random.rand()\n            if self.success_memory_F:\n                self.F = np.random.choice(self.success_memory_F)\n            else:\n                self.F = 0.6 + 0.3 * np.random.rand()\n\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning\n                num_factors = min(3, self.dim)  # Consider only 3 dimensions for orthogonal design\n                levels = 3\n                design = self.orthogonal_design(num_factors, levels)\n                \n                # Randomly select dimensions for orthogonal learning\n                dims_to_optimize = np.random.choice(self.dim, num_factors, replace=False)\n                \n                candidates = np.zeros((levels**num_factors//3 if num_factors==3 else levels**num_factors, self.dim))\n                \n                for k in range(design.shape[0]):\n                    candidate = np.copy(u)\n                    for l in range(num_factors):\n                         level = design[k,l]\n                         range_dim = func.bounds.ub[dims_to_optimize[l]] - func.bounds.lb[dims_to_optimize[l]]\n                         candidate[dims_to_optimize[l]] = func.bounds.lb[dims_to_optimize[l]] + level * (range_dim / (levels - 1))\n                    candidates[k,:] = candidate\n                \n                candidate_fitnesses = np.array([func(candidates[k,:]) for k in range(candidates.shape[0])])\n                self.evals += candidates.shape[0]\n                best_candidate_idx = np.argmin(candidate_fitnesses)\n                best_candidate = candidates[best_candidate_idx, :]\n                f_best_candidate = candidate_fitnesses[best_candidate_idx]\n\n                # Selection\n                f_u = func(u) if self.evals <= self.budget else np.inf # Ensure not exceeding budget\n                self.evals += 1 if self.evals <= self.budget else 0  # increment evals conditionally\n                \n                if f_best_candidate < min(f_u, self.fitness[i]):\n                     if f_best_candidate < self.fitness[i]:\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            worst_arch_idx = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                                 self.archive[worst_arch_idx] = self.population[i].copy()\n                                 self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                        self.fitness[i] = f_best_candidate\n                        self.population[i] = best_candidate\n\n                     if f_best_candidate < self.f_opt:\n                         self.f_opt = f_best_candidate\n                         self.x_opt = best_candidate\n\n\n                elif f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    if len(self.success_memory_CR) < self.memory_size:\n                        self.success_memory_CR.append(self.CR)\n                        self.success_memory_F.append(self.F)\n                    else:\n                        self.success_memory_CR[np.random.randint(self.memory_size)] = self.CR\n                        self.success_memory_F[np.random.randint(self.memory_size)] = self.F\n\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDEOrthogonalLearning scored 0.314 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c549f739-9427-485f-b91e-61a339a7588b"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive DE with archive and self-adaptive parameters, incorporates orthogonal learning to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEOrthogonalLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n        self.success_memory_CR = []\n        self.success_memory_F = []\n        self.memory_size = 10\n\n\n    def orthogonal_design(self, num_factors, levels):\n        if num_factors == 2 and levels == 3:\n            return np.array([[1, 1], [2, 3], [3, 2]]) - 1 # Subtract 1 to make it 0-indexed\n        elif num_factors == 3 and levels == 3:\n             return np.array([[1, 1, 1], [1, 2, 2], [1, 3, 3], [2, 1, 2], [2, 2, 3], [2, 3, 1], [3, 1, 3], [3, 2, 1], [3, 3, 2]]) - 1\n\n        else:\n            raise ValueError(\"Orthogonal design not implemented for these parameters.\")\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            if self.success_memory_CR:\n                self.CR = np.random.choice(self.success_memory_CR)\n            else:\n                self.CR = 0.5 + 0.4 * np.random.rand()\n            if self.success_memory_F:\n                self.F = np.random.choice(self.success_memory_F)\n            else:\n                self.F = 0.6 + 0.3 * np.random.rand()\n\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning\n                num_factors = min(3, self.dim)  # Consider only 3 dimensions for orthogonal design\n                levels = 3\n                design = self.orthogonal_design(num_factors, levels)\n                \n                # Randomly select dimensions for orthogonal learning\n                dims_to_optimize = np.random.choice(self.dim, num_factors, replace=False)\n                \n                candidates = np.zeros((levels**num_factors//3 if num_factors==3 else levels**num_factors, self.dim))\n                \n                for k in range(design.shape[0]):\n                    candidate = np.copy(u)\n                    for l in range(num_factors):\n                         level = design[k,l]\n                         range_dim = func.bounds.ub[dims_to_optimize[l]] - func.bounds.lb[dims_to_optimize[l]]\n                         candidate[dims_to_optimize[l]] = func.bounds.lb[dims_to_optimize[l]] + level * (range_dim / (levels - 1))\n                    candidates[k,:] = candidate\n                \n                candidate_fitnesses = np.array([func(candidates[k,:]) for k in range(candidates.shape[0])])\n                self.evals += candidates.shape[0]\n                best_candidate_idx = np.argmin(candidate_fitnesses)\n                best_candidate = candidates[best_candidate_idx, :]\n                f_best_candidate = candidate_fitnesses[best_candidate_idx]\n\n                # Selection\n                f_u = func(u) if self.evals <= self.budget else np.inf # Ensure not exceeding budget\n                self.evals += 1 if self.evals <= self.budget else 0  # increment evals conditionally\n                \n                if f_best_candidate < min(f_u, self.fitness[i]):\n                     if f_best_candidate < self.fitness[i]:\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            worst_arch_idx = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                                 self.archive[worst_arch_idx] = self.population[i].copy()\n                                 self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                        self.fitness[i] = f_best_candidate\n                        self.population[i] = best_candidate\n\n                     if f_best_candidate < self.f_opt:\n                         self.f_opt = f_best_candidate\n                         self.x_opt = best_candidate\n\n\n                elif f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    if len(self.success_memory_CR) < self.memory_size:\n                        self.success_memory_CR.append(self.CR)\n                        self.success_memory_F.append(self.F)\n                    else:\n                        self.success_memory_CR[np.random.randint(self.memory_size)] = self.CR\n                        self.success_memory_F[np.random.randint(self.memory_size)] = self.F\n\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14966854645449834, 0.20565717145609397, 0.28521023061039363, 0.2107879137178128, 0.2528121992311111, 0.3150854187608799, 0.25838483265278356, 0.23904509254184048, 0.2740732768606864, 0.16655043356852184, 0.2646598738514915, 0.9983403087781543, 0.28744062454765495, 0.27589783542731294, 0.6532402346339325, 0.29003465131207207, 0.2560787224913049, 0.2748328727711291, 0.16209293528923374, 0.4686692225980643], "operator": "mutation", "theta_sampled": 0.0036843587537974667, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "52f53457-a0ce-43d3-a936-e257063d0e6c", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_GLS", "description": "Adaptively blends PSO and DE, incorporating a gradient-based local search to enhance exploitation and utilizes a CMA-ES-inspired step size adaptation for exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_GLS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, ls_prob=0.1, ls_step_size=0.1, cma_lr = 0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Gradient-based Local Search (GLS) and CMA-ES inspired step size.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            ls_prob (float): Probability of performing local search on a particle.\n            ls_step_size (float): Initial step size for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.ls_prob = ls_prob\n        self.ls_step_size = ls_step_size\n        self.cma_lr = cma_lr #Learning Rate for CMA step size adaptation\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n        self.step_size = np.ones(dim) * 0.1  # Individual step sizes for each dimension\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n    def local_search(self, func):\n        \"\"\"\n        Performs a gradient-based local search on a randomly selected particle.\n        \"\"\"\n        i = np.random.randint(self.pop_size)\n        x = self.population[i].copy()\n        f_current = self.fitness[i]\n\n        # Estimate gradient using finite differences\n        gradient = np.zeros(self.dim)\n        for j in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            step = self.step_size[j]  # Use dimension-specific step size\n            x_plus[j] += step\n            x_minus[j] -= step\n\n            # Ensure the step doesn't take us out of bounds\n            x_plus[j] = np.clip(x_plus[j], func.bounds.lb[j], func.bounds.ub[j])\n            x_minus[j] = np.clip(x_minus[j], func.bounds.lb[j], func.bounds.ub[j])\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.func_evals += 2\n\n            gradient[j] = (f_plus - f_minus) / (2 * step)\n        \n        # Update position based on gradient\n        x_new = x - self.ls_step_size * self.step_size * gradient  #Use dimension specific step_sizes\n\n        # Clip to ensure bounds are satisfied.\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n        f_new = func(x_new)\n        self.func_evals += 1\n        \n        if f_new < f_current:\n            self.population[i] = x_new\n            self.fitness[i] = f_new\n            \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = x_new.copy()\n                \n            if f_new < self.global_best_fitness:\n                self.global_best_fitness = f_new\n                self.global_best_position = x_new.copy()\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.step_size = np.ones(self.dim) * 0.1\n\n\n    def update_step_size(self):\n      \"\"\"\n      Adapt step sizes for each dimension, inspired by CMA-ES.\n      \"\"\"\n      g_best = self.global_best_position\n      for j in range(self.dim):\n          # Adjust step size based on the magnitude of the global best's coordinate\n          # This is a simplified adaptation strategy\n          self.step_size[j] *= np.exp(self.cma_lr * (np.abs(g_best[j]) - 1)) #if abs(g_best[j]) > 1: increase, else decrease\n\n          #Clamp step size\n          self.step_size[j] = np.clip(self.step_size[j], 1e-6, 1) #Ensure a minimum/maximum value for stability.\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n            \n            #Local Search\n            if np.random.rand() < self.ls_prob:\n                self.local_search(func)\n                \n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.update_step_size() #Update the CMA-inspired step size\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridPSO_DE_GLS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively blends PSO and DE, incorporating a gradient-based local search to enhance exploitation and utilizes a CMA-ES-inspired step size adaptation for exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_GLS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, ls_prob=0.1, ls_step_size=0.1, cma_lr = 0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Gradient-based Local Search (GLS) and CMA-ES inspired step size.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            ls_prob (float): Probability of performing local search on a particle.\n            ls_step_size (float): Initial step size for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.ls_prob = ls_prob\n        self.ls_step_size = ls_step_size\n        self.cma_lr = cma_lr #Learning Rate for CMA step size adaptation\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n\n        self.step_size = np.ones(dim) * 0.1  # Individual step sizes for each dimension\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n    def local_search(self, func):\n        \"\"\"\n        Performs a gradient-based local search on a randomly selected particle.\n        \"\"\"\n        i = np.random.randint(self.pop_size)\n        x = self.population[i].copy()\n        f_current = self.fitness[i]\n\n        # Estimate gradient using finite differences\n        gradient = np.zeros(self.dim)\n        for j in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            step = self.step_size[j]  # Use dimension-specific step size\n            x_plus[j] += step\n            x_minus[j] -= step\n\n            # Ensure the step doesn't take us out of bounds\n            x_plus[j] = np.clip(x_plus[j], func.bounds.lb[j], func.bounds.ub[j])\n            x_minus[j] = np.clip(x_minus[j], func.bounds.lb[j], func.bounds.ub[j])\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.func_evals += 2\n\n            gradient[j] = (f_plus - f_minus) / (2 * step)\n        \n        # Update position based on gradient\n        x_new = x - self.ls_step_size * self.step_size * gradient  #Use dimension specific step_sizes\n\n        # Clip to ensure bounds are satisfied.\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n        f_new = func(x_new)\n        self.func_evals += 1\n        \n        if f_new < f_current:\n            self.population[i] = x_new\n            self.fitness[i] = f_new\n            \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = x_new.copy()\n                \n            if f_new < self.global_best_fitness:\n                self.global_best_fitness = f_new\n                self.global_best_position = x_new.copy()\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.step_size = np.ones(self.dim) * 0.1\n\n\n    def update_step_size(self):\n      \"\"\"\n      Adapt step sizes for each dimension, inspired by CMA-ES.\n      \"\"\"\n      g_best = self.global_best_position\n      for j in range(self.dim):\n          # Adjust step size based on the magnitude of the global best's coordinate\n          # This is a simplified adaptation strategy\n          self.step_size[j] *= np.exp(self.cma_lr * (np.abs(g_best[j]) - 1)) #if abs(g_best[j]) > 1: increase, else decrease\n\n          #Clamp step size\n          self.step_size[j] = np.clip(self.step_size[j], 1e-6, 1) #Ensure a minimum/maximum value for stability.\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n            \n            #Local Search\n            if np.random.rand() < self.ls_prob:\n                self.local_search(func)\n                \n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.update_step_size() #Update the CMA-inspired step size\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.0036661270439585355, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "60daf9a4-a037-4736-a8fc-47f413f0bce2", "fitness": 0.5604676967574997, "name": "AdaptiveHybridPSO_DE_Restart", "description": "Dynamically adjusts PSO and DE parameters based on their performance and introduces a restart mechanism with Gaussian perturbation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, restart_frequency=0.1, gaussian_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.restart_frequency = restart_frequency\n        self.gaussian_scale = gaussian_scale\n        self.stagnation_counter = 0\n        self.stagnation_threshold = budget // 100 # e.g., restart after 1% of budget without improvement\n\n        self.best_fitness_history = []\n\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        self.best_fitness_history.append(gbest_fitness)\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Stagnation check and restart\n            if gbest_fitness < min(self.best_fitness_history):\n                self.stagnation_counter = 0\n                self.best_fitness_history.append(gbest_fitness)\n                if len(self.best_fitness_history) > 10:\n                    self.best_fitness_history.pop(0)  # Keep only the last 10 fitness values\n            else:\n                self.stagnation_counter += 1\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_frequency:\n                    # Restart with Gaussian perturbation around the best solution\n                    pop = np.random.normal(gbest_pos, self.gaussian_scale * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                    pop = np.clip(pop, func.bounds.lb, func.bounds.ub)\n                    fitness = np.array([func(x) for x in pop])\n                    self.budget -= self.pop_size\n                    \n                    pbest_pop = pop.copy()\n                    pbest_fitness = fitness.copy()\n\n                    gbest_index = np.argmin(fitness)\n                    gbest_pos = pop[gbest_index].copy()\n                    gbest_fitness = fitness[gbest_index]\n                    self.stagnation_counter = 0\n                    self.best_fitness_history = [gbest_fitness]  # Reset history\n                    velocity = np.zeros_like(pop) # Reset velocity\n                    \n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridPSO_DE_Restart scored 0.560 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO and DE parameters based on their performance and introduces a restart mechanism with Gaussian perturbation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, restart_frequency=0.1, gaussian_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.restart_frequency = restart_frequency\n        self.gaussian_scale = gaussian_scale\n        self.stagnation_counter = 0\n        self.stagnation_threshold = budget // 100 # e.g., restart after 1% of budget without improvement\n\n        self.best_fitness_history = []\n\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5): # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        self.best_fitness_history.append(gbest_fitness)\n        \n        velocity = np.zeros_like(pop) # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 #clip velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy() # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = self.w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy() #Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + self.f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                if self.budget <= 0:\n                  break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Stagnation check and restart\n            if gbest_fitness < min(self.best_fitness_history):\n                self.stagnation_counter = 0\n                self.best_fitness_history.append(gbest_fitness)\n                if len(self.best_fitness_history) > 10:\n                    self.best_fitness_history.pop(0)  # Keep only the last 10 fitness values\n            else:\n                self.stagnation_counter += 1\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_frequency:\n                    # Restart with Gaussian perturbation around the best solution\n                    pop = np.random.normal(gbest_pos, self.gaussian_scale * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                    pop = np.clip(pop, func.bounds.lb, func.bounds.ub)\n                    fitness = np.array([func(x) for x in pop])\n                    self.budget -= self.pop_size\n                    \n                    pbest_pop = pop.copy()\n                    pbest_fitness = fitness.copy()\n\n                    gbest_index = np.argmin(fitness)\n                    gbest_pos = pop[gbest_index].copy()\n                    gbest_fitness = fitness[gbest_index]\n                    self.stagnation_counter = 0\n                    self.best_fitness_history = [gbest_fitness]  # Reset history\n                    velocity = np.zeros_like(pop) # Reset velocity\n                    \n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            if self.budget <= 0:\n              break\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.14998417217853532, 0.2607126248271612, 0.642147309131084, 0.8479464556372214, 0.4967579706688984, 0.7237478674326095, 0.3424152941851062, 0.5570298356053713, 0.6995250921540371, 0.2296951875810912, 0.8642180191477984, 0.9988896927802926, 0.2713772540435745, 0.5899134933675401, 0.8971260782005775, 0.7299582925073231, 0.42203585883322337, 0.7659819767989144, 0.21242386664163126, 0.5074675934280066], "operator": "mutation", "theta_sampled": 0.0046286335853404185, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "e7832314-9fb0-4eac-8044-00381937821d", "fitness": 0.30466039829525166, "name": "AdaptiveAgingDEArchive", "description": "Adaptive Differential Evolution with Aging, Archive, and dynamic parameter control to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveAgingDEArchive scored 0.305 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25", "c549f739-9427-485f-b91e-61a339a7588b"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Aging, Archive, and dynamic parameter control to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2021052989116786, 0.3616516917027027, 0.6548846025666253, 0], "operator": "crossover", "theta_sampled": 0.003362575062885127, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "1a3b733c-8455-41ff-9cb1-e496fdabc048", "fitness": 0.0, "name": "FitnessLandscapeAdaptiveEvolution", "description": "A population-based algorithm with a self-adjusting mutation strategy based on fitness landscape exploration and a local search component.", "code": "import numpy as np\n\nclass FitnessLandscapeAdaptiveEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Selection (Tournament selection)\n            tournament_size = 5\n            selected_indices = []\n            for _ in range(self.pop_size):\n                candidates = np.random.choice(self.pop_size, tournament_size, replace=False)\n                winner = candidates[np.argmin(self.fitness[candidates])]\n                selected_indices.append(winner)\n            selected_population = self.population[selected_indices]\n\n            # Crossover (Uniform crossover)\n            offspring = np.empty_like(selected_population)\n            for i in range(self.pop_size):\n                parent1 = selected_population[i]\n                parent2_index = np.random.randint(self.pop_size)\n                parent2 = selected_population[parent2_index]\n                mask = np.random.rand(self.dim) < 0.5\n                offspring[i] = np.where(mask, parent1, parent2)\n\n            # Mutation (Self-Adjusting Mutation)\n            mutation_strengths = np.random.rand(self.pop_size) * self.mutation_rate # Individual mutation strength\n            for i in range(self.pop_size):\n                mutation_vector = np.random.normal(0, mutation_strengths[i], size=self.dim)\n                offspring[i] = np.clip(offspring[i] + mutation_vector, func.bounds.lb, func.bounds.ub)\n\n            # Local Search (around the best individual)\n            best_index = np.argmin(self.fitness)\n            best_individual = self.population[best_index]\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                \n                # Random local perturbation\n                perturbation = np.random.uniform(-0.1, 0.1, size=self.dim)\n                local_x = np.clip(best_individual + perturbation, func.bounds.lb, func.bounds.ub)\n                local_f = func(local_x)\n                self.budget -= 1\n\n                if local_f < self.fitness[best_index]:\n                    self.fitness[best_index] = local_f\n                    self.population[best_index] = local_x\n                    best_individual = local_x # Update the best individual\n                    if local_f < self.f_opt:\n                         self.f_opt = local_f\n                         self.x_opt = local_x\n\n            # Evaluation\n            new_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Replacement (Replace if better)\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if new_fitness[i] < self.fitness[i]:\n                    self.fitness[i] = new_fitness[i]\n                    self.population[i] = offspring[i]\n\n            # Update global best\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm FitnessLandscapeAdaptiveEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with a self-adjusting mutation strategy based on fitness landscape exploration and a local search component.\n# Code:\n```python\nimport numpy as np\n\nclass FitnessLandscapeAdaptiveEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Selection (Tournament selection)\n            tournament_size = 5\n            selected_indices = []\n            for _ in range(self.pop_size):\n                candidates = np.random.choice(self.pop_size, tournament_size, replace=False)\n                winner = candidates[np.argmin(self.fitness[candidates])]\n                selected_indices.append(winner)\n            selected_population = self.population[selected_indices]\n\n            # Crossover (Uniform crossover)\n            offspring = np.empty_like(selected_population)\n            for i in range(self.pop_size):\n                parent1 = selected_population[i]\n                parent2_index = np.random.randint(self.pop_size)\n                parent2 = selected_population[parent2_index]\n                mask = np.random.rand(self.dim) < 0.5\n                offspring[i] = np.where(mask, parent1, parent2)\n\n            # Mutation (Self-Adjusting Mutation)\n            mutation_strengths = np.random.rand(self.pop_size) * self.mutation_rate # Individual mutation strength\n            for i in range(self.pop_size):\n                mutation_vector = np.random.normal(0, mutation_strengths[i], size=self.dim)\n                offspring[i] = np.clip(offspring[i] + mutation_vector, func.bounds.lb, func.bounds.ub)\n\n            # Local Search (around the best individual)\n            best_index = np.argmin(self.fitness)\n            best_individual = self.population[best_index]\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                \n                # Random local perturbation\n                perturbation = np.random.uniform(-0.1, 0.1, size=self.dim)\n                local_x = np.clip(best_individual + perturbation, func.bounds.lb, func.bounds.ub)\n                local_f = func(local_x)\n                self.budget -= 1\n\n                if local_f < self.fitness[best_index]:\n                    self.fitness[best_index] = local_f\n                    self.population[best_index] = local_x\n                    best_individual = local_x # Update the best individual\n                    if local_f < self.f_opt:\n                         self.f_opt = local_f\n                         self.x_opt = local_x\n\n            # Evaluation\n            new_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Replacement (Replace if better)\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if new_fitness[i] < self.fitness[i]:\n                    self.fitness[i] = new_fitness[i]\n                    self.population[i] = offspring[i]\n\n            # Update global best\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.000358966509993627, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "6b2e3131-bc11-4aff-a03e-b93125a994e1", "fitness": 0.5683900098302439, "name": "AdaptiveHybridPSO_DE_v2", "description": "Dynamically adjusts PSO/DE parameters based on success rate and stagnation detection using a mirrored-sampling technique for boundary handling and incorporates a self-adaptive mutation strategy within DE.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_start=0.9, cr_end=0.3, f_start=0.5, f_end=0.9, pso_prob=0.5, success_memory=10, stagnation_threshold=1e-6, stagnation_window=50):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with dynamic parameter adaptation and mirrored boundary handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_start (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_start (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            stagnation_threshold (float): Threshold for detecting stagnation.\n            stagnation_window (int): Window size for detecting stagnation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_start = cr_start\n        self.cr_end = cr_end\n        self.f_start = f_start\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_window = stagnation_window\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.best_fitness_history.append(self.global_best_fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            return True\n        return False\n    \n    def mirrored_sampling(self, x, lb, ub):\n        \"\"\"\n        Handles boundary violations using a mirrored sampling technique.\n        \"\"\"\n        x_corrected = x.copy()\n        for i in range(self.dim):\n            if x[i] < lb[i]:\n                x_corrected[i] = lb[i] + (lb[i] - x[i])\n                if x_corrected[i] > ub[i]:\n                    x_corrected[i] = np.random.uniform(lb[i], ub[i])  # Resample if still out of bounds\n            elif x[i] > ub[i]:\n                x_corrected[i] = ub[i] - (x[i] - ub[i])\n                if x_corrected[i] < lb[i]:\n                    x_corrected[i] = np.random.uniform(lb[i], ub[i])  # Resample if still out of bounds\n        return x_corrected\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Dynamic inertia weight\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling using mirrored sampling\n        for i in range(self.pop_size):\n            self.population[i] = self.mirrored_sampling(self.population[i], func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        improved = self.update_global_best()\n        if improved:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with self-adaptive F.\n        \"\"\"\n        improved = False\n        # Dynamic crossover rate\n        cr = self.cr_start - (self.cr_start - self.cr_end) * (self.func_evals / self.budget)\n        \n        for i in range(self.pop_size):\n            # Mutation: Self-adaptive F\n            f = self.f_start + (self.f_end - self.f_start) * np.random.rand()\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = self.mirrored_sampling(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n        \n    def check_stagnation(self):\n        \"\"\"\n        Checks if the optimization process has stagnated.\n        \"\"\"\n        if len(self.best_fitness_history) > self.stagnation_window:\n            window_fitness = self.best_fitness_history[-self.stagnation_window:]\n            if np.std(window_fitness) < self.stagnation_threshold:\n                self.stagnation_counter += 1\n                return True\n        return False\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.best_fitness_history.append(self.global_best_fitness)\n        self.stagnation_counter = 0 # Reset stagnation counter after restart\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            \n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.best_fitness_history.append(self.global_best_fitness)\n\n            if self.check_stagnation():\n                self.restart_population(func)\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridPSO_DE_v2 scored 0.568 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO/DE parameters based on success rate and stagnation detection using a mirrored-sampling technique for boundary handling and incorporates a self-adaptive mutation strategy within DE.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_start=0.9, cr_end=0.3, f_start=0.5, f_end=0.9, pso_prob=0.5, success_memory=10, stagnation_threshold=1e-6, stagnation_window=50):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with dynamic parameter adaptation and mirrored boundary handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_start (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f_start (float): Initial scaling factor for DE.\n            f_end (float): Final scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            stagnation_threshold (float): Threshold for detecting stagnation.\n            stagnation_window (int): Window size for detecting stagnation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_start = cr_start\n        self.cr_end = cr_end\n        self.f_start = f_start\n        self.f_end = f_end\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_window = stagnation_window\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.best_fitness_history.append(self.global_best_fitness)\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            return True\n        return False\n    \n    def mirrored_sampling(self, x, lb, ub):\n        \"\"\"\n        Handles boundary violations using a mirrored sampling technique.\n        \"\"\"\n        x_corrected = x.copy()\n        for i in range(self.dim):\n            if x[i] < lb[i]:\n                x_corrected[i] = lb[i] + (lb[i] - x[i])\n                if x_corrected[i] > ub[i]:\n                    x_corrected[i] = np.random.uniform(lb[i], ub[i])  # Resample if still out of bounds\n            elif x[i] > ub[i]:\n                x_corrected[i] = ub[i] - (x[i] - ub[i])\n                if x_corrected[i] < lb[i]:\n                    x_corrected[i] = np.random.uniform(lb[i], ub[i])  # Resample if still out of bounds\n        return x_corrected\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        # Dynamic inertia weight\n        w = self.w_start - (self.w_start - self.w_end) * (self.func_evals / self.budget)\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling using mirrored sampling\n        for i in range(self.pop_size):\n            self.population[i] = self.mirrored_sampling(self.population[i], func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        improved = self.update_global_best()\n        if improved:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with self-adaptive F.\n        \"\"\"\n        improved = False\n        # Dynamic crossover rate\n        cr = self.cr_start - (self.cr_start - self.cr_end) * (self.func_evals / self.budget)\n        \n        for i in range(self.pop_size):\n            # Mutation: Self-adaptive F\n            f = self.f_start + (self.f_end - self.f_start) * np.random.rand()\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = self.mirrored_sampling(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n        \n    def check_stagnation(self):\n        \"\"\"\n        Checks if the optimization process has stagnated.\n        \"\"\"\n        if len(self.best_fitness_history) > self.stagnation_window:\n            window_fitness = self.best_fitness_history[-self.stagnation_window:]\n            if np.std(window_fitness) < self.stagnation_threshold:\n                self.stagnation_counter += 1\n                return True\n        return False\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.best_fitness_history.append(self.global_best_fitness)\n        self.stagnation_counter = 0 # Reset stagnation counter after restart\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.func_evals < self.budget:\n            \n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.best_fitness_history.append(self.global_best_fitness)\n\n            if self.check_stagnation():\n                self.restart_population(func)\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.19087788779688875, 0.5763010959757153, 0.6162305921310423, 0.77109705263495, 0.6433798515453477, 0.5298357522033705, 0.3302188860558962, 0.5241450147356819, 0.6665003571876971, 0.2474933824480039, 0.8108095090164673, 0.9977022758698626, 0.2812098224948979, 0.5772639998695253, 0.8529011907889599, 0.6327643011631907, 0.5143233661396327, 0.7789335665518026, 0.30277479719018896, 0.5230374948057561], "operator": "mutation", "theta_sampled": 0.003376826354486254, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "bf01da07-f084-4d1a-90ff-45fd31eea2a5", "fitness": 0.09171269901050988, "name": "AdaptiveAgingDE", "description": "An adaptive Differential Evolution algorithm with aging and a self-adaptive strategy for parameter control and mutation operators.", "code": "import numpy as np\n\nclass AdaptiveAgingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_strategies=None, aging_rate=0.01, p_mutation=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\", \"rand2\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.p_mutation = p_mutation # Probability of mutation\n        self.success_history_CR = []\n        self.success_history_F = []\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Parameter Adaptation\n                CR_i = np.random.normal(self.CR, 0.1)\n                CR_i = np.clip(CR_i, 0.0, 1.0)\n                F_i = np.random.normal(self.F, 0.1)\n                F_i = np.clip(F_i, 0.0, 1.0)\n                \n                if np.random.rand() < self.p_mutation:\n                # Mutation\n                    if mutation_strategy == \"rand1\":\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n                        x_1, x_2, x_3 = self.population[idxs]\n                        v = x_1 + F_i * (x_2 - x_3)\n                    elif mutation_strategy == \"best2\":\n                        best_idx = np.argmin(self.fitness)\n                        idxs = np.random.choice(self.pop_size, 2, replace=False)\n                        x_1, x_2 = self.population[idxs]\n                        v = self.population[best_idx] + F_i * (x_1 - x_2)\n                    elif mutation_strategy == \"currtorand1\":\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n                        x_1, x_2, x_3 = self.population[idxs]\n                        v = self.population[i] + F_i * (x_1 - self.population[i]) + F_i * (x_2 - x_3)\n                    elif mutation_strategy == \"rand2\":\n                        idxs = np.random.choice(self.pop_size, 5, replace=False)\n                        x_1, x_2, x_3, x_4, x_5 = self.population[idxs]\n                        v = x_1 + F_i * (x_2 - x_3) + F_i * (x_4 - x_5)\n                    else:\n                        raise ValueError(\"Unknown mutation strategy\")\n\n                    # Crossover\n                    u = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < CR_i or j == j_rand:\n                            u[j] = v[j]\n\n                    u = self.repair(u, lb, ub)\n                else:\n                    u = np.copy(self.population[i])  # No mutation\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    \n                    self.success_history_CR.append(CR_i)\n                    self.success_history_F.append(F_i)\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            if self.success_history_CR:\n                self.CR = np.mean(self.success_history_CR)\n                self.F = np.mean(self.success_history_F)\n                self.success_history_CR = []\n                self.success_history_F = []\n            else:\n                 self.CR *= self.CR_decay  # Decay CR\n                 self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveAgingDE scored 0.092 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution algorithm with aging and a self-adaptive strategy for parameter control and mutation operators.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_strategies=None, aging_rate=0.01, p_mutation=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\", \"rand2\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.p_mutation = p_mutation # Probability of mutation\n        self.success_history_CR = []\n        self.success_history_F = []\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Parameter Adaptation\n                CR_i = np.random.normal(self.CR, 0.1)\n                CR_i = np.clip(CR_i, 0.0, 1.0)\n                F_i = np.random.normal(self.F, 0.1)\n                F_i = np.clip(F_i, 0.0, 1.0)\n                \n                if np.random.rand() < self.p_mutation:\n                # Mutation\n                    if mutation_strategy == \"rand1\":\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n                        x_1, x_2, x_3 = self.population[idxs]\n                        v = x_1 + F_i * (x_2 - x_3)\n                    elif mutation_strategy == \"best2\":\n                        best_idx = np.argmin(self.fitness)\n                        idxs = np.random.choice(self.pop_size, 2, replace=False)\n                        x_1, x_2 = self.population[idxs]\n                        v = self.population[best_idx] + F_i * (x_1 - x_2)\n                    elif mutation_strategy == \"currtorand1\":\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n                        x_1, x_2, x_3 = self.population[idxs]\n                        v = self.population[i] + F_i * (x_1 - self.population[i]) + F_i * (x_2 - x_3)\n                    elif mutation_strategy == \"rand2\":\n                        idxs = np.random.choice(self.pop_size, 5, replace=False)\n                        x_1, x_2, x_3, x_4, x_5 = self.population[idxs]\n                        v = x_1 + F_i * (x_2 - x_3) + F_i * (x_4 - x_5)\n                    else:\n                        raise ValueError(\"Unknown mutation strategy\")\n\n                    # Crossover\n                    u = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < CR_i or j == j_rand:\n                            u[j] = v[j]\n\n                    u = self.repair(u, lb, ub)\n                else:\n                    u = np.copy(self.population[i])  # No mutation\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    \n                    self.success_history_CR.append(CR_i)\n                    self.success_history_F.append(F_i)\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            if self.success_history_CR:\n                self.CR = np.mean(self.success_history_CR)\n                self.F = np.mean(self.success_history_F)\n                self.success_history_CR = []\n                self.success_history_F = []\n            else:\n                 self.CR *= self.CR_decay  # Decay CR\n                 self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.18342539802101976, 0], "operator": "mutation", "theta_sampled": 0.003259006918264038, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "c46fd59c-124a-420c-b9d9-abd460de2f16", "fitness": 0.41316021586885476, "name": "NicheDifferentialEvolution", "description": "A population-based algorithm that combines aspects of differential evolution with a niching strategy to maintain diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass NicheDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.niche_radius = niche_radius\n        self.pop = None\n        self.fitness = None\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n\n    def apply_differential_evolution(self, func):\n        for i in range(self.pop_size):\n            # Ensure we don't pick the same index twice\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            # Mutation\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # Crossover\n            trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.CR:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f_trial = func(trial)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial\n                self.fitness[i] = f_trial\n        \n    def apply_niching(self):\n        # Simple crowding-based niching\n        for i in range(self.pop_size):\n            crowd_count = 0\n            for j in range(self.pop_size):\n                if i != j:\n                    distance = np.linalg.norm(self.pop[i] - self.pop[j])\n                    if distance < self.niche_radius:\n                        crowd_count += 1\n            \n            # If overcrowded, replace with a random individual\n            if crowd_count > self.pop_size / 5:  # Example threshold\n                self.pop[i] = np.random.uniform(self.pop[0].size * [-5], self.pop[0].size * [5])  # Assuming bounds are -5 to 5\n                # Evaluate fitness of new individual (IMPORTANT: Don't evaluate inside the niching function if it is called frequently)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.func_evals < self.budget:\n            self.apply_differential_evolution(func)\n            self.apply_niching() # Apply niching every iteration (or less frequently)\n            if self.func_evals > self.budget:\n                break\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.pop[best_index]", "configspace": "", "generation": 10, "feedback": "The algorithm NicheDifferentialEvolution scored 0.413 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution with a niching strategy to maintain diversity and prevent premature convergence.\n\n# Code:\n```python\nimport numpy as np\n\nclass NicheDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.niche_radius = niche_radius\n        self.pop = None\n        self.fitness = None\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n\n    def apply_differential_evolution(self, func):\n        for i in range(self.pop_size):\n            # Ensure we don't pick the same index twice\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            # Mutation\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # Crossover\n            trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.CR:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f_trial = func(trial)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial\n                self.fitness[i] = f_trial\n        \n    def apply_niching(self):\n        # Simple crowding-based niching\n        for i in range(self.pop_size):\n            crowd_count = 0\n            for j in range(self.pop_size):\n                if i != j:\n                    distance = np.linalg.norm(self.pop[i] - self.pop[j])\n                    if distance < self.niche_radius:\n                        crowd_count += 1\n            \n            # If overcrowded, replace with a random individual\n            if crowd_count > self.pop_size / 5:  # Example threshold\n                self.pop[i] = np.random.uniform(self.pop[0].size * [-5], self.pop[0].size * [5])  # Assuming bounds are -5 to 5\n                # Evaluate fitness of new individual (IMPORTANT: Don't evaluate inside the niching function if it is called frequently)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.func_evals < self.budget:\n            self.apply_differential_evolution(func)\n            self.apply_niching() # Apply niching every iteration (or less frequently)\n            if self.func_evals > self.budget:\n                break\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.pop[best_index]\n```", "aucs": [0.19513632786362956, 0.3529619783713501, 0.38739319587368914, 0.44447943106471055, 0.2944113720136806, 0.3808998381803701, 0.3314500550785179, 0.3142226305764938, 0.3046523345075173, 0.2756108548786338, 0.4694862097848438, 0.9852242798991717, 0.45217596926183634, 0.31253315076789, 0.8093743317578013, 0.41699598643516156, 0.33978919576023725, 0.45017063008263436, 0.24404093227151624, 0.5021956129474103], "operator": "random_new", "theta_sampled": 0.0009988610159916722, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "492a6a90-8c1d-40e6-a322-da3c4303ba3d", "fitness": 0.26573144843416513, "name": "AdaptiveHybridPSO_DE", "description": "Adaptive hybrid PSO-DE with self-adaptive parameters, velocity clamping, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1_init=2.5, c1_end=1.0, c2_init=0.5, c2_end=2.5, cr_init=0.3, cr_end=0.9, f_init=0.5, f_end=0.9, pso_ratio=0.5, local_search_probability=0.05, restart_probability=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1_init = c1_init\n        self.c1_end = c1_end\n        self.c2_init = c2_init\n        self.c2_end = c2_end\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.restart_probability = restart_probability\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5):  # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)  # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # clip velocity\n        \n        generation = 0\n\n        while self.budget > 0:\n            # Adaptive parameter updates\n            w = self.w_init + (self.w_end - self.w_init) * generation / (self.budget + generation)\n            c1 = self.c1_init + (self.c1_end - self.c1_init) * generation / (self.budget + generation)\n            c2 = self.c2_init + (self.c2_end - self.c2_init) * generation / (self.budget + generation)\n            cr = self.cr_init + (self.cr_end - self.cr_init) * generation / (self.budget + generation)\n            f = self.f_init + (self.f_end - self.f_init) * generation / (self.budget + generation)\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()  # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = w * velocity[i] + c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n\n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()  # Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n\n                    for j in range(self.dim):\n                        if np.random.rand() < cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n                \n                if self.budget <= 0:\n                    break\n                    \n            # Restart Mechanism\n            if np.random.rand() < self.restart_probability:\n                for i in range(self.pop_size):\n                    pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i]\n                \n                gbest_index = np.argmin(fitness)\n                gbest_pos = pop[gbest_index].copy()\n                gbest_fitness = fitness[gbest_index]\n                velocity = np.zeros_like(pop)\n\n            # Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n\n            if self.budget <= 0:\n                break\n            \n            generation += 1\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.266 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive hybrid PSO-DE with self-adaptive parameters, velocity clamping, and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1_init=2.5, c1_end=1.0, c2_init=0.5, c2_end=2.5, cr_init=0.3, cr_end=0.9, f_init=0.5, f_end=0.9, pso_ratio=0.5, local_search_probability=0.05, restart_probability=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1_init = c1_init\n        self.c1_end = c1_end\n        self.c2_init = c2_init\n        self.c2_end = c2_end\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.restart_probability = restart_probability\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(5):  # Reduced local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocity = np.zeros_like(pop)  # Initialize velocity\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # clip velocity\n        \n        generation = 0\n\n        while self.budget > 0:\n            # Adaptive parameter updates\n            w = self.w_init + (self.w_end - self.w_init) * generation / (self.budget + generation)\n            c1 = self.c1_init + (self.c1_end - self.c1_init) * generation / (self.budget + generation)\n            c2 = self.c2_init + (self.c2_end - self.c2_init) * generation / (self.budget + generation)\n            cr = self.cr_init + (self.cr_end - self.cr_init) * generation / (self.budget + generation)\n            f = self.f_init + (self.f_end - self.f_init) * generation / (self.budget + generation)\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()  # Initialize\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = w * velocity[i] + c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    # Velocity clipping\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n\n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n\n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()  # Initialize\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n\n                    for j in range(self.dim):\n                        if np.random.rand() < cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n\n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n\n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n                \n                if self.budget <= 0:\n                    break\n                    \n            # Restart Mechanism\n            if np.random.rand() < self.restart_probability:\n                for i in range(self.pop_size):\n                    pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i]\n                \n                gbest_index = np.argmin(fitness)\n                gbest_pos = pop[gbest_index].copy()\n                gbest_fitness = fitness[gbest_index]\n                velocity = np.zeros_like(pop)\n\n            # Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n\n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n\n            if self.budget <= 0:\n                break\n            \n            generation += 1\n\n        return gbest_fitness, gbest_pos\n```", "aucs": [0.13083674582978178, 0.20386564715112854, 0.37829693566757483, 0.4730484189699722, 0.28553880636656603, 0.38229416269873406, 0.28156724474120975, 0.2775953106521968, 0.24427121226448734, 0], "operator": "mutation", "theta_sampled": 0.0019193056962964093, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "74a9c583-8194-4b7f-8171-b67a4365494a", "fitness": 0.6297936732471753, "name": "AdaptiveAgingDEArchive", "description": "Combines adaptive mutation strategies, an external archive, aging, and dynamic parameter control for robust exploration and exploitation in continuous optimization.", "code": "import numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995\n        self.F_decay = 0.995\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = max(0.1, min(0.9, self.CR * self.CR_decay + 0.1 * np.random.randn())) # Decay with noise\n            self.F = max(0.1, min(1.0, self.F * self.F_decay + 0.05 * np.random.randn())) # Decay with noise\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if f_u < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveAgingDEArchive scored 0.630 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25", "c549f739-9427-485f-b91e-61a339a7588b"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive mutation strategies, an external archive, aging, and dynamic parameter control for robust exploration and exploitation in continuous optimization.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995\n        self.F_decay = 0.995\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = max(0.1, min(0.9, self.CR * self.CR_decay + 0.1 * np.random.randn())) # Decay with noise\n            self.F = max(0.1, min(1.0, self.F * self.F_decay + 0.05 * np.random.randn())) # Decay with noise\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if f_u < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23245849687829356, 0.3904356947099995, 0.8713577694282106, 0.7532366195294723, 0.6098396602894498, 0.8077044833230856, 0.6232272971511491, 0.5831366781145051, 0.6181450546409504, 0.24807729749921725, 0.6829287542722948, 0.9906651512579572, 0.4562563324268909, 0.7657995737063736, 0.9020776088773728, 0.9214997273970158, 0.512967042188426, 0.8791201881319481, 0.23527605426802178, 0.5116639808528718], "operator": "crossover", "theta_sampled": -0.0005739769699010149, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "2ff2e849-8640-4265-a8ec-0f445273680c", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_OL", "description": "Dynamically adjusts PSO and DE parameters based on their success rates and introduces a diversity maintenance strategy using orthogonal learning.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, ol_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.ol_probability = ol_probability #Probability of performing orthogonal learning\n        self.v_max_ratio = 0.1  # Ratio for calculating v_max\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        if self.budget <= 0:\n            return best_f, best_x\n            \n        num_evals = min(5, self.budget) #Reduce local search evaluations and respect budget\n\n        for _ in range(num_evals):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            new_f = func(new_x)\n            self.budget -= 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n            if self.budget <= 0:\n                return best_f, best_x\n        return best_f, best_x\n\n    def orthogonal_learning(self, func, pop, i, num_samples=5):  # Reduced num_samples\n        \"\"\"Performs orthogonal learning to generate diverse solutions.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        basis = self.create_orthogonal_basis(self.dim)\n        \n        best_x = pop[i].copy()\n        best_f = func(pop[i])\n        \n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(num_samples):\n            # Generate a new solution based on orthogonal design\n            new_x = np.zeros(self.dim)\n            for j in range(self.dim):\n                level = np.random.randint(2) # Binary levels for simplicity\n                new_x[j] = pop[i][j] + (level - 0.5) * basis[j]  #Perturb around current position\n\n            new_x = np.clip(new_x, lb, ub)\n\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n\n        return best_f, best_x\n        \n    def create_orthogonal_basis(self, dim):\n        \"\"\"Creates a simple orthogonal basis (e.g., using Hadamard matrix).\"\"\"\n        if dim == 1:\n            return np.array([[1]])\n        \n        size = 2**int(np.ceil(np.log2(dim))) #Find smallest power of 2\n\n        hadamard = np.ones((size, size))\n        for i in range(1, size):\n            for j in range(1, size):\n                if i & (i - 1) == 0: #Check if i is a power of 2\n                    hadamard[i, j] = hadamard[i // 2, j // 2] * (-1 if (i // (i // 2)) & (j // (j // 2)) else 1)\n                else:\n                    hadamard[i,j] = hadamard[i & (i - 1), j]\n\n        basis = hadamard[1:dim+1, :dim] #Take first dim rows and columns\n        return basis\n    \n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop)\n        v_max = (ub - lb) * self.v_max_ratio\n\n        # Dynamic parameter adaptation\n        adaptive_w = self.w\n        adaptive_cr = self.cr\n        adaptive_f = self.f\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = adaptive_w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, lb, ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + adaptive_f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < adaptive_cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, lb, ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                # Orthogonal learning\n                if np.random.rand() < self.ol_probability:\n                    ol_f, ol_x = self.orthogonal_learning(func, pop, i)\n                    if ol_f < pbest_fitness[i]:\n                        pbest_fitness[i] = ol_f\n                        pbest_pop[i] = ol_x.copy()\n                        if ol_f < gbest_fitness:\n                            gbest_fitness = ol_f\n                            gbest_pos = ol_x.copy()\n                    pop[i] = ol_x.copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # Adapt DE parameters\n            adaptive_cr = np.clip(np.random.normal(self.cr, 0.1), 0, 1)\n            adaptive_f = np.clip(np.random.normal(self.f, 0.1), 0, 2)  # Wider range for f\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: integer division or modulo by zero", "parent_ids": ["1aa1b998-c2f7-4304-9a58-dbe9fee2b412"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO and DE parameters based on their success rates and introduces a diversity maintenance strategy using orthogonal learning.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_ratio=0.5, local_search_probability=0.05, ol_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_ratio = pso_ratio\n        self.success_pso = 0\n        self.success_de = 0\n        self.total_pso = 0\n        self.total_de = 0\n        self.local_search_probability = local_search_probability\n        self.ol_probability = ol_probability #Probability of performing orthogonal learning\n        self.v_max_ratio = 0.1  # Ratio for calculating v_max\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        if self.budget <= 0:\n            return best_f, best_x\n            \n        num_evals = min(5, self.budget) #Reduce local search evaluations and respect budget\n\n        for _ in range(num_evals):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            new_f = func(new_x)\n            self.budget -= 1\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n            if self.budget <= 0:\n                return best_f, best_x\n        return best_f, best_x\n\n    def orthogonal_learning(self, func, pop, i, num_samples=5):  # Reduced num_samples\n        \"\"\"Performs orthogonal learning to generate diverse solutions.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        basis = self.create_orthogonal_basis(self.dim)\n        \n        best_x = pop[i].copy()\n        best_f = func(pop[i])\n        \n        if self.budget <= 0:\n            return best_f, best_x\n\n        for _ in range(num_samples):\n            # Generate a new solution based on orthogonal design\n            new_x = np.zeros(self.dim)\n            for j in range(self.dim):\n                level = np.random.randint(2) # Binary levels for simplicity\n                new_x[j] = pop[i][j] + (level - 0.5) * basis[j]  #Perturb around current position\n\n            new_x = np.clip(new_x, lb, ub)\n\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                return best_f, best_x\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n\n        return best_f, best_x\n        \n    def create_orthogonal_basis(self, dim):\n        \"\"\"Creates a simple orthogonal basis (e.g., using Hadamard matrix).\"\"\"\n        if dim == 1:\n            return np.array([[1]])\n        \n        size = 2**int(np.ceil(np.log2(dim))) #Find smallest power of 2\n\n        hadamard = np.ones((size, size))\n        for i in range(1, size):\n            for j in range(1, size):\n                if i & (i - 1) == 0: #Check if i is a power of 2\n                    hadamard[i, j] = hadamard[i // 2, j // 2] * (-1 if (i // (i // 2)) & (j // (j // 2)) else 1)\n                else:\n                    hadamard[i,j] = hadamard[i & (i - 1), j]\n\n        basis = hadamard[1:dim+1, :dim] #Take first dim rows and columns\n        return basis\n    \n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        velocity = np.zeros_like(pop)\n        v_max = (ub - lb) * self.v_max_ratio\n\n        # Dynamic parameter adaptation\n        adaptive_w = self.w\n        adaptive_cr = self.cr\n        adaptive_f = self.f\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                new_pos_pso = pop[i].copy()\n                new_fitness_pso = np.inf\n\n                if np.random.rand() < self.pso_ratio:\n                    self.total_pso += 1\n                    v = adaptive_w * velocity[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + self.c2 * np.random.rand(self.dim) * (gbest_pos - pop[i])\n                    v = np.clip(v, -v_max, v_max)\n                    velocity[i] = v\n                    new_pos_pso = pop[i] + v\n                    \n                    # Clip to bounds\n                    new_pos_pso = np.clip(new_pos_pso, lb, ub)\n                    \n                    new_fitness_pso = func(new_pos_pso)\n                    self.budget -= 1\n                    \n                    if new_fitness_pso < pbest_fitness[i]:\n                        self.success_pso += 1\n\n                # Differential Evolution update\n                new_pos_de = pop[i].copy()\n                new_fitness_de = np.inf\n                if np.random.rand() > self.pso_ratio:\n                    self.total_de += 1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    diff_vector = x1 + adaptive_f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    \n                    for j in range(self.dim):\n                        if np.random.rand() < adaptive_cr or j == j_rand:\n                            new_pos_de[j] = diff_vector[j]\n\n                    # Clip to bounds\n                    new_pos_de = np.clip(new_pos_de, lb, ub)\n                    \n                    new_fitness_de = func(new_pos_de)\n                    self.budget -= 1\n\n                    if new_fitness_de < pbest_fitness[i]:\n                        self.success_de += 1\n                \n                # Select the better update (PSO or DE)\n                if new_fitness_pso < new_fitness_de:\n                    new_pos = new_pos_pso\n                    new_fitness = new_fitness_pso\n                else:\n                    new_pos = new_pos_de\n                    new_fitness = new_fitness_de\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                \n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    local_f, local_x = self.local_search(func, pop[i].copy())\n                    if local_f < pbest_fitness[i]:\n                        pbest_fitness[i] = local_f\n                        pbest_pop[i] = local_x.copy()\n                        if local_f < gbest_fitness:\n                            gbest_fitness = local_f\n                            gbest_pos = local_x.copy()\n                    pop[i] = local_x.copy()\n\n                # Orthogonal learning\n                if np.random.rand() < self.ol_probability:\n                    ol_f, ol_x = self.orthogonal_learning(func, pop, i)\n                    if ol_f < pbest_fitness[i]:\n                        pbest_fitness[i] = ol_f\n                        pbest_pop[i] = ol_x.copy()\n                        if ol_f < gbest_fitness:\n                            gbest_fitness = ol_f\n                            gbest_pos = ol_x.copy()\n                    pop[i] = ol_x.copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Adapt pso ratio\n            if self.total_pso > 0 and self.total_de > 0:\n                success_rate_pso = self.success_pso / self.total_pso if self.total_pso > 0 else 0\n                success_rate_de = self.success_de / self.total_de if self.total_de > 0 else 0\n\n                if success_rate_pso + success_rate_de > 0:\n                    self.pso_ratio = success_rate_pso / (success_rate_pso + success_rate_de)\n            \n            # Reset success counters\n            self.success_pso = 0\n            self.success_de = 0\n            self.total_pso = 0\n            self.total_de = 0\n            \n            # Adapt DE parameters\n            adaptive_cr = np.clip(np.random.normal(self.cr, 0.1), 0, 1)\n            adaptive_f = np.clip(np.random.normal(self.f, 0.1), 0, 2)  # Wider range for f\n\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pos\n```", "operator": "mutation", "theta_sampled": 0.0028961342777400496, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "7f6d7153-9b58-4649-876f-52d58409b96d", "fitness": 0.18625595827311622, "name": "CauchySwarm", "description": "A swarm-based algorithm with a Cauchy mutation to explore the search space and a dynamic population size to adapt to the landscape.", "code": "import numpy as np\n\nclass CauchySwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size_init=50, c1=1.49, c2=1.49, cauchy_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size_init = swarm_size_init\n        self.c1 = c1\n        self.c2 = c2\n        self.cauchy_scale = cauchy_scale\n        self.swarm_size = swarm_size_init  # Dynamic swarm size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.eval_count += self.swarm_size\n        \n        pbest_swarm = swarm.copy()\n        pbest_fitness = fitness.copy()\n        \n        gbest_index = np.argmin(fitness)\n        gbest_fitness = fitness[gbest_index]\n        gbest_position = swarm[gbest_index].copy()\n\n        velocity = np.zeros_like(swarm)\n\n        while self.eval_count < self.budget:\n            # Update velocity and position\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            \n            velocity = (velocity\n                        + self.c1 * r1 * (pbest_swarm - swarm)\n                        + self.c2 * r2 * (gbest_position - swarm))\n            \n            # Cauchy mutation for exploration\n            mutation = self.cauchy_scale * np.random.standard_cauchy(size=(self.swarm_size, self.dim))\n            new_swarm = swarm + velocity + mutation\n\n            # Clip to bounds\n            new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n            \n            new_fitness = np.array([func(x) for x in new_swarm])\n            self.eval_count += self.swarm_size\n\n            # Update personal best\n            improved = new_fitness < pbest_fitness\n            pbest_swarm[improved] = new_swarm[improved]\n            pbest_fitness[improved] = new_fitness[improved]\n            \n            # Update global best\n            new_gbest_index = np.argmin(pbest_fitness)\n            if pbest_fitness[new_gbest_index] < gbest_fitness:\n                gbest_fitness = pbest_fitness[new_gbest_index]\n                gbest_position = pbest_swarm[new_gbest_index].copy()\n                \n                if gbest_fitness < self.f_opt:\n                    self.f_opt = gbest_fitness\n                    self.x_opt = gbest_position.copy()\n            \n            swarm = new_swarm.copy()\n\n            # Dynamic Swarm Size Adjustment (Example: Shrink if stagnation)\n            if self.eval_count % (self.budget // 10) == 0: # Check every 10% of budget\n                if np.std(pbest_fitness) < 1e-6: # Stagnation detected\n                    self.swarm_size = max(10, self.swarm_size // 2) # Reduce swarm size\n                    # Re-initialize a smaller swarm\n                    swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n                    fitness = np.array([func(x) for x in swarm])\n                    self.eval_count += self.swarm_size\n\n                    pbest_swarm = swarm.copy()\n                    pbest_fitness = fitness.copy()\n                    \n                    gbest_index = np.argmin(fitness)\n                    gbest_fitness = fitness[gbest_index]\n                    gbest_position = swarm[gbest_index].copy()\n                    velocity = np.zeros_like(swarm)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm CauchySwarm scored 0.186 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A swarm-based algorithm with a Cauchy mutation to explore the search space and a dynamic population size to adapt to the landscape.\n# Code: \n```python\nimport numpy as np\n\nclass CauchySwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size_init=50, c1=1.49, c2=1.49, cauchy_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size_init = swarm_size_init\n        self.c1 = c1\n        self.c2 = c2\n        self.cauchy_scale = cauchy_scale\n        self.swarm_size = swarm_size_init  # Dynamic swarm size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.eval_count += self.swarm_size\n        \n        pbest_swarm = swarm.copy()\n        pbest_fitness = fitness.copy()\n        \n        gbest_index = np.argmin(fitness)\n        gbest_fitness = fitness[gbest_index]\n        gbest_position = swarm[gbest_index].copy()\n\n        velocity = np.zeros_like(swarm)\n\n        while self.eval_count < self.budget:\n            # Update velocity and position\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            \n            velocity = (velocity\n                        + self.c1 * r1 * (pbest_swarm - swarm)\n                        + self.c2 * r2 * (gbest_position - swarm))\n            \n            # Cauchy mutation for exploration\n            mutation = self.cauchy_scale * np.random.standard_cauchy(size=(self.swarm_size, self.dim))\n            new_swarm = swarm + velocity + mutation\n\n            # Clip to bounds\n            new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n            \n            new_fitness = np.array([func(x) for x in new_swarm])\n            self.eval_count += self.swarm_size\n\n            # Update personal best\n            improved = new_fitness < pbest_fitness\n            pbest_swarm[improved] = new_swarm[improved]\n            pbest_fitness[improved] = new_fitness[improved]\n            \n            # Update global best\n            new_gbest_index = np.argmin(pbest_fitness)\n            if pbest_fitness[new_gbest_index] < gbest_fitness:\n                gbest_fitness = pbest_fitness[new_gbest_index]\n                gbest_position = pbest_swarm[new_gbest_index].copy()\n                \n                if gbest_fitness < self.f_opt:\n                    self.f_opt = gbest_fitness\n                    self.x_opt = gbest_position.copy()\n            \n            swarm = new_swarm.copy()\n\n            # Dynamic Swarm Size Adjustment (Example: Shrink if stagnation)\n            if self.eval_count % (self.budget // 10) == 0: # Check every 10% of budget\n                if np.std(pbest_fitness) < 1e-6: # Stagnation detected\n                    self.swarm_size = max(10, self.swarm_size // 2) # Reduce swarm size\n                    # Re-initialize a smaller swarm\n                    swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n                    fitness = np.array([func(x) for x in swarm])\n                    self.eval_count += self.swarm_size\n\n                    pbest_swarm = swarm.copy()\n                    pbest_fitness = fitness.copy()\n                    \n                    gbest_index = np.argmin(fitness)\n                    gbest_fitness = fitness[gbest_index]\n                    gbest_position = swarm[gbest_index].copy()\n                    velocity = np.zeros_like(swarm)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13215855698748602, 0.16473389555851392, 0.25681243450252056, 0.21007730245659018, 0.22436851460538088, 0.23031152787150144, 0.22386747167495558, 0.2087174127270519, 0.19112595131941823, 0.17743822427127653, 0.2154602073026992, 0], "operator": "random_new", "theta_sampled": -0.00011518978877540195, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "30e56729-7536-4ec4-a61e-17af9a6d0b48", "fitness": 0.0, "name": "AdaptiveAgingDE", "description": "Adaptive Aging DE with dynamic population size and self-adaptive CR/F, further uses a ranking-based mutation strategy selection.", "code": "import numpy as np\n\nclass AdaptiveAgingDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, mutation_strategies=None, aging_rate=0.01, pop_size_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.pop_size = pop_size_init  # Initial population size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.num_strategies = len(self.mutation_strategies)\n        self.mutation_success = np.zeros(self.num_strategies)  # Track successful mutations\n        self.mutation_counts = np.ones(self.num_strategies)  # Keep track of usage count\n        self.aging_rate = aging_rate\n        self.age = np.zeros(self.pop_size)\n        self.CR = 0.5 * np.ones(self.pop_size)  # Individual CR values\n        self.F = 0.5 * np.ones(self.pop_size)   # Individual F values\n        self.CR_memory = 0.5 * np.ones(10)  # Memory for CR\n        self.F_memory = 0.5 * np.ones(10)  # Memory for F\n        self.memory_index = 0\n        self.pop_size_factor = pop_size_factor  # Factor to dynamically adjust pop size\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Adjust population size dynamically based on budget remaining\n            self.pop_size = max(10, int(self.pop_size_init * (1 + self.pop_size_factor * (1 - self.evals / self.budget))))\n            if self.population.shape[0] != self.pop_size:\n                # Resize population (crude but effective)\n                if self.pop_size > self.population.shape[0]:\n                    num_new = self.pop_size - self.population.shape[0]\n                    new_pop = np.random.uniform(lb, ub, size=(num_new, self.dim))\n                    new_fitness = np.array([func(x) for x in new_pop])\n                    self.evals += num_new\n                    self.population = np.vstack((self.population, new_pop))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                    self.age = np.concatenate((self.age, np.zeros(num_new)))\n                    self.CR = np.concatenate((self.CR, 0.5 * np.ones(num_new)))\n                    self.F = np.concatenate((self.F, 0.5 * np.ones(num_new)))\n\n\n                else:\n                    # Reduce the population by removing the worst\n                    indices = np.argsort(self.fitness)[::-1]\n                    remove_count = self.population.shape[0] - self.pop_size\n                    self.population = self.population[indices[remove_count:]]\n                    self.fitness = self.fitness[indices[remove_count:]]\n                    self.age = self.age[indices[remove_count:]]\n                    self.CR = self.CR[indices[remove_count:]]\n                    self.F = self.F[indices[remove_count:]]\n\n\n            # Rank-based strategy selection\n            fitness_rank = np.argsort(self.fitness)\n            strategy_weights = np.zeros(self.num_strategies)\n            for i in range(self.num_strategies):\n                strategy_weights[i] = np.sum(fitness_rank[self.mutation_counts == (i + 1)]) # Reward strategies that produced better individuals\n\n            if np.sum(strategy_weights) > 0:\n                 strategy_probs = strategy_weights / np.sum(strategy_weights)\n            else:\n                strategy_probs = np.ones(self.num_strategies) / self.num_strategies\n\n\n\n            for i in range(self.pop_size):\n\n                # Strategy Selection\n                mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=strategy_probs)\n                mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F[i] * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F[i] * (x_1 - x_2)\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F[i] * (x_1 - self.population[i]) + self.F[i] * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR[i] or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_success[mutation_strategy_idx] += 1\n                    # Update CR and F values\n                    self.CR_memory[self.memory_index] = self.CR[i]\n                    self.F_memory[self.memory_index] = self.F[i]\n                    self.memory_index = (self.memory_index + 1) % 10\n\n                    self.CR[i] = np.random.normal(np.mean(self.CR_memory), 0.1)\n                    self.F[i] = np.random.normal(np.mean(self.F_memory), 0.1)\n                    self.CR[i] = np.clip(self.CR[i], 0.1, 0.9)\n                    self.F[i] = np.clip(self.F[i], 0.1, 1.0)\n\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                else:\n                    self.age[i] += 1\n                self.mutation_counts[mutation_strategy_idx] += 1 # Increase usage count\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: boolean index did not match indexed array along axis 0; size of axis is 52 but size of corresponding boolean axis is 3", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Aging DE with dynamic population size and self-adaptive CR/F, further uses a ranking-based mutation strategy selection.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, mutation_strategies=None, aging_rate=0.01, pop_size_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.pop_size = pop_size_init  # Initial population size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.num_strategies = len(self.mutation_strategies)\n        self.mutation_success = np.zeros(self.num_strategies)  # Track successful mutations\n        self.mutation_counts = np.ones(self.num_strategies)  # Keep track of usage count\n        self.aging_rate = aging_rate\n        self.age = np.zeros(self.pop_size)\n        self.CR = 0.5 * np.ones(self.pop_size)  # Individual CR values\n        self.F = 0.5 * np.ones(self.pop_size)   # Individual F values\n        self.CR_memory = 0.5 * np.ones(10)  # Memory for CR\n        self.F_memory = 0.5 * np.ones(10)  # Memory for F\n        self.memory_index = 0\n        self.pop_size_factor = pop_size_factor  # Factor to dynamically adjust pop size\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Adjust population size dynamically based on budget remaining\n            self.pop_size = max(10, int(self.pop_size_init * (1 + self.pop_size_factor * (1 - self.evals / self.budget))))\n            if self.population.shape[0] != self.pop_size:\n                # Resize population (crude but effective)\n                if self.pop_size > self.population.shape[0]:\n                    num_new = self.pop_size - self.population.shape[0]\n                    new_pop = np.random.uniform(lb, ub, size=(num_new, self.dim))\n                    new_fitness = np.array([func(x) for x in new_pop])\n                    self.evals += num_new\n                    self.population = np.vstack((self.population, new_pop))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                    self.age = np.concatenate((self.age, np.zeros(num_new)))\n                    self.CR = np.concatenate((self.CR, 0.5 * np.ones(num_new)))\n                    self.F = np.concatenate((self.F, 0.5 * np.ones(num_new)))\n\n\n                else:\n                    # Reduce the population by removing the worst\n                    indices = np.argsort(self.fitness)[::-1]\n                    remove_count = self.population.shape[0] - self.pop_size\n                    self.population = self.population[indices[remove_count:]]\n                    self.fitness = self.fitness[indices[remove_count:]]\n                    self.age = self.age[indices[remove_count:]]\n                    self.CR = self.CR[indices[remove_count:]]\n                    self.F = self.F[indices[remove_count:]]\n\n\n            # Rank-based strategy selection\n            fitness_rank = np.argsort(self.fitness)\n            strategy_weights = np.zeros(self.num_strategies)\n            for i in range(self.num_strategies):\n                strategy_weights[i] = np.sum(fitness_rank[self.mutation_counts == (i + 1)]) # Reward strategies that produced better individuals\n\n            if np.sum(strategy_weights) > 0:\n                 strategy_probs = strategy_weights / np.sum(strategy_weights)\n            else:\n                strategy_probs = np.ones(self.num_strategies) / self.num_strategies\n\n\n\n            for i in range(self.pop_size):\n\n                # Strategy Selection\n                mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=strategy_probs)\n                mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F[i] * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F[i] * (x_1 - x_2)\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F[i] * (x_1 - self.population[i]) + self.F[i] * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR[i] or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_success[mutation_strategy_idx] += 1\n                    # Update CR and F values\n                    self.CR_memory[self.memory_index] = self.CR[i]\n                    self.F_memory[self.memory_index] = self.F[i]\n                    self.memory_index = (self.memory_index + 1) % 10\n\n                    self.CR[i] = np.random.normal(np.mean(self.CR_memory), 0.1)\n                    self.F[i] = np.random.normal(np.mean(self.F_memory), 0.1)\n                    self.CR[i] = np.clip(self.CR[i], 0.1, 0.9)\n                    self.F[i] = np.clip(self.F[i], 0.1, 1.0)\n\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                else:\n                    self.age[i] += 1\n                self.mutation_counts[mutation_strategy_idx] += 1 # Increase usage count\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.0006555853848053208, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "a814906c-9e5e-40a9-b22f-523c4520bc45", "fitness": 0.6369264468664751, "name": "AdaptiveAgingDEArchive", "description": "Combines adaptive mutation strategies, aging, and an archive to enhance exploration and exploitation in differential evolution.", "code": "import numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.archive = []\n        self.archive_fitness = []\n\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()  # Dynamic CR\n            self.F = 0.6 + 0.3 * np.random.rand()  # Dynamic F\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveAgingDEArchive scored 0.637 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25", "c549f739-9427-485f-b91e-61a339a7588b"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive mutation strategies, aging, and an archive to enhance exploration and exploitation in differential evolution.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.archive = []\n        self.archive_fitness = []\n\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()  # Dynamic CR\n            self.F = 0.6 + 0.3 * np.random.rand()  # Dynamic F\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20131598164382658, 0.46651325435034574, 0.6597588621840407, 0.8658430461717564, 0.7509993947614362, 0.7961155101666475, 0.4929341150622176, 0.6033065550888944, 0.7385778252345854, 0.6181516735034496, 0.836590858425425, 0.9957305423607081, 0.4388190986488989, 0.662592793311064, 0.7320482855111814, 0.7944934615727419, 0.510274999345917, 0.8584829586240019, 0.1978080613928307, 0.5181716599695332], "operator": "crossover", "theta_sampled": 0.0006785756975869162, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "ed2528a2-b5c3-4414-a287-dbdc8e672597", "fitness": 0.6461990839147709, "name": "AdaptiveAgingDEArchive", "description": "Adaptive Aging DE with a dynamically adjusted archive size based on performance and a self-adaptive mutation factor F.", "code": "import numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size_init=10, mutation_strategies=None, aging_rate=0.01, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size_init = archive_size_init\n        self.archive_size = archive_size_init  # Dynamic archive size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.5  # Initialize F\n        self.CR_decay = 0.995\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n        self.success_history = [] #History of successful F values\n        self.success_rate_memory = success_rate_memory #How many recent F values to consider\n        self.f_history = []\n        \n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = max(0.1, min(0.9, self.CR * self.CR_decay + 0.1 * np.random.randn())) # Decay with noise\n            # Self-adaptive F\n            if len(self.success_history) > 0:\n                self.F = np.clip(np.random.normal(np.mean(self.success_history), 0.1), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        if len(self.archive) > 0: #Prevent crash if archive is empty\n                            worst_arch_idx = np.argmax(self.archive_fitness)\n                            if f_u < self.archive_fitness[worst_arch_idx]:\n                                self.archive[worst_arch_idx] = self.population[i].copy()\n                                self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n                    \n                    self.success_history.append(self.F)\n                    if len(self.success_history) > self.success_rate_memory:\n                        self.success_history.pop(0)\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                        #Adaptive Archive size\n                        self.f_history.append(f_u)\n                        if len(self.f_history) > 10:\n                            self.f_history.pop(0)\n                            if np.std(self.f_history) < 1e-6: #Converged\n                                self.archive_size = min(self.archive_size + 1, self.pop_size)\n                            else:\n                                self.archive_size = max(self.archive_size - 1, 1)\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveAgingDEArchive scored 0.646 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74a9c583-8194-4b7f-8171-b67a4365494a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Aging DE with a dynamically adjusted archive size based on performance and a self-adaptive mutation factor F.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size_init=10, mutation_strategies=None, aging_rate=0.01, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size_init = archive_size_init\n        self.archive_size = archive_size_init  # Dynamic archive size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.5  # Initialize F\n        self.CR_decay = 0.995\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n        self.success_history = [] #History of successful F values\n        self.success_rate_memory = success_rate_memory #How many recent F values to consider\n        self.f_history = []\n        \n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = max(0.1, min(0.9, self.CR * self.CR_decay + 0.1 * np.random.randn())) # Decay with noise\n            # Self-adaptive F\n            if len(self.success_history) > 0:\n                self.F = np.clip(np.random.normal(np.mean(self.success_history), 0.1), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        if len(self.archive) > 0: #Prevent crash if archive is empty\n                            worst_arch_idx = np.argmax(self.archive_fitness)\n                            if f_u < self.archive_fitness[worst_arch_idx]:\n                                self.archive[worst_arch_idx] = self.population[i].copy()\n                                self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n                    \n                    self.success_history.append(self.F)\n                    if len(self.success_history) > self.success_rate_memory:\n                        self.success_history.pop(0)\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                        #Adaptive Archive size\n                        self.f_history.append(f_u)\n                        if len(self.f_history) > 10:\n                            self.f_history.pop(0)\n                            if np.std(self.f_history) < 1e-6: #Converged\n                                self.archive_size = min(self.archive_size + 1, self.pop_size)\n                            else:\n                                self.archive_size = max(self.archive_size - 1, 1)\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2282569013982716, 0.8515222224004804, 0.8995151468386527, 0.7817590627821552, 0.4497124149466232, 0.9030975311773525, 0.3013404465555113, 0.612668790636763, 0.7110200599424714, 0.18601750051293353, 0.8110938617552387, 0.9930613458830471, 0.3502226885329798, 0.8111087025679382, 0.8869962505730187, 0.9443324534165715, 0.6492238380023374, 0.8327393874327101, 0.2235070428007263, 0.4967860301396346], "operator": "mutation", "theta_sampled": 0.003509305186577149, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "6d43085b-ec2b-4845-bc64-0b440252262c", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_Niching_CMAES", "description": "An adaptive hybrid PSO-DE algorithm that incorporates a niching strategy to promote diversity and uses a CMA-ES based self-adaptation of parameters to improve convergence.", "code": "import numpy as np\nimport cmalib\nfrom scipy.spatial import distance\n\nclass AdaptiveHybridPSO_DE_Niching_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, num_niches=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching and CMA-ES adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            num_niches (int): Number of niches for niching strategy.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.num_niches = num_niches\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100\n\n        # Niching parameters\n        self.niches = None  # Store the center of each niche\n        self.niche_radius = 0.5  # Radius of each niche\n\n        # CMA-ES parameters for self-adaptation\n        self.cmaes_sigma = 0.1\n        self.cmaes_population_size = int(pop_size/2) # Reduced population size for CMA-ES\n        self.cmaes_optimizer = cmalib.CMALib(mean=np.array([w, c1, c2, cr, f, pso_prob]), sigma=self.cmaes_sigma, bounds=np.array([[0.0, 2.0], [0.0, 5.0], [0.0, 5.0], [0.0, 1.0], [0.0, 2.0], [0.0, 1.0]]), population_size=self.cmaes_population_size)\n        self.cmaes_learning_rate = 0.1\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population and niches with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n        # Initialize niches randomly\n        self.niches = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_niches, self.dim))\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles with niching.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        # Niching: Attract particles towards the closest niche\n        niche_attraction = np.zeros((self.pop_size, self.dim))\n        for i in range(self.pop_size):\n            distances = np.array([distance.euclidean(self.population[i], niche) for niche in self.niches])\n            closest_niche_index = np.argmin(distances)\n            if distances[closest_niche_index] < self.niche_radius:\n                niche_attraction[i] = self.niches[closest_niche_index] - self.population[i]\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population) +\n                           0.1 * niche_attraction)  # Added niche attraction term\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with niching.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Niching: Encourage diversity by moving away from crowded niches\n            distances_to_niches = np.array([distance.euclidean(u_crossover, niche) for niche in self.niches])\n            closest_niche_index = np.argmin(distances_to_niches)\n            if distances_to_niches[closest_niche_index] < self.niche_radius:\n                # Move away from the closest niche\n                u_crossover = u_crossover + 0.1 * (u_crossover - self.niches[closest_niche_index]) # Repulsion\n                u_crossover = np.clip(u_crossover, func.bounds.lb, func.bounds.ub)\n            \n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population and niches to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n        # Re-initialize niches\n        self.niches = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_niches, self.dim))\n        \n    def adapt_parameters_cmaes(self):\n        \"\"\"\n        Adapts PSO and DE parameters using CMA-ES.\n        \"\"\"\n        # Sample new parameters from CMA-ES\n        solutions = self.cmaes_optimizer.ask()\n        fitness_values = np.zeros(self.cmaes_population_size)\n\n        # Evaluate the sampled parameters (using a simplified fitness based on recent PSO/DE performance)\n        for i in range(self.cmaes_population_size):\n            w, c1, c2, cr, f, pso_prob = solutions[i]\n            #Clip the parameters to adhere to the bounds\n            w = np.clip(w, 0.0, 2.0)\n            c1 = np.clip(c1, 0.0, 5.0)\n            c2 = np.clip(c2, 0.0, 5.0)\n            cr = np.clip(cr, 0.0, 1.0)\n            f = np.clip(f, 0.0, 2.0)\n            pso_prob = np.clip(pso_prob, 0.0, 1.0)\n            \n            # Use a simplified fitness function that favors parameters leading to balanced PSO/DE success\n            # This could be improved with a more sophisticated evaluation\n            fitness_values[i] = -abs(0.5 - pso_prob)  # Closer to 0.5 is better\n            \n        # Tell CMA-ES about the fitness of the solutions\n        self.cmaes_optimizer.tell(fitness_values)\n        \n        # Update the parameters using the best solution found by CMA-ES (using learning rate)\n        best_solution = solutions[np.argmin(fitness_values)]\n        w, c1, c2, cr, f, pso_prob = best_solution\n        \n        #Clip parameters to adhere to bounds\n        w = np.clip(w, 0.0, 2.0)\n        c1 = np.clip(c1, 0.0, 5.0)\n        c2 = np.clip(c2, 0.0, 5.0)\n        cr = np.clip(cr, 0.0, 1.0)\n        f = np.clip(f, 0.0, 2.0)\n        pso_prob = np.clip(pso_prob, 0.0, 1.0)\n\n        self.w = (1 - self.cmaes_learning_rate) * self.w + self.cmaes_learning_rate * w\n        self.c1 = (1 - self.cmaes_learning_rate) * self.c1 + self.cmaes_learning_rate * c1\n        self.c2 = (1 - self.cmaes_learning_rate) * self.c2 + self.cmaes_learning_rate * c2\n        self.cr = (1 - self.cmaes_learning_rate) * self.cr + self.cmaes_learning_rate * cr\n        self.f = (1 - self.cmaes_learning_rate) * self.f + self.cmaes_learning_rate * f\n        self.pso_prob = (1 - self.cmaes_learning_rate) * self.pso_prob + self.cmaes_learning_rate * pso_prob\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with niching and CMA-ES adaptation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n            self.adapt_parameters_cmaes() #Adapt parameters using CMA-ES\n        \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: No module named 'cmalib'", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm that incorporates a niching strategy to promote diversity and uses a CMA-ES based self-adaptation of parameters to improve convergence.\n# Code: \n```python\nimport numpy as np\nimport cmalib\nfrom scipy.spatial import distance\n\nclass AdaptiveHybridPSO_DE_Niching_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, num_niches=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching and CMA-ES adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            num_niches (int): Number of niches for niching strategy.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.num_niches = num_niches\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100\n\n        # Niching parameters\n        self.niches = None  # Store the center of each niche\n        self.niche_radius = 0.5  # Radius of each niche\n\n        # CMA-ES parameters for self-adaptation\n        self.cmaes_sigma = 0.1\n        self.cmaes_population_size = int(pop_size/2) # Reduced population size for CMA-ES\n        self.cmaes_optimizer = cmalib.CMALib(mean=np.array([w, c1, c2, cr, f, pso_prob]), sigma=self.cmaes_sigma, bounds=np.array([[0.0, 2.0], [0.0, 5.0], [0.0, 5.0], [0.0, 1.0], [0.0, 2.0], [0.0, 1.0]]), population_size=self.cmaes_population_size)\n        self.cmaes_learning_rate = 0.1\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population and niches with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n        # Initialize niches randomly\n        self.niches = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_niches, self.dim))\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles with niching.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        # Niching: Attract particles towards the closest niche\n        niche_attraction = np.zeros((self.pop_size, self.dim))\n        for i in range(self.pop_size):\n            distances = np.array([distance.euclidean(self.population[i], niche) for niche in self.niches])\n            closest_niche_index = np.argmin(distances)\n            if distances[closest_niche_index] < self.niche_radius:\n                niche_attraction[i] = self.niches[closest_niche_index] - self.population[i]\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population) +\n                           0.1 * niche_attraction)  # Added niche attraction term\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n        \"\"\"\n        Updates the population using Differential Evolution principles with niching.\n        \"\"\"\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n            \n            # Ensure mutated vector is within bounds (clip)\n            v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = self.population[i, j]\n\n            # Niching: Encourage diversity by moving away from crowded niches\n            distances_to_niches = np.array([distance.euclidean(u_crossover, niche) for niche in self.niches])\n            closest_niche_index = np.argmin(distances_to_niches)\n            if distances_to_niches[closest_niche_index] < self.niche_radius:\n                # Move away from the closest niche\n                u_crossover = u_crossover + 0.1 * (u_crossover - self.niches[closest_niche_index]) # Repulsion\n                u_crossover = np.clip(u_crossover, func.bounds.lb, func.bounds.ub)\n            \n            # Selection\n            f_trial = func(u_crossover)\n            self.func_evals += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = u_crossover\n                self.fitness[i] = f_trial\n                #Update personal best if needed\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_crossover.copy()\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_crossover.copy()\n                    improved = True\n        if improved:\n            self.de_success[self.success_index] = 1\n        else:\n            self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population and niches to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n        # Re-initialize niches\n        self.niches = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_niches, self.dim))\n        \n    def adapt_parameters_cmaes(self):\n        \"\"\"\n        Adapts PSO and DE parameters using CMA-ES.\n        \"\"\"\n        # Sample new parameters from CMA-ES\n        solutions = self.cmaes_optimizer.ask()\n        fitness_values = np.zeros(self.cmaes_population_size)\n\n        # Evaluate the sampled parameters (using a simplified fitness based on recent PSO/DE performance)\n        for i in range(self.cmaes_population_size):\n            w, c1, c2, cr, f, pso_prob = solutions[i]\n            #Clip the parameters to adhere to the bounds\n            w = np.clip(w, 0.0, 2.0)\n            c1 = np.clip(c1, 0.0, 5.0)\n            c2 = np.clip(c2, 0.0, 5.0)\n            cr = np.clip(cr, 0.0, 1.0)\n            f = np.clip(f, 0.0, 2.0)\n            pso_prob = np.clip(pso_prob, 0.0, 1.0)\n            \n            # Use a simplified fitness function that favors parameters leading to balanced PSO/DE success\n            # This could be improved with a more sophisticated evaluation\n            fitness_values[i] = -abs(0.5 - pso_prob)  # Closer to 0.5 is better\n            \n        # Tell CMA-ES about the fitness of the solutions\n        self.cmaes_optimizer.tell(fitness_values)\n        \n        # Update the parameters using the best solution found by CMA-ES (using learning rate)\n        best_solution = solutions[np.argmin(fitness_values)]\n        w, c1, c2, cr, f, pso_prob = best_solution\n        \n        #Clip parameters to adhere to bounds\n        w = np.clip(w, 0.0, 2.0)\n        c1 = np.clip(c1, 0.0, 5.0)\n        c2 = np.clip(c2, 0.0, 5.0)\n        cr = np.clip(cr, 0.0, 1.0)\n        f = np.clip(f, 0.0, 2.0)\n        pso_prob = np.clip(pso_prob, 0.0, 1.0)\n\n        self.w = (1 - self.cmaes_learning_rate) * self.w + self.cmaes_learning_rate * w\n        self.c1 = (1 - self.cmaes_learning_rate) * self.c1 + self.cmaes_learning_rate * c1\n        self.c2 = (1 - self.cmaes_learning_rate) * self.c2 + self.cmaes_learning_rate * c2\n        self.cr = (1 - self.cmaes_learning_rate) * self.cr + self.cmaes_learning_rate * cr\n        self.f = (1 - self.cmaes_learning_rate) * self.f + self.cmaes_learning_rate * f\n        self.pso_prob = (1 - self.cmaes_learning_rate) * self.pso_prob + self.cmaes_learning_rate * pso_prob\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with niching and CMA-ES adaptation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n            self.adapt_parameters_cmaes() #Adapt parameters using CMA-ES\n        \n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "mutation", "theta_sampled": 0.0017914156661038429, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "cc0dd4e6-3318-4f16-834a-85e355b33cc1", "fitness": 0.3556371186966938, "name": "AdaptiveAgingDEArchiveHybrid", "description": "Combines Adaptive Aging DE with an external archive and dynamic parameter adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveAgingDEArchiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n            \n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveAgingDEArchiveHybrid scored 0.356 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25", "c549f739-9427-485f-b91e-61a339a7588b"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive Aging DE with an external archive and dynamic parameter adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDEArchiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n            \n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23312413260928666, 0.5218747937977142, 0.6675495483797742, 0], "operator": "crossover", "theta_sampled": 0.00032980933104567094, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "74e1f98a-41b1-4751-9d0e-54e5b46d12a1", "fitness": 0.35088242297290223, "name": "AdaptiveHybridPSO_DE_CMA", "description": "Integrates a CMA-ES inspired adaptation of step size into the Adaptive Hybrid PSO-DE framework for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, initial_step_size=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with CMA-ES inspired step-size adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            initial_step_size (float): Initial step size for CMA-ES adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.step_size = initial_step_size\n        self.c_sigma = 0.3  # Learning rate for step size\n        self.d_sigma = 1.0  # Damping factor for step size\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.path_sigma = np.zeros(dim) # CMA-ES path for step-size adaptation\n\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 * self.step_size # Scale v_max by step_size\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3) * self.step_size # Scale by step size\n\n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n    \n    def update_step_size(self):\n        \"\"\"\n        Updates the step size using CMA-ES inspired adaptation.\n        \"\"\"\n        # Update evolution path\n        z = (self.global_best_position - self.personal_best_positions[np.argmin(self.fitness)]) / self.step_size\n        self.path_sigma = (1 - self.c_sigma) * self.path_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z\n\n        # Update step size\n        norm_path = np.linalg.norm(self.path_sigma)\n        self.step_size *= np.exp(self.c_sigma / self.d_sigma * (norm_path / np.sqrt(self.dim) - 1))\n\n        # Keep step size within reasonable bounds\n        self.step_size = np.clip(self.step_size, 1e-6, 1.0)\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.step_size = 0.1  # Reset step size upon restart\n        self.path_sigma = np.zeros(self.dim)  # Reset path\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.update_step_size()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMA scored 0.351 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5e7a0050-d169-4c89-9cd3-4defec887974"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a CMA-ES inspired adaptation of step size into the Adaptive Hybrid PSO-DE framework for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, pso_prob=0.5, success_memory=10, initial_step_size=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with CMA-ES inspired step-size adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the swarm.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Scaling factor for DE.\n            pso_prob (float): Initial probability of using PSO.\n            success_memory (int): Number of iterations to remember PSO/DE success.\n            initial_step_size (float): Initial step size for CMA-ES adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pso_prob = pso_prob\n        self.success_memory = success_memory\n        self.step_size = initial_step_size\n        self.c_sigma = 0.3  # Learning rate for step size\n        self.d_sigma = 1.0  # Damping factor for step size\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.func_evals = 0\n        self.pso_success = np.zeros(success_memory)\n        self.de_success = np.zeros(success_memory)\n        self.success_index = 0\n        self.restart_counter = 0\n        self.restart_interval = 100 # Restart every 100 iterations if no improvement\n        self.path_sigma = np.zeros(dim) # CMA-ES path for step-size adaptation\n\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions within the bounds.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities randomly\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n\n    def update_global_best(self):\n        \"\"\"\n        Updates the global best position and fitness.\n        \"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n            self.last_best_fitness = self.global_best_fitness\n            self.restart_counter = 0\n\n    def pso_update(self, func):\n        \"\"\"\n        Updates the population using PSO principles.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (self.w * self.velocities +\n                           self.c1 * r1 * (self.personal_best_positions - self.population) +\n                           self.c2 * r2 * (self.global_best_position - self.population))\n\n        # Velocity clamping\n        v_max = (func.bounds.ub - func.bounds.lb) * 0.1 * self.step_size # Scale v_max by step_size\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        \n        self.population += self.velocities\n\n        # Boundary handling (reflecting boundaries)\n        for i in range(self.pop_size):\n             for j in range(self.dim):\n                if self.population[i, j] < func.bounds.lb[j]:\n                    self.population[i, j] = func.bounds.lb[j] + (func.bounds.lb[j] - self.population[i, j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n                elif self.population[i, j] > func.bounds.ub[j]:\n                    self.population[i, j] = func.bounds.ub[j] - (self.population[i, j] - func.bounds.ub[j])  # Reflect\n                    self.velocities[i, j] = -self.velocities[i,j]\n\n\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.fitness = new_fitness\n\n        # Update personal bests\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n        old_global_best = self.global_best_fitness\n        self.update_global_best()\n        if self.global_best_fitness < old_global_best:\n            self.pso_success[self.success_index] = 1\n        else:\n            self.pso_success[self.success_index] = 0\n\n    def de_update(self, func):\n            \"\"\"\n            Updates the population using Differential Evolution principles.\n            \"\"\"\n            improved = False\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3) * self.step_size # Scale by step size\n\n                # Ensure mutated vector is within bounds (clip)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_crossover = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == j_rand:\n                        u_crossover[j] = v_mutation[j]\n                    else:\n                        u_crossover[j] = self.population[i, j]\n\n                # Selection\n                f_trial = func(u_crossover)\n                self.func_evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = u_crossover\n                    self.fitness[i] = f_trial\n                    #Update personal best if needed\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = u_crossover.copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = u_crossover.copy()\n                        improved = True\n            if improved:\n                self.de_success[self.success_index] = 1\n            else:\n                self.de_success[self.success_index] = 0\n\n\n    def update_probabilities(self):\n        \"\"\"\n        Updates the probabilities of using PSO or DE based on their recent success.\n        \"\"\"\n        avg_pso_success = np.mean(self.pso_success)\n        avg_de_success = np.mean(self.de_success)\n\n        if avg_pso_success + avg_de_success > 0:\n            self.pso_prob = avg_pso_success / (avg_pso_success + avg_de_success)\n        else:\n            self.pso_prob = 0.5  # Default to 50% if no success recorded\n        self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9) # Keep probabilities away from 0 or 1\n    \n    def update_step_size(self):\n        \"\"\"\n        Updates the step size using CMA-ES inspired adaptation.\n        \"\"\"\n        # Update evolution path\n        z = (self.global_best_position - self.personal_best_positions[np.argmin(self.fitness)]) / self.step_size\n        self.path_sigma = (1 - self.c_sigma) * self.path_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z\n\n        # Update step size\n        norm_path = np.linalg.norm(self.path_sigma)\n        self.step_size *= np.exp(self.c_sigma / self.d_sigma * (norm_path / np.sqrt(self.dim) - 1))\n\n        # Keep step size within reasonable bounds\n        self.step_size = np.clip(self.step_size, 1e-6, 1.0)\n\n\n    def restart_population(self, func):\n        \"\"\"\n        Restarts the population to potentially escape local optima.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.global_best_fitness\n        self.step_size = 0.1  # Reset step size upon restart\n        self.path_sigma = np.zeros(self.dim)  # Reset path\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.last_best_fitness = self.global_best_fitness\n        \n        while self.func_evals < self.budget:\n            self.restart_counter +=1\n            if np.random.rand() < self.pso_prob:\n                self.pso_update(func)\n            else:\n                self.de_update(func)\n\n            self.success_index = (self.success_index + 1) % self.success_memory\n            self.update_probabilities()\n            self.update_step_size()\n\n            if self.restart_counter > self.restart_interval:\n                self.restart_population(func)\n                self.restart_counter = 0\n                \n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.15159635441858865, 0.18247912885612938, 0.3080788743418891, 0.21569682280254932, 0.22067300992283767, 0.27238691553260597, 0.24832395790687511, 0.24920725697550217, 0.34612408018241136, 0.26943603417779827, 0.8245898786328991, 0.998350571683024, 0.2789411267103423, 0.3972645672888371, 0.5458424217129997, 0.3345091553442612, 0.23647738690391873, 0.25902527020752664, 0.21576282204714026, 0.4628828238099091], "operator": "mutation", "theta_sampled": 0.0013239933376878853, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "219362aa-644f-4b60-ac99-630f8cd56008", "fitness": 0.21098049113961034, "name": "AdaptiveGaussianHillClimber", "description": "A hybrid approach combining a Gaussian mutation-based search with a local hill-climbing refinement strategy, adaptively adjusting the mutation strength based on the optimization progress.", "code": "import numpy as np\n\nclass AdaptiveGaussianHillClimber:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, hill_climb_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma  # Adaptive sigma\n        self.hill_climb_steps = hill_climb_steps\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize randomly\n        self.f_opt = func(self.x_opt)\n        self.eval_count += 1\n        \n        archive_x = [self.x_opt]\n        archive_f = [self.f_opt]\n\n        while self.eval_count < self.budget:\n            # Gaussian Mutation\n            x_mut = self.x_opt + self.sigma * np.random.normal(0, 1, size=self.dim)\n            x_mut = np.clip(x_mut, self.lb, self.ub)\n            \n            f_mut = func(x_mut)\n            self.eval_count += 1\n\n            # Hill Climbing Refinement (if mutation improved)\n            if f_mut < self.f_opt and self.eval_count < self.budget:\n                x_refined = x_mut.copy()\n                f_refined = f_mut\n                for _ in range(self.hill_climb_steps):\n                    # Small step in random direction\n                    direction = np.random.normal(0, 0.1, size=self.dim)  # Smaller steps for refinement\n                    x_new = x_refined + direction\n                    x_new = np.clip(x_new, self.lb, self.ub)\n\n                    f_new = func(x_new)\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                         break\n\n                    if f_new < f_refined:\n                        x_refined = x_new\n                        f_refined = f_new\n                    else:\n                         break\n                \n                if f_refined < self.f_opt:\n                    self.f_opt = f_refined\n                    self.x_opt = x_refined\n\n            # Update the archive with the new solution\n            archive_x.append(self.x_opt)\n            archive_f.append(self.f_opt)\n            \n            # Adaptive Sigma update: Reduce sigma if no improvement for a while\n            if len(archive_f) > 20:\n                if np.min(archive_f[-20:]) >= self.f_opt:\n                    self.sigma *= 0.9  # Reduce sigma\n                else:\n                    self.sigma = self.initial_sigma  # Reset Sigma\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveGaussianHillClimber scored 0.211 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A hybrid approach combining a Gaussian mutation-based search with a local hill-climbing refinement strategy, adaptively adjusting the mutation strength based on the optimization progress.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveGaussianHillClimber:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, hill_climb_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma  # Adaptive sigma\n        self.hill_climb_steps = hill_climb_steps\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize randomly\n        self.f_opt = func(self.x_opt)\n        self.eval_count += 1\n        \n        archive_x = [self.x_opt]\n        archive_f = [self.f_opt]\n\n        while self.eval_count < self.budget:\n            # Gaussian Mutation\n            x_mut = self.x_opt + self.sigma * np.random.normal(0, 1, size=self.dim)\n            x_mut = np.clip(x_mut, self.lb, self.ub)\n            \n            f_mut = func(x_mut)\n            self.eval_count += 1\n\n            # Hill Climbing Refinement (if mutation improved)\n            if f_mut < self.f_opt and self.eval_count < self.budget:\n                x_refined = x_mut.copy()\n                f_refined = f_mut\n                for _ in range(self.hill_climb_steps):\n                    # Small step in random direction\n                    direction = np.random.normal(0, 0.1, size=self.dim)  # Smaller steps for refinement\n                    x_new = x_refined + direction\n                    x_new = np.clip(x_new, self.lb, self.ub)\n\n                    f_new = func(x_new)\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                         break\n\n                    if f_new < f_refined:\n                        x_refined = x_new\n                        f_refined = f_new\n                    else:\n                         break\n                \n                if f_refined < self.f_opt:\n                    self.f_opt = f_refined\n                    self.x_opt = x_refined\n\n            # Update the archive with the new solution\n            archive_x.append(self.x_opt)\n            archive_f.append(self.f_opt)\n            \n            # Adaptive Sigma update: Reduce sigma if no improvement for a while\n            if len(archive_f) > 20:\n                if np.min(archive_f[-20:]) >= self.f_opt:\n                    self.sigma *= 0.9  # Reduce sigma\n                else:\n                    self.sigma = self.initial_sigma  # Reset Sigma\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.03475072714009986, 0.16138226626698216, 0.4218628895519566, 0.1152938382687424, 0.1201205188176151, 0.13338042578525988, 0.1619671433660096, 0.15301090203698864, 0.16772742011212327, 0.12759999979610004, 0.29430748949061003, 0.12881145716005615, 0.21950881534767397, 0.13956519875308826, 0.5737290770672561, 0.27661883619712824, 0.1745824861823767, 0.24134382096093965, 0.1456649837282028, 0.428381526762997], "operator": "random_new", "theta_sampled": 0.0005603199345597372, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "f9dfa530-96d8-4dd4-88ab-024c36465698", "fitness": 0.6242465857113005, "name": "AdaptiveDifferentialEvolutionArchive", "description": "Adaptive Differential Evolution with a self-organizing archive and fitness-aware mutation parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n        self.success_history_CR = []\n        self.success_history_F = []\n        self.memory_size = 5\n        self.archive_decay_rate = 0.95 # Decay factor for the archive fitness values\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control using success history\n            if self.success_history_CR:\n                self.CR = np.mean(self.success_history_CR)\n            else:\n                self.CR = 0.7  # Default value if history is empty\n\n            if self.success_history_F:\n                self.F = np.mean(self.success_history_F)\n            else:\n                self.F = 0.8 # Default value if history is empty\n            \n            self.CR = np.clip(self.CR + 0.1 * np.random.normal(), 0.1, 0.9)\n            self.F = np.clip(self.F + 0.1 * np.random.normal(), 0.1, 1.0)\n\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    # Self-organizing archive: Decay the fitness values of the archive over time.\n                    self.archive_fitness = [fitness * self.archive_decay_rate for fitness in self.archive_fitness]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    \n                    # Store successful CR and F values\n                    self.success_history_CR.append(self.CR)\n                    self.success_history_F.append(self.F)\n                    if len(self.success_history_CR) > self.memory_size:\n                        self.success_history_CR.pop(0)\n                        self.success_history_F.pop(0)\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDifferentialEvolutionArchive scored 0.624 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c549f739-9427-485f-b91e-61a339a7588b"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with a self-organizing archive and fitness-aware mutation parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n        self.success_history_CR = []\n        self.success_history_F = []\n        self.memory_size = 5\n        self.archive_decay_rate = 0.95 # Decay factor for the archive fitness values\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control using success history\n            if self.success_history_CR:\n                self.CR = np.mean(self.success_history_CR)\n            else:\n                self.CR = 0.7  # Default value if history is empty\n\n            if self.success_history_F:\n                self.F = np.mean(self.success_history_F)\n            else:\n                self.F = 0.8 # Default value if history is empty\n            \n            self.CR = np.clip(self.CR + 0.1 * np.random.normal(), 0.1, 0.9)\n            self.F = np.clip(self.F + 0.1 * np.random.normal(), 0.1, 1.0)\n\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    # Self-organizing archive: Decay the fitness values of the archive over time.\n                    self.archive_fitness = [fitness * self.archive_decay_rate for fitness in self.archive_fitness]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    \n                    # Store successful CR and F values\n                    self.success_history_CR.append(self.CR)\n                    self.success_history_F.append(self.F)\n                    if len(self.success_history_CR) > self.memory_size:\n                        self.success_history_CR.pop(0)\n                        self.success_history_F.pop(0)\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19818311500889874, 0.24634059896218696, 0.6170128202811417, 0.7135870105072459, 0.6118406001005885, 0.9334835367297296, 0.7342365278425103, 0.5944045485597054, 0.8879509063667955, 0.4021628811230712, 0.8471087947483238, 0.9932044605305265, 0.3888461263369619, 0.7675740978092527, 0.8173079087360106, 0.7902958165975931, 0.3345287888784695, 0.8718940134542528, 0.20956153055277704, 0.5254076310999692], "operator": "mutation", "theta_sampled": 0.0007029427072162514, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "adcd5b43-3cdc-48d0-acc5-4204c57526af", "fitness": 0.35199338001896974, "name": "CooperativeForagingOptimization", "description": "Bio-inspired Cooperative Foraging Optimization using a dynamic population and local search inspired by ant colony foraging.", "code": "import numpy as np\n\nclass CooperativeForagingOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.local_search_iterations = local_search_iterations\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.population_size\n        \n    def local_search(self, func, x):\n        x_best = x.copy()\n        f_best = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.local_search_iterations):\n            # Generate a neighbor\n            neighbor = x + np.random.normal(0, 0.1, size=self.dim)  # Gaussian perturbation\n            neighbor = np.clip(neighbor, self.lb, self.ub) #clip values\n\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = neighbor.copy()\n                \n            if self.eval_count >= self.budget:\n                break\n        \n        return f_best, x_best\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Find the best individual in the population\n            best_index = np.argmin(self.fitness)\n            best_x = self.population[best_index].copy()\n            best_f = self.fitness[best_index]\n\n            # Update global best if necessary\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x.copy()\n\n            # Cooperative Foraging: Individuals move towards the best, but with some randomness\n            for i in range(self.population_size):\n                # Calculate movement vector (attraction to best + random exploration)\n                attraction = 0.5 * (best_x - self.population[i])\n                exploration = 0.1 * np.random.uniform(-1, 1, size=self.dim)  # Smaller exploration\n\n                new_x = self.population[i] + attraction + exploration\n                new_x = np.clip(new_x, self.lb, self.ub)\n\n                # Perform Local Search\n                f_local, x_local = self.local_search(func, new_x)\n                \n                # Update individual only if local search improves it\n                if f_local < self.fitness[i]:\n                    self.fitness[i] = f_local\n                    self.population[i] = x_local.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm CooperativeForagingOptimization scored 0.352 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Bio-inspired Cooperative Foraging Optimization using a dynamic population and local search inspired by ant colony foraging.\n# Code: \n```python\nimport numpy as np\n\nclass CooperativeForagingOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.local_search_iterations = local_search_iterations\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.population_size\n        \n    def local_search(self, func, x):\n        x_best = x.copy()\n        f_best = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.local_search_iterations):\n            # Generate a neighbor\n            neighbor = x + np.random.normal(0, 0.1, size=self.dim)  # Gaussian perturbation\n            neighbor = np.clip(neighbor, self.lb, self.ub) #clip values\n\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = neighbor.copy()\n                \n            if self.eval_count >= self.budget:\n                break\n        \n        return f_best, x_best\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Find the best individual in the population\n            best_index = np.argmin(self.fitness)\n            best_x = self.population[best_index].copy()\n            best_f = self.fitness[best_index]\n\n            # Update global best if necessary\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x.copy()\n\n            # Cooperative Foraging: Individuals move towards the best, but with some randomness\n            for i in range(self.population_size):\n                # Calculate movement vector (attraction to best + random exploration)\n                attraction = 0.5 * (best_x - self.population[i])\n                exploration = 0.1 * np.random.uniform(-1, 1, size=self.dim)  # Smaller exploration\n\n                new_x = self.population[i] + attraction + exploration\n                new_x = np.clip(new_x, self.lb, self.ub)\n\n                # Perform Local Search\n                f_local, x_local = self.local_search(func, new_x)\n                \n                # Update individual only if local search improves it\n                if f_local < self.fitness[i]:\n                    self.fitness[i] = f_local\n                    self.population[i] = x_local.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.12151402406747347, 0.16402575807295416, 0.4243584391439743, 0.1970224034557304, 0.21918585696564663, 0.4463486295950012, 0.26810754825172967, 0.24494898262304443, 0.33199554249553564, 0.1912973277801413, 0.7135740974973395, 0.9931282823622717, 0.2983776944541493, 0.18548678243323324, 0.46690330303360583, 0.29981936525194175, 0.28404622308864413, 0.5166415050920682, 0.21086488087356547, 0.4622209538413449], "operator": "random_new", "theta_sampled": -0.0009908173324099136, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "fc3b52fc-245b-4fb7-9407-aaaef0eb2eff", "fitness": 0.3478181333083148, "name": "AdaptiveAgingDEArchiveDynParam", "description": "Combines Adaptive Aging DE with an archive and dynamic parameter adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveAgingDEArchiveDynParam:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.archive = []\n        self.archive_fitness = []\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n            \n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        if len(self.archive_fitness) > 0:  # Check if archive_fitness is not empty\n                            worst_arch_idx = np.argmax(self.archive_fitness)\n                            if f_u < self.archive_fitness[worst_arch_idx]:\n                                self.archive[worst_arch_idx] = self.population[i].copy()\n                                self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveAgingDEArchiveDynParam scored 0.348 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25", "c549f739-9427-485f-b91e-61a339a7588b"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive Aging DE with an archive and dynamic parameter adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveAgingDEArchiveDynParam:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995  # Decay factor for CR\n        self.F_decay = 0.995  # Decay factor for F\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.archive = []\n        self.archive_fitness = []\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n            \n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        if len(self.archive_fitness) > 0:  # Check if archive_fitness is not empty\n                            worst_arch_idx = np.argmax(self.archive_fitness)\n                            if f_u < self.archive_fitness[worst_arch_idx]:\n                                self.archive[worst_arch_idx] = self.population[i].copy()\n                                self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0  # Reset age\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2665181554283771, 0.45064648495031545, 0.6741078928545667, 0], "operator": "crossover", "theta_sampled": 0.00019598651743126633, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "f7ed9eda-257d-454d-aff7-c5324ab35ba8", "fitness": 0.3482771340785621, "name": "ForagingOptimization", "description": "Bio-inspired foraging algorithm that combines scout bees for global exploration with worker bees for local exploitation around promising solutions.", "code": "import numpy as np\n\nclass ForagingOptimization:\n    def __init__(self, budget=10000, dim=10, scout_ratio=0.1, worker_ratio=0.8, neighborhood_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.scout_ratio = scout_ratio\n        self.worker_ratio = worker_ratio\n        self.neighborhood_size = neighborhood_size  # As a fraction of the search space\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        n_scouts = int(self.scout_ratio * self.budget)\n        n_workers = int(self.worker_ratio * self.budget)\n        n_remaining = self.budget - n_scouts - n_workers\n\n\n        # Scout phase: Global exploration\n        for i in range(n_scouts):\n            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            f = func(x)\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        # Worker phase: Local exploitation around the best solution found by scouts\n        if self.x_opt is not None:\n            for i in range(n_workers):\n                # Generate a neighbor within a defined neighborhood\n                x = self.x_opt + np.random.uniform(-self.neighborhood_size * (func.bounds.ub[0]-func.bounds.lb[0]), self.neighborhood_size * (func.bounds.ub[0]-func.bounds.lb[0]), size=self.dim)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n                \n                f = func(x)\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n        \n        # remaining evaluations as random search\n        for i in range(n_remaining):\n            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            f = func(x)\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm ForagingOptimization scored 0.348 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Bio-inspired foraging algorithm that combines scout bees for global exploration with worker bees for local exploitation around promising solutions.\n# Code: \n```python\nimport numpy as np\n\nclass ForagingOptimization:\n    def __init__(self, budget=10000, dim=10, scout_ratio=0.1, worker_ratio=0.8, neighborhood_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.scout_ratio = scout_ratio\n        self.worker_ratio = worker_ratio\n        self.neighborhood_size = neighborhood_size  # As a fraction of the search space\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        n_scouts = int(self.scout_ratio * self.budget)\n        n_workers = int(self.worker_ratio * self.budget)\n        n_remaining = self.budget - n_scouts - n_workers\n\n\n        # Scout phase: Global exploration\n        for i in range(n_scouts):\n            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            f = func(x)\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        # Worker phase: Local exploitation around the best solution found by scouts\n        if self.x_opt is not None:\n            for i in range(n_workers):\n                # Generate a neighbor within a defined neighborhood\n                x = self.x_opt + np.random.uniform(-self.neighborhood_size * (func.bounds.ub[0]-func.bounds.lb[0]), self.neighborhood_size * (func.bounds.ub[0]-func.bounds.lb[0]), size=self.dim)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n                \n                f = func(x)\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n        \n        # remaining evaluations as random search\n        for i in range(n_remaining):\n            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            f = func(x)\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16735801888621704, 0.270022797929358, 0.34454967489588784, 0.38309567940554456, 0.2641726253151391, 0.3296946103406859, 0.2818107425888081, 0.27476944900927014, 0.26772619751267057, 0.18381595647475168, 0.35756836249239965, 0.9991065574855772, 0.30423549579835285, 0.26098566549121427, 0.5735826626850049, 0.34100735740759613, 0.2881374550550906, 0.37750115648003124, 0.20201611551420362, 0.4943861008034379], "operator": "random_new", "theta_sampled": 0.0007207002884930214, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "7ec4cbea-c5a1-410a-bffc-1322dc2f4b4d", "fitness": 0.0, "name": "HybridDE", "description": "Combines adaptive mutation strategy selection and aging from AdaptiveAgingDE with archive interaction from AdaptiveDifferentialEvolutionArchive, dynamically adjusting CR and F, and introducing a local search phase.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01, local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995\n        self.F_decay = 0.995\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.local_search_probability = local_search_probability\n\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def local_search(self, x, func, lb, ub, step_size=0.1):\n        \"\"\"Performs a simple local search around x.\"\"\"\n        x_new = x.copy()\n        for i in range(self.dim):\n            # Explore in both directions\n            delta = np.random.uniform(-step_size, step_size)\n            x_new[i] = x[i] + delta\n            x_new = self.repair(x_new, lb, ub)\n\n            f_new = func(x_new)\n            if f_new < func(x):\n                x = x_new.copy()  #Move\n        return x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    u = self.local_search(u, func, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm HybridDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b560cb53-c04f-4c2b-a476-50b6c9483c25", "c549f739-9427-485f-b91e-61a339a7588b"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive mutation strategy selection and aging from AdaptiveAgingDE with archive interaction from AdaptiveDifferentialEvolutionArchive, dynamically adjusting CR and F, and introducing a local search phase.\n# Code:\n```python\nimport numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None, aging_rate=0.01, local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.CR_decay = 0.995\n        self.F_decay = 0.995\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)\n        self.local_search_probability = local_search_probability\n\n\n    def repair(self, x, lb, ub):\n        \"\"\"Repair an individual to lie within the bounds.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def local_search(self, x, func, lb, ub, step_size=0.1):\n        \"\"\"Performs a simple local search around x.\"\"\"\n        x_new = x.copy()\n        for i in range(self.dim):\n            # Explore in both directions\n            delta = np.random.uniform(-step_size, step_size)\n            x_new[i] = x[i] + delta\n            x_new = self.repair(x_new, lb, ub)\n\n            f_new = func(x_new)\n            if f_new < func(x):\n                x = x_new.copy()  #Move\n        return x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n\n                v = self.repair(v, lb, ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = self.repair(u, lb, ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    u = self.local_search(u, func, lb, ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n                    self.age[i] += 1\n\n                if self.evals >= self.budget:\n                    break\n\n            # Aging mechanism\n            for i in range(self.pop_size):\n                if self.age[i] > 1.0 / self.aging_rate:\n                    self.population[i] = np.random.uniform(lb, ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.evals += 1\n                    self.age[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            self.CR *= self.CR_decay  # Decay CR\n            self.F *= self.F_decay    # Decay F\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.0008544794341995353, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "097317e7-2d07-4947-8d73-76d8c8af35d7", "fitness": 0.0, "name": "ExplorationEnhancedPSO", "description": "Population-based algorithm with a novel selection mechanism favoring exploration and adaptive step size control based on past success.", "code": "import numpy as np\n\nclass ExplorationEnhancedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_factor = exploration_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.v_max = (self.ub - self.lb) * 0.1  # Maximum velocity\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best and global best\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Adaptive Step Size Control\n        step_size = (self.ub - self.lb) * 0.1\n        success_rate = 0.0\n        successful_moves = 0\n\n        archive = [] # Store explored positions\n        archive_fitness = []\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = self.inertia * velocities + self.c1 * r1 * (pbest_pop - pop) + self.c2 * r2 * (global_best_pos - pop)\n            \n            # Clip velocities\n            velocities = np.clip(velocities, -self.v_max, self.v_max)\n            \n            new_pop = pop + velocities\n            \n            # Clip positions\n            new_pop = np.clip(new_pop, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_pop])\n            self.budget -= self.pop_size\n            \n\n            # Update personal best\n            improved = new_fitness < pbest_fitness\n            pbest_pop[improved] = new_pop[improved].copy()\n            pbest_fitness[improved] = new_fitness[improved].copy()\n\n            # Exploration-Enhanced Selection\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_factor:\n                    # Replace with a randomly selected archive member\n                    if len(archive) > 0:\n                        idx = np.random.randint(0, len(archive))\n                        new_pop[i] = archive[idx]\n                        new_fitness[i] = archive_fitness[idx]\n                    else:\n                        #If the archive is empty, create a new random candidate\n                        new_pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                        new_fitness[i] = func(new_pop[i])\n                        self.budget -= 1\n\n            #Update Global Best\n            for i in range(self.pop_size):\n                if new_fitness[i] < global_best_fitness:\n                    global_best_fitness = new_fitness[i]\n                    global_best_pos = new_pop[i].copy()\n                    \n            # Update population\n            pop = new_pop.copy()\n            fitness = new_fitness.copy()\n\n            # Archive explored positions\n            for i in range(self.pop_size):\n                archive.append(pop[i].copy())\n                archive_fitness.append(fitness[i])\n\n            # Adaptive Step Size Control\n            if successful_moves > 0:\n                success_rate = successful_moves / self.pop_size\n                if success_rate > 0.2:\n                    step_size *= 1.1  # Increase step size if successful\n                else:\n                    step_size *= 0.9  # Decrease step size if unsuccessful\n            successful_moves = 0\n            \n            self.v_max = step_size\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 12, "feedback": "The algorithm ExplorationEnhancedPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a novel selection mechanism favoring exploration and adaptive step size control based on past success.\n# Code: \n```python\nimport numpy as np\n\nclass ExplorationEnhancedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_factor = exploration_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.v_max = (self.ub - self.lb) * 0.1  # Maximum velocity\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best and global best\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Adaptive Step Size Control\n        step_size = (self.ub - self.lb) * 0.1\n        success_rate = 0.0\n        successful_moves = 0\n\n        archive = [] # Store explored positions\n        archive_fitness = []\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = self.inertia * velocities + self.c1 * r1 * (pbest_pop - pop) + self.c2 * r2 * (global_best_pos - pop)\n            \n            # Clip velocities\n            velocities = np.clip(velocities, -self.v_max, self.v_max)\n            \n            new_pop = pop + velocities\n            \n            # Clip positions\n            new_pop = np.clip(new_pop, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_pop])\n            self.budget -= self.pop_size\n            \n\n            # Update personal best\n            improved = new_fitness < pbest_fitness\n            pbest_pop[improved] = new_pop[improved].copy()\n            pbest_fitness[improved] = new_fitness[improved].copy()\n\n            # Exploration-Enhanced Selection\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_factor:\n                    # Replace with a randomly selected archive member\n                    if len(archive) > 0:\n                        idx = np.random.randint(0, len(archive))\n                        new_pop[i] = archive[idx]\n                        new_fitness[i] = archive_fitness[idx]\n                    else:\n                        #If the archive is empty, create a new random candidate\n                        new_pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                        new_fitness[i] = func(new_pop[i])\n                        self.budget -= 1\n\n            #Update Global Best\n            for i in range(self.pop_size):\n                if new_fitness[i] < global_best_fitness:\n                    global_best_fitness = new_fitness[i]\n                    global_best_pos = new_pop[i].copy()\n                    \n            # Update population\n            pop = new_pop.copy()\n            fitness = new_fitness.copy()\n\n            # Archive explored positions\n            for i in range(self.pop_size):\n                archive.append(pop[i].copy())\n                archive_fitness.append(fitness[i])\n\n            # Adaptive Step Size Control\n            if successful_moves > 0:\n                success_rate = successful_moves / self.pop_size\n                if success_rate > 0.2:\n                    step_size *= 1.1  # Increase step size if successful\n                else:\n                    step_size *= 0.9  # Decrease step size if unsuccessful\n            successful_moves = 0\n            \n            self.v_max = step_size\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0], "operator": "random_new", "theta_sampled": -0.00034478692651943255, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "e37a894a-c987-4b35-b086-96fe3c6feb83", "fitness": 0.21957457203648256, "name": "AdaptiveTemperatureSimulatedAnnealing", "description": "A population-based algorithm with adaptive exploration and exploitation phases controlled by a temperature parameter, combined with local search to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveTemperatureSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f = func(self.x)\n        self.eval_count = 1\n\n        self.temp = self.initial_temp\n\n        while self.eval_count < self.budget:\n            # Adaptive temperature adjustment based on fitness improvement\n            if self.f < self.f_opt:\n                self.f_opt = self.f\n                self.x_opt = self.x\n                self.temp = self.initial_temp  # Reset temperature if improvement is found\n            else:\n                self.temp *= self.cooling_rate  # Otherwise, cool down\n\n            # Generate a neighbor solution with decreasing step size as temperature decreases\n            step_size = self.temp * (func.bounds.ub[0] - func.bounds.lb[0]) / 10  # Scale step size\n\n            x_new = self.x + np.random.uniform(-step_size, step_size, size=self.dim)\n\n            # Clip the new solution to stay within bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            # Acceptance criterion based on Metropolis algorithm\n            if f_new < self.f or np.random.rand() < np.exp(-(f_new - self.f) / self.temp):\n                self.x = x_new\n                self.f = f_new\n\n            # Local search around the current best solution\n            if self.eval_count < self.budget and self.f < self.f_opt:\n                for _ in range(self.local_search_iterations):\n                    x_local_new = self.x + np.random.normal(0, step_size / 2, size=self.dim)\n                    x_local_new = np.clip(x_local_new, func.bounds.lb, func.bounds.ub)\n                    f_local_new = func(x_local_new)\n                    self.eval_count += 1\n\n                    if f_local_new < self.f:\n                        self.x = x_local_new\n                        self.f = f_local_new\n                        if f_local_new < self.f_opt:\n                            self.f_opt = f_local_new\n                            self.x_opt = x_local_new\n                    if self.eval_count >= self.budget:\n                        break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveTemperatureSimulatedAnnealing scored 0.220 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive exploration and exploitation phases controlled by a temperature parameter, combined with local search to refine promising solutions.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveTemperatureSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f = func(self.x)\n        self.eval_count = 1\n\n        self.temp = self.initial_temp\n\n        while self.eval_count < self.budget:\n            # Adaptive temperature adjustment based on fitness improvement\n            if self.f < self.f_opt:\n                self.f_opt = self.f\n                self.x_opt = self.x\n                self.temp = self.initial_temp  # Reset temperature if improvement is found\n            else:\n                self.temp *= self.cooling_rate  # Otherwise, cool down\n\n            # Generate a neighbor solution with decreasing step size as temperature decreases\n            step_size = self.temp * (func.bounds.ub[0] - func.bounds.lb[0]) / 10  # Scale step size\n\n            x_new = self.x + np.random.uniform(-step_size, step_size, size=self.dim)\n\n            # Clip the new solution to stay within bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            # Acceptance criterion based on Metropolis algorithm\n            if f_new < self.f or np.random.rand() < np.exp(-(f_new - self.f) / self.temp):\n                self.x = x_new\n                self.f = f_new\n\n            # Local search around the current best solution\n            if self.eval_count < self.budget and self.f < self.f_opt:\n                for _ in range(self.local_search_iterations):\n                    x_local_new = self.x + np.random.normal(0, step_size / 2, size=self.dim)\n                    x_local_new = np.clip(x_local_new, func.bounds.lb, func.bounds.ub)\n                    f_local_new = func(x_local_new)\n                    self.eval_count += 1\n\n                    if f_local_new < self.f:\n                        self.x = x_local_new\n                        self.f = f_local_new\n                        if f_local_new < self.f_opt:\n                            self.f_opt = f_local_new\n                            self.x_opt = x_local_new\n                    if self.eval_count >= self.budget:\n                        break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1285749916349278, 0.17960412893752564, 0.27570018273003294, 0.27579223533437636, 0.1371601916145322, 0.14573158379737028, 0.20464696511544966, 0.19531274744805716, 0.20696304151367761, 0.18496665936167211, 0.2591716288960736, 0.2405428735114068, 0.23912452116964888, 0.18852767988278396, 0.565000673009782, 0.2711973874621726, 0.23785286461665978, 0.14763030761342366, 0.1447782194449373, 0.16321255763514164], "operator": "random_new", "theta_sampled": -0.001395937958636967, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "f0a1df77-6903-487b-8cb8-34dc0df69360", "fitness": 0.5926961190077493, "name": "GaussianCMAES", "description": "Population-based algorithm that combines Gaussian Mutation with Covariance Matrix Adaptation and restarts to avoid premature convergence.", "code": "import numpy as np\n\nclass GaussianCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0  # Initial step size\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean inside the bounds\n            sigma = self.sigma0\n            C = np.eye(self.dim)  # Covariance matrix\n            ps = np.zeros(self.dim)  # Evolution path for step size\n            pc = np.zeros(self.dim)  # Evolution path for covariance matrix\n            \n            mu = self.pop_size // 2 # Number of parents/selected individuals\n            weights = np.log(mu+0.5) - np.log(np.arange(1, mu + 1)) # Mu ranking weights\n            weights /= np.sum(weights)\n            \n            mueff = np.sum(weights)**2 / np.sum(weights**2)\n            \n            cc = (4 + mueff/self.dim) / (self.dim + 4 + 2*mueff/self.dim)\n            cs = (mueff + 2) / (self.dim + mueff + 5)\n            c1 = 2 / ((self.dim + 1.3)**2 + mueff)\n            cmu = min(1-c1, 2 * (mueff - 2 + 1/mueff) / ((self.dim + 2)**2 + mueff))\n            damps = 1 + 2*max(0, np.sqrt((mueff-1)/(self.dim+1)) - 1) + cs\n            \n            \n            while evals_used < self.budget:\n                # Sampling\n                z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n                try:\n                    A = np.linalg.cholesky(C) # Matrix A for sampling\n                except np.linalg.LinAlgError: # In case the matrix is not positive definite\n                    C = C + 1e-8 * np.eye(self.dim)\n                    A = np.linalg.cholesky(C)\n\n                x = mean + sigma * z @ A.T  # Sample population\n\n                # Clipping to bounds\n                for i in range(self.pop_size):\n                    x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f = np.array([func(x[i]) for i in range(self.pop_size)])\n                evals_used += self.pop_size\n\n                if np.any(f < self.f_opt): # update x_opt\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[best_idx]\n\n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sel = x[idx[:mu]]\n                z_sel = z[idx[:mu]]\n                \n                y_w = np.sum(weights[:,None] * z_sel, axis=0)\n                mean_new = np.sum(weights[:,None] * x_sel, axis=0)\n\n                # Update Evolution Paths\n                ps = (1-cs)*ps + np.sqrt(cs*(2-cs)*mueff) * y_w\n                pc = (1-cc)*pc + np.sqrt(cc*(2-cc)*mueff) * (mean_new - mean) / sigma\n\n                # Update Covariance Matrix\n                C = (1-c1-cmu) * C + c1 * (pc[:,None] @ pc[None,:]) + cmu * (weights[:,None] * z_sel).T @ (z_sel)\n                mean = mean_new\n\n                # Update Step Size\n                sigma *= np.exp((cs/damps) * (np.linalg.norm(ps)/np.sqrt(self.dim) - 1))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm GaussianCMAES scored 0.593 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines Gaussian Mutation with Covariance Matrix Adaptation and restarts to avoid premature convergence.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0  # Initial step size\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean inside the bounds\n            sigma = self.sigma0\n            C = np.eye(self.dim)  # Covariance matrix\n            ps = np.zeros(self.dim)  # Evolution path for step size\n            pc = np.zeros(self.dim)  # Evolution path for covariance matrix\n            \n            mu = self.pop_size // 2 # Number of parents/selected individuals\n            weights = np.log(mu+0.5) - np.log(np.arange(1, mu + 1)) # Mu ranking weights\n            weights /= np.sum(weights)\n            \n            mueff = np.sum(weights)**2 / np.sum(weights**2)\n            \n            cc = (4 + mueff/self.dim) / (self.dim + 4 + 2*mueff/self.dim)\n            cs = (mueff + 2) / (self.dim + mueff + 5)\n            c1 = 2 / ((self.dim + 1.3)**2 + mueff)\n            cmu = min(1-c1, 2 * (mueff - 2 + 1/mueff) / ((self.dim + 2)**2 + mueff))\n            damps = 1 + 2*max(0, np.sqrt((mueff-1)/(self.dim+1)) - 1) + cs\n            \n            \n            while evals_used < self.budget:\n                # Sampling\n                z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n                try:\n                    A = np.linalg.cholesky(C) # Matrix A for sampling\n                except np.linalg.LinAlgError: # In case the matrix is not positive definite\n                    C = C + 1e-8 * np.eye(self.dim)\n                    A = np.linalg.cholesky(C)\n\n                x = mean + sigma * z @ A.T  # Sample population\n\n                # Clipping to bounds\n                for i in range(self.pop_size):\n                    x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f = np.array([func(x[i]) for i in range(self.pop_size)])\n                evals_used += self.pop_size\n\n                if np.any(f < self.f_opt): # update x_opt\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[best_idx]\n\n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sel = x[idx[:mu]]\n                z_sel = z[idx[:mu]]\n                \n                y_w = np.sum(weights[:,None] * z_sel, axis=0)\n                mean_new = np.sum(weights[:,None] * x_sel, axis=0)\n\n                # Update Evolution Paths\n                ps = (1-cs)*ps + np.sqrt(cs*(2-cs)*mueff) * y_w\n                pc = (1-cc)*pc + np.sqrt(cc*(2-cc)*mueff) * (mean_new - mean) / sigma\n\n                # Update Covariance Matrix\n                C = (1-c1-cmu) * C + c1 * (pc[:,None] @ pc[None,:]) + cmu * (weights[:,None] * z_sel).T @ (z_sel)\n                mean = mean_new\n\n                # Update Step Size\n                sigma *= np.exp((cs/damps) * (np.linalg.norm(ps)/np.sqrt(self.dim) - 1))\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2713094226199462, 0.21594210838816208, 0.9361076319045347, 0.18046890220827994, 0.957052009720976, 0.9539042707743066, 0.36698245529864715, 0.9218292200199596, 0.9478061258237005, 0.20574015380666932, 0.9701678684132303, 0.9953688130233693, 0.2511572452700247, 0.19705705017151554, 0.5632128077608557, 0.36090375351738513, 0.9108958439244679, 0.9510685277133656, 0.24220216554868856, 0.45474600424690015], "operator": "random_new", "theta_sampled": 0.00045169947338337586, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "bbc195ff-69b6-4065-a604-13842a44ecf0", "fitness": 0.0, "name": "AdaptiveDEOrthogonalArchive", "description": "Adaptive Differential Evolution with orthogonal learning and archive to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n        self.orthogonal_basis = self._generate_orthogonal_basis()\n\n    def _generate_orthogonal_basis(self):\n        # Generate a random orthogonal basis using Gram-Schmidt process\n        basis = np.random.rand(self.dim, self.dim)\n        for i in range(self.dim):\n            for j in range(i):\n                basis[:, i] -= np.dot(basis[:, i], basis[:, j]) * basis[:, j]\n            basis[:, i] /= np.linalg.norm(basis[:, i])\n        return basis\n\n    def orthogonal_crossover(self, x, v, func):\n        # Apply orthogonal crossover around the current individual x\n        u = np.copy(x)\n        basis_idxs = np.random.choice(self.dim, min(5, self.dim), replace=False)  # Select a subset of basis vectors\n\n        for j in basis_idxs:\n            direction = self.orthogonal_basis[:, j]\n\n            # Sample two points along the orthogonal direction\n            step_size = np.random.uniform(-0.1, 0.1)  # Adaptive step size\n            point1 = x + step_size * direction\n            point2 = x - step_size * direction\n\n            point1 = np.clip(point1, func.bounds.lb, func.bounds.ub)\n            point2 = np.clip(point2, func.bounds.lb, func.bounds.ub)\n            \n            f1 = func(point1)\n            f2 = func(point2)\n            self.evals += 2\n\n            # Select the better point\n            if f1 < f2:\n                if f1 < func(u):\n                    u = point1\n            else:\n                if f2 < func(u):\n                    u = point2\n            \n            if self.evals >= self.budget:\n                break\n\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                if np.random.rand() < 0.2: #Probability for applying orthogonal crossover\n                    u = self.orthogonal_crossover(self.population[i], v, func) #Perform orthogonal crossover to enhance local search\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDEOrthogonalArchive scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c549f739-9427-485f-b91e-61a339a7588b"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with orthogonal learning and archive to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEOrthogonalArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            \"rand1\", \"best2\", \"currtorand1\"\n        ]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.CR = 0.7\n        self.F = 0.8\n        self.archive = []\n        self.archive_fitness = []\n        self.orthogonal_basis = self._generate_orthogonal_basis()\n\n    def _generate_orthogonal_basis(self):\n        # Generate a random orthogonal basis using Gram-Schmidt process\n        basis = np.random.rand(self.dim, self.dim)\n        for i in range(self.dim):\n            for j in range(i):\n                basis[:, i] -= np.dot(basis[:, i], basis[:, j]) * basis[:, j]\n            basis[:, i] /= np.linalg.norm(basis[:, i])\n        return basis\n\n    def orthogonal_crossover(self, x, v, func):\n        # Apply orthogonal crossover around the current individual x\n        u = np.copy(x)\n        basis_idxs = np.random.choice(self.dim, min(5, self.dim), replace=False)  # Select a subset of basis vectors\n\n        for j in basis_idxs:\n            direction = self.orthogonal_basis[:, j]\n\n            # Sample two points along the orthogonal direction\n            step_size = np.random.uniform(-0.1, 0.1)  # Adaptive step size\n            point1 = x + step_size * direction\n            point2 = x - step_size * direction\n\n            point1 = np.clip(point1, func.bounds.lb, func.bounds.ub)\n            point2 = np.clip(point2, func.bounds.lb, func.bounds.ub)\n            \n            f1 = func(point1)\n            f2 = func(point2)\n            self.evals += 2\n\n            # Select the better point\n            if f1 < f2:\n                if f1 < func(u):\n                    u = point1\n            else:\n                if f2 < func(u):\n                    u = point2\n            \n            if self.evals >= self.budget:\n                break\n\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Dynamic parameter control\n            self.CR = 0.5 + 0.4 * np.random.rand()\n            self.F = 0.6 + 0.3 * np.random.rand()\n\n            mutation_strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n            mutation_strategy = self.mutation_strategies[mutation_strategy_idx]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = x_1 + self.F * (x_2 - x_3)\n                elif mutation_strategy == \"best2\":\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_1, x_2 = self.population[idxs]\n                    v = self.population[best_idx] + self.F * (x_1 - x_2)\n                elif mutation_strategy == \"currtorand1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x_1 - self.population[i]) + self.F * (x_2 - x_3)\n\n                # Add archive interaction\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    v += 0.1 * (self.archive[arch_idx] - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                if np.random.rand() < 0.2: #Probability for applying orthogonal crossover\n                    u = self.orthogonal_crossover(self.population[i], v, func) #Perform orthogonal crossover to enhance local search\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Strategy adaptation: increase probability of successful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 1.1\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[worst_arch_idx]:\n                             self.archive[worst_arch_idx] = self.population[i].copy()\n                             self.archive_fitness[worst_arch_idx] = self.fitness[i]\n\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Strategy adaptation: decrease probability of unsuccessful strategy\n                    self.mutation_probs[mutation_strategy_idx] *= 0.9\n                    self.mutation_probs /= np.sum(self.mutation_probs)  # Normalize probabilities\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.0014046037538132643, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "b9b195b7-0fc0-4c20-aadc-458efbe6bb29", "fitness": 0.0, "name": "StochasticNelderMead", "description": "A gradient-free optimization algorithm that combines Nelder-Mead simplex method with a stochastic restart mechanism to escape local optima.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass StochasticNelderMead:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Initial guess: random point within bounds\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n            # Initial simplex\n            initial_simplex = self.generate_initial_simplex(x0, self.initial_simplex_size)\n\n            # Optimization using Nelder-Mead\n            result = minimize(func, x0, method='Nelder-Mead',\n                                 options={'maxfev': self.budget - eval_count, 'initial_simplex': initial_simplex, 'xatol': 1e-6, 'fatol': 1e-6})\n\n            eval_count += result.nfev\n\n            if result.fun < self.f_opt:\n                self.f_opt = result.fun\n                self.x_opt = result.x\n            \n            # Stochastic restart\n            if np.random.rand() < self.restart_prob and eval_count < self.budget:\n                pass # Simply continue to the next iteration, which starts with a new random initial guess\n            else:\n                if eval_count >= self.budget:\n                    break # Break out of the loop\n\n        return self.f_opt, self.x_opt\n\n    def generate_initial_simplex(self, x0, size):\n        \"\"\"Generates an initial simplex around x0.\"\"\"\n        simplex = np.zeros((self.dim + 1, self.dim))\n        simplex[0] = x0\n        for i in range(self.dim):\n            simplex[i + 1] = x0 + np.eye(self.dim)[i] * size\n            # Clip the simplex points to be within the bounds\n            simplex[i + 1] = np.clip(simplex[i + 1], func.bounds.lb, func.bounds.ub)\n\n        return simplex", "configspace": "", "generation": 12, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A gradient-free optimization algorithm that combines Nelder-Mead simplex method with a stochastic restart mechanism to escape local optima.\n\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass StochasticNelderMead:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Initial guess: random point within bounds\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n            # Initial simplex\n            initial_simplex = self.generate_initial_simplex(x0, self.initial_simplex_size)\n\n            # Optimization using Nelder-Mead\n            result = minimize(func, x0, method='Nelder-Mead',\n                                 options={'maxfev': self.budget - eval_count, 'initial_simplex': initial_simplex, 'xatol': 1e-6, 'fatol': 1e-6})\n\n            eval_count += result.nfev\n\n            if result.fun < self.f_opt:\n                self.f_opt = result.fun\n                self.x_opt = result.x\n            \n            # Stochastic restart\n            if np.random.rand() < self.restart_prob and eval_count < self.budget:\n                pass # Simply continue to the next iteration, which starts with a new random initial guess\n            else:\n                if eval_count >= self.budget:\n                    break # Break out of the loop\n\n        return self.f_opt, self.x_opt\n\n    def generate_initial_simplex(self, x0, size):\n        \"\"\"Generates an initial simplex around x0.\"\"\"\n        simplex = np.zeros((self.dim + 1, self.dim))\n        simplex[0] = x0\n        for i in range(self.dim):\n            simplex[i + 1] = x0 + np.eye(self.dim)[i] * size\n            # Clip the simplex points to be within the bounds\n            simplex[i + 1] = np.clip(simplex[i + 1], func.bounds.lb, func.bounds.ub)\n\n        return simplex\n```", "operator": "random_new", "theta_sampled": 0.0015444982562699912, "reward": 0.0, "generation": 12}, "task_prompt": ""}
