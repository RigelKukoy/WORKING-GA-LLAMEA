{"id": "78d1624f-9992-44bd-b548-f93c5d69f2ff", "fitness": 0.0, "name": "CMAES_LocalSearch", "description": "Covariance matrix adaptation evolution strategy (CMA-ES) with restarts and a simplified adaptation rule for computational efficiency, combined with a local search operator to refine promising solutions.", "code": "import numpy as np\n\nclass CMAES_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, mu_factor=0.25, cs=0.3, cmu=0.3, csigma=0.3, lambda_factor=4, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.mu = int(self.pop_size * mu_factor)\n        self.cs = cs\n        self.cmu = cmu\n        self.csigma = csigma\n        self.lambda_ = int(self.pop_size * lambda_factor)  # Number of offspring\n        self.local_search_prob = local_search_prob # Probability of performing local search\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        \n        # Initialization\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        restart_trigger = False\n        restart_iter = 0\n\n        while eval_count < self.budget:\n            # Generate offspring\n            z = np.random.randn(self.dim, self.lambda_)\n            x = mean[:, np.newaxis] + sigma * np.dot(np.linalg.cholesky(C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            f = np.array([func(x[:, i]) for i in range(self.lambda_)])\n            eval_count += self.lambda_\n\n            if eval_count > self.budget:\n                f = f[:(self.budget - (eval_count - self.lambda_))]\n                x = x[:,:(self.budget - (eval_count - self.lambda_))]\n            \n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n            f_sorted = f[idx]\n            \n            if f_sorted[0] < self.f_opt:\n                self.f_opt = f_sorted[0]\n                self.x_opt = x_sorted[:, 0]\n\n            # Local Search (optional) on the best solution\n            if np.random.rand() < self.local_search_prob:\n                x_local = self.local_search(x_sorted[:, 0], func)\n                f_local = func(x_local)\n                eval_count += 1\n                if eval_count > self.budget:\n                    break\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(x_sorted[:, :self.mu], axis=1)\n\n            # Update evolution path\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mu) * np.dot(np.linalg.inv(np.linalg.cholesky(C)), (mean - mean_old)) / sigma\n\n            # Update covariance matrix (simplified)\n            C = (1 - self.cmu) * C + self.cmu * np.outer((mean - mean_old) / sigma, (mean - mean_old) / sigma)\n\n            # Update step size\n            sigma = sigma * np.exp(self.csigma * (np.linalg.norm(ps) - np.sqrt(self.dim)))\n            sigma = np.clip(sigma, 1e-10, 10) # Avoid sigma getting too small/large\n            \n            # Restart Mechanism\n            restart_trigger = False\n            if restart_trigger == True:\n                restart_iter += 1\n                if restart_iter > 5:\n                    mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    sigma = self.sigma0\n                    C = np.eye(self.dim)\n                    pc = np.zeros(self.dim)\n                    ps = np.zeros(self.dim)\n                    restart_iter = 0\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, step_size=0.1, num_steps=10):\n        \"\"\"Simple local search around a point x.\"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n\n        for _ in range(num_steps):\n            x_neighbor = x + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(x_neighbor)\n\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor\n        return x_best", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,24) (2,) (2,) ", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Covariance matrix adaptation evolution strategy (CMA-ES) with restarts and a simplified adaptation rule for computational efficiency, combined with a local search operator to refine promising solutions.\n\n# Code:\n```python\nimport numpy as np\n\nclass CMAES_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, mu_factor=0.25, cs=0.3, cmu=0.3, csigma=0.3, lambda_factor=4, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.mu = int(self.pop_size * mu_factor)\n        self.cs = cs\n        self.cmu = cmu\n        self.csigma = csigma\n        self.lambda_ = int(self.pop_size * lambda_factor)  # Number of offspring\n        self.local_search_prob = local_search_prob # Probability of performing local search\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        \n        # Initialization\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        restart_trigger = False\n        restart_iter = 0\n\n        while eval_count < self.budget:\n            # Generate offspring\n            z = np.random.randn(self.dim, self.lambda_)\n            x = mean[:, np.newaxis] + sigma * np.dot(np.linalg.cholesky(C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            f = np.array([func(x[:, i]) for i in range(self.lambda_)])\n            eval_count += self.lambda_\n\n            if eval_count > self.budget:\n                f = f[:(self.budget - (eval_count - self.lambda_))]\n                x = x[:,:(self.budget - (eval_count - self.lambda_))]\n            \n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n            f_sorted = f[idx]\n            \n            if f_sorted[0] < self.f_opt:\n                self.f_opt = f_sorted[0]\n                self.x_opt = x_sorted[:, 0]\n\n            # Local Search (optional) on the best solution\n            if np.random.rand() < self.local_search_prob:\n                x_local = self.local_search(x_sorted[:, 0], func)\n                f_local = func(x_local)\n                eval_count += 1\n                if eval_count > self.budget:\n                    break\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(x_sorted[:, :self.mu], axis=1)\n\n            # Update evolution path\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mu) * np.dot(np.linalg.inv(np.linalg.cholesky(C)), (mean - mean_old)) / sigma\n\n            # Update covariance matrix (simplified)\n            C = (1 - self.cmu) * C + self.cmu * np.outer((mean - mean_old) / sigma, (mean - mean_old) / sigma)\n\n            # Update step size\n            sigma = sigma * np.exp(self.csigma * (np.linalg.norm(ps) - np.sqrt(self.dim)))\n            sigma = np.clip(sigma, 1e-10, 10) # Avoid sigma getting too small/large\n            \n            # Restart Mechanism\n            restart_trigger = False\n            if restart_trigger == True:\n                restart_iter += 1\n                if restart_iter > 5:\n                    mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    sigma = self.sigma0\n                    C = np.eye(self.dim)\n                    pc = np.zeros(self.dim)\n                    ps = np.zeros(self.dim)\n                    restart_iter = 0\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, step_size=0.1, num_steps=10):\n        \"\"\"Simple local search around a point x.\"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n\n        for _ in range(num_steps):\n            x_neighbor = x + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(x_neighbor)\n\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor\n        return x_best\n```"}, "task_prompt": ""}
{"id": "3c150f0a-66dc-4e79-9d64-bf8a1358e6bd", "fitness": 0.0, "name": "HybridDE", "description": "A population-based algorithm that uses a combination of differential evolution and a simple local search strategy to improve solution quality.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size # Reduce budget by initial pop size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clipping\n\n                # Crossover\n                trial = np.copy(pop[i])\n                mask = np.random.rand(self.dim) < self.CR\n                trial[mask] = mutant[mask]\n                \n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1 # reduce budget\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                # Local Search (optional)\n                if self.budget > 0:\n                    x_local = self.local_search(func, pop[i].copy())\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < fitness[i]:\n                      fitness[i] = f_local\n                      pop[i] = x_local\n\n                      if f_local < self.f_opt:\n                          self.f_opt = f_local\n                          self.x_opt = x_local.copy()\n\n                if self.budget <= 0:\n                  break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x):\n        # Simple local search around x\n        best_x = x.copy()\n        best_f = func(x)\n        \n        for _ in range(self.local_search_iterations):\n            # Generate a random neighbor\n            neighbor = x + np.random.uniform(-0.1, 0.1, size=self.dim) # Smaller step size\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            \n            f_neighbor = func(neighbor)\n            \n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n        \n        return best_x", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of differential evolution and a simple local search strategy to improve solution quality.\n\n# Code:\n```python\nimport numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size # Reduce budget by initial pop size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clipping\n\n                # Crossover\n                trial = np.copy(pop[i])\n                mask = np.random.rand(self.dim) < self.CR\n                trial[mask] = mutant[mask]\n                \n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1 # reduce budget\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                # Local Search (optional)\n                if self.budget > 0:\n                    x_local = self.local_search(func, pop[i].copy())\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < fitness[i]:\n                      fitness[i] = f_local\n                      pop[i] = x_local\n\n                      if f_local < self.f_opt:\n                          self.f_opt = f_local\n                          self.x_opt = x_local.copy()\n\n                if self.budget <= 0:\n                  break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x):\n        # Simple local search around x\n        best_x = x.copy()\n        best_f = func(x)\n        \n        for _ in range(self.local_search_iterations):\n            # Generate a random neighbor\n            neighbor = x + np.random.uniform(-0.1, 0.1, size=self.dim) # Smaller step size\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            \n            f_neighbor = func(neighbor)\n            \n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n        \n        return best_x\n```", "aucs": [0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "08f14cdf-0d8b-4b0d-b08b-8b97dedbfef8", "fitness": 0.0, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines particle swarm optimization (PSO) with differential evolution (DE) for exploration and exploitation, dynamically adjusting the balance between them based on population diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        \"\"\"\n        Initializes the Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles/individuals in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Mutation factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.diversity_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population randomly within the search space.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity based on the average distance from the centroid.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_by_pso(self, func):\n        \"\"\"Updates the population using Particle Swarm Optimization.\"\"\"\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n\n    def update_by_de(self, func):\n        \"\"\"Updates the population using Differential Evolution.\"\"\"\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + self.f * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            u = np.array([v_trial[j] if np.random.rand() < self.cr or j == j_rand else self.population[i][j] for j in range(self.dim)])\n\n            f = func(u)\n\n            if f < self.fitness[i]:\n                self.population[i] = u\n                self.fitness[i] = f\n\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black-box function.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.diversity_history.append(diversity)\n\n            # Adjust PSO/DE balance based on diversity\n            if diversity > np.mean(self.diversity_history[-min(10, len(self.diversity_history)):]) if len(self.diversity_history) > 0 else diversity:\n                # High diversity: prioritize DE for exploration\n                self.update_by_de(func)\n            else:\n                # Low diversity: prioritize PSO for exploitation\n                self.update_by_pso(func)\n            \n            eval_count = np.sum(self.fitness!=self.fitness) #counts how many times func was called\n\n            #Ensure budget is respected\n            eval_count = 0\n            for i in range(self.pop_size):\n                x_new = self.population[i].copy()\n                f_new = func(x_new)\n\n                if f_new < self.fitness[i]:\n                    self.fitness[i] = f_new\n                    if f_new < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_new\n                        self.personal_best_positions[i] = x_new.copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_position = x_new.copy()\n            eval_count += self.pop_size\n           \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n            if eval_count > self.budget:\n                 eval_count = self.budget\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines particle swarm optimization (PSO) with differential evolution (DE) for exploration and exploitation, dynamically adjusting the balance between them based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        \"\"\"\n        Initializes the Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles/individuals in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Mutation factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.diversity_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population randomly within the search space.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity based on the average distance from the centroid.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_by_pso(self, func):\n        \"\"\"Updates the population using Particle Swarm Optimization.\"\"\"\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n\n    def update_by_de(self, func):\n        \"\"\"Updates the population using Differential Evolution.\"\"\"\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + self.f * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            u = np.array([v_trial[j] if np.random.rand() < self.cr or j == j_rand else self.population[i][j] for j in range(self.dim)])\n\n            f = func(u)\n\n            if f < self.fitness[i]:\n                self.population[i] = u\n                self.fitness[i] = f\n\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black-box function.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.diversity_history.append(diversity)\n\n            # Adjust PSO/DE balance based on diversity\n            if diversity > np.mean(self.diversity_history[-min(10, len(self.diversity_history)):]) if len(self.diversity_history) > 0 else diversity:\n                # High diversity: prioritize DE for exploration\n                self.update_by_de(func)\n            else:\n                # Low diversity: prioritize PSO for exploitation\n                self.update_by_pso(func)\n            \n            eval_count = np.sum(self.fitness!=self.fitness) #counts how many times func was called\n\n            #Ensure budget is respected\n            eval_count = 0\n            for i in range(self.pop_size):\n                x_new = self.population[i].copy()\n                f_new = func(x_new)\n\n                if f_new < self.fitness[i]:\n                    self.fitness[i] = f_new\n                    if f_new < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_new\n                        self.personal_best_positions[i] = x_new.copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_position = x_new.copy()\n            eval_count += self.pop_size\n           \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n            if eval_count > self.budget:\n                 eval_count = self.budget\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "d11c0d83-daad-4c5e-b9b4-11a5980944a1", "fitness": 0.0, "name": "AdaptiveHybridDE", "description": "A population-based algorithm that combines elements of differential evolution with a local search strategy based on Nelder-Mead simplex method, adaptively adjusting parameters based on success rate.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_prob=0.1):\n        \"\"\"\n        Adaptive Hybrid Differential Evolution with Local Search.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The size of the population.\n            F (float): The differential weight.\n            CR (float): The crossover rate.\n            local_search_prob (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.archive = []\n        self.archive_size = pop_size  # Size of the archive\n\n        self.success_F = 0.5\n        self.success_CR = 0.7\n        self.success_count = 0\n        self.iteration_count = 0\n        self.adaptation_rate = 0.1\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.update_best()\n\n        while self.budget > 0:\n            self.iteration_count += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.population[idxs]\n\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[i])\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    self.success_count += 1  # Increment success count\n                else:\n                    self.archive.append(self.population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive parameter update based on success rate\n            success_rate = self.success_count / self.pop_size\n            self.F = np.clip(self.F + self.adaptation_rate * (success_rate - 0.5), 0.1, 0.9)\n            self.CR = np.clip(self.CR + self.adaptation_rate * (success_rate - 0.5), 0.1, 0.9)\n            self.success_count = 0  # Reset success count\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Local Search\n            if np.random.rand() < self.local_search_prob:\n                idx = np.random.randint(self.pop_size)\n                x0 = self.population[idx]\n                \n                #Define the local search function to check budget\n                def local_func(x):\n                    if self.budget > 0:\n                      f = func(x)\n                      self.budget -= 1\n                      return f\n                    else:\n                        return np.inf\n                \n                res = minimize(local_func, x0, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': self.budget//10 if self.budget > 10 else 1})  # Limit local search evaluations\n                if res.fun < self.fitness[idx]:\n                   self.population[idx] = res.x\n                   self.fitness[idx] = res.fun\n\n\n            self.update_best()\n\n        return self.f_opt, self.x_opt\n\n    def update_best(self):\n        \"\"\"Updates the best solution found so far.\"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of differential evolution with a local search strategy based on Nelder-Mead simplex method, adaptively adjusting parameters based on success rate.\n\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_prob=0.1):\n        \"\"\"\n        Adaptive Hybrid Differential Evolution with Local Search.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The size of the population.\n            F (float): The differential weight.\n            CR (float): The crossover rate.\n            local_search_prob (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.archive = []\n        self.archive_size = pop_size  # Size of the archive\n\n        self.success_F = 0.5\n        self.success_CR = 0.7\n        self.success_count = 0\n        self.iteration_count = 0\n        self.adaptation_rate = 0.1\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.update_best()\n\n        while self.budget > 0:\n            self.iteration_count += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.population[idxs]\n\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[i])\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    self.success_count += 1  # Increment success count\n                else:\n                    self.archive.append(self.population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive parameter update based on success rate\n            success_rate = self.success_count / self.pop_size\n            self.F = np.clip(self.F + self.adaptation_rate * (success_rate - 0.5), 0.1, 0.9)\n            self.CR = np.clip(self.CR + self.adaptation_rate * (success_rate - 0.5), 0.1, 0.9)\n            self.success_count = 0  # Reset success count\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Local Search\n            if np.random.rand() < self.local_search_prob:\n                idx = np.random.randint(self.pop_size)\n                x0 = self.population[idx]\n                \n                #Define the local search function to check budget\n                def local_func(x):\n                    if self.budget > 0:\n                      f = func(x)\n                      self.budget -= 1\n                      return f\n                    else:\n                        return np.inf\n                \n                res = minimize(local_func, x0, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': self.budget//10 if self.budget > 10 else 1})  # Limit local search evaluations\n                if res.fun < self.fitness[idx]:\n                   self.population[idx] = res.x\n                   self.fitness[idx] = res.fun\n\n\n            self.update_best()\n\n        return self.f_opt, self.x_opt\n\n    def update_best(self):\n        \"\"\"Updates the best solution found so far.\"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n```"}, "task_prompt": ""}
{"id": "8685e41a-9867-4d91-aec0-41ad8c9620e4", "fitness": 0.36586320106204245, "name": "SlimeMoldOptimization", "description": "Bio-inspired search algorithm mimicking slime mold's foraging behavior, adaptively adjusting step size and direction based on fitness landscape.", "code": "import numpy as np\n\nclass SlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c = c  # Confidence factor, influences step size\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.current_evaluations = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :]\n\n    def update_best(self):\n        current_best_index = np.argmin(self.fitness)\n        if self.fitness[current_best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[current_best_index]\n            self.best_position = self.positions[current_best_index, :].copy()\n\n    def update_positions(self, func):\n        w = np.random.rand(self.population_size, self.dim)  # Adaptive weight based on fitness\n        \n        # Calculate influence vector towards the best position\n        influence = self.c * (self.best_position - self.positions) * np.random.rand(self.population_size, self.dim) # Confidence-based influence\n\n        # Calculate exploration/exploitation balance vector\n        exploration = np.random.normal(0, 1, size=(self.population_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * 0.01 # Small Gaussian perturbation\n\n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break  # Stop if budget is exceeded\n\n            new_position = self.positions[i, :] + w[i, :] * influence[i, :] + exploration[i, :] # Slime mold-inspired movement\n            \n            # Clip positions to bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            new_position = np.clip(new_position, lb, ub)\n\n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n            \n            if new_fitness < self.fitness[i]: # Replace only if better (elitism)\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n                \n        self.update_best()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm SlimeMoldOptimization scored 0.366 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Bio-inspired search algorithm mimicking slime mold's foraging behavior, adaptively adjusting step size and direction based on fitness landscape.\n# Code: \n```python\nimport numpy as np\n\nclass SlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c = c  # Confidence factor, influences step size\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.current_evaluations = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :]\n\n    def update_best(self):\n        current_best_index = np.argmin(self.fitness)\n        if self.fitness[current_best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[current_best_index]\n            self.best_position = self.positions[current_best_index, :].copy()\n\n    def update_positions(self, func):\n        w = np.random.rand(self.population_size, self.dim)  # Adaptive weight based on fitness\n        \n        # Calculate influence vector towards the best position\n        influence = self.c * (self.best_position - self.positions) * np.random.rand(self.population_size, self.dim) # Confidence-based influence\n\n        # Calculate exploration/exploitation balance vector\n        exploration = np.random.normal(0, 1, size=(self.population_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * 0.01 # Small Gaussian perturbation\n\n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break  # Stop if budget is exceeded\n\n            new_position = self.positions[i, :] + w[i, :] * influence[i, :] + exploration[i, :] # Slime mold-inspired movement\n            \n            # Clip positions to bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            new_position = np.clip(new_position, lb, ub)\n\n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n            \n            if new_fitness < self.fitness[i]: # Replace only if better (elitism)\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n                \n        self.update_best()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position\n```", "aucs": [0.10488747240626617, 0.19779044093599973, 0.4114323349488661, 0.6539047288082966, 0.1871018145022758, 0.37241251989212354, 0.24434320813003274, 0.25473762697239855, 0.31142169440195777, 0.1729266237213002, 0.6681412705184308, 0.9710294967734826, 0.25900568460888884, 0.18953119298574383, 0.710367305906396, 0.28996345661968703, 0.3039197289377761, 0.5029697344144478, 0.17288166002253236, 0.3384960257339461], "operator": "random_new", "theta_sampled": 0.30201822705837644, "reward": 0.36586320106204245, "generation": 1}, "task_prompt": ""}
{"id": "877eaf14-c664-4520-8b9b-e52439ced948", "fitness": 0.3879208892240663, "name": "RankDiversityAdaptation", "description": "Population-based algorithm with adaptive mutation and crossover based on fitness ranking and diversity measures.", "code": "import numpy as np\n\nclass RankDiversityAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = 100\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Ranking-based selection and crossover\n            ranked_indices = np.argsort(fitness)\n            parents = population[ranked_indices[:self.pop_size // 2]] # Select top half as parents\n\n            offspring = []\n            for i in range(self.pop_size):\n                p1_idx = np.random.randint(0, len(parents))\n                p2_idx = np.random.randint(0, len(parents))\n                p1 = parents[p1_idx]\n                p2 = parents[p2_idx]\n\n                # Adaptive Crossover: Blend based on rank\n                rank_p1 = np.where(ranked_indices == np.where(np.all(population == p1, axis=1))[0][0])[0][0]  # Get rank of p1\n                rank_p2 = np.where(ranked_indices == np.where(np.all(population == p2, axis=1))[0][0])[0][0]  # Get rank of p2\n                \n                alpha = 0.5 + 0.5*(rank_p1 - rank_p2)/self.pop_size # Bias towards better parent. if same rank, alpha=0.5\n                child = alpha * p1 + (1 - alpha) * p2\n                child = np.clip(child, self.lb, self.ub)\n                offspring.append(child)\n\n            offspring = np.array(offspring)\n            \n            # Adaptive Mutation based on diversity\n            diversity = np.std(population, axis=0).mean() \n            mutation_rate = 0.05 + 0.2 * (1 - diversity) # Higher mutation when population is less diverse\n            mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n            mutation = np.random.normal(0, 1, size=offspring.shape)\n            offspring = offspring + mutation_mask * mutation\n\n            offspring = np.clip(offspring, self.lb, self.ub)\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Update population: elitism and replacement\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n            \n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.pop_size]]\n            fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm RankDiversityAdaptation scored 0.388 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive mutation and crossover based on fitness ranking and diversity measures.\n# Code: \n```python\nimport numpy as np\n\nclass RankDiversityAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = 100\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Ranking-based selection and crossover\n            ranked_indices = np.argsort(fitness)\n            parents = population[ranked_indices[:self.pop_size // 2]] # Select top half as parents\n\n            offspring = []\n            for i in range(self.pop_size):\n                p1_idx = np.random.randint(0, len(parents))\n                p2_idx = np.random.randint(0, len(parents))\n                p1 = parents[p1_idx]\n                p2 = parents[p2_idx]\n\n                # Adaptive Crossover: Blend based on rank\n                rank_p1 = np.where(ranked_indices == np.where(np.all(population == p1, axis=1))[0][0])[0][0]  # Get rank of p1\n                rank_p2 = np.where(ranked_indices == np.where(np.all(population == p2, axis=1))[0][0])[0][0]  # Get rank of p2\n                \n                alpha = 0.5 + 0.5*(rank_p1 - rank_p2)/self.pop_size # Bias towards better parent. if same rank, alpha=0.5\n                child = alpha * p1 + (1 - alpha) * p2\n                child = np.clip(child, self.lb, self.ub)\n                offspring.append(child)\n\n            offspring = np.array(offspring)\n            \n            # Adaptive Mutation based on diversity\n            diversity = np.std(population, axis=0).mean() \n            mutation_rate = 0.05 + 0.2 * (1 - diversity) # Higher mutation when population is less diverse\n            mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n            mutation = np.random.normal(0, 1, size=offspring.shape)\n            offspring = offspring + mutation_mask * mutation\n\n            offspring = np.clip(offspring, self.lb, self.ub)\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Update population: elitism and replacement\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n            \n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.pop_size]]\n            fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17039589638243613, 0.21680766316176958, 0.4085001586063248, 0.17831503887823563, 0.3026131775800044, 0.4798663739961475, 0.3513619776112663, 0.2801730144729184, 0.39839772474408597, 0.20380006433041054, 0.3381742981483242, 0.9969134321273512, 0.3028940910958827, 0.3311863340319574, 0.6797770449190434, 0.4532712850013637, 0.36077787975730957, 0.6196309138515859, 0.19233956098688954, 0.49322185479801883], "operator": "random_new", "theta_sampled": 0.20088300173300924, "reward": 0.3879208892240663, "generation": 1}, "task_prompt": ""}
{"id": "3c600221-bb6a-43a2-999f-922a7cb86197", "fitness": 0.4172712788137757, "name": "SymbioticOrganismsSearch", "description": "Population-based algorithm inspired by symbiotic relationships in nature, where individuals adapt based on interactions with others, promoting both individual and collective learning.", "code": "import numpy as np\n\nclass SymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break  # Stop evaluation if budget is exhausted\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.population[i])\n\n            # Randomly change some dimensions of the parasite\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]", "configspace": "", "generation": 1, "feedback": "The algorithm SymbioticOrganismsSearch scored 0.417 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm inspired by symbiotic relationships in nature, where individuals adapt based on interactions with others, promoting both individual and collective learning.\n# Code: \n```python\nimport numpy as np\n\nclass SymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break  # Stop evaluation if budget is exhausted\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.population[i])\n\n            # Randomly change some dimensions of the parasite\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]\n```", "aucs": [0.16389552015784536, 0.3329035731037482, 0.421560704249456, 0.6600299762872879, 0.3148618602133787, 0.45571161811884653, 0.3352281131873366, 0.3019304914308867, 0.39915854269757467, 0.192395479401697, 0.35760601974071093, 0.9824676833991388, 0.29860284367399137, 0.3209481363620331, 0.7205017937978264, 0.389747377524429, 0.3622586158463361, 0.6510892920904872, 0.1901082121312595, 0.49441972286124336], "operator": "random_new", "theta_sampled": 0.36407548219595176, "reward": 0.4172712788137757, "generation": 1}, "task_prompt": ""}
{"id": "1f4d8b00-f709-4412-a89a-dc183c8ea455", "fitness": 0.0, "name": "AdaptiveRadiusRandomSearch", "description": "Adaptive Radius Random Search with Shrinking and Expansion based on Success Rate", "code": "import numpy as np\n\nclass AdaptiveRadiusRandomSearch:\n    def __init__(self, budget=10000, dim=10, initial_radius=0.5, shrink_factor=0.95, expand_factor=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.radius = initial_radius\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize at a random point\n        self.f_opt = func(x)\n        self.x_opt = x\n        success_count = 0\n\n        for i in range(self.budget):\n            # Generate a random point within the radius of the current best\n            x_new = self.x_opt + np.random.uniform(-self.radius, self.radius, size=self.dim)\n\n            # Clip to ensure the new point is within bounds\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                success_count += 1\n\n            # Adapt the radius based on the success rate\n            if (i+1) % 100 == 0:\n                success_rate = success_count / 100\n                if success_rate > self.success_threshold:\n                    self.radius *= self.expand_factor\n                else:\n                    self.radius *= self.shrink_factor\n                \n                #Keep radius in reasonable range\n                self.radius = np.clip(self.radius, 0.0001, (self.ub - self.lb)/2) #prevent radius from exploding or vanishing\n                \n                success_count = 0 #reset success counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveRadiusRandomSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptive Radius Random Search with Shrinking and Expansion based on Success Rate\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveRadiusRandomSearch:\n    def __init__(self, budget=10000, dim=10, initial_radius=0.5, shrink_factor=0.95, expand_factor=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.radius = initial_radius\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize at a random point\n        self.f_opt = func(x)\n        self.x_opt = x\n        success_count = 0\n\n        for i in range(self.budget):\n            # Generate a random point within the radius of the current best\n            x_new = self.x_opt + np.random.uniform(-self.radius, self.radius, size=self.dim)\n\n            # Clip to ensure the new point is within bounds\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                success_count += 1\n\n            # Adapt the radius based on the success rate\n            if (i+1) % 100 == 0:\n                success_rate = success_count / 100\n                if success_rate > self.success_threshold:\n                    self.radius *= self.expand_factor\n                else:\n                    self.radius *= self.shrink_factor\n                \n                #Keep radius in reasonable range\n                self.radius = np.clip(self.radius, 0.0001, (self.ub - self.lb)/2) #prevent radius from exploding or vanishing\n                \n                success_count = 0 #reset success counter\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.3948926787142167, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "349918e2-9613-4e66-b7e0-7d2fbb1d6b92", "fitness": 0.0, "name": "SobolNelderMead", "description": "Population-based algorithm using Nelder-Mead simplex for local search within promising regions identified by a global exploration strategy based on Sobol sequences and shrinking bounds.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=10, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.sobol_seq = self.generate_sobol_sequence(budget, dim)\n\n\n    def generate_sobol_sequence(self, n, dim):\n        try:\n            from sobol_seq import i4_sobol_generate\n            sobol = i4_sobol_generate(dim, n)\n            return sobol\n        except ImportError:\n            print(\"Sobol sequence generator not found. Please install 'sobol_seq'. Falling back to uniform random sampling.\")\n            return np.random.rand(n, dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initial population (Sobol sequence scaled to bounds)\n        population = lb + (ub - lb) * self.sobol_seq[:self.pop_size]\n        eval_count += self.pop_size\n        fitness = np.array([func(x) for x in population])\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n\n        # Main optimization loop\n        while eval_count < self.budget:\n            # Select promising individuals (e.g., top 20%)\n            num_elite = max(1, int(0.2 * self.pop_size))\n            elite_indices = np.argsort(fitness)[:num_elite]\n            elite_population = population[elite_indices]\n\n            # Apply Nelder-Mead to each elite individual\n            for i in range(num_elite):\n                x0 = elite_population[i]\n                remaining_evals = self.budget - eval_count\n                options = {'maxiter': min(self.local_search_iterations, remaining_evals)}\n                \n                res = minimize(func, x0, method='Nelder-Mead', bounds=[(lb[j], ub[j]) for j in range(self.dim)], options=options)\n                eval_count += res.nit  # Number of iterations is approximately the number of function evaluations.\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n            \n            # Shrink bounds based on the best solution so far\n            range_size = 0.5 # Percentage of the initial range\n            new_lb = np.maximum(lb, self.x_opt - (ub - lb) * range_size/2)\n            new_ub = np.minimum(ub, self.x_opt + (ub - lb) * range_size/2)\n\n            # Generate new individuals using Sobol sequence within shrunken bounds\n            num_new = min(self.pop_size, self.budget - eval_count)\n\n            if num_new > 0:\n                new_population = new_lb + (new_ub - new_lb) * self.sobol_seq[self.pop_size:self.pop_size + num_new] # Ensure unique sampling\n\n                new_fitness = np.array([func(x) for x in new_population])\n                eval_count += num_new\n\n                # Replace worst individuals in the population with new individuals\n                worst_indices = np.argsort(fitness)[-num_new:]  # Indices of the worst individuals\n                population[worst_indices] = new_population\n                fitness[worst_indices] = new_fitness\n            \n\n                if np.min(fitness) < self.f_opt:\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = population[np.argmin(fitness)]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using Nelder-Mead simplex for local search within promising regions identified by a global exploration strategy based on Sobol sequences and shrinking bounds.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=10, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.sobol_seq = self.generate_sobol_sequence(budget, dim)\n\n\n    def generate_sobol_sequence(self, n, dim):\n        try:\n            from sobol_seq import i4_sobol_generate\n            sobol = i4_sobol_generate(dim, n)\n            return sobol\n        except ImportError:\n            print(\"Sobol sequence generator not found. Please install 'sobol_seq'. Falling back to uniform random sampling.\")\n            return np.random.rand(n, dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initial population (Sobol sequence scaled to bounds)\n        population = lb + (ub - lb) * self.sobol_seq[:self.pop_size]\n        eval_count += self.pop_size\n        fitness = np.array([func(x) for x in population])\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n\n        # Main optimization loop\n        while eval_count < self.budget:\n            # Select promising individuals (e.g., top 20%)\n            num_elite = max(1, int(0.2 * self.pop_size))\n            elite_indices = np.argsort(fitness)[:num_elite]\n            elite_population = population[elite_indices]\n\n            # Apply Nelder-Mead to each elite individual\n            for i in range(num_elite):\n                x0 = elite_population[i]\n                remaining_evals = self.budget - eval_count\n                options = {'maxiter': min(self.local_search_iterations, remaining_evals)}\n                \n                res = minimize(func, x0, method='Nelder-Mead', bounds=[(lb[j], ub[j]) for j in range(self.dim)], options=options)\n                eval_count += res.nit  # Number of iterations is approximately the number of function evaluations.\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n            \n            # Shrink bounds based on the best solution so far\n            range_size = 0.5 # Percentage of the initial range\n            new_lb = np.maximum(lb, self.x_opt - (ub - lb) * range_size/2)\n            new_ub = np.minimum(ub, self.x_opt + (ub - lb) * range_size/2)\n\n            # Generate new individuals using Sobol sequence within shrunken bounds\n            num_new = min(self.pop_size, self.budget - eval_count)\n\n            if num_new > 0:\n                new_population = new_lb + (new_ub - new_lb) * self.sobol_seq[self.pop_size:self.pop_size + num_new] # Ensure unique sampling\n\n                new_fitness = np.array([func(x) for x in new_population])\n                eval_count += num_new\n\n                # Replace worst individuals in the population with new individuals\n                worst_indices = np.argsort(fitness)[-num_new:]  # Indices of the worst individuals\n                population[worst_indices] = new_population\n                fitness[worst_indices] = new_fitness\n            \n\n                if np.min(fitness) < self.f_opt:\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = population[np.argmin(fitness)]\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.3145500995484164, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "01dc715f-ad42-4db1-a613-41dd99e3ec92", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Adaptive hybrid of PSO and DE with a local search component that dynamically adjusts PSO/DE balance based on diversity and employs a more refined local search.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, ls_prob=0.1, ls_iterations=3):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE with Local Search algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles/individuals in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Mutation factor for DE.\n            ls_prob (float): Probability of performing local search on a particle.\n            ls_iterations (int): Number of iterations for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.ls_prob = ls_prob\n        self.ls_iterations = ls_iterations\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.diversity_history = []\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population randomly within the search space.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity based on the average distance from the centroid.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_by_pso(self, func):\n        \"\"\"Updates the population using Particle Swarm Optimization.\"\"\"\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.eval_count += 1\n\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n\n    def update_by_de(self, func):\n        \"\"\"Updates the population using Differential Evolution.\"\"\"\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + self.f * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            u = np.array([v_trial[j] if np.random.rand() < self.cr or j == j_rand else self.population[i][j] for j in range(self.dim)])\n\n            f = func(u)\n            self.eval_count += 1\n\n            if f < self.fitness[i]:\n                self.population[i] = u\n                self.fitness[i] = f\n\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around the given solution.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.ls_iterations):\n            neighbor = best_x + np.random.normal(0, 0.05, size=self.dim)  # Smaller, normally distributed steps\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n\n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n\n        return best_x, best_f\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black-box function.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.diversity_history.append(diversity)\n\n            # Adjust PSO/DE balance based on diversity\n            if len(self.diversity_history) > 1 and diversity > np.mean(self.diversity_history[-min(10, len(self.diversity_history)):-1]):\n                # High diversity: prioritize DE for exploration\n                self.update_by_de(func)\n            else:\n                # Low diversity: prioritize PSO for exploitation\n                self.update_by_pso(func)\n\n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                    x_local, f_local = self.local_search(func, self.population[i].copy())\n\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.population[i] = x_local.copy()\n\n                        if f_local < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_local\n                            self.personal_best_positions[i] = x_local.copy()\n                        if f_local < self.global_best_fitness:\n                            self.global_best_fitness = f_local\n                            self.global_best_position = x_local.copy()\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c150f0a-66dc-4e79-9d64-bf8a1358e6bd", "08f14cdf-0d8b-4b0d-b08b-8b97dedbfef8"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive hybrid of PSO and DE with a local search component that dynamically adjusts PSO/DE balance based on diversity and employs a more refined local search.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, ls_prob=0.1, ls_iterations=3):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE with Local Search algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles/individuals in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Mutation factor for DE.\n            ls_prob (float): Probability of performing local search on a particle.\n            ls_iterations (int): Number of iterations for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.ls_prob = ls_prob\n        self.ls_iterations = ls_iterations\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.diversity_history = []\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population randomly within the search space.\n        \"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity based on the average distance from the centroid.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_by_pso(self, func):\n        \"\"\"Updates the population using Particle Swarm Optimization.\"\"\"\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.eval_count += 1\n\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n\n    def update_by_de(self, func):\n        \"\"\"Updates the population using Differential Evolution.\"\"\"\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + self.f * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            u = np.array([v_trial[j] if np.random.rand() < self.cr or j == j_rand else self.population[i][j] for j in range(self.dim)])\n\n            f = func(u)\n            self.eval_count += 1\n\n            if f < self.fitness[i]:\n                self.population[i] = u\n                self.fitness[i] = f\n\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around the given solution.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.ls_iterations):\n            neighbor = best_x + np.random.normal(0, 0.05, size=self.dim)  # Smaller, normally distributed steps\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n\n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n\n        return best_x, best_f\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black-box function.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.diversity_history.append(diversity)\n\n            # Adjust PSO/DE balance based on diversity\n            if len(self.diversity_history) > 1 and diversity > np.mean(self.diversity_history[-min(10, len(self.diversity_history)):-1]):\n                # High diversity: prioritize DE for exploration\n                self.update_by_de(func)\n            else:\n                # Low diversity: prioritize PSO for exploitation\n                self.update_by_pso(func)\n\n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                    x_local, f_local = self.local_search(func, self.population[i].copy())\n\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.population[i] = x_local.copy()\n\n                        if f_local < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_local\n                            self.personal_best_positions[i] = x_local.copy()\n                        if f_local < self.global_best_fitness:\n                            self.global_best_fitness = f_local\n                            self.global_best_position = x_local.copy()\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.21516103415704754, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "e77bdf4e-d270-412d-87f9-4687cf9c642c", "fitness": 0.0, "name": "FitnessBlendedPSO_DE", "description": "Population-based algorithm that combines aspects of particle swarm optimization and differential evolution, using a fitness-dependent blending factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass FitnessBlendedPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F # Differential evolution factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pop = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i])\n                                 + self.c2 * np.random.rand(self.dim) * (gbest_pop - pop[i]))\n\n                # Create a trial vector using DE with fitness-dependent blending\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Calculate a blending factor based on relative fitness\n                if fitness[i] < np.mean(fitness):\n                    blending_factor = 0.9\n                else:\n                    blending_factor = 0.1\n\n                trial_vector = pop[i] + blending_factor * self.F * (pop[b] - pop[c])\n\n                # Ensure trial vector stays within bounds\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break # crucial to stop the evaluation\n\n                # Update population if trial vector is better\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial_vector.copy()\n                    fitness[i] = trial_fitness.copy()\n\n                    # Update personal best\n                    if trial_fitness < pbest_fitness[i]:\n                        pbest_pop[i] = trial_vector.copy()\n                        pbest_fitness[i] = trial_fitness.copy()\n\n                        # Update global best\n                        if trial_fitness < gbest_fitness:\n                            gbest_pop = trial_vector.copy()\n                            gbest_fitness = trial_fitness.copy()\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pop", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: 'float' object has no attribute 'copy'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines aspects of particle swarm optimization and differential evolution, using a fitness-dependent blending factor to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass FitnessBlendedPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F # Differential evolution factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pop = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i])\n                                 + self.c2 * np.random.rand(self.dim) * (gbest_pop - pop[i]))\n\n                # Create a trial vector using DE with fitness-dependent blending\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Calculate a blending factor based on relative fitness\n                if fitness[i] < np.mean(fitness):\n                    blending_factor = 0.9\n                else:\n                    blending_factor = 0.1\n\n                trial_vector = pop[i] + blending_factor * self.F * (pop[b] - pop[c])\n\n                # Ensure trial vector stays within bounds\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break # crucial to stop the evaluation\n\n                # Update population if trial vector is better\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial_vector.copy()\n                    fitness[i] = trial_fitness.copy()\n\n                    # Update personal best\n                    if trial_fitness < pbest_fitness[i]:\n                        pbest_pop[i] = trial_vector.copy()\n                        pbest_fitness[i] = trial_fitness.copy()\n\n                        # Update global best\n                        if trial_fitness < gbest_fitness:\n                            gbest_pop = trial_vector.copy()\n                            gbest_fitness = trial_fitness.copy()\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_pop\n```", "operator": "random_new", "theta_sampled": 0.31016010651024295, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "f5ef09fa-f3a7-40b9-a78a-bd165fd78ea3", "fitness": 0.0, "name": "AdaptiveHybrid", "description": "A hybrid Differential Evolution and Particle Swarm Optimization algorithm with adaptive strategy selection based on population diversity and a local search enhancement.", "code": "import numpy as np\n\nclass AdaptiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid algorithm, combining PSO and DE with adaptive strategy selection and local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.diversity_history = []\n        self.strategy_probabilities = np.array([0.5, 0.5])  # Initial probabilities for PSO and DE\n        self.success_rates = np.zeros(2) # Track success rates of PSO and DE\n        self.learning_rate = 0.1 # Learning rate for adjusting strategy probabilities\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population randomly.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_by_pso(self, func):\n        \"\"\"Updates the population using Particle Swarm Optimization.\"\"\"\n        improved = 0\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n\n            if f < self.fitness[i]:\n                improved += 1\n                self.fitness[i] = f\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n        return improved\n\n    def update_by_de(self, func):\n        \"\"\"Updates the population using Differential Evolution.\"\"\"\n        improved = 0\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + self.f * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            u = np.array([v_trial[j] if np.random.rand() < self.cr or j == j_rand else self.population[i][j] for j in range(self.dim)])\n\n            f = func(u)\n\n            if f < self.fitness[i]:\n                improved += 1\n                self.population[i] = u\n                self.fitness[i] = f\n\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n        return improved\n\n    def local_search(self, func, x):\n        \"\"\"Simple local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n\n        for _ in range(self.local_search_iterations):\n            neighbor = x + np.random.uniform(-0.1, 0.1, size=self.dim)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(neighbor)\n\n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n\n        return best_x, best_f\n        \n    def adjust_strategy_probabilities(self):\n        \"\"\"Adjusts the probabilities of selecting PSO or DE based on their recent success.\"\"\"\n        # Update success rates using exponential moving average\n        self.success_rates = 0.9 * self.success_rates + 0.1 * np.array(self.recent_improvements)\n\n        # Normalize success rates to get probabilities\n        sum_success = np.sum(self.success_rates)\n        if sum_success > 0:\n            new_probabilities = self.success_rates / sum_success\n        else:\n            new_probabilities = np.array([0.5, 0.5]) #reset if no improvement\n\n        # Apply learning rate to update strategy probabilities\n        self.strategy_probabilities = (1 - self.learning_rate) * self.strategy_probabilities + self.learning_rate * new_probabilities\n        self.strategy_probabilities /= np.sum(self.strategy_probabilities) # Normalize\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given black-box function.\"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n        self.recent_improvements = [0, 0] # PSO, DE\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.diversity_history.append(diversity)\n\n            # Choose strategy based on probabilities\n            if np.random.rand() < self.strategy_probabilities[0]:\n                # Apply PSO\n                improved = self.update_by_pso(func)\n                self.recent_improvements[0] = improved\n            else:\n                # Apply DE\n                improved = self.update_by_de(func)\n                self.recent_improvements[1] = improved\n                \n            eval_count = 0 #recalculate eval count\n            for i in range(self.pop_size):\n                x_new = self.population[i].copy()\n                f_new = func(x_new)\n\n                if f_new < self.fitness[i]:\n                    self.fitness[i] = f_new\n                    if f_new < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_new\n                        self.personal_best_positions[i] = x_new.copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_position = x_new.copy()\n            eval_count += self.pop_size\n\n            # Local Search (applied to the best individual)\n            if eval_count < self.budget:\n                best_idx = np.argmin(self.fitness)\n                x_local, f_local = self.local_search(func, self.population[best_idx].copy())\n                eval_count += self.local_search_iterations\n\n                if f_local < self.fitness[best_idx]:\n                    self.fitness[best_idx] = f_local\n                    self.population[best_idx] = x_local\n                    if f_local < self.personal_best_fitness[best_idx]:\n                        self.personal_best_fitness[best_idx] = f_local\n                        self.personal_best_positions[best_idx] = x_local.copy()\n                    if f_local < self.global_best_fitness:\n                        self.global_best_fitness = f_local\n                        self.global_best_position = x_local.copy()\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n            \n            self.adjust_strategy_probabilities()\n\n            if eval_count > self.budget:\n                eval_count = self.budget\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybrid scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c150f0a-66dc-4e79-9d64-bf8a1358e6bd", "08f14cdf-0d8b-4b0d-b08b-8b97dedbfef8"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid Differential Evolution and Particle Swarm Optimization algorithm with adaptive strategy selection based on population diversity and a local search enhancement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid algorithm, combining PSO and DE with adaptive strategy selection and local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.diversity_history = []\n        self.strategy_probabilities = np.array([0.5, 0.5])  # Initial probabilities for PSO and DE\n        self.success_rates = np.zeros(2) # Track success rates of PSO and DE\n        self.learning_rate = 0.1 # Learning rate for adjusting strategy probabilities\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population randomly.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity.\"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_by_pso(self, func):\n        \"\"\"Updates the population using Particle Swarm Optimization.\"\"\"\n        improved = 0\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n\n            if f < self.fitness[i]:\n                improved += 1\n                self.fitness[i] = f\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n        return improved\n\n    def update_by_de(self, func):\n        \"\"\"Updates the population using Differential Evolution.\"\"\"\n        improved = 0\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + self.f * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            u = np.array([v_trial[j] if np.random.rand() < self.cr or j == j_rand else self.population[i][j] for j in range(self.dim)])\n\n            f = func(u)\n\n            if f < self.fitness[i]:\n                improved += 1\n                self.population[i] = u\n                self.fitness[i] = f\n\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.population[i].copy()\n        return improved\n\n    def local_search(self, func, x):\n        \"\"\"Simple local search around x.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n\n        for _ in range(self.local_search_iterations):\n            neighbor = x + np.random.uniform(-0.1, 0.1, size=self.dim)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(neighbor)\n\n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n\n        return best_x, best_f\n        \n    def adjust_strategy_probabilities(self):\n        \"\"\"Adjusts the probabilities of selecting PSO or DE based on their recent success.\"\"\"\n        # Update success rates using exponential moving average\n        self.success_rates = 0.9 * self.success_rates + 0.1 * np.array(self.recent_improvements)\n\n        # Normalize success rates to get probabilities\n        sum_success = np.sum(self.success_rates)\n        if sum_success > 0:\n            new_probabilities = self.success_rates / sum_success\n        else:\n            new_probabilities = np.array([0.5, 0.5]) #reset if no improvement\n\n        # Apply learning rate to update strategy probabilities\n        self.strategy_probabilities = (1 - self.learning_rate) * self.strategy_probabilities + self.learning_rate * new_probabilities\n        self.strategy_probabilities /= np.sum(self.strategy_probabilities) # Normalize\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given black-box function.\"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n        self.recent_improvements = [0, 0] # PSO, DE\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.diversity_history.append(diversity)\n\n            # Choose strategy based on probabilities\n            if np.random.rand() < self.strategy_probabilities[0]:\n                # Apply PSO\n                improved = self.update_by_pso(func)\n                self.recent_improvements[0] = improved\n            else:\n                # Apply DE\n                improved = self.update_by_de(func)\n                self.recent_improvements[1] = improved\n                \n            eval_count = 0 #recalculate eval count\n            for i in range(self.pop_size):\n                x_new = self.population[i].copy()\n                f_new = func(x_new)\n\n                if f_new < self.fitness[i]:\n                    self.fitness[i] = f_new\n                    if f_new < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_new\n                        self.personal_best_positions[i] = x_new.copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_position = x_new.copy()\n            eval_count += self.pop_size\n\n            # Local Search (applied to the best individual)\n            if eval_count < self.budget:\n                best_idx = np.argmin(self.fitness)\n                x_local, f_local = self.local_search(func, self.population[best_idx].copy())\n                eval_count += self.local_search_iterations\n\n                if f_local < self.fitness[best_idx]:\n                    self.fitness[best_idx] = f_local\n                    self.population[best_idx] = x_local\n                    if f_local < self.personal_best_fitness[best_idx]:\n                        self.personal_best_fitness[best_idx] = f_local\n                        self.personal_best_positions[best_idx] = x_local.copy()\n                    if f_local < self.global_best_fitness:\n                        self.global_best_fitness = f_local\n                        self.global_best_position = x_local.copy()\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n            \n            self.adjust_strategy_probabilities()\n\n            if eval_count > self.budget:\n                eval_count = self.budget\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.27472610757932425, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "4a1cd5e9-bff4-4c62-a453-1327b18b69d8", "fitness": 0.2891943669115917, "name": "AdaptiveSlimeMoldOptimization", "description": "Adaptively adjusts exploration and exploitation based on fitness improvement and incorporates a repulsive force from the worst-performing individual to enhance diversity.", "code": "import numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c1=0.1, c2=0.01, c3=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c1 = c1  # Confidence factor towards best\n        self.c2 = c2  # Exploration factor\n        self.c3 = c3  # Repulsion factor from worst\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.worst_fitness = -np.inf\n        self.worst_position = None\n        self.current_evaluations = 0\n        self.inertia = 0.7  # Inertia weight for position updates\n        self.exploration_rate = 0.7 # probability for exploration\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :].copy()\n        self.worst_fitness = np.max(self.fitness)\n        self.worst_position = self.positions[np.argmax(self.fitness), :].copy()\n\n    def update_best_worst(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[best_index]\n            self.best_position = self.positions[best_index, :].copy()\n\n        worst_index = np.argmax(self.fitness)\n        if self.fitness[worst_index] > self.worst_fitness:\n            self.worst_fitness = self.fitness[worst_index]\n            self.worst_position = self.positions[worst_index, :].copy()\n\n    def update_positions(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Adaptive adjustment of exploration rate\n        improvement_ratio = (self.worst_fitness - self.best_fitness) / (abs(self.best_fitness) + 1e-8)\n        self.exploration_rate = np.clip(self.exploration_rate * (1 + 0.1 * improvement_ratio), 0.1, 0.9)\n        \n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break  # Stop if budget is exceeded\n                \n            q = np.random.rand()\n            if q < self.exploration_rate:\n                # Exploration: random jump\n                new_position = np.random.uniform(lb, ub, size=self.dim)\n            else:\n                # Exploitation: Slime mold-inspired movement with adaptive components\n                influence = self.c1 * np.random.rand() * (self.best_position - self.positions[i, :])\n                repulsion = self.c3 * np.random.rand() * (self.positions[i, :] - self.worst_position)\n\n                exploration = self.c2 * np.random.normal(0, 1, size=self.dim) * (ub - lb) * 0.01\n                \n                new_position = self.inertia * self.positions[i, :] + influence + repulsion + exploration\n                \n                # Clip positions to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n            \n            if new_fitness < self.fitness[i]: # Replace only if better (elitism)\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n                \n        self.update_best_worst()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveSlimeMoldOptimization scored 0.289 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8685e41a-9867-4d91-aec0-41ad8c9620e4"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively adjusts exploration and exploitation based on fitness improvement and incorporates a repulsive force from the worst-performing individual to enhance diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c1=0.1, c2=0.01, c3=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c1 = c1  # Confidence factor towards best\n        self.c2 = c2  # Exploration factor\n        self.c3 = c3  # Repulsion factor from worst\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.worst_fitness = -np.inf\n        self.worst_position = None\n        self.current_evaluations = 0\n        self.inertia = 0.7  # Inertia weight for position updates\n        self.exploration_rate = 0.7 # probability for exploration\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :].copy()\n        self.worst_fitness = np.max(self.fitness)\n        self.worst_position = self.positions[np.argmax(self.fitness), :].copy()\n\n    def update_best_worst(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[best_index]\n            self.best_position = self.positions[best_index, :].copy()\n\n        worst_index = np.argmax(self.fitness)\n        if self.fitness[worst_index] > self.worst_fitness:\n            self.worst_fitness = self.fitness[worst_index]\n            self.worst_position = self.positions[worst_index, :].copy()\n\n    def update_positions(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Adaptive adjustment of exploration rate\n        improvement_ratio = (self.worst_fitness - self.best_fitness) / (abs(self.best_fitness) + 1e-8)\n        self.exploration_rate = np.clip(self.exploration_rate * (1 + 0.1 * improvement_ratio), 0.1, 0.9)\n        \n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break  # Stop if budget is exceeded\n                \n            q = np.random.rand()\n            if q < self.exploration_rate:\n                # Exploration: random jump\n                new_position = np.random.uniform(lb, ub, size=self.dim)\n            else:\n                # Exploitation: Slime mold-inspired movement with adaptive components\n                influence = self.c1 * np.random.rand() * (self.best_position - self.positions[i, :])\n                repulsion = self.c3 * np.random.rand() * (self.positions[i, :] - self.worst_position)\n\n                exploration = self.c2 * np.random.normal(0, 1, size=self.dim) * (ub - lb) * 0.01\n                \n                new_position = self.inertia * self.positions[i, :] + influence + repulsion + exploration\n                \n                # Clip positions to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n            \n            if new_fitness < self.fitness[i]: # Replace only if better (elitism)\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n                \n        self.update_best_worst()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position\n```", "aucs": [0.11531316774044409, 0.19025916397576537, 0.320357776993625, 0.2527319782431836, 0.2020833404499609, 0.22342048568804762, 0.24081598404151072, 0.21927153851308745, 0.21542116526988087, 0.1611691462968492, 0.20767449512744396, 0.9987514227927874, 0.25424278450246296, 0.20071070541440117, 0.5715852561542888, 0.2759053064722996, 0.2628722335224095, 0.2528643070648532, 0.16069133310917805, 0.45774574685935543], "operator": "mutation", "theta_sampled": 0.4785958756748436, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "34dc02ea-4441-482d-b5cf-828bb5cce452", "fitness": 0.32645483859586477, "name": "AdaptiveSymbioticOrganismsSearch", "description": "Adaptive Symbiotic Organisms Search with dynamic population size and learning rates, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.initial_lr = initial_lr  # Initial learning rate\n        self.lr = initial_lr  # Current learning rate\n        self.pop_size_decay_rate = 0.99 # Decay the population size by this fraction when there is no improvement.\n        self.best_fitness = np.inf\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n            else:\n                break  # Stop evaluation if budget is exhausted\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.population[i] + self.lr * np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + self.lr * np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n                    if fitness_i < self.best_fitness:\n                        self.best_fitness = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n                    if fitness_j < self.best_fitness:\n                        self.best_fitness = fitness_j\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.population[i] + self.lr * np.random.rand(self.dim) * (self.population[j] - self.population[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n                    if fitness < self.best_fitness:\n                        self.best_fitness = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.population[i])\n\n            # Randomly change some dimensions of the parasite\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n                    if fitness_parasite < self.best_fitness:\n                        self.best_fitness = fitness_parasite\n    \n    def adapt_parameters(self):\n        # Reduce population size if no improvement\n        if self.best_fitness == np.min(self.fitness):\n            self.pop_size = int(self.pop_size * self.pop_size_decay_rate)\n            self.pop_size = max(10, self.pop_size)  # Ensure minimum population size\n            self.population = self.population[:self.pop_size]\n            self.fitness = self.fitness[:self.pop_size]\n            \n        # Reduce learning rate over time\n        self.lr = self.initial_lr * (1 - self.eval_count / self.budget)\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        previous_best_fitness = np.inf\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n            self.adapt_parameters()\n\n            current_best_fitness = np.min(self.fitness)\n\n            if current_best_fitness < previous_best_fitness:\n                previous_best_fitness = current_best_fitness\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveSymbioticOrganismsSearch scored 0.326 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Symbiotic Organisms Search with dynamic population size and learning rates, enhancing exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.initial_lr = initial_lr  # Initial learning rate\n        self.lr = initial_lr  # Current learning rate\n        self.pop_size_decay_rate = 0.99 # Decay the population size by this fraction when there is no improvement.\n        self.best_fitness = np.inf\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n            else:\n                break  # Stop evaluation if budget is exhausted\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.population[i] + self.lr * np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + self.lr * np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n                    if fitness_i < self.best_fitness:\n                        self.best_fitness = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n                    if fitness_j < self.best_fitness:\n                        self.best_fitness = fitness_j\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.population[i] + self.lr * np.random.rand(self.dim) * (self.population[j] - self.population[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n                    if fitness < self.best_fitness:\n                        self.best_fitness = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.population[i])\n\n            # Randomly change some dimensions of the parasite\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n                    if fitness_parasite < self.best_fitness:\n                        self.best_fitness = fitness_parasite\n    \n    def adapt_parameters(self):\n        # Reduce population size if no improvement\n        if self.best_fitness == np.min(self.fitness):\n            self.pop_size = int(self.pop_size * self.pop_size_decay_rate)\n            self.pop_size = max(10, self.pop_size)  # Ensure minimum population size\n            self.population = self.population[:self.pop_size]\n            self.fitness = self.fitness[:self.pop_size]\n            \n        # Reduce learning rate over time\n        self.lr = self.initial_lr * (1 - self.eval_count / self.budget)\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        previous_best_fitness = np.inf\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n            self.adapt_parameters()\n\n            current_best_fitness = np.min(self.fitness)\n\n            if current_best_fitness < previous_best_fitness:\n                previous_best_fitness = current_best_fitness\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]\n```", "aucs": [0.13638088902578982, 0.21668374325027684, 0.32291660033376823, 0.32662703100832, 0.22549993773899457, 0.30481017574564173, 0.292043853885406, 0.26470504917698534, 0.22510054676792424, 0.17612660543133685, 0.26684962642850674, 0.997977996414263, 0.3080505777555955, 0.24684374797008657, 0.5858597097248686, 0.3370593347901233, 0.2873776820809736, 0.3209857762049151, 0.1931124584075139, 0.4940854297760058], "operator": "mutation", "theta_sampled": 0.5257827338383878, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "e55571da-b122-4e64-a8a0-3db9d80ce023", "fitness": 0.3939622813509486, "name": "AdaptiveSymbioticOrganismsSearch", "description": "An enhanced Symbiotic Organisms Search with adaptive parameters and a tournament selection-based population update to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutualism_rate = 0.7  # Probability of performing mutualism\n        self.commensalism_rate = 0.2  # Probability of performing commensalism\n        self.parasitism_rate = 0.1  # Probability of performing parasitism\n\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism_i)\n            self.tournament_selection(func, j, new_organism_j)\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism)\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            self.tournament_selection(func, j, parasite)\n\n    def tournament_selection(self, func, index, new_organism):\n        if self.eval_count >= self.budget:\n            return\n        \n        fitness_new = func(new_organism)\n        self.eval_count += 1\n\n        if fitness_new < self.fitness[index]:\n            self.population[index] = new_organism\n            self.fitness[index] = fitness_new\n\n    def update_rates(self):\n        # Dynamically adjust rates based on the success of each phase\n        # (This is a simplified example; more sophisticated methods are possible)\n        improvement_mutualism = 0\n        improvement_commensalism = 0\n        improvement_parasitism = 0\n\n        # This is a placeholder and would require tracking improvements in each phase\n        # based on the number of updates made in each phase over some iterations.\n        # For example:\n        # improvement_mutualism = number of successful updates in mutualism / total mutualism calls\n        # Then we can adjust probabilities proportionally to the improvement.\n\n        total_improvement = improvement_mutualism + improvement_commensalism + improvement_parasitism\n\n        if total_improvement > 0:\n            self.mutualism_rate = improvement_mutualism / total_improvement\n            self.commensalism_rate = improvement_commensalism / total_improvement\n            self.parasitism_rate = improvement_parasitism / total_improvement\n        else:\n            # If no improvement, maintain the initial rates.\n            pass\n\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            # Apply phases based on their probabilities\n            rand = np.random.rand()\n            if rand < self.mutualism_rate:\n                self.mutualism_phase(func)\n            elif rand < self.mutualism_rate + self.commensalism_rate:\n                self.commensalism_phase(func)\n            else:\n                self.parasitism_phase(func)\n\n            # self.update_rates()  # Commented out as it requires a way to track improvement per phase.\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveSymbioticOrganismsSearch scored 0.394 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "mutation", "metadata": {"llm_response": "# Description: An enhanced Symbiotic Organisms Search with adaptive parameters and a tournament selection-based population update to improve exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutualism_rate = 0.7  # Probability of performing mutualism\n        self.commensalism_rate = 0.2  # Probability of performing commensalism\n        self.parasitism_rate = 0.1  # Probability of performing parasitism\n\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism_i)\n            self.tournament_selection(func, j, new_organism_j)\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism)\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            self.tournament_selection(func, j, parasite)\n\n    def tournament_selection(self, func, index, new_organism):\n        if self.eval_count >= self.budget:\n            return\n        \n        fitness_new = func(new_organism)\n        self.eval_count += 1\n\n        if fitness_new < self.fitness[index]:\n            self.population[index] = new_organism\n            self.fitness[index] = fitness_new\n\n    def update_rates(self):\n        # Dynamically adjust rates based on the success of each phase\n        # (This is a simplified example; more sophisticated methods are possible)\n        improvement_mutualism = 0\n        improvement_commensalism = 0\n        improvement_parasitism = 0\n\n        # This is a placeholder and would require tracking improvements in each phase\n        # based on the number of updates made in each phase over some iterations.\n        # For example:\n        # improvement_mutualism = number of successful updates in mutualism / total mutualism calls\n        # Then we can adjust probabilities proportionally to the improvement.\n\n        total_improvement = improvement_mutualism + improvement_commensalism + improvement_parasitism\n\n        if total_improvement > 0:\n            self.mutualism_rate = improvement_mutualism / total_improvement\n            self.commensalism_rate = improvement_commensalism / total_improvement\n            self.parasitism_rate = improvement_parasitism / total_improvement\n        else:\n            # If no improvement, maintain the initial rates.\n            pass\n\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            # Apply phases based on their probabilities\n            rand = np.random.rand()\n            if rand < self.mutualism_rate:\n                self.mutualism_phase(func)\n            elif rand < self.mutualism_rate + self.commensalism_rate:\n                self.commensalism_phase(func)\n            else:\n                self.parasitism_phase(func)\n\n            # self.update_rates()  # Commented out as it requires a way to track improvement per phase.\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]\n```", "aucs": [0.13138018007597474, 0.24767832393403666, 0.3758972527136957, 0.724853530488946, 0.27526151245927444, 0.34400257869883033, 0.2860998350105498, 0.3214787797591785, 0.2972681592236647, 0.2031160974913634, 0.5177728098061001, 0.9969700163305072, 0.28031141209645916, 0.24052876457534356, 0.7284206000977969, 0.4216963473183649, 0.31623860941354065, 0.4822710521556889, 0.19962351685229118, 0.4883762485173647], "operator": "mutation", "theta_sampled": 0.19736384380820873, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "576c4791-d79a-4388-bb0f-06d496f51c30", "fitness": 0.3903486251835411, "name": "HybridSOSRDA", "description": "Synergistically combines Symbiotic Organisms Search with Rank Diversity Adaptation to balance exploration and exploitation, adaptively adjusting parameters based on population diversity and rank.", "code": "import numpy as np\n\nclass HybridSOSRDA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.diversity_weight = 0.5  # Weight for diversity-based parameter adaptation\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def rank_diversity_adaptation(self, func):\n        # Ranking-based selection and crossover\n        ranked_indices = np.argsort(self.fitness)\n        parents = self.population[ranked_indices[:self.pop_size // 2]]  # Select top half as parents\n\n        offspring = []\n        for i in range(self.pop_size):\n            p1_idx = np.random.randint(0, len(parents))\n            p2_idx = np.random.randint(0, len(parents))\n            p1 = parents[p1_idx]\n            p2 = parents[p2_idx]\n\n            # Adaptive Crossover: Blend based on rank\n            rank_p1 = np.where(ranked_indices == np.where(np.all(self.population == p1, axis=1))[0][0])[0][0]  # Get rank of p1\n            rank_p2 = np.where(ranked_indices == np.where(np.all(self.population == p2, axis=1))[0][0])[0][0]  # Get rank of p2\n\n            alpha = 0.5 + 0.5 * (rank_p1 - rank_p2) / self.pop_size  # Bias towards better parent. if same rank, alpha=0.5\n            child = alpha * p1 + (1 - alpha) * p2\n            child = np.clip(child, self.lb, self.ub)\n            offspring.append(child)\n\n        offspring = np.array(offspring)\n\n        # Adaptive Mutation based on diversity\n        diversity = np.std(self.population, axis=0).mean()\n        mutation_rate = 0.05 + 0.2 * (1 - diversity)  # Higher mutation when population is less diverse\n        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n        mutation = np.random.normal(0, 1, size=offspring.shape)\n        offspring = offspring + mutation_mask * mutation\n\n        offspring = np.clip(offspring, self.lb, self.ub)\n\n        # Evaluation\n        offspring_fitness = np.array([func(x) for x in offspring])\n        self.eval_count += self.pop_size\n        if self.eval_count > self.budget:\n            offspring_fitness = offspring_fitness[:(self.budget - (self.eval_count - self.pop_size))]\n\n        # Update population: elitism and replacement\n        combined_population = np.vstack((self.population, offspring))\n        combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n        sorted_indices = np.argsort(combined_fitness)\n        self.population = combined_population[sorted_indices[:self.pop_size]]\n        self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        best_index = np.argmin(self.fitness)\n        f_opt = self.fitness[best_index]\n        x_opt = self.population[best_index]\n\n\n        while self.eval_count < self.budget:\n            # Dynamically adjust the balance between SOS and RDA based on population diversity\n            diversity = np.std(self.population, axis=0).mean()\n            sos_prob = 0.5 + self.diversity_weight * (1 - diversity)  # Favor SOS when diversity is low\n\n            if np.random.rand() < sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                self.rank_diversity_adaptation(func)\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < f_opt:\n                f_opt = self.fitness[best_index]\n                x_opt = self.population[best_index]\n\n        return f_opt, x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridSOSRDA scored 0.390 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c600221-bb6a-43a2-999f-922a7cb86197", "877eaf14-c664-4520-8b9b-e52439ced948"], "operator": "crossover", "metadata": {"llm_response": "# Description: Synergistically combines Symbiotic Organisms Search with Rank Diversity Adaptation to balance exploration and exploitation, adaptively adjusting parameters based on population diversity and rank.\n# Code: \n```python\nimport numpy as np\n\nclass HybridSOSRDA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.diversity_weight = 0.5  # Weight for diversity-based parameter adaptation\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def rank_diversity_adaptation(self, func):\n        # Ranking-based selection and crossover\n        ranked_indices = np.argsort(self.fitness)\n        parents = self.population[ranked_indices[:self.pop_size // 2]]  # Select top half as parents\n\n        offspring = []\n        for i in range(self.pop_size):\n            p1_idx = np.random.randint(0, len(parents))\n            p2_idx = np.random.randint(0, len(parents))\n            p1 = parents[p1_idx]\n            p2 = parents[p2_idx]\n\n            # Adaptive Crossover: Blend based on rank\n            rank_p1 = np.where(ranked_indices == np.where(np.all(self.population == p1, axis=1))[0][0])[0][0]  # Get rank of p1\n            rank_p2 = np.where(ranked_indices == np.where(np.all(self.population == p2, axis=1))[0][0])[0][0]  # Get rank of p2\n\n            alpha = 0.5 + 0.5 * (rank_p1 - rank_p2) / self.pop_size  # Bias towards better parent. if same rank, alpha=0.5\n            child = alpha * p1 + (1 - alpha) * p2\n            child = np.clip(child, self.lb, self.ub)\n            offspring.append(child)\n\n        offspring = np.array(offspring)\n\n        # Adaptive Mutation based on diversity\n        diversity = np.std(self.population, axis=0).mean()\n        mutation_rate = 0.05 + 0.2 * (1 - diversity)  # Higher mutation when population is less diverse\n        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n        mutation = np.random.normal(0, 1, size=offspring.shape)\n        offspring = offspring + mutation_mask * mutation\n\n        offspring = np.clip(offspring, self.lb, self.ub)\n\n        # Evaluation\n        offspring_fitness = np.array([func(x) for x in offspring])\n        self.eval_count += self.pop_size\n        if self.eval_count > self.budget:\n            offspring_fitness = offspring_fitness[:(self.budget - (self.eval_count - self.pop_size))]\n\n        # Update population: elitism and replacement\n        combined_population = np.vstack((self.population, offspring))\n        combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n        sorted_indices = np.argsort(combined_fitness)\n        self.population = combined_population[sorted_indices[:self.pop_size]]\n        self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        best_index = np.argmin(self.fitness)\n        f_opt = self.fitness[best_index]\n        x_opt = self.population[best_index]\n\n\n        while self.eval_count < self.budget:\n            # Dynamically adjust the balance between SOS and RDA based on population diversity\n            diversity = np.std(self.population, axis=0).mean()\n            sos_prob = 0.5 + self.diversity_weight * (1 - diversity)  # Favor SOS when diversity is low\n\n            if np.random.rand() < sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                self.rank_diversity_adaptation(func)\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < f_opt:\n                f_opt = self.fitness[best_index]\n                x_opt = self.population[best_index]\n\n        return f_opt, x_opt\n```", "aucs": [0.13230499007678576, 0.23226227585357273, 0.3899466157021766, 0.4005708629103597, 0.26145395375041636, 0.3823389105424938, 0.37280651974852497, 0.3387511163905842, 0.31654188135467665, 0.23930018093091066, 0.2670408248523334, 0.9995909303191479, 0.27891378483169793, 0.4045576824785547, 0.7520280822676375, 0.3953823955006738, 0.4159770258918095, 0.4758487318898331, 0.2556811213290533, 0.4956746170495787], "operator": "crossover", "theta_sampled": 0.36369836635236086, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "2d6aed13-eb4b-4032-a2fa-5d851ca7a950", "fitness": 0.3836329722038723, "name": "HybridSOSRDA", "description": "Combines Symbiotic Organisms Search phases with Rank Diversity Adaptation's adaptive crossover and mutation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSOSRDA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_solution = None\n\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_solution = self.population[i]\n\n            else:\n                break\n\n    def adaptive_crossover(self, parents, ranked_indices, population):\n        offspring = []\n        for i in range(self.pop_size):\n            p1_idx = np.random.randint(0, len(parents))\n            p2_idx = np.random.randint(0, len(parents))\n            p1 = parents[p1_idx]\n            p2 = parents[p2_idx]\n\n            # Adaptive Crossover: Blend based on rank\n            rank_p1 = np.where(ranked_indices == np.where(np.all(population == p1, axis=1))[0][0])[0][0]  # Get rank of p1\n            rank_p2 = np.where(ranked_indices == np.where(np.all(population == p2, axis=1))[0][0])[0][0]  # Get rank of p2\n            \n            alpha = 0.5 + 0.5*(rank_p1 - rank_p2)/self.pop_size # Bias towards better parent. if same rank, alpha=0.5\n            child = alpha * p1 + (1 - alpha) * p2\n            child = np.clip(child, self.lb, self.ub)\n            offspring.append(child)\n\n        return np.array(offspring)\n        \n    def adaptive_mutation(self, population):\n        diversity = np.std(population, axis=0).mean() \n        mutation_rate = 0.05 + 0.2 * (1 - diversity) # Higher mutation when population is less diverse\n        mutation_mask = np.random.rand(*population.shape) < mutation_rate\n        mutation = np.random.normal(0, 1, size=population.shape)\n        mutated_population = population + mutation_mask * mutation\n        mutated_population = np.clip(mutated_population, self.lb, self.ub)\n        return mutated_population\n\n    def symbiotic_phases(self, func):\n        # Ranking-based selection for parents\n        ranked_indices = np.argsort(self.fitness)\n        parents = self.population[ranked_indices[:self.pop_size // 2]]\n\n        # Adaptive Crossover to generate offspring\n        offspring = self.adaptive_crossover(parents, ranked_indices, self.population)\n        offspring = self.adaptive_mutation(offspring)\n        \n        # Evaluate the offspring\n        offspring_fitness = np.full(self.pop_size, np.inf)\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                offspring_fitness[i] = func(offspring[i])\n                self.eval_count += 1\n                if offspring_fitness[i] < self.best_fitness:\n                    self.best_fitness = offspring_fitness[i]\n                    self.best_solution = offspring[i]\n            else:\n                break\n\n        # Elitism-based replacement strategy\n        combined_population = np.vstack((self.population, offspring))\n        combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        self.population = combined_population[sorted_indices[:self.pop_size]]\n        self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n        #Update the best solution\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[best_index]\n            self.best_solution = self.population[best_index]\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.symbiotic_phases(func)\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 2, "feedback": "The algorithm HybridSOSRDA scored 0.384 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c600221-bb6a-43a2-999f-922a7cb86197", "877eaf14-c664-4520-8b9b-e52439ced948"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Symbiotic Organisms Search phases with Rank Diversity Adaptation's adaptive crossover and mutation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridSOSRDA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_solution = None\n\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_solution = self.population[i]\n\n            else:\n                break\n\n    def adaptive_crossover(self, parents, ranked_indices, population):\n        offspring = []\n        for i in range(self.pop_size):\n            p1_idx = np.random.randint(0, len(parents))\n            p2_idx = np.random.randint(0, len(parents))\n            p1 = parents[p1_idx]\n            p2 = parents[p2_idx]\n\n            # Adaptive Crossover: Blend based on rank\n            rank_p1 = np.where(ranked_indices == np.where(np.all(population == p1, axis=1))[0][0])[0][0]  # Get rank of p1\n            rank_p2 = np.where(ranked_indices == np.where(np.all(population == p2, axis=1))[0][0])[0][0]  # Get rank of p2\n            \n            alpha = 0.5 + 0.5*(rank_p1 - rank_p2)/self.pop_size # Bias towards better parent. if same rank, alpha=0.5\n            child = alpha * p1 + (1 - alpha) * p2\n            child = np.clip(child, self.lb, self.ub)\n            offspring.append(child)\n\n        return np.array(offspring)\n        \n    def adaptive_mutation(self, population):\n        diversity = np.std(population, axis=0).mean() \n        mutation_rate = 0.05 + 0.2 * (1 - diversity) # Higher mutation when population is less diverse\n        mutation_mask = np.random.rand(*population.shape) < mutation_rate\n        mutation = np.random.normal(0, 1, size=population.shape)\n        mutated_population = population + mutation_mask * mutation\n        mutated_population = np.clip(mutated_population, self.lb, self.ub)\n        return mutated_population\n\n    def symbiotic_phases(self, func):\n        # Ranking-based selection for parents\n        ranked_indices = np.argsort(self.fitness)\n        parents = self.population[ranked_indices[:self.pop_size // 2]]\n\n        # Adaptive Crossover to generate offspring\n        offspring = self.adaptive_crossover(parents, ranked_indices, self.population)\n        offspring = self.adaptive_mutation(offspring)\n        \n        # Evaluate the offspring\n        offspring_fitness = np.full(self.pop_size, np.inf)\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                offspring_fitness[i] = func(offspring[i])\n                self.eval_count += 1\n                if offspring_fitness[i] < self.best_fitness:\n                    self.best_fitness = offspring_fitness[i]\n                    self.best_solution = offspring[i]\n            else:\n                break\n\n        # Elitism-based replacement strategy\n        combined_population = np.vstack((self.population, offspring))\n        combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        self.population = combined_population[sorted_indices[:self.pop_size]]\n        self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n        #Update the best solution\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[best_index]\n            self.best_solution = self.population[best_index]\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.symbiotic_phases(func)\n\n        return self.best_fitness, self.best_solution\n```", "aucs": [0.16859570135947521, 0.3072114750351961, 0.37769590954116394, 0.18272676350307637, 0.2722320334210462, 0.4701832871188585, 0.34830862109162564, 0.3119908766436721, 0.29845300960016874, 0.17817018604383617, 0.33261994388209126, 0.9882640387581776, 0.2628051127480481, 0.3894631263791791, 0.7203128906814208, 0.4496331063810265, 0.31653946921096077, 0.5712890958312007, 0.23262331677115478, 0.493541480076067], "operator": "crossover", "theta_sampled": 0.3720117695646907, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "c9c302f5-d397-45d0-8f71-22c15516f00e", "fitness": 0.0, "name": "AntColonyOptimization", "description": "A population-based algorithm mimicking the foraging behavior of ants, incorporating pheromone-based search and adaptive step sizes.", "code": "import numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, n_ants=50, evaporation_rate=0.1, alpha=1.0, beta=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_ants = n_ants\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha  # Influence of pheromone\n        self.beta = beta  # Influence of heuristic information\n        self.pheromone = np.ones((dim,))  # Initial pheromone levels\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        solutions = np.zeros((self.n_ants, self.dim))\n        fitness = np.zeros(self.n_ants)\n        eval_count = 0\n\n        for i in range(self.n_ants):\n            solutions[i] = np.random.uniform(lb, ub, self.dim)\n            fitness[i] = func(solutions[i])\n            eval_count += 1\n\n            if fitness[i] < self.best_fitness:\n                self.best_fitness = fitness[i]\n                self.best_solution = solutions[i].copy()\n\n\n        while eval_count < self.budget:\n            for i in range(self.n_ants):\n                # Pheromone-based search with adaptive step size\n                probabilities = self.pheromone**self.alpha / np.sum(self.pheromone**self.alpha) # Normalize pheromone\n                \n                # Heuristic information (fitness-based attraction)\n                heuristic_info = np.zeros(self.dim)\n                for d in range(self.dim):\n                    heuristic_info[d] = np.mean([np.exp(-np.abs(solutions[i, d] - solutions[j, d]) / (abs(self.best_solution[d] - solutions[i, d]) + 1e-8) ) if i!=j else 0 for j in range(self.n_ants)])  # Attractiveness based on distance to other ants; avoid div by zero\n                \n                # Combine pheromone and heuristic information\n                combined_influence = (probabilities**self.alpha) * (heuristic_info**self.beta)\n                combined_influence /= np.sum(combined_influence) # Normalize\n\n                # Select new location based on weighted average, add small random exploration\n                step_size = np.random.uniform(0.01, 0.1) * (ub - lb) # Adaptively adjust step size based on search space\n                new_solution = solutions[i].copy()\n                for d in range(self.dim):\n                    new_solution[d] += step_size * combined_influence[d] * np.random.normal()\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                eval_count += 1\n\n                if new_fitness < fitness[i]:\n                    solutions[i] = new_solution.copy()\n                    fitness[i] = new_fitness\n\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_solution = new_solution.copy()\n                \n                if eval_count >= self.budget:\n                    break\n\n            # Update pheromone (evaporation and reinforcement)\n            self.pheromone *= (1 - self.evaporation_rate)\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.n_ants):\n                delta_pheromone += (self.best_fitness / fitness[i]) * (solutions[i] - self.best_solution) # Reinforce based on fitness relative to best\n            self.pheromone += delta_pheromone\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm mimicking the foraging behavior of ants, incorporating pheromone-based search and adaptive step sizes.\n# Code: \n```python\nimport numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, n_ants=50, evaporation_rate=0.1, alpha=1.0, beta=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_ants = n_ants\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha  # Influence of pheromone\n        self.beta = beta  # Influence of heuristic information\n        self.pheromone = np.ones((dim,))  # Initial pheromone levels\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        solutions = np.zeros((self.n_ants, self.dim))\n        fitness = np.zeros(self.n_ants)\n        eval_count = 0\n\n        for i in range(self.n_ants):\n            solutions[i] = np.random.uniform(lb, ub, self.dim)\n            fitness[i] = func(solutions[i])\n            eval_count += 1\n\n            if fitness[i] < self.best_fitness:\n                self.best_fitness = fitness[i]\n                self.best_solution = solutions[i].copy()\n\n\n        while eval_count < self.budget:\n            for i in range(self.n_ants):\n                # Pheromone-based search with adaptive step size\n                probabilities = self.pheromone**self.alpha / np.sum(self.pheromone**self.alpha) # Normalize pheromone\n                \n                # Heuristic information (fitness-based attraction)\n                heuristic_info = np.zeros(self.dim)\n                for d in range(self.dim):\n                    heuristic_info[d] = np.mean([np.exp(-np.abs(solutions[i, d] - solutions[j, d]) / (abs(self.best_solution[d] - solutions[i, d]) + 1e-8) ) if i!=j else 0 for j in range(self.n_ants)])  # Attractiveness based on distance to other ants; avoid div by zero\n                \n                # Combine pheromone and heuristic information\n                combined_influence = (probabilities**self.alpha) * (heuristic_info**self.beta)\n                combined_influence /= np.sum(combined_influence) # Normalize\n\n                # Select new location based on weighted average, add small random exploration\n                step_size = np.random.uniform(0.01, 0.1) * (ub - lb) # Adaptively adjust step size based on search space\n                new_solution = solutions[i].copy()\n                for d in range(self.dim):\n                    new_solution[d] += step_size * combined_influence[d] * np.random.normal()\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                eval_count += 1\n\n                if new_fitness < fitness[i]:\n                    solutions[i] = new_solution.copy()\n                    fitness[i] = new_fitness\n\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_solution = new_solution.copy()\n                \n                if eval_count >= self.budget:\n                    break\n\n            # Update pheromone (evaporation and reinforcement)\n            self.pheromone *= (1 - self.evaporation_rate)\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.n_ants):\n                delta_pheromone += (self.best_fitness / fitness[i]) * (solutions[i] - self.best_solution) # Reinforce based on fitness relative to best\n            self.pheromone += delta_pheromone\n\n        return self.best_fitness, self.best_solution\n```", "operator": "random_new", "theta_sampled": 0.17624438003104578, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "f3af4ebd-6ba6-4792-990c-8bd076dff530", "fitness": 0.41081450129101915, "name": "AdaptiveSlimeMoldOptimization", "description": "Adaptive Slime Mold Optimization with dynamic parameter adjustment and improved exploration-exploitation balance using Levy flights and a probabilistic selection of movement strategies.", "code": "import numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c_init=0.3, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c_init = c_init  # Initial confidence factor\n        self.c = c_init  # Dynamic confidence factor\n        self.levy_exponent = levy_exponent\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.current_evaluations = 0\n        self.adaptive_weights = np.ones(population_size) / population_size\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :]\n\n    def update_best(self):\n        current_best_index = np.argmin(self.fitness)\n        if self.fitness[current_best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[current_best_index]\n            self.best_position = self.positions[current_best_index, :].copy()\n\n    def levy_flight(self, size):\n        num = np.random.normal(0, 1, size)\n        den = np.power(np.abs(np.random.normal(0, 1, size)), (1 / self.levy_exponent))\n        return num / den\n\n    def update_adaptive_weights(self):\n        # Calculate normalized fitness values\n        fitness_normalized = np.max(self.fitness) - self.fitness + 1e-9  # Avoid division by zero\n        fitness_normalized = fitness_normalized / np.sum(fitness_normalized)\n        self.adaptive_weights = fitness_normalized\n\n    def update_positions(self, func):\n        self.update_adaptive_weights()\n\n        q = np.random.rand(self.population_size, self.dim) # probability\n        \n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break\n\n            # Strategy Selection (Probability-based)\n            if q[i,0] < 0.33: # Move towards best\n                 influence = self.c * (self.best_position - self.positions[i, :])\n                 new_position = self.positions[i, :] + influence + 0.01 * self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb)\n            elif q[i,0] < 0.66: # Explore neighborhood\n                neighbor_index = np.random.choice(self.population_size, 1)[0]\n                new_position = self.positions[i, :] + self.c * (self.positions[neighbor_index, :] - self.positions[i, :]) +  0.01 * self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb)\n\n            else: # Levy flight exploration\n                new_position = self.positions[i, :] + 0.1 * self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb) # Larger step levy flight\n\n            # Clip positions to bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            new_position = np.clip(new_position, lb, ub)\n            \n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n\n            if new_fitness < self.fitness[i]:\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n\n        self.update_best()\n        # Dynamic Confidence Adjustment\n        self.c = self.c_init * (1 - self.current_evaluations / self.budget)  # Linear decay\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveSlimeMoldOptimization scored 0.411 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8685e41a-9867-4d91-aec0-41ad8c9620e4"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Slime Mold Optimization with dynamic parameter adjustment and improved exploration-exploitation balance using Levy flights and a probabilistic selection of movement strategies.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c_init=0.3, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c_init = c_init  # Initial confidence factor\n        self.c = c_init  # Dynamic confidence factor\n        self.levy_exponent = levy_exponent\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.current_evaluations = 0\n        self.adaptive_weights = np.ones(population_size) / population_size\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :]\n\n    def update_best(self):\n        current_best_index = np.argmin(self.fitness)\n        if self.fitness[current_best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[current_best_index]\n            self.best_position = self.positions[current_best_index, :].copy()\n\n    def levy_flight(self, size):\n        num = np.random.normal(0, 1, size)\n        den = np.power(np.abs(np.random.normal(0, 1, size)), (1 / self.levy_exponent))\n        return num / den\n\n    def update_adaptive_weights(self):\n        # Calculate normalized fitness values\n        fitness_normalized = np.max(self.fitness) - self.fitness + 1e-9  # Avoid division by zero\n        fitness_normalized = fitness_normalized / np.sum(fitness_normalized)\n        self.adaptive_weights = fitness_normalized\n\n    def update_positions(self, func):\n        self.update_adaptive_weights()\n\n        q = np.random.rand(self.population_size, self.dim) # probability\n        \n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break\n\n            # Strategy Selection (Probability-based)\n            if q[i,0] < 0.33: # Move towards best\n                 influence = self.c * (self.best_position - self.positions[i, :])\n                 new_position = self.positions[i, :] + influence + 0.01 * self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb)\n            elif q[i,0] < 0.66: # Explore neighborhood\n                neighbor_index = np.random.choice(self.population_size, 1)[0]\n                new_position = self.positions[i, :] + self.c * (self.positions[neighbor_index, :] - self.positions[i, :]) +  0.01 * self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb)\n\n            else: # Levy flight exploration\n                new_position = self.positions[i, :] + 0.1 * self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb) # Larger step levy flight\n\n            # Clip positions to bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            new_position = np.clip(new_position, lb, ub)\n            \n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n\n            if new_fitness < self.fitness[i]:\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n\n        self.update_best()\n        # Dynamic Confidence Adjustment\n        self.c = self.c_init * (1 - self.current_evaluations / self.budget)  # Linear decay\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position\n```", "aucs": [0.1391690964911222, 0.24060275194832226, 0.40868273513961584, 0.5264994855391801, 0.35233657797027806, 0.4348032043708966, 0.29097426504733737, 0.36988359476329635, 0.33995608534140165, 0.19580240938362536, 0.6360001131867827, 0.9971334897718768, 0.2823402398127711, 0.36728518954126543, 0.719102551434416, 0.3361284630488103, 0.3394662731482754, 0.5226079481126051, 0.2161731116918031, 0.5013424400767009], "operator": "mutation", "theta_sampled": 0.10346139945908067, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "170fb7ad-a97c-47cb-a7e0-b059f50e2b71", "fitness": 0.0, "name": "AdaptiveSymbioticOrganismsSearch", "description": "Modified SOS with adaptive parameter control and local search using Nelder-Mead.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutualism_factor=0.5, commensalism_factor=0.3, parasitism_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutualism_factor = mutualism_factor\n        self.commensalism_factor = commensalism_factor\n        self.parasitism_factor = parasitism_factor\n        self.adaptation_rate = 0.1  # Rate for adapting parameters\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * self.mutualism_factor * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * self.mutualism_factor * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * self.commensalism_factor * (self.population[j] - self.population[i])\n\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def local_search(self, func, organism):\n        if self.eval_count >= self.budget:\n            return organism, func(organism)\n\n        bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n        res = minimize(func, organism, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(50, self.budget - self.eval_count)})\n\n        if res.success:\n            organism = res.x\n            fitness = res.fun\n            self.eval_count += res.nfev\n            return organism, fitness\n        else:\n            return organism, func(organism)\n\n    def adapt_parameters(self):\n        # Example adaptation: Adjust factors based on fitness improvement\n        fitness_change = np.mean(self.fitness) - np.min(self.fitness)\n        if fitness_change > 0:  # If there's improvement, reduce exploration\n            self.mutualism_factor *= (1 - self.adaptation_rate)\n            self.commensalism_factor *= (1 - self.adaptation_rate)\n            self.parasitism_factor += self.adaptation_rate\n        else:  # If stagnation, increase exploration\n            self.mutualism_factor += self.adaptation_rate\n            self.commensalism_factor += self.adaptation_rate\n            self.parasitism_factor *= (1 - self.adaptation_rate)\n\n        self.mutualism_factor = np.clip(self.mutualism_factor, 0.1, 0.9)\n        self.commensalism_factor = np.clip(self.commensalism_factor, 0.1, 0.9)\n        self.parasitism_factor = np.clip(self.parasitism_factor, 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Local search for the best organism\n            best_index = np.argmin(self.fitness)\n            self.population[best_index], self.fitness[best_index] = self.local_search(func, self.population[best_index])\n\n            self.adapt_parameters()  # Adapt the parameters\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "mutation", "metadata": {"llm_response": "# Description: Modified SOS with adaptive parameter control and local search using Nelder-Mead.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutualism_factor=0.5, commensalism_factor=0.3, parasitism_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutualism_factor = mutualism_factor\n        self.commensalism_factor = commensalism_factor\n        self.parasitism_factor = parasitism_factor\n        self.adaptation_rate = 0.1  # Rate for adapting parameters\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * self.mutualism_factor * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * self.mutualism_factor * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * self.commensalism_factor * (self.population[j] - self.population[i])\n\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def local_search(self, func, organism):\n        if self.eval_count >= self.budget:\n            return organism, func(organism)\n\n        bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n        res = minimize(func, organism, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(50, self.budget - self.eval_count)})\n\n        if res.success:\n            organism = res.x\n            fitness = res.fun\n            self.eval_count += res.nfev\n            return organism, fitness\n        else:\n            return organism, func(organism)\n\n    def adapt_parameters(self):\n        # Example adaptation: Adjust factors based on fitness improvement\n        fitness_change = np.mean(self.fitness) - np.min(self.fitness)\n        if fitness_change > 0:  # If there's improvement, reduce exploration\n            self.mutualism_factor *= (1 - self.adaptation_rate)\n            self.commensalism_factor *= (1 - self.adaptation_rate)\n            self.parasitism_factor += self.adaptation_rate\n        else:  # If stagnation, increase exploration\n            self.mutualism_factor += self.adaptation_rate\n            self.commensalism_factor += self.adaptation_rate\n            self.parasitism_factor *= (1 - self.adaptation_rate)\n\n        self.mutualism_factor = np.clip(self.mutualism_factor, 0.1, 0.9)\n        self.commensalism_factor = np.clip(self.commensalism_factor, 0.1, 0.9)\n        self.parasitism_factor = np.clip(self.parasitism_factor, 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Local search for the best organism\n            best_index = np.argmin(self.fitness)\n            self.population[best_index], self.fitness[best_index] = self.local_search(func, self.population[best_index])\n\n            self.adapt_parameters()  # Adapt the parameters\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]\n```", "operator": "mutation", "theta_sampled": 0.057444023999837446, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "64991e5c-a35d-4ae9-b03d-68e95e0a349c", "fitness": 0.0, "name": "AdaptiveSymbioticOrganismsSearchV2", "description": "A self-adaptive symbiotic organisms search algorithm with dynamic population size adjustment and enhanced exploitation.", "code": "import numpy as np\n\nclass AdaptiveSymbioticOrganismsSearchV2:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=50, pop_size_min=10, pop_size_max=100, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_initial\n        self.pop_size_initial = pop_size_initial\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.adaptation_rate = adaptation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness_history = []\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def adjust_population_size(self):\n        if len(self.best_fitness_history) > 10:\n            improvement = self.best_fitness_history[-10] - self.best_fitness_history[-1]\n            if improvement > 0:  # Stagnation\n                self.pop_size = min(self.pop_size + int(self.adaptation_rate * self.pop_size_initial), self.pop_size_max)\n            else:\n                self.pop_size = max(self.pop_size - int(self.adaptation_rate * self.pop_size_initial), self.pop_size_min)\n            self.pop_size = int(self.pop_size)\n            # Resize population if necessary. Simplest way to do is is re-initilize population\n            if self.pop_size != self.population.shape[0]:\n                self.initialize_population()\n                self.evaluate_population(func) #re-evaluate to have up to date fitness.\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.normal(0, 1, self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.normal(0, 1, self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.normal(0, 0.5, self.dim) * (self.population[j] - self.population[i])\n\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n        best_index = np.argmin(self.fitness)\n        best_fitness = self.fitness[best_index]\n        self.best_fitness_history.append(best_fitness)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            best_index = np.argmin(self.fitness)\n            current_best_fitness = self.fitness[best_index]\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.adjust_population_size()\n\n\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": ["3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "mutation", "metadata": {"llm_response": "# Description: A self-adaptive symbiotic organisms search algorithm with dynamic population size adjustment and enhanced exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveSymbioticOrganismsSearchV2:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=50, pop_size_min=10, pop_size_max=100, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_initial\n        self.pop_size_initial = pop_size_initial\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.adaptation_rate = adaptation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness_history = []\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def adjust_population_size(self):\n        if len(self.best_fitness_history) > 10:\n            improvement = self.best_fitness_history[-10] - self.best_fitness_history[-1]\n            if improvement > 0:  # Stagnation\n                self.pop_size = min(self.pop_size + int(self.adaptation_rate * self.pop_size_initial), self.pop_size_max)\n            else:\n                self.pop_size = max(self.pop_size - int(self.adaptation_rate * self.pop_size_initial), self.pop_size_min)\n            self.pop_size = int(self.pop_size)\n            # Resize population if necessary. Simplest way to do is is re-initilize population\n            if self.pop_size != self.population.shape[0]:\n                self.initialize_population()\n                self.evaluate_population(func) #re-evaluate to have up to date fitness.\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.normal(0, 1, self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.normal(0, 1, self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.normal(0, 0.5, self.dim) * (self.population[j] - self.population[i])\n\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n        best_index = np.argmin(self.fitness)\n        best_fitness = self.fitness[best_index]\n        self.best_fitness_history.append(best_fitness)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            best_index = np.argmin(self.fitness)\n            current_best_fitness = self.fitness[best_index]\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.adjust_population_size()\n\n\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]\n```", "operator": "mutation", "theta_sampled": 0.18886262044344848, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "cfd47c47-3331-48cb-98e9-5f785eafa119", "fitness": 0.0, "name": "GradientInformedSearch", "description": "Gradient-informed random search, utilizing a population and gradient estimation to guide exploration.", "code": "import numpy as np\n\nclass GradientInformedSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while eval_count < self.budget:\n            # Estimate gradient using finite differences (central difference)\n            gradient_estimate = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Small perturbation\n                delta = np.zeros(self.dim)\n                delta[i] = 1e-5  # A small step size\n\n                # Ensure the perturbed solutions are within bounds\n                x_plus = np.clip(self.x_opt + delta, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(self.x_opt - delta, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate perturbed solutions (check budget)\n                if eval_count + 2 <= self.budget: #Evaluate both new points only if budget allows it\n                    f_plus = func(x_plus)\n                    f_minus = func(x_minus)\n                    eval_count += 2\n\n                    gradient_estimate[i] = (f_plus - f_minus) / (2 * 1e-5)\n                else:\n                    break\n            \n            # Normalize the gradient\n            norm = np.linalg.norm(gradient_estimate)\n            if norm > 0:\n                gradient_estimate = gradient_estimate / norm\n\n            # Generate new candidate solutions around the current best, informed by the gradient.\n            new_x = np.random.normal(self.x_opt - self.learning_rate * gradient_estimate, scale=0.1, size=(self.pop_size, self.dim)) # Sample around gradient-informed point with std 0.1\n\n            # Clip new solutions to stay within bounds\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in new_x])\n            eval_count += self.pop_size\n\n            # Update the population (replace worst individuals if new ones are better)\n            for i in range(self.pop_size):\n                worst_idx = np.argmax(fitness)\n                if new_fitness[i] < fitness[worst_idx]:\n                    fitness[worst_idx] = new_fitness[i]\n                    population[worst_idx] = new_x[i]\n\n            # Update the best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm GradientInformedSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Gradient-informed random search, utilizing a population and gradient estimation to guide exploration.\n# Code: \n```python\nimport numpy as np\n\nclass GradientInformedSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while eval_count < self.budget:\n            # Estimate gradient using finite differences (central difference)\n            gradient_estimate = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Small perturbation\n                delta = np.zeros(self.dim)\n                delta[i] = 1e-5  # A small step size\n\n                # Ensure the perturbed solutions are within bounds\n                x_plus = np.clip(self.x_opt + delta, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(self.x_opt - delta, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate perturbed solutions (check budget)\n                if eval_count + 2 <= self.budget: #Evaluate both new points only if budget allows it\n                    f_plus = func(x_plus)\n                    f_minus = func(x_minus)\n                    eval_count += 2\n\n                    gradient_estimate[i] = (f_plus - f_minus) / (2 * 1e-5)\n                else:\n                    break\n            \n            # Normalize the gradient\n            norm = np.linalg.norm(gradient_estimate)\n            if norm > 0:\n                gradient_estimate = gradient_estimate / norm\n\n            # Generate new candidate solutions around the current best, informed by the gradient.\n            new_x = np.random.normal(self.x_opt - self.learning_rate * gradient_estimate, scale=0.1, size=(self.pop_size, self.dim)) # Sample around gradient-informed point with std 0.1\n\n            # Clip new solutions to stay within bounds\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in new_x])\n            eval_count += self.pop_size\n\n            # Update the population (replace worst individuals if new ones are better)\n            for i in range(self.pop_size):\n                worst_idx = np.argmax(fitness)\n                if new_fitness[i] < fitness[worst_idx]:\n                    fitness[worst_idx] = new_fitness[i]\n                    population[worst_idx] = new_x[i]\n\n            # Update the best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": -0.01950320007915876, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "62875f65-ea04-4ada-b298-d2d287c83646", "fitness": 0.0, "name": "AdaptiveSymbioticOrganismsSearch", "description": "Adaptive Symbiotic Organisms Search with a dynamic population size and a diversity-enhancing mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutualism_rate = 0.7\n        self.commensalism_rate = 0.2\n        self.parasitism_rate = 0.1\n        self.pop_size = initial_pop_size\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism_i)\n            self.tournament_selection(func, j, new_organism_j)\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism)\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Diversity-enhancing mutation\n            if np.random.rand() < 0.1:  # Small chance of mutation\n                mutation_indices = np.random.choice(self.dim, num_changes, replace=False)\n                parasite[mutation_indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            self.tournament_selection(func, j, parasite)\n\n    def tournament_selection(self, func, index, new_organism):\n        if self.eval_count >= self.budget:\n            return\n        \n        fitness_new = func(new_organism)\n        self.eval_count += 1\n\n        if fitness_new < self.fitness[index]:\n            self.population[index] = new_organism\n            self.fitness[index] = fitness_new\n\n    def update_rates(self):\n        # Dynamically adjust rates based on the success of each phase\n        # (This is a simplified example; more sophisticated methods are possible)\n        improvement_mutualism = 0\n        improvement_commensalism = 0\n        improvement_parasitism = 0\n\n        # This is a placeholder and would require tracking improvements in each phase\n        # based on the number of updates made in each phase over some iterations.\n        # For example:\n        # improvement_mutualism = number of successful updates in mutualism / total mutualism calls\n        # Then we can adjust probabilities proportionally to the improvement.\n\n        total_improvement = improvement_mutualism + improvement_commensalism + improvement_parasitism\n\n        if total_improvement > 0:\n            self.mutualism_rate = improvement_mutualism / total_improvement\n            self.commensalism_rate = improvement_commensalism / total_improvement\n            self.parasitism_rate = improvement_parasitism / total_improvement\n        else:\n            # If no improvement, maintain the initial rates.\n            pass\n\n    def adjust_population_size(self):\n        # Simple strategy: If the population hasn't improved much in the last few iterations,\n        # increase the size to explore more. If it's improving rapidly, decrease to exploit.\n\n        # Calculate the standard deviation of the fitness values.  A lower std dev means\n        # population is converging.\n        fitness_std = np.std(self.fitness)\n\n        if fitness_std < 0.01 and self.pop_size < self.max_pop_size:  # Reduced threshold\n            self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n            # Add new random organisms\n            new_organisms = np.random.uniform(self.lb, self.ub, (5, self.dim))\n            new_fitness = np.full(5, np.inf)\n            for i in range(5):\n                if self.eval_count < self.budget:\n                    new_fitness[i] = func(new_organisms[i])\n                    self.eval_count += 1\n                else:\n                    break\n\n            self.population = np.concatenate((self.population, new_organisms[:i+1]), axis=0)\n            self.fitness = np.concatenate((self.fitness, new_fitness[:i+1]), axis=0)\n\n\n        elif fitness_std > 1 and self.pop_size > self.min_pop_size: # Increased threshold\n            # Kill off the worst organisms\n            num_to_kill = min(5, self.pop_size - self.min_pop_size)\n            worst_indices = np.argsort(self.fitness)[-num_to_kill:]\n            keep_indices = np.setdiff1d(np.arange(self.pop_size), worst_indices)\n            self.population = self.population[keep_indices]\n            self.fitness = self.fitness[keep_indices]\n            self.pop_size = self.population.shape[0]\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            # Apply phases based on their probabilities\n            rand = np.random.rand()\n            if rand < self.mutualism_rate:\n                self.mutualism_phase(func)\n            elif rand < self.mutualism_rate + self.commensalism_rate:\n                self.commensalism_phase(func)\n            else:\n                self.parasitism_phase(func)\n\n            # self.update_rates()  # Commented out as it requires a way to track improvement per phase.\n            self.adjust_population_size()\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": ["e55571da-b122-4e64-a8a0-3db9d80ce023"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Symbiotic Organisms Search with a dynamic population size and a diversity-enhancing mutation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutualism_rate = 0.7\n        self.commensalism_rate = 0.2\n        self.parasitism_rate = 0.1\n        self.pop_size = initial_pop_size\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism_i)\n            self.tournament_selection(func, j, new_organism_j)\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            self.tournament_selection(func, i, new_organism)\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Diversity-enhancing mutation\n            if np.random.rand() < 0.1:  # Small chance of mutation\n                mutation_indices = np.random.choice(self.dim, num_changes, replace=False)\n                parasite[mutation_indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            self.tournament_selection(func, j, parasite)\n\n    def tournament_selection(self, func, index, new_organism):\n        if self.eval_count >= self.budget:\n            return\n        \n        fitness_new = func(new_organism)\n        self.eval_count += 1\n\n        if fitness_new < self.fitness[index]:\n            self.population[index] = new_organism\n            self.fitness[index] = fitness_new\n\n    def update_rates(self):\n        # Dynamically adjust rates based on the success of each phase\n        # (This is a simplified example; more sophisticated methods are possible)\n        improvement_mutualism = 0\n        improvement_commensalism = 0\n        improvement_parasitism = 0\n\n        # This is a placeholder and would require tracking improvements in each phase\n        # based on the number of updates made in each phase over some iterations.\n        # For example:\n        # improvement_mutualism = number of successful updates in mutualism / total mutualism calls\n        # Then we can adjust probabilities proportionally to the improvement.\n\n        total_improvement = improvement_mutualism + improvement_commensalism + improvement_parasitism\n\n        if total_improvement > 0:\n            self.mutualism_rate = improvement_mutualism / total_improvement\n            self.commensalism_rate = improvement_commensalism / total_improvement\n            self.parasitism_rate = improvement_parasitism / total_improvement\n        else:\n            # If no improvement, maintain the initial rates.\n            pass\n\n    def adjust_population_size(self):\n        # Simple strategy: If the population hasn't improved much in the last few iterations,\n        # increase the size to explore more. If it's improving rapidly, decrease to exploit.\n\n        # Calculate the standard deviation of the fitness values.  A lower std dev means\n        # population is converging.\n        fitness_std = np.std(self.fitness)\n\n        if fitness_std < 0.01 and self.pop_size < self.max_pop_size:  # Reduced threshold\n            self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n            # Add new random organisms\n            new_organisms = np.random.uniform(self.lb, self.ub, (5, self.dim))\n            new_fitness = np.full(5, np.inf)\n            for i in range(5):\n                if self.eval_count < self.budget:\n                    new_fitness[i] = func(new_organisms[i])\n                    self.eval_count += 1\n                else:\n                    break\n\n            self.population = np.concatenate((self.population, new_organisms[:i+1]), axis=0)\n            self.fitness = np.concatenate((self.fitness, new_fitness[:i+1]), axis=0)\n\n\n        elif fitness_std > 1 and self.pop_size > self.min_pop_size: # Increased threshold\n            # Kill off the worst organisms\n            num_to_kill = min(5, self.pop_size - self.min_pop_size)\n            worst_indices = np.argsort(self.fitness)[-num_to_kill:]\n            keep_indices = np.setdiff1d(np.arange(self.pop_size), worst_indices)\n            self.population = self.population[keep_indices]\n            self.fitness = self.fitness[keep_indices]\n            self.pop_size = self.population.shape[0]\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            # Apply phases based on their probabilities\n            rand = np.random.rand()\n            if rand < self.mutualism_rate:\n                self.mutualism_phase(func)\n            elif rand < self.mutualism_rate + self.commensalism_rate:\n                self.commensalism_phase(func)\n            else:\n                self.parasitism_phase(func)\n\n            # self.update_rates()  # Commented out as it requires a way to track improvement per phase.\n            self.adjust_population_size()\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]\n```", "operator": "mutation", "theta_sampled": 0.26811188705016475, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "d00e589b-dadd-45dd-8632-bb26e5b4f278", "fitness": 0.5313085452680214, "name": "CovarianceMatrixDifferentialEvolution", "description": "A population-based algorithm that combines elements of differential evolution and covariance matrix adaptation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass CovarianceMatrixDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None # Population\n        self.F = None # Population Fitness\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CovarianceMatrixDifferentialEvolution scored 0.531 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of differential evolution and covariance matrix adaptation to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass CovarianceMatrixDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None # Population\n        self.F = None # Population Fitness\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.12521068180151962, 0.20911723825181605, 0.8242224191245879, 0.8324625230488862, 0.26206955101279517, 0.1576504742705347, 0.3691005291232432, 0.6158094457416019, 0.7683419052881469, 0.1981431054048587, 0.8946500928379544, 0.9716301993205309, 0.29221515547574917, 0.24792770242184037, 0.9005775210553273, 0.8809527985766492, 0.5362389813552897, 0.8337518259885331, 0.19575983112393136, 0.510338924136633], "operator": "random_new", "theta_sampled": 0.07944044452655824, "reward": 0.11403726645424572, "generation": 3}, "task_prompt": ""}
{"id": "f66c5c84-6918-4a00-a14a-08089444a02c", "fitness": 0.20207279209571488, "name": "PotentialFieldOptimization", "description": "Population-based algorithm mimicking the diffusion and interaction of particles in a potential field, where particles are attracted to better solutions and repelled from each other.", "code": "import numpy as np\n\nclass PotentialFieldOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, attraction_factor=0.1, repulsion_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.attraction_factor = attraction_factor\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Calculate attractive force towards the best solution\n                attractive_force = self.attraction_factor * (self.x_opt - population[i])\n\n                # Calculate repulsive forces from other particles\n                repulsive_force = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = np.linalg.norm(population[i] - population[j])\n                        if distance > 0:  # Avoid division by zero\n                             repulsive_force += self.repulsion_factor * (population[i] - population[j]) / (distance**2 + 1e-8)  # Adding a small value to avoid singularities\n\n                # Update particle position\n                new_position = population[i] + attractive_force + repulsive_force\n\n                # Clip the new position to stay within the bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1 # Update budget\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position\n\n                    # Update best solution if necessary\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm PotentialFieldOptimization scored 0.202 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm mimicking the diffusion and interaction of particles in a potential field, where particles are attracted to better solutions and repelled from each other.\n# Code:\n```python\nimport numpy as np\n\nclass PotentialFieldOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, attraction_factor=0.1, repulsion_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.attraction_factor = attraction_factor\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Calculate attractive force towards the best solution\n                attractive_force = self.attraction_factor * (self.x_opt - population[i])\n\n                # Calculate repulsive forces from other particles\n                repulsive_force = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = np.linalg.norm(population[i] - population[j])\n                        if distance > 0:  # Avoid division by zero\n                             repulsive_force += self.repulsion_factor * (population[i] - population[j]) / (distance**2 + 1e-8)  # Adding a small value to avoid singularities\n\n                # Update particle position\n                new_position = population[i] + attractive_force + repulsive_force\n\n                # Clip the new position to stay within the bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1 # Update budget\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position\n\n                    # Update best solution if necessary\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.061346122935518776, 0.1631800972493056, 0.22575744466772452, 0.13841498270729957, 0.1790765899650849, 0.18925149904950322, 0.18712088950584727, 0.16655548528986874, 0.17323763033891615, 0.14035265108750772, 0.1505934324531909, 0.20649449143145304, 0.06355470941627406, 0.21299527725057132, 0.5464207448286365, 0.23212655493848355, 0.20663011265956122, 0.22239312017945756, 0.12129112710114509, 0.45466287885894774], "operator": "random_new", "theta_sampled": 0.22943910591187178, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "8f0dc881-6b47-4e51-819d-df4dbc16a761", "fitness": 0.0, "name": "HybridSOSDE", "description": "A hybrid algorithm combining Symbiotic Organisms Search (SOS) with Differential Evolution (DE) and a local search component based on Nelder-Mead simplex, adaptively switching between them based on the population's diversity and performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSOSDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50, local_search_frequency=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.diversity_weight = 0.5  # Weight for diversity-based parameter adaptation\n        self.de_mutation_factor = 0.5\n        self.de_crossover_rate = 0.7\n        self.local_search_frequency = local_search_frequency\n        self.local_search_iterations = 5  # Limited local search iterations\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select three distinct indices\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[indices]\n\n            # Mutation\n            mutant = a + self.de_mutation_factor * (b - c)\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            if self.eval_count < self.budget:\n                fitness = func(trial_vector)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = fitness\n                    \n    def local_search(self, func, x0):\n        bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n        res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.local_search_iterations})\n        return res.fun, res.x  # Return fitness and the solution\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        best_index = np.argmin(self.fitness)\n        f_opt = self.fitness[best_index]\n        x_opt = self.population[best_index]\n\n        iteration = 0\n        while self.eval_count < self.budget:\n            iteration += 1\n            # Dynamically adjust the balance between SOS and DE based on population diversity\n            diversity = np.std(self.population, axis=0).mean()\n            sos_prob = 0.5 + self.diversity_weight * (1 - diversity)  # Favor SOS when diversity is low\n\n            if np.random.rand() < sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                self.differential_evolution(func)\n\n            # Local Search every few iterations\n            if iteration % self.local_search_frequency == 0:\n                best_index = np.argmin(self.fitness)\n                current_best_x = self.population[best_index].copy()  # Use .copy() to avoid modifying the original population\n                \n                # Perform local search with the current best solution\n                f_local_opt, x_local_opt = self.local_search(func, current_best_x)\n                self.eval_count += self.local_search_iterations  # Account for the evaluations used by Nelder-Mead\n\n                if f_local_opt < self.fitness[best_index]:\n                     self.population[best_index] = x_local_opt\n                     self.fitness[best_index] = f_local_opt\n            \n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < f_opt:\n                f_opt = self.fitness[best_index]\n                x_opt = self.population[best_index]\n\n            if self.eval_count > self.budget:\n                break\n        \n        return f_opt, x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["576c4791-d79a-4388-bb0f-06d496f51c30"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Symbiotic Organisms Search (SOS) with Differential Evolution (DE) and a local search component based on Nelder-Mead simplex, adaptively switching between them based on the population's diversity and performance.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSOSDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50, local_search_frequency=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.diversity_weight = 0.5  # Weight for diversity-based parameter adaptation\n        self.de_mutation_factor = 0.5\n        self.de_crossover_rate = 0.7\n        self.local_search_frequency = local_search_frequency\n        self.local_search_iterations = 5  # Limited local search iterations\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select three distinct indices\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[indices]\n\n            # Mutation\n            mutant = a + self.de_mutation_factor * (b - c)\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            if self.eval_count < self.budget:\n                fitness = func(trial_vector)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = fitness\n                    \n    def local_search(self, func, x0):\n        bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n        res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.local_search_iterations})\n        return res.fun, res.x  # Return fitness and the solution\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        best_index = np.argmin(self.fitness)\n        f_opt = self.fitness[best_index]\n        x_opt = self.population[best_index]\n\n        iteration = 0\n        while self.eval_count < self.budget:\n            iteration += 1\n            # Dynamically adjust the balance between SOS and DE based on population diversity\n            diversity = np.std(self.population, axis=0).mean()\n            sos_prob = 0.5 + self.diversity_weight * (1 - diversity)  # Favor SOS when diversity is low\n\n            if np.random.rand() < sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                self.differential_evolution(func)\n\n            # Local Search every few iterations\n            if iteration % self.local_search_frequency == 0:\n                best_index = np.argmin(self.fitness)\n                current_best_x = self.population[best_index].copy()  # Use .copy() to avoid modifying the original population\n                \n                # Perform local search with the current best solution\n                f_local_opt, x_local_opt = self.local_search(func, current_best_x)\n                self.eval_count += self.local_search_iterations  # Account for the evaluations used by Nelder-Mead\n\n                if f_local_opt < self.fitness[best_index]:\n                     self.population[best_index] = x_local_opt\n                     self.fitness[best_index] = f_local_opt\n            \n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < f_opt:\n                f_opt = self.fitness[best_index]\n                x_opt = self.population[best_index]\n\n            if self.eval_count > self.budget:\n                break\n        \n        return f_opt, x_opt\n```", "operator": "mutation", "theta_sampled": 0.10645772837688892, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "bb9f7fa2-9a68-47cf-8f61-646996d1b3c9", "fitness": 0.3381457295572917, "name": "ElectrostaticParticleSwarm", "description": "A population-based algorithm that simulates the movement of charged particles under electrostatic forces, combined with a velocity update rule inspired by PSO.", "code": "import numpy as np\n\nclass ElectrostaticParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, charge_decay=0.99, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.charge_decay = charge_decay\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n        self.positions = None\n        self.velocities = None\n        self.charges = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.charges = np.zeros(self.pop_size)  # Initialize charges (fitness-dependent later)\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_fitness = np.array([np.inf] * self.pop_size)\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.positions[i])\n            self.budget -= 1\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.positions[i].copy()\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.positions[i].copy()\n\n    def calculate_charges(self):\n        # Charge is inversely proportional to fitness (better fitness -> higher charge)\n        max_fitness = np.max(self.fitness)\n        min_fitness = np.min(self.fitness)\n        \n        # Avoid division by zero if all particles have the same fitness\n        if max_fitness == min_fitness:\n            self.charges = np.ones(self.pop_size)  # Assign equal charge to all particles\n        else:\n            self.charges = (max_fitness - self.fitness) / (max_fitness - min_fitness)\n\n\n    def calculate_electrostatic_force(self):\n        forces = np.zeros((self.pop_size, self.dim))\n        epsilon = 1e-9  # Small constant to avoid division by zero\n\n        for i in range(self.pop_size):\n            for j in range(self.pop_size):\n                if i != j:\n                    distance = self.positions[j] - self.positions[i]\n                    magnitude = np.linalg.norm(distance) + epsilon\n                    force_direction = distance / magnitude\n                    force_magnitude = (self.charges[i] * self.charges[j]) / (magnitude**2 + epsilon) #Simplified Coulomb's Law\n                    forces[i] += force_magnitude * force_direction\n        return forces\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            self.calculate_charges()\n            electrostatic_forces = self.calculate_electrostatic_force()\n            \n            # Update velocities based on PSO and Electrostatic forces\n            self.velocities = (self.inertia_weight * self.velocities +\n                               self.cognitive_coeff * np.random.rand(self.pop_size, self.dim) * (self.personal_best_positions - self.positions) +\n                               self.social_coeff * np.random.rand(self.pop_size, self.dim) * (self.global_best_position - self.positions) +\n                               electrostatic_forces)\n\n            # Update positions\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            self.positions = self.positions + self.velocities\n            self.positions = np.clip(self.positions, lb, ub) # Clamp to boundaries\n\n            # Evaluate fitness and update best positions\n            for i in range(self.pop_size):\n                f = func(self.positions[i])\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = self.positions[i].copy()\n\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_position = self.positions[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n\n            # Decay charges (optional, but can help exploration)\n            self.charges *= self.charge_decay  # Decay charge to avoid stagnation\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm ElectrostaticParticleSwarm scored 0.338 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that simulates the movement of charged particles under electrostatic forces, combined with a velocity update rule inspired by PSO.\n# Code: \n```python\nimport numpy as np\n\nclass ElectrostaticParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, charge_decay=0.99, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.charge_decay = charge_decay\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n        self.positions = None\n        self.velocities = None\n        self.charges = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.charges = np.zeros(self.pop_size)  # Initialize charges (fitness-dependent later)\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_fitness = np.array([np.inf] * self.pop_size)\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.positions[i])\n            self.budget -= 1\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.positions[i].copy()\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.positions[i].copy()\n\n    def calculate_charges(self):\n        # Charge is inversely proportional to fitness (better fitness -> higher charge)\n        max_fitness = np.max(self.fitness)\n        min_fitness = np.min(self.fitness)\n        \n        # Avoid division by zero if all particles have the same fitness\n        if max_fitness == min_fitness:\n            self.charges = np.ones(self.pop_size)  # Assign equal charge to all particles\n        else:\n            self.charges = (max_fitness - self.fitness) / (max_fitness - min_fitness)\n\n\n    def calculate_electrostatic_force(self):\n        forces = np.zeros((self.pop_size, self.dim))\n        epsilon = 1e-9  # Small constant to avoid division by zero\n\n        for i in range(self.pop_size):\n            for j in range(self.pop_size):\n                if i != j:\n                    distance = self.positions[j] - self.positions[i]\n                    magnitude = np.linalg.norm(distance) + epsilon\n                    force_direction = distance / magnitude\n                    force_magnitude = (self.charges[i] * self.charges[j]) / (magnitude**2 + epsilon) #Simplified Coulomb's Law\n                    forces[i] += force_magnitude * force_direction\n        return forces\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            self.calculate_charges()\n            electrostatic_forces = self.calculate_electrostatic_force()\n            \n            # Update velocities based on PSO and Electrostatic forces\n            self.velocities = (self.inertia_weight * self.velocities +\n                               self.cognitive_coeff * np.random.rand(self.pop_size, self.dim) * (self.personal_best_positions - self.positions) +\n                               self.social_coeff * np.random.rand(self.pop_size, self.dim) * (self.global_best_position - self.positions) +\n                               electrostatic_forces)\n\n            # Update positions\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            self.positions = self.positions + self.velocities\n            self.positions = np.clip(self.positions, lb, ub) # Clamp to boundaries\n\n            # Evaluate fitness and update best positions\n            for i in range(self.pop_size):\n                f = func(self.positions[i])\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = self.positions[i].copy()\n\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_position = self.positions[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n\n            # Decay charges (optional, but can help exploration)\n            self.charges *= self.charge_decay  # Decay charge to avoid stagnation\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.11471736190857684, 0.28308368629245084, 0.3894859961352042, 0.2418818360864029, 0.2376778491375079, 0.2505725063167351, 0.23737146419716992, 0.3185219811594835, 0.30424857868235866, 0.2281859855479792, 0.4152394275146274, 0.9969281178071772, 0.2443713726655028, 0.24707964932985582, 0.5845461615153208, 0.3949022448085262, 0.32895092776921886, 0.21442267707799512, 0.2538414581875581, 0.4768853090061832], "operator": "random_new", "theta_sampled": 0.06788541213888101, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "955fd1b4-e76a-4b91-9ed2-ac07e798a2c5", "fitness": 0.4040693843200822, "name": "AdaptiveSlimeMoldOptimization", "description": "Adaptive Slime Mold Optimization with improved exploration via orthogonal learning and dynamic parameter adjustments.", "code": "import numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c_init=0.3, levy_exponent=1.5, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c_init = c_init  # Initial confidence factor\n        self.c = c_init  # Dynamic confidence factor\n        self.levy_exponent = levy_exponent\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.current_evaluations = 0\n        self.adaptive_weights = np.ones(population_size) / population_size\n        self.orthogonal_learning_rate = orthogonal_learning_rate # Rate for orthogonal learning\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :]\n\n    def update_best(self):\n        current_best_index = np.argmin(self.fitness)\n        if self.fitness[current_best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[current_best_index]\n            self.best_position = self.positions[current_best_index, :].copy()\n\n    def levy_flight(self, size):\n        num = np.random.normal(0, 1, size)\n        den = np.power(np.abs(np.random.normal(0, 1, size)), (1 / self.levy_exponent))\n        return num / den\n\n    def update_adaptive_weights(self):\n        # Calculate normalized fitness values\n        fitness_normalized = np.max(self.fitness) - self.fitness + 1e-9  # Avoid division by zero\n        fitness_normalized = fitness_normalized / np.sum(fitness_normalized)\n        self.adaptive_weights = fitness_normalized\n\n    def orthogonal_learning(self, position, lb, ub):\n        \"\"\"Performs orthogonal learning to generate a new candidate solution.\"\"\"\n        basis_vectors = np.random.randn(self.dim, self.dim)  # Generate random basis vectors\n        basis_vectors = np.linalg.qr(basis_vectors)[0]  # Orthonormalize the basis vectors\n\n        new_position = position.copy()\n        for i in range(self.dim):\n            projection = np.dot(position, basis_vectors[i, :])\n            new_value = projection + self.orthogonal_learning_rate * np.random.uniform(-1, 1)\n            new_position += new_value * basis_vectors[i, :]\n\n        return np.clip(new_position, lb, ub)\n\n\n    def update_positions(self, func):\n        self.update_adaptive_weights()\n\n        q = np.random.rand(self.population_size, self.dim) # probability\n        \n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break\n\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n\n            # Strategy Selection (Probability-based)\n            if q[i,0] < 0.33: # Move towards best\n                 influence = self.c * (self.best_position - self.positions[i, :])\n                 new_position = self.positions[i, :] + influence + 0.01 * self.levy_flight(self.dim) * (ub - lb)\n            elif q[i,0] < 0.66: # Explore neighborhood\n                neighbor_index = np.random.choice(self.population_size, 1)[0]\n                new_position = self.positions[i, :] + self.c * (self.positions[neighbor_index, :] - self.positions[i, :]) +  0.01 * self.levy_flight(self.dim) * (ub - lb)\n\n            else: # Levy flight exploration and Orthogonal learning\n                new_position = self.positions[i, :] + 0.1 * self.levy_flight(self.dim) * (ub - lb) # Larger step levy flight\n                new_position = self.orthogonal_learning(new_position, lb, ub)\n\n\n            # Clip positions to bounds\n            new_position = np.clip(new_position, lb, ub)\n            \n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n\n            if new_fitness < self.fitness[i]:\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n\n        self.update_best()\n        # Dynamic Confidence Adjustment\n        self.c = self.c_init * (1 - self.current_evaluations / self.budget)  # Linear decay\n        self.orthogonal_learning_rate = 0.1 * (1 - self.current_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveSlimeMoldOptimization scored 0.404 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3af4ebd-6ba6-4792-990c-8bd076dff530"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Slime Mold Optimization with improved exploration via orthogonal learning and dynamic parameter adjustments.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c_init=0.3, levy_exponent=1.5, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c_init = c_init  # Initial confidence factor\n        self.c = c_init  # Dynamic confidence factor\n        self.levy_exponent = levy_exponent\n        self.positions = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.current_evaluations = 0\n        self.adaptive_weights = np.ones(population_size) / population_size\n        self.orthogonal_learning_rate = orthogonal_learning_rate # Rate for orthogonal learning\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(self.positions[i, :]) for i in range(self.population_size)])\n        self.current_evaluations = self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.positions[np.argmin(self.fitness), :]\n\n    def update_best(self):\n        current_best_index = np.argmin(self.fitness)\n        if self.fitness[current_best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[current_best_index]\n            self.best_position = self.positions[current_best_index, :].copy()\n\n    def levy_flight(self, size):\n        num = np.random.normal(0, 1, size)\n        den = np.power(np.abs(np.random.normal(0, 1, size)), (1 / self.levy_exponent))\n        return num / den\n\n    def update_adaptive_weights(self):\n        # Calculate normalized fitness values\n        fitness_normalized = np.max(self.fitness) - self.fitness + 1e-9  # Avoid division by zero\n        fitness_normalized = fitness_normalized / np.sum(fitness_normalized)\n        self.adaptive_weights = fitness_normalized\n\n    def orthogonal_learning(self, position, lb, ub):\n        \"\"\"Performs orthogonal learning to generate a new candidate solution.\"\"\"\n        basis_vectors = np.random.randn(self.dim, self.dim)  # Generate random basis vectors\n        basis_vectors = np.linalg.qr(basis_vectors)[0]  # Orthonormalize the basis vectors\n\n        new_position = position.copy()\n        for i in range(self.dim):\n            projection = np.dot(position, basis_vectors[i, :])\n            new_value = projection + self.orthogonal_learning_rate * np.random.uniform(-1, 1)\n            new_position += new_value * basis_vectors[i, :]\n\n        return np.clip(new_position, lb, ub)\n\n\n    def update_positions(self, func):\n        self.update_adaptive_weights()\n\n        q = np.random.rand(self.population_size, self.dim) # probability\n        \n        for i in range(self.population_size):\n            if self.current_evaluations >= self.budget:\n                break\n\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n\n            # Strategy Selection (Probability-based)\n            if q[i,0] < 0.33: # Move towards best\n                 influence = self.c * (self.best_position - self.positions[i, :])\n                 new_position = self.positions[i, :] + influence + 0.01 * self.levy_flight(self.dim) * (ub - lb)\n            elif q[i,0] < 0.66: # Explore neighborhood\n                neighbor_index = np.random.choice(self.population_size, 1)[0]\n                new_position = self.positions[i, :] + self.c * (self.positions[neighbor_index, :] - self.positions[i, :]) +  0.01 * self.levy_flight(self.dim) * (ub - lb)\n\n            else: # Levy flight exploration and Orthogonal learning\n                new_position = self.positions[i, :] + 0.1 * self.levy_flight(self.dim) * (ub - lb) # Larger step levy flight\n                new_position = self.orthogonal_learning(new_position, lb, ub)\n\n\n            # Clip positions to bounds\n            new_position = np.clip(new_position, lb, ub)\n            \n            new_fitness = func(new_position)\n            self.current_evaluations += 1\n\n            if new_fitness < self.fitness[i]:\n                self.positions[i, :] = new_position\n                self.fitness[i] = new_fitness\n\n        self.update_best()\n        # Dynamic Confidence Adjustment\n        self.c = self.c_init * (1 - self.current_evaluations / self.budget)  # Linear decay\n        self.orthogonal_learning_rate = 0.1 * (1 - self.current_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.current_evaluations < self.budget:\n            self.update_positions(func)\n\n        return self.best_fitness, self.best_position\n```", "aucs": [0.15702567905060383, 0.22053243285164936, 0.40563528775964386, 0.49936412274421726, 0.3399155330185025, 0.4853724195120176, 0.2985343044908878, 0.36071468121712036, 0.3294430792002939, 0.21032931245474507, 0.5157334180984485, 0.9929035366644038, 0.2668774813407836, 0.38184758134941954, 0.7186100304085143, 0.33910008470401776, 0.3296820680845477, 0.5245944112067056, 0.21280045745616605, 0.4923717647889564], "operator": "mutation", "theta_sampled": 0.06561478749049066, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "030ff57f-8ed0-4d56-9083-2e2fc00cf331", "fitness": 0.43796534409820065, "name": "HybridEvolutionarySymbiosis", "description": "A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Symbiotic Organisms Search for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridEvolutionarySymbiosis:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, de_rate=0.5, sos_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.de_rate = de_rate\n        self.sos_rate = sos_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Apply Differential Evolution with CMA\n            if np.random.rand() < self.de_rate:\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n                # Covariance Matrix Adaptation (CMA) - Simplified\n                best_idx = np.argmin(self.F)\n                x_mean = np.mean(self.X, axis=0)\n\n                # Update the mean\n                self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n                # Update the step size\n                diff = self.mu - x_mean\n                self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            # Apply Symbiotic Organisms Search\n            elif np.random.rand() < self.sos_rate:\n                for i in range(self.pop_size):\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Select a random organism (excluding itself)\n                    j = i\n                    while j == i:\n                        j = np.random.randint(0, self.pop_size)\n\n                    # Calculate mutual benefit factor\n                    BF1 = np.random.choice([1, 2])\n                    BF2 = np.random.choice([1, 2])\n\n                    # Calculate mean of the two organisms\n                    mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n                    # Generate new solutions based on mutualism\n                    new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n                    new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n                    # Clip the new solutions to the search space\n                    new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n                    new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n                    # Evaluate the new solutions\n                    if self.eval_count < self.budget:\n                        fitness_i = func(new_organism_i)\n                        self.eval_count += 1\n                        if fitness_i < self.F[i]:\n                            self.X[i] = new_organism_i\n                            self.F[i] = fitness_i\n\n                    if self.eval_count < self.budget:\n                        fitness_j = func(new_organism_j)\n                        self.eval_count += 1\n                        if fitness_j < self.F[j]:\n                            self.X[j] = new_organism_j\n                            self.F[j] = fitness_j\n            else: #Commensalism and Parasitism are less computationally expensive, applying them regularly\n                for i in range(self.pop_size):\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Select a random organism (excluding itself)\n                    j = i\n                    while j == i:\n                        j = np.random.randint(0, self.pop_size)\n\n                    # Generate new solution based on commensalism\n                    new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n\n                    # Clip the new solution to the search space\n                    new_organism = np.clip(new_organism, self.lb, self.ub)\n\n                    # Evaluate the new solution\n                    if self.eval_count < self.budget:\n                        fitness = func(new_organism)\n                        self.eval_count += 1\n                        if fitness < self.F[i]:\n                            self.X[i] = new_organism\n                            self.F[i] = fitness\n                            \n                for i in range(self.pop_size):\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Create a parasite (copy of an organism)\n                    parasite = np.copy(self.X[i])\n\n                    # Randomly change some dimensions of the parasite\n                    num_changes = np.random.randint(1, self.dim + 1)\n                    indices = np.random.choice(self.dim, num_changes, replace=False)\n                    parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n                    # Select a random organism to be the host\n                    j = np.random.randint(0, self.pop_size)\n\n                    # Evaluate the parasite\n                    if self.eval_count < self.budget:\n                        fitness_parasite = func(parasite)\n                        self.eval_count += 1\n\n                        # Replace the host if the parasite is better\n                        if fitness_parasite < self.F[j]:\n                            self.X[j] = parasite\n                            self.F[j] = fitness_parasite\n\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridEvolutionarySymbiosis scored 0.438 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Symbiotic Organisms Search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridEvolutionarySymbiosis:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, de_rate=0.5, sos_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.de_rate = de_rate\n        self.sos_rate = sos_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Apply Differential Evolution with CMA\n            if np.random.rand() < self.de_rate:\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n                # Covariance Matrix Adaptation (CMA) - Simplified\n                best_idx = np.argmin(self.F)\n                x_mean = np.mean(self.X, axis=0)\n\n                # Update the mean\n                self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n                # Update the step size\n                diff = self.mu - x_mean\n                self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            # Apply Symbiotic Organisms Search\n            elif np.random.rand() < self.sos_rate:\n                for i in range(self.pop_size):\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Select a random organism (excluding itself)\n                    j = i\n                    while j == i:\n                        j = np.random.randint(0, self.pop_size)\n\n                    # Calculate mutual benefit factor\n                    BF1 = np.random.choice([1, 2])\n                    BF2 = np.random.choice([1, 2])\n\n                    # Calculate mean of the two organisms\n                    mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n                    # Generate new solutions based on mutualism\n                    new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n                    new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n                    # Clip the new solutions to the search space\n                    new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n                    new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n                    # Evaluate the new solutions\n                    if self.eval_count < self.budget:\n                        fitness_i = func(new_organism_i)\n                        self.eval_count += 1\n                        if fitness_i < self.F[i]:\n                            self.X[i] = new_organism_i\n                            self.F[i] = fitness_i\n\n                    if self.eval_count < self.budget:\n                        fitness_j = func(new_organism_j)\n                        self.eval_count += 1\n                        if fitness_j < self.F[j]:\n                            self.X[j] = new_organism_j\n                            self.F[j] = fitness_j\n            else: #Commensalism and Parasitism are less computationally expensive, applying them regularly\n                for i in range(self.pop_size):\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Select a random organism (excluding itself)\n                    j = i\n                    while j == i:\n                        j = np.random.randint(0, self.pop_size)\n\n                    # Generate new solution based on commensalism\n                    new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n\n                    # Clip the new solution to the search space\n                    new_organism = np.clip(new_organism, self.lb, self.ub)\n\n                    # Evaluate the new solution\n                    if self.eval_count < self.budget:\n                        fitness = func(new_organism)\n                        self.eval_count += 1\n                        if fitness < self.F[i]:\n                            self.X[i] = new_organism\n                            self.F[i] = fitness\n                            \n                for i in range(self.pop_size):\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Create a parasite (copy of an organism)\n                    parasite = np.copy(self.X[i])\n\n                    # Randomly change some dimensions of the parasite\n                    num_changes = np.random.randint(1, self.dim + 1)\n                    indices = np.random.choice(self.dim, num_changes, replace=False)\n                    parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n                    # Select a random organism to be the host\n                    j = np.random.randint(0, self.pop_size)\n\n                    # Evaluate the parasite\n                    if self.eval_count < self.budget:\n                        fitness_parasite = func(parasite)\n                        self.eval_count += 1\n\n                        # Replace the host if the parasite is better\n                        if fitness_parasite < self.F[j]:\n                            self.X[j] = parasite\n                            self.F[j] = fitness_parasite\n\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.15012740060451146, 0.7131593756709753, 0.37234832385925276, 0.9148338486110147, 0.3061331540839185, 0.39098563790465546, 0.29822197113393867, 0.34015515629872084, 0.30162453381239185, 0.2038362843968503, 0.506026880374288, 0.9882202242571902, 0.29871803558518295, 0.2889517937189062, 0.8772407581334574, 0.3058696180662568, 0.27887946510944195, 0.5062926371580602, 0.2266176654545372, 0.4910641177304641], "operator": "crossover", "theta_sampled": 0.6026077118943824, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "0746a5e1-4f33-447a-b99b-29395fcb75b0", "fitness": 0.45051627575368586, "name": "HybridCMAES_SOS", "description": "A hybrid approach combining Covariance Matrix Adaptation with Symbiotic Organisms Search, leveraging CMA's efficient search adaptation and SOS's diverse interaction strategies.", "code": "import numpy as np\n\nclass HybridCMAES_SOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, sos_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None # Population (CMA) / Organisms (SOS)\n        self.F = None # Population Fitness\n        self.eval_count = 0\n        self.sos_prob = sos_prob  #Probability of performing SOS phases\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.X[i])\n\n            # Randomly change some dimensions of the parasite\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # SOS phases with probability sos_prob\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                #Mutation and Crossover (Differential Evolution) - CMA part\n\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, self.lb, self.ub)\n\n                # Evaluation\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                # Selection\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridCMAES_SOS scored 0.451 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid approach combining Covariance Matrix Adaptation with Symbiotic Organisms Search, leveraging CMA's efficient search adaptation and SOS's diverse interaction strategies.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_SOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, sos_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None # Population (CMA) / Organisms (SOS)\n        self.F = None # Population Fitness\n        self.eval_count = 0\n        self.sos_prob = sos_prob  #Probability of performing SOS phases\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.X[i])\n\n            # Randomly change some dimensions of the parasite\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # SOS phases with probability sos_prob\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                #Mutation and Crossover (Differential Evolution) - CMA part\n\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, self.lb, self.ub)\n\n                # Evaluation\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                # Selection\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14695200177399004, 0.20715157535702688, 0.48688092559681295, 0.8715268720699682, 0.2437052128696341, 0.5459286423485927, 0.3391253633247153, 0.25024634327545525, 0.32153564270306445, 0.2497737081728153, 0.4302793379104115, 0.9920343620085758, 0.2698391192748143, 0.25706434816783164, 0.9117989666376003, 0.7950023852660805, 0.30971555383437566, 0.6458086964561538, 0.23180390086370062, 0.5041525571621], "operator": "crossover", "theta_sampled": 0.07228649601803579, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "2c4cdc80-0a1a-4797-afc0-1440970dcc4f", "fitness": 0.29786686069361623, "name": "AttractRepelOptimization", "description": "Population-based algorithm where individuals are attracted towards the best solution while simultaneously being repelled by the worst solution, with adaptive step size control.", "code": "import numpy as np\n\nclass AttractRepelOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, attraction_factor=0.1, repulsion_factor=0.1, step_size_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.attraction_factor = attraction_factor\n        self.repulsion_factor = repulsion_factor\n        self.step_size_decay = step_size_decay\n        self.step_size = 1.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        worst_idx = np.argmax(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n\n        while self.budget > 0:\n            # Update population\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Attraction towards the best\n                attraction = self.attraction_factor * self.step_size * (self.x_opt - population[i])\n\n                # Repulsion from the worst\n                repulsion = self.repulsion_factor * self.step_size * (population[i] - population[worst_idx])\n\n                # Random movement\n                random_movement = np.random.uniform(-self.step_size * 0.1, self.step_size * 0.1, size=self.dim) # Small random pertubation\n\n\n                new_position = population[i] + attraction + repulsion + random_movement\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position\n\n                    # Update best solution\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n\n\n            # Update best and worst indices\n            best_idx = np.argmin(fitness)\n            worst_idx = np.argmax(fitness)\n            self.step_size *= self.step_size_decay  # Reduce step size\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AttractRepelOptimization scored 0.298 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm where individuals are attracted towards the best solution while simultaneously being repelled by the worst solution, with adaptive step size control.\n# Code: \n```python\nimport numpy as np\n\nclass AttractRepelOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, attraction_factor=0.1, repulsion_factor=0.1, step_size_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.attraction_factor = attraction_factor\n        self.repulsion_factor = repulsion_factor\n        self.step_size_decay = step_size_decay\n        self.step_size = 1.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        worst_idx = np.argmax(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n\n        while self.budget > 0:\n            # Update population\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Attraction towards the best\n                attraction = self.attraction_factor * self.step_size * (self.x_opt - population[i])\n\n                # Repulsion from the worst\n                repulsion = self.repulsion_factor * self.step_size * (population[i] - population[worst_idx])\n\n                # Random movement\n                random_movement = np.random.uniform(-self.step_size * 0.1, self.step_size * 0.1, size=self.dim) # Small random pertubation\n\n\n                new_position = population[i] + attraction + repulsion + random_movement\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position\n\n                    # Update best solution\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n\n\n            # Update best and worst indices\n            best_idx = np.argmin(fitness)\n            worst_idx = np.argmax(fitness)\n            self.step_size *= self.step_size_decay  # Reduce step size\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11061220740897026, 0.19434065279603008, 0.2501106804700305, 0.18397429619323835, 0.22056024874061642, 0.23058242794685835, 0.24320077886398817, 0.21576002846138342, 0.1934957070944172, 0.14492999791406913, 0.24284743959855604, 1.0, 0.3378273092899472, 0.24689053350445234, 0.6906049032949653, 0.3448066730504349, 0.29745550249974817, 0.22628931024200694, 0.1461924655746052, 0.4368560509280066], "operator": "random_new", "theta_sampled": 0.054620308618249215, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "9bca7ece-c0d5-47dc-916b-dfe484db30ed", "fitness": 0.4927950327849591, "name": "HybridCovarianceSymbiosis", "description": "A hybrid approach combining Covariance Matrix Adaptation with Symbiotic Organisms Search for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCovarianceSymbiosis:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, sos_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.sos_prob = sos_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n            else:\n                # Mutation and Crossover (Differential Evolution)\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                # Selection\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridCovarianceSymbiosis scored 0.493 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid approach combining Covariance Matrix Adaptation with Symbiotic Organisms Search for efficient exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCovarianceSymbiosis:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, sos_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.sos_prob = sos_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n            else:\n                # Mutation and Crossover (Differential Evolution)\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                # Selection\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14264935588107108, 0.21395182522023992, 0.5506355070924442, 0.8176270960524228, 0.43386043383310946, 0.6252614896475476, 0.30147729451859473, 0.43833856012600825, 0.456256066785517, 0.18318316088865538, 0.738541144224717, 0.9893513482067796, 0.3133412003368993, 0.29479612685181733, 0.8447983265291958, 0.6840747683815604, 0.3720529824965694, 0.781331993236714, 0.18835110282212453, 0.48602087256719395], "operator": "crossover", "theta_sampled": 0.00035902319519799983, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "7d8de8ed-1f4f-4f28-8a0a-67e58429af75", "fitness": 0.4941088035940336, "name": "AdaptiveSymbioticOrganismsSearch", "description": "Symbiotic Organisms Search with adaptive parameters and a self-adaptive mutation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.mutation_decay = 0.995 # Decay factor for mutation rate\n        self.BF_prob = 0.5 # probability to choose BF1 or BF2 as constant or random\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveSymbioticOrganismsSearch scored 0.494 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c600221-bb6a-43a2-999f-922a7cb86197"], "operator": "mutation", "metadata": {"llm_response": "# Description: Symbiotic Organisms Search with adaptive parameters and a self-adaptive mutation strategy for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.mutation_decay = 0.995 # Decay factor for mutation rate\n        self.BF_prob = 0.5 # probability to choose BF1 or BF2 as constant or random\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n            else:\n                break\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.population[i] + self.population[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.population[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.population[j])\n            new_organism_j = self.population[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.population[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.fitness[i]:\n                    self.population[i] = new_organism_i\n                    self.fitness[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.fitness[j]:\n                    self.population[j] = new_organism_j\n                    self.fitness[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.population[i] + np.random.rand(self.dim) * (self.population[j] - self.population[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.fitness[i]:\n                    self.population[i] = new_organism\n                    self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.population[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.fitness[j]:\n                    self.population[j] = parasite\n                    self.fitness[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n        best_index = np.argmin(self.fitness)\n        return self.fitness[best_index], self.population[best_index]\n```", "aucs": [0.20398402994116527, 0.2940991515026078, 0.4537135462765365, 0.7206074370427601, 0.5176965634638606, 0.49521626217725345, 0.45380648859864714, 0.4263735083010354, 0.48586445024359304, 0.20318156922407338, 0.785883719394764, 0.9994799107898955, 0.28252045897675215, 0.4878740109949786, 0.8133346730676441, 0.6423490915298395, 0.35665276161953274, 0.5615084091049107, 0.20528050434534795, 0.49274952528547333], "operator": "mutation", "theta_sampled": 0.21923588115564205, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "d02bdf72-b115-4d5b-a357-37357ca66e94", "fitness": 0.0, "name": "DynamicPopulationAdaptiveRadiusSearch", "description": "An algorithm that uses a dynamic population, adaptive search radius based on fitness landscape characteristics, and a restarting mechanism to escape local optima.", "code": "import numpy as np\n\nclass DynamicPopulationAdaptiveRadiusSearch:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, exploration_factor=1.0, exploitation_factor=0.1, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.restart_trigger = restart_trigger\n        self.population = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.evaluations = 0\n        self.search_radius = (5.0 - (-5.0)) / 2.0  # Initial search radius\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[best_index]\n            self.best_solution = self.population[best_index]\n\n    def adapt_search_radius(self):\n          # Adaptive radius based on fitness improvement.\n        fitness_improvement = np.mean(self.fitness) - self.best_fitness\n        if fitness_improvement > 0:  # Stagnation\n            self.search_radius *= (1 + self.exploration_factor)  # Increase radius for exploration\n        else:\n            self.search_radius *= (1 - self.exploitation_factor)  # Decrease radius for exploitation\n\n        self.search_radius = np.clip(self.search_radius, 0.001, (5.0 - (-5.0)) / 2.0) #bound the search radius\n    \n    def adjust_population_size(self):\n      # Linearly decreasing population size.\n      self.population_size = max(10, int(50 - (50-10) * (self.evaluations / self.budget)))\n\n    def restart_mechanism(self):\n        # Restart if the improvement is below a threshold\n        if self.best_fitness > 0 and np.abs(self.best_fitness) < 1e-6: # Close to zero, so terminate\n          return True\n        \n        if (np.random.rand() < self.restart_trigger) and (self.evaluations > self.budget/10.0): #restart probability increases with the number of evaluations\n            return True\n        else:\n            return False\n    \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evaluations < self.budget:\n\n            self.adapt_search_radius()\n            self.adjust_population_size()\n\n            new_population = np.zeros((self.population_size, self.dim))\n            for i in range(self.population_size):\n                # Sample new solutions around the current best and existing solutions.\n                if np.random.rand() < 0.5:\n                  new_solution = self.best_solution + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim)\n                else:\n                  index = np.random.randint(0, self.population_size)\n                  new_solution = self.population[index] + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim)\n                \n                new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub) # Clip to boundary\n                new_population[i, :] = new_solution\n                \n            new_fitness = np.array([func(x) for x in new_population])\n            self.evaluations += self.population_size\n            \n            # Selection: Replace old population with new if they are better.\n            for i in range(self.population_size):\n                if new_fitness[i] < self.fitness[i]:\n                    self.population[i] = new_population[i]\n                    self.fitness[i] = new_fitness[i]\n\n                    if new_fitness[i] < self.best_fitness:\n                        self.best_fitness = new_fitness[i]\n                        self.best_solution = new_population[i]\n\n            if self.restart_mechanism():\n              self.initialize_population(func) # Restart the population.\n\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm DynamicPopulationAdaptiveRadiusSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that uses a dynamic population, adaptive search radius based on fitness landscape characteristics, and a restarting mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass DynamicPopulationAdaptiveRadiusSearch:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, exploration_factor=1.0, exploitation_factor=0.1, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.restart_trigger = restart_trigger\n        self.population = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.evaluations = 0\n        self.search_radius = (5.0 - (-5.0)) / 2.0  # Initial search radius\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.best_fitness:\n            self.best_fitness = self.fitness[best_index]\n            self.best_solution = self.population[best_index]\n\n    def adapt_search_radius(self):\n          # Adaptive radius based on fitness improvement.\n        fitness_improvement = np.mean(self.fitness) - self.best_fitness\n        if fitness_improvement > 0:  # Stagnation\n            self.search_radius *= (1 + self.exploration_factor)  # Increase radius for exploration\n        else:\n            self.search_radius *= (1 - self.exploitation_factor)  # Decrease radius for exploitation\n\n        self.search_radius = np.clip(self.search_radius, 0.001, (5.0 - (-5.0)) / 2.0) #bound the search radius\n    \n    def adjust_population_size(self):\n      # Linearly decreasing population size.\n      self.population_size = max(10, int(50 - (50-10) * (self.evaluations / self.budget)))\n\n    def restart_mechanism(self):\n        # Restart if the improvement is below a threshold\n        if self.best_fitness > 0 and np.abs(self.best_fitness) < 1e-6: # Close to zero, so terminate\n          return True\n        \n        if (np.random.rand() < self.restart_trigger) and (self.evaluations > self.budget/10.0): #restart probability increases with the number of evaluations\n            return True\n        else:\n            return False\n    \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evaluations < self.budget:\n\n            self.adapt_search_radius()\n            self.adjust_population_size()\n\n            new_population = np.zeros((self.population_size, self.dim))\n            for i in range(self.population_size):\n                # Sample new solutions around the current best and existing solutions.\n                if np.random.rand() < 0.5:\n                  new_solution = self.best_solution + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim)\n                else:\n                  index = np.random.randint(0, self.population_size)\n                  new_solution = self.population[index] + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim)\n                \n                new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub) # Clip to boundary\n                new_population[i, :] = new_solution\n                \n            new_fitness = np.array([func(x) for x in new_population])\n            self.evaluations += self.population_size\n            \n            # Selection: Replace old population with new if they are better.\n            for i in range(self.population_size):\n                if new_fitness[i] < self.fitness[i]:\n                    self.population[i] = new_population[i]\n                    self.fitness[i] = new_fitness[i]\n\n                    if new_fitness[i] < self.best_fitness:\n                        self.best_fitness = new_fitness[i]\n                        self.best_solution = new_population[i]\n\n            if self.restart_mechanism():\n              self.initialize_population(func) # Restart the population.\n\n\n        return self.best_fitness, self.best_solution\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.0770230432048746, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "09592061-807e-4b04-b609-4a9e8262d119", "fitness": 0.0, "name": "ChargedParticleOptimization", "description": "An algorithm that simulates the behavior of charged particles in an electromagnetic field, where particles are attracted to fitter solutions and repelled from less fit ones, with adaptive step sizes.", "code": "import numpy as np\n\nclass ChargedParticleOptimization:\n    def __init__(self, budget=10000, dim=10, num_particles=50, charge_decay=0.95, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.charge_decay = charge_decay\n        self.repulsion_factor = repulsion_factor\n\n        self.positions = None\n        self.velocities = None\n        self.fitness = None\n        self.charges = None\n        self.best_position = None\n        self.best_fitness = np.inf\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.num_particles, self.dim))\n        self.velocities = np.zeros((self.num_particles, self.dim))\n        self.fitness = np.array([func(x) for x in self.positions])\n        self.charges = np.ones(self.num_particles)\n        \n        best_index = np.argmin(self.fitness)\n        self.best_position = self.positions[best_index].copy()\n        self.best_fitness = self.fitness[best_index]\n\n    def calculate_charges(self):\n        # Charges are inversely proportional to fitness rank, better solutions have higher charge\n        ranked_indices = np.argsort(self.fitness)\n        self.charges[ranked_indices] = np.linspace(1, 0.1, self.num_particles) # Linear decrease in charge\n\n    def calculate_forces(self):\n        forces = np.zeros((self.num_particles, self.dim))\n        for i in range(self.num_particles):\n            for j in range(self.num_particles):\n                if i != j:\n                    distance = self.positions[j] - self.positions[i]\n                    magnitude = (self.charges[i] * self.charges[j]) / (np.linalg.norm(distance)**2 + 1e-8)  # Adding a small value to avoid division by zero\n                    forces[i] += magnitude * distance\n        return forces\n\n    def update_positions(self, forces, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        inertia = 0.7\n        damping = 0.9  # Damping factor for velocity\n\n        for i in range(self.num_particles):\n            self.velocities[i] = inertia * self.velocities[i] + forces[i] + np.random.rand(self.dim)*(self.best_position-self.positions[i])\n            self.velocities[i] *= damping\n            self.positions[i] += self.velocities[i]\n\n            # Boundary Handling (Reflection)\n            for d in range(self.dim):\n                if self.positions[i, d] < lb:\n                    self.positions[i, d] = lb + np.abs(self.positions[i, d] - lb)\n                    self.velocities[i,d] = -self.velocities[i,d]*self.repulsion_factor  #Reverse velocity and add repulsion\n                elif self.positions[i, d] > ub:\n                    self.positions[i, d] = ub - np.abs(self.positions[i, d] - ub)\n                    self.velocities[i,d] = -self.velocities[i,d]*self.repulsion_factor #Reverse velocity and add repulsion\n\n\n            self.positions[i] = np.clip(self.positions[i], lb, ub)  # Ensure positions stay within bounds\n\n    def __call__(self, func):\n        self.initialize(func)\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            self.calculate_charges()\n            forces = self.calculate_forces()\n            self.update_positions(forces, func)\n\n            # Evaluate fitness of new positions\n            for i in range(self.num_particles):\n                self.fitness[i] = func(self.positions[i])\n                eval_count += 1\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_position = self.positions[i].copy()\n                    \n                if eval_count >= self.budget:\n                    break\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that simulates the behavior of charged particles in an electromagnetic field, where particles are attracted to fitter solutions and repelled from less fit ones, with adaptive step sizes.\n# Code: \n```python\nimport numpy as np\n\nclass ChargedParticleOptimization:\n    def __init__(self, budget=10000, dim=10, num_particles=50, charge_decay=0.95, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.charge_decay = charge_decay\n        self.repulsion_factor = repulsion_factor\n\n        self.positions = None\n        self.velocities = None\n        self.fitness = None\n        self.charges = None\n        self.best_position = None\n        self.best_fitness = np.inf\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.num_particles, self.dim))\n        self.velocities = np.zeros((self.num_particles, self.dim))\n        self.fitness = np.array([func(x) for x in self.positions])\n        self.charges = np.ones(self.num_particles)\n        \n        best_index = np.argmin(self.fitness)\n        self.best_position = self.positions[best_index].copy()\n        self.best_fitness = self.fitness[best_index]\n\n    def calculate_charges(self):\n        # Charges are inversely proportional to fitness rank, better solutions have higher charge\n        ranked_indices = np.argsort(self.fitness)\n        self.charges[ranked_indices] = np.linspace(1, 0.1, self.num_particles) # Linear decrease in charge\n\n    def calculate_forces(self):\n        forces = np.zeros((self.num_particles, self.dim))\n        for i in range(self.num_particles):\n            for j in range(self.num_particles):\n                if i != j:\n                    distance = self.positions[j] - self.positions[i]\n                    magnitude = (self.charges[i] * self.charges[j]) / (np.linalg.norm(distance)**2 + 1e-8)  # Adding a small value to avoid division by zero\n                    forces[i] += magnitude * distance\n        return forces\n\n    def update_positions(self, forces, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        inertia = 0.7\n        damping = 0.9  # Damping factor for velocity\n\n        for i in range(self.num_particles):\n            self.velocities[i] = inertia * self.velocities[i] + forces[i] + np.random.rand(self.dim)*(self.best_position-self.positions[i])\n            self.velocities[i] *= damping\n            self.positions[i] += self.velocities[i]\n\n            # Boundary Handling (Reflection)\n            for d in range(self.dim):\n                if self.positions[i, d] < lb:\n                    self.positions[i, d] = lb + np.abs(self.positions[i, d] - lb)\n                    self.velocities[i,d] = -self.velocities[i,d]*self.repulsion_factor  #Reverse velocity and add repulsion\n                elif self.positions[i, d] > ub:\n                    self.positions[i, d] = ub - np.abs(self.positions[i, d] - ub)\n                    self.velocities[i,d] = -self.velocities[i,d]*self.repulsion_factor #Reverse velocity and add repulsion\n\n\n            self.positions[i] = np.clip(self.positions[i], lb, ub)  # Ensure positions stay within bounds\n\n    def __call__(self, func):\n        self.initialize(func)\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            self.calculate_charges()\n            forces = self.calculate_forces()\n            self.update_positions(forces, func)\n\n            # Evaluate fitness of new positions\n            for i in range(self.num_particles):\n                self.fitness[i] = func(self.positions[i])\n                eval_count += 1\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_position = self.positions[i].copy()\n                    \n                if eval_count >= self.budget:\n                    break\n\n\n        return self.best_fitness, self.best_position\n```", "operator": "random_new", "theta_sampled": 0.04799062342802313, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "4cb25d2d-aa52-4786-95aa-17ba88b657ab", "fitness": 0.0, "name": "LevyGaussianExploration", "description": "An algorithm that uses a combination of Levy flight and Gaussian mutation to explore the search space and converges by reducing the mutation step size and standard deviation of levy flight.", "code": "import numpy as np\n\nclass LevyGaussianExploration:\n    def __init__(self, budget=10000, dim=10, levy_exponent=1.5, gaussian_scale=0.1):\n        \"\"\"\n        Initializes the LevyGaussianExploration optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            levy_exponent (float): The exponent for the Levy flight distribution.  Controls the step size distribution.\n            gaussian_scale (float): Initial scale for the Gaussian mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.levy_exponent = levy_exponent\n        self.gaussian_scale = gaussian_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.population_size = 50  # Define population size\n\n    def levy_flight(self, beta):\n        \"\"\"\n        Generates a Levy flight step.\n\n        Args:\n            beta (float):  Parameter controlling the Levy distribution.\n\n        Returns:\n            numpy.ndarray: A Levy flight step.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the LevyGaussianExploration algorithm.\n\n        Args:\n            func (callable): The function to optimize.  Must accept a numpy array of dimension `self.dim` and return a float.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize the population\n        population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.population_size\n\n        # Find the initial best solution\n        best_index = np.argmin(fitness)\n        self.x_opt = population[best_index]\n        self.f_opt = fitness[best_index]\n\n        while eval_count < self.budget:\n            # Adaptive scaling\n            remaining_evaluations = self.budget - eval_count\n            scale_reduction_factor = remaining_evaluations / self.budget\n            current_gaussian_scale = self.gaussian_scale * scale_reduction_factor\n            current_levy_exponent = self.levy_exponent #keep constant, no visible benefits in adaptation\n\n            for i in range(self.population_size):\n                # Levy flight exploration\n                levy_step = self.levy_flight(current_levy_exponent)\n                new_position_levy = population[i] + levy_step * current_gaussian_scale #Using gaussian_scale as step size\n                new_position_levy = np.clip(new_position_levy, self.lb, self.ub)\n\n                # Gaussian mutation\n                new_position_gaussian = population[i] + np.random.normal(0, current_gaussian_scale, self.dim)\n                new_position_gaussian = np.clip(new_position_gaussian, self.lb, self.ub)\n\n                # Evaluate both new positions\n                f_levy = func(new_position_levy)\n                f_gaussian = func(new_position_gaussian)\n                eval_count += 2\n\n                # Select the better position and update\n                if f_levy < fitness[i] and f_levy <= f_gaussian:\n                    population[i] = new_position_levy\n                    fitness[i] = f_levy\n                elif f_gaussian < fitness[i]:\n                    population[i] = new_position_gaussian\n                    fitness[i] = f_gaussian\n\n                # Update the best solution found so far\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = population[i]\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that uses a combination of Levy flight and Gaussian mutation to explore the search space and converges by reducing the mutation step size and standard deviation of levy flight.\n# Code: \n```python\nimport numpy as np\n\nclass LevyGaussianExploration:\n    def __init__(self, budget=10000, dim=10, levy_exponent=1.5, gaussian_scale=0.1):\n        \"\"\"\n        Initializes the LevyGaussianExploration optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            levy_exponent (float): The exponent for the Levy flight distribution.  Controls the step size distribution.\n            gaussian_scale (float): Initial scale for the Gaussian mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.levy_exponent = levy_exponent\n        self.gaussian_scale = gaussian_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.population_size = 50  # Define population size\n\n    def levy_flight(self, beta):\n        \"\"\"\n        Generates a Levy flight step.\n\n        Args:\n            beta (float):  Parameter controlling the Levy distribution.\n\n        Returns:\n            numpy.ndarray: A Levy flight step.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the LevyGaussianExploration algorithm.\n\n        Args:\n            func (callable): The function to optimize.  Must accept a numpy array of dimension `self.dim` and return a float.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize the population\n        population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.population_size\n\n        # Find the initial best solution\n        best_index = np.argmin(fitness)\n        self.x_opt = population[best_index]\n        self.f_opt = fitness[best_index]\n\n        while eval_count < self.budget:\n            # Adaptive scaling\n            remaining_evaluations = self.budget - eval_count\n            scale_reduction_factor = remaining_evaluations / self.budget\n            current_gaussian_scale = self.gaussian_scale * scale_reduction_factor\n            current_levy_exponent = self.levy_exponent #keep constant, no visible benefits in adaptation\n\n            for i in range(self.population_size):\n                # Levy flight exploration\n                levy_step = self.levy_flight(current_levy_exponent)\n                new_position_levy = population[i] + levy_step * current_gaussian_scale #Using gaussian_scale as step size\n                new_position_levy = np.clip(new_position_levy, self.lb, self.ub)\n\n                # Gaussian mutation\n                new_position_gaussian = population[i] + np.random.normal(0, current_gaussian_scale, self.dim)\n                new_position_gaussian = np.clip(new_position_gaussian, self.lb, self.ub)\n\n                # Evaluate both new positions\n                f_levy = func(new_position_levy)\n                f_gaussian = func(new_position_gaussian)\n                eval_count += 2\n\n                # Select the better position and update\n                if f_levy < fitness[i] and f_levy <= f_gaussian:\n                    population[i] = new_position_levy\n                    fitness[i] = f_levy\n                elif f_gaussian < fitness[i]:\n                    population[i] = new_position_gaussian\n                    fitness[i] = f_gaussian\n\n                # Update the best solution found so far\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = population[i]\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.010401199454839192, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "2a75d533-5433-4adb-968a-22b420b9c1ef", "fitness": 0.3427015478223966, "name": "JumpAndGaussianSearch", "description": "Population-based algorithm that combines exploration through random jumps with exploitation of promising regions using a Gaussian-based local search.", "code": "import numpy as np\n\nclass JumpAndGaussianSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, jump_prob=0.1, gaussian_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.jump_prob = jump_prob\n        self.gaussian_scale = gaussian_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration: Random Jump\n                if np.random.rand() < self.jump_prob:\n                    x_new = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                \n                # Exploitation: Gaussian Local Search\n                else:\n                    x_new = population[i] + np.random.normal(0, self.gaussian_scale, size=self.dim)\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(x_new)\n                self.budget -= 1\n                \n                if f_new < fitness[i]:\n                    fitness[i] = f_new\n                    population[i] = x_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm JumpAndGaussianSearch scored 0.343 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines exploration through random jumps with exploitation of promising regions using a Gaussian-based local search.\n# Code:\n```python\nimport numpy as np\n\nclass JumpAndGaussianSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, jump_prob=0.1, gaussian_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.jump_prob = jump_prob\n        self.gaussian_scale = gaussian_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration: Random Jump\n                if np.random.rand() < self.jump_prob:\n                    x_new = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                \n                # Exploitation: Gaussian Local Search\n                else:\n                    x_new = population[i] + np.random.normal(0, self.gaussian_scale, size=self.dim)\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(x_new)\n                self.budget -= 1\n                \n                if f_new < fitness[i]:\n                    fitness[i] = f_new\n                    population[i] = x_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11151095735300554, 0.19678870606995047, 0.3846014936739963, 0.41394821425878314, 0.18677657569316364, 0.3580036656420731, 0.2376343425879529, 0.30611909089305034, 0.2237912810574164, 0.17974665545975477, 0.41018298336721715, 0.9423534473463226, 0.2709153411861106, 0.20597260839078835, 0.6987895482213606, 0.32460580869856615, 0.2514096112176868, 0.5010545599257723, 0.18934301449644297, 0.46048305090851704], "operator": "random_new", "theta_sampled": 0.007175288962277086, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "eafbaad4-4023-4a1c-9824-66f2beb10d4b", "fitness": 0.0, "name": "ShrinkingMutationPSO", "description": "An algorithm that combines particle swarm optimization with a shrinking search space and a mutation operator to escape local optima.", "code": "import numpy as np\n\nclass ShrinkingMutationPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, shrink_factor=0.99, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.shrink_factor = shrink_factor\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        swarm = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb) / 2, abs(ub - lb) / 2, size=(self.swarm_size, self.dim))\n        \n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        \n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n        \n        eval_count = self.swarm_size\n\n        # Shrinking bounds\n        current_lb = lb\n        current_ub = ub\n        \n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            \n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            swarm = swarm + velocities\n            \n            # Apply bounds\n            swarm = np.clip(swarm, current_lb, current_ub)\n\n            # Mutation operator\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_dim = np.random.randint(0, self.dim)\n                    swarm[i, mutation_dim] = np.random.uniform(current_lb, current_ub)\n\n            # Evaluate fitness\n            fitnesses = np.array([func(x) for x in swarm])\n            eval_count += self.swarm_size\n\n            # Update personal bests\n            for i in range(self.swarm_size):\n                if fitnesses[i] < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitnesses[i]\n                    personal_best_positions[i] = swarm[i].copy()\n                    \n                    # Update global best\n                    if fitnesses[i] < global_best_fitness:\n                        global_best_fitness = fitnesses[i]\n                        global_best_position = swarm[i].copy()\n            \n            # Shrink search space\n            current_lb = global_best_position - (ub - lb) / 2 * self.shrink_factor\n            current_ub = global_best_position + (ub - lb) / 2 * self.shrink_factor\n            current_lb = np.maximum(current_lb, lb)\n            current_ub = np.minimum(current_ub, ub)\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that combines particle swarm optimization with a shrinking search space and a mutation operator to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass ShrinkingMutationPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, shrink_factor=0.99, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.shrink_factor = shrink_factor\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        swarm = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb) / 2, abs(ub - lb) / 2, size=(self.swarm_size, self.dim))\n        \n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        \n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n        \n        eval_count = self.swarm_size\n\n        # Shrinking bounds\n        current_lb = lb\n        current_ub = ub\n        \n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            \n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            swarm = swarm + velocities\n            \n            # Apply bounds\n            swarm = np.clip(swarm, current_lb, current_ub)\n\n            # Mutation operator\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_dim = np.random.randint(0, self.dim)\n                    swarm[i, mutation_dim] = np.random.uniform(current_lb, current_ub)\n\n            # Evaluate fitness\n            fitnesses = np.array([func(x) for x in swarm])\n            eval_count += self.swarm_size\n\n            # Update personal bests\n            for i in range(self.swarm_size):\n                if fitnesses[i] < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitnesses[i]\n                    personal_best_positions[i] = swarm[i].copy()\n                    \n                    # Update global best\n                    if fitnesses[i] < global_best_fitness:\n                        global_best_fitness = fitnesses[i]\n                        global_best_position = swarm[i].copy()\n            \n            # Shrink search space\n            current_lb = global_best_position - (ub - lb) / 2 * self.shrink_factor\n            current_ub = global_best_position + (ub - lb) / 2 * self.shrink_factor\n            current_lb = np.maximum(current_lb, lb)\n            current_ub = np.minimum(current_ub, ub)\n            \n        return global_best_fitness, global_best_position\n```", "operator": "random_new", "theta_sampled": -0.0008784295896173133, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "216bb3d4-f084-4592-9ca8-fcfa52b89079", "fitness": 0.0, "name": "HybridCMA_DE_SOS", "description": "A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Symbiotic Organisms Search with adaptive parameter control.", "code": "import numpy as np\n\nclass HybridCMA_DE_SOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1,\n                 mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Mutualism, Commensalism, and Parasitism phases from SOS\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, self.lb, self.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            self.eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm HybridCMA_DE_SOS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "7d8de8ed-1f4f-4f28-8a0a-67e58429af75"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Symbiotic Organisms Search with adaptive parameter control.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMA_DE_SOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1,\n                 mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Mutualism, Commensalism, and Parasitism phases from SOS\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, self.lb, self.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            self.eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.12251656400181199, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "19dc8fba-ec6a-45bd-b77c-f2b9308c7693", "fitness": 0.0, "name": "AdaptiveHybridOptimizer", "description": "An adaptive population-based algorithm that combines elements of differential evolution, particle swarm optimization, and simulated annealing, adjusting parameters based on observed performance.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.5, pso_rate=0.3, sa_rate=0.2, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate  # Proportion of DE updates\n        self.pso_rate = pso_rate # Proportion of PSO updates\n        self.sa_rate = sa_rate # Proportion of SA updates\n        self.cooling_rate = cooling_rate\n        self.temperature = 1.0\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.best_positions = self.population.copy()\n\n        self.global_best_fitness = np.min(self.fitness)\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n\n\n    def differential_evolution(self, func, lb, ub):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.de_rate:\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                F = np.random.uniform(0.0, 1.0)\n                CR = np.random.uniform(0.0, 1.0)\n\n                trial_vector = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(self.dim):\n                        trial_vector[j] = a[j] + F * (b[j] - c[j])\n\n                trial_vector = np.clip(trial_vector, lb, ub)\n                trial_fitness = func(trial_vector)\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = trial_fitness\n\n                    if trial_fitness < np.min(self.fitness):\n                        self.best_positions[i] = trial_vector\n                    \n                    if trial_fitness < self.global_best_fitness:\n                        self.global_best_fitness = trial_fitness\n                        self.global_best_position = trial_vector.copy()\n\n\n    def particle_swarm_optimization(self, func, lb, ub):\n        w = 0.7  # Inertia weight\n        c1 = 1.5 # Cognitive coefficient\n        c2 = 1.5 # Social coefficient\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_rate:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.velocities[i] = w * self.velocities[i] + \\\n                                 c1 * r1 * (self.best_positions[i] - self.population[i]) + \\\n                                 c2 * r2 * (self.global_best_position - self.population[i])\n\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], lb, ub)\n\n                fitness = func(self.population[i])\n\n                if fitness < self.fitness[i]:\n                    self.fitness[i] = fitness\n                    if fitness < np.min(self.fitness):\n                        self.best_positions[i] = self.population[i].copy()\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.population[i].copy()\n\n\n    def simulated_annealing(self, func, lb, ub):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.sa_rate:\n                neighbor = self.population[i] + np.random.normal(0, 0.1, size=self.dim)\n                neighbor = np.clip(neighbor, lb, ub)\n\n                neighbor_fitness = func(neighbor)\n                delta_e = neighbor_fitness - self.fitness[i]\n\n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temperature):\n                    self.population[i] = neighbor\n                    self.fitness[i] = neighbor_fitness\n\n                    if neighbor_fitness < np.min(self.fitness):\n                        self.best_positions[i] = neighbor.copy()\n                    if neighbor_fitness < self.global_best_fitness:\n                        self.global_best_fitness = neighbor_fitness\n                        self.global_best_position = neighbor.copy()\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        self.initialize(func)\n\n        eval_count = self.pop_size  # Initial population evaluation\n\n        while eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.particle_swarm_optimization(func, lb, ub)\n            self.simulated_annealing(func, lb, ub)\n\n            self.temperature *= self.cooling_rate\n            eval_count = np.count_nonzero(self.fitness != np.inf) + self.pop_size #Correctly updates eval count based on calls in individual methods\n\n            if eval_count > self.budget:\n                break #Ensures we don't exceed the budget\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that combines elements of differential evolution, particle swarm optimization, and simulated annealing, adjusting parameters based on observed performance.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.5, pso_rate=0.3, sa_rate=0.2, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate  # Proportion of DE updates\n        self.pso_rate = pso_rate # Proportion of PSO updates\n        self.sa_rate = sa_rate # Proportion of SA updates\n        self.cooling_rate = cooling_rate\n        self.temperature = 1.0\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.best_positions = self.population.copy()\n\n        self.global_best_fitness = np.min(self.fitness)\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n\n\n    def differential_evolution(self, func, lb, ub):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.de_rate:\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                F = np.random.uniform(0.0, 1.0)\n                CR = np.random.uniform(0.0, 1.0)\n\n                trial_vector = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(self.dim):\n                        trial_vector[j] = a[j] + F * (b[j] - c[j])\n\n                trial_vector = np.clip(trial_vector, lb, ub)\n                trial_fitness = func(trial_vector)\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = trial_fitness\n\n                    if trial_fitness < np.min(self.fitness):\n                        self.best_positions[i] = trial_vector\n                    \n                    if trial_fitness < self.global_best_fitness:\n                        self.global_best_fitness = trial_fitness\n                        self.global_best_position = trial_vector.copy()\n\n\n    def particle_swarm_optimization(self, func, lb, ub):\n        w = 0.7  # Inertia weight\n        c1 = 1.5 # Cognitive coefficient\n        c2 = 1.5 # Social coefficient\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_rate:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.velocities[i] = w * self.velocities[i] + \\\n                                 c1 * r1 * (self.best_positions[i] - self.population[i]) + \\\n                                 c2 * r2 * (self.global_best_position - self.population[i])\n\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], lb, ub)\n\n                fitness = func(self.population[i])\n\n                if fitness < self.fitness[i]:\n                    self.fitness[i] = fitness\n                    if fitness < np.min(self.fitness):\n                        self.best_positions[i] = self.population[i].copy()\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.population[i].copy()\n\n\n    def simulated_annealing(self, func, lb, ub):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.sa_rate:\n                neighbor = self.population[i] + np.random.normal(0, 0.1, size=self.dim)\n                neighbor = np.clip(neighbor, lb, ub)\n\n                neighbor_fitness = func(neighbor)\n                delta_e = neighbor_fitness - self.fitness[i]\n\n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temperature):\n                    self.population[i] = neighbor\n                    self.fitness[i] = neighbor_fitness\n\n                    if neighbor_fitness < np.min(self.fitness):\n                        self.best_positions[i] = neighbor.copy()\n                    if neighbor_fitness < self.global_best_fitness:\n                        self.global_best_fitness = neighbor_fitness\n                        self.global_best_position = neighbor.copy()\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        self.initialize(func)\n\n        eval_count = self.pop_size  # Initial population evaluation\n\n        while eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.particle_swarm_optimization(func, lb, ub)\n            self.simulated_annealing(func, lb, ub)\n\n            self.temperature *= self.cooling_rate\n            eval_count = np.count_nonzero(self.fitness != np.inf) + self.pop_size #Correctly updates eval count based on calls in individual methods\n\n            if eval_count > self.budget:\n                break #Ensures we don't exceed the budget\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.01511395711654672, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "d837eef0-7b16-42ed-9d4f-507fc07cd807", "fitness": 0.31006964975804296, "name": "HybridCMA_DE_ASOS", "description": "Hybrid optimization algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Adaptive Symbiotic Organisms Search.", "code": "import numpy as np\n\nclass HybridCMA_DE_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None # Population\n        self.F = None # Population Fitness\n        self.eval_count = 0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, self.lb, self.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            self.eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n            self.sigma = np.clip(self.sigma, 0.01, 1) # Clip sigma to prevent it from becoming too small or large\n\n            # Adaptive Symbiotic Organisms Search - Parasitism Phase\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                parasite = np.copy(self.X[i])\n\n                # Self-adaptive mutation\n                num_changes = np.random.binomial(self.dim, self.mutation_rate)\n                indices = np.random.choice(self.dim, num_changes, replace=False)\n                parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n                j = np.random.randint(0, self.pop_size)\n\n                if self.eval_count < self.budget:\n                    fitness_parasite = func(parasite)\n                    self.eval_count += 1\n\n                    if fitness_parasite < self.F[j]:\n                        self.X[j] = parasite\n                        self.F[j] = fitness_parasite\n            \n            self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n            self.mutation_rate = max(self.mutation_rate, 0.01) # Clip the mutation rate\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm HybridCMA_DE_ASOS scored 0.310 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "7d8de8ed-1f4f-4f28-8a0a-67e58429af75"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid optimization algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Adaptive Symbiotic Organisms Search.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMA_DE_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None # Population\n        self.F = None # Population Fitness\n        self.eval_count = 0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, self.lb, self.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            self.eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n            self.sigma = np.clip(self.sigma, 0.01, 1) # Clip sigma to prevent it from becoming too small or large\n\n            # Adaptive Symbiotic Organisms Search - Parasitism Phase\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                parasite = np.copy(self.X[i])\n\n                # Self-adaptive mutation\n                num_changes = np.random.binomial(self.dim, self.mutation_rate)\n                indices = np.random.choice(self.dim, num_changes, replace=False)\n                parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n                j = np.random.randint(0, self.pop_size)\n\n                if self.eval_count < self.budget:\n                    fitness_parasite = func(parasite)\n                    self.eval_count += 1\n\n                    if fitness_parasite < self.F[j]:\n                        self.X[j] = parasite\n                        self.F[j] = fitness_parasite\n            \n            self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n            self.mutation_rate = max(self.mutation_rate, 0.01) # Clip the mutation rate\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1562927101435787, 0.178457629931136, 0.3533535971525693, 0.16684078586879003, 0.231441975823797, 0.3269894519592699, 0.33447598078687957, 0.24533156916257226, 0.23587852331641102, 0.15799217034751123, 0.22551129730205588, 0.9615196845190664, 0.2489488909006592, 0.23253491847087493, 0.5955563472158165, 0.3212079439631542, 0.2958685972156867, 0.32526529826830397, 0.14634686617830261, 0.46157875663442416], "operator": "crossover", "theta_sampled": 0.14484375033060395, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "52c58168-5320-4d6c-b19e-51431c9536fd", "fitness": 0.0, "name": "AdaptiveDE_NM", "description": "A novel hybrid algorithm combining the exploration of differential evolution with the exploitation of a Nelder-Mead simplex, adaptively switching between them based on performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, de_popsize=20, nm_n_restarts=2):\n        self.budget = budget\n        self.dim = dim\n        self.de_popsize = de_popsize\n        self.nm_n_restarts = nm_n_restarts\n        self.de_fraction = 0.7  # Fraction of budget for DE\n        self.nm_fraction = 1.0 - self.de_fraction\n\n    def differential_evolution(self, func, budget_de):\n        popsize = self.de_popsize\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(popsize, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        budget_spent = popsize # each individual is a call to func\n        \n        CR = 0.7\n        F = 0.8\n        \n        while budget_spent < budget_de:\n            for i in range(popsize):\n                if budget_spent >= budget_de:\n                    break\n                idxs = [idx for idx in range(popsize) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                mutant = pop[a] + F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                trial = np.copy(pop[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == jrand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                budget_spent += 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial\n        \n        best_index = np.argmin(fitness)\n        return fitness[best_index], pop[best_index]\n\n    def nelder_mead(self, func, x0, budget_nm):\n        bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        \n        res = minimize(func, x0, method='Nelder-Mead', options={'maxiter': budget_nm // (self.dim + 1)}, bounds=bounds)\n        \n        return res.fun, res.x\n\n    def __call__(self, func):\n        budget_de = int(self.budget * self.de_fraction)\n        budget_nm = int(self.budget * self.nm_fraction)\n        \n        f_opt_de, x_opt_de = self.differential_evolution(func, budget_de)\n        \n        f_opt = f_opt_de\n        x_opt = x_opt_de\n        \n        # Restart Nelder-Mead multiple times from the DE solution\n        for _ in range(self.nm_n_restarts):\n          f_nm, x_nm = self.nelder_mead(func, x_opt_de, budget_nm // self.nm_n_restarts)\n          if f_nm < f_opt:\n              f_opt = f_nm\n              x_opt = x_nm\n        \n        return f_opt, x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A novel hybrid algorithm combining the exploration of differential evolution with the exploitation of a Nelder-Mead simplex, adaptively switching between them based on performance.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, de_popsize=20, nm_n_restarts=2):\n        self.budget = budget\n        self.dim = dim\n        self.de_popsize = de_popsize\n        self.nm_n_restarts = nm_n_restarts\n        self.de_fraction = 0.7  # Fraction of budget for DE\n        self.nm_fraction = 1.0 - self.de_fraction\n\n    def differential_evolution(self, func, budget_de):\n        popsize = self.de_popsize\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(popsize, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        budget_spent = popsize # each individual is a call to func\n        \n        CR = 0.7\n        F = 0.8\n        \n        while budget_spent < budget_de:\n            for i in range(popsize):\n                if budget_spent >= budget_de:\n                    break\n                idxs = [idx for idx in range(popsize) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                mutant = pop[a] + F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                trial = np.copy(pop[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == jrand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                budget_spent += 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial\n        \n        best_index = np.argmin(fitness)\n        return fitness[best_index], pop[best_index]\n\n    def nelder_mead(self, func, x0, budget_nm):\n        bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        \n        res = minimize(func, x0, method='Nelder-Mead', options={'maxiter': budget_nm // (self.dim + 1)}, bounds=bounds)\n        \n        return res.fun, res.x\n\n    def __call__(self, func):\n        budget_de = int(self.budget * self.de_fraction)\n        budget_nm = int(self.budget * self.nm_fraction)\n        \n        f_opt_de, x_opt_de = self.differential_evolution(func, budget_de)\n        \n        f_opt = f_opt_de\n        x_opt = x_opt_de\n        \n        # Restart Nelder-Mead multiple times from the DE solution\n        for _ in range(self.nm_n_restarts):\n          f_nm, x_nm = self.nelder_mead(func, x_opt_de, budget_nm // self.nm_n_restarts)\n          if f_nm < f_opt:\n              f_opt = f_nm\n              x_opt = x_nm\n        \n        return f_opt, x_opt\n```", "operator": "random_new", "theta_sampled": 0.020327730047269576, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "c097e952-666c-4aa0-b108-abd1271160b6", "fitness": 0.0, "name": "AgingCovarianceMatrixDE", "description": "Covariance Matrix Adaptation with aging population and momentum-based sigma adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AgingCovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, age_limit=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.ages = None # Population Ages\n        self.age_limit = age_limit\n        self.sigma_momentum = np.zeros_like(self.sigma)\n        self.momentum_beta = 0.9\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.ages = np.zeros(self.pop_size)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection and Aging\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n                    self.ages[i] = 0 # Reset age\n                else:\n                    self.ages[i] += 1\n\n            # Replace old individuals\n            for i in range(self.pop_size):\n                if self.ages[i] > self.age_limit:\n                    self.X[i] = np.random.normal(loc=self.mu, scale=self.sigma, size=self.dim)\n                    self.X[i] = np.clip(self.X[i], func.bounds.lb, func.bounds.ub)\n                    self.F[i] = func(self.X[i])\n                    eval_count += 1\n                    self.ages[i] = 0\n            \n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size with momentum\n            diff = self.mu - x_mean\n            sigma_update = self.c_cov * np.linalg.norm(diff)\n            self.sigma_momentum = self.momentum_beta * self.sigma_momentum + (1 - self.momentum_beta) * sigma_update\n            self.sigma = self.sigma * (1 + self.sigma_momentum) #Using Momentum\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AgingCovarianceMatrixDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278"], "operator": "mutation", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation with aging population and momentum-based sigma adaptation for enhanced exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AgingCovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, age_limit=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.ages = None # Population Ages\n        self.age_limit = age_limit\n        self.sigma_momentum = np.zeros_like(self.sigma)\n        self.momentum_beta = 0.9\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.ages = np.zeros(self.pop_size)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection and Aging\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n                    self.ages[i] = 0 # Reset age\n                else:\n                    self.ages[i] += 1\n\n            # Replace old individuals\n            for i in range(self.pop_size):\n                if self.ages[i] > self.age_limit:\n                    self.X[i] = np.random.normal(loc=self.mu, scale=self.sigma, size=self.dim)\n                    self.X[i] = np.clip(self.X[i], func.bounds.lb, func.bounds.ub)\n                    self.F[i] = func(self.X[i])\n                    eval_count += 1\n                    self.ages[i] = 0\n            \n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size with momentum\n            diff = self.mu - x_mean\n            sigma_update = self.c_cov * np.linalg.norm(diff)\n            self.sigma_momentum = self.momentum_beta * self.sigma_momentum + (1 - self.momentum_beta) * sigma_update\n            self.sigma = self.sigma * (1 + self.sigma_momentum) #Using Momentum\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.13883055373482728, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "fd22298d-25ab-4fe7-9bda-d09bcdeac6d4", "fitness": 0.13956341345579934, "name": "AdaptiveHybridCMAES_SOS", "description": "A hybrid algorithm combining CMA-ES with a modified Symbiotic Organisms Search (SOS) incorporating a self-adaptive learning rate and dynamic population size adjustment.", "code": "import numpy as np\n\nclass AdaptiveHybridCMAES_SOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, sos_prob=0.3, lr=0.1, pop_resize_freq=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population (CMA) / Organisms (SOS)\n        self.F = None  # Population Fitness\n        self.eval_count = 0\n        self.sos_prob = sos_prob  # Probability of performing SOS phases\n        self.lb = -5.0\n        self.ub = 5.0\n        self.lr = lr #Learning rate for CMAES\n        self.pop_resize_freq = pop_resize_freq #frequency for population resizing\n        self.generation = 0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor - adaptive based on fitness\n            BF1 = 1 + np.random.rand() * (self.F[j] - self.F[i])  #Adaptive BF1\n            BF2 = 1 + np.random.rand() * (self.F[i] - self.F[j])  #Adaptive BF2\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.X[i])\n\n            # Randomly change some dimensions of the parasite - adaptive change\n            num_changes = np.random.randint(1, int(np.sqrt(self.dim)) + 1) #fewer changes\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            self.generation += 1\n\n            # SOS phases with probability sos_prob\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                #Mutation and Crossover (Differential Evolution) - CMA part\n\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + self.lr * (x_r1 - x_r2)  #DE Mutation - Adaptive Learning Rate\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, self.lb, self.ub)\n\n                # Evaluation\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                # Selection\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n            \n            #Adaptive Learning Rate Adjustment\n            if self.generation % 10 == 0:\n                improvement = self.f_opt - self.F[best_idx]\n                if improvement > 0:\n                    self.lr *= 1.05 #Increase learning rate if improving\n                else:\n                    self.lr *= 0.95 #Decrease learning rate if not improving\n\n            #Population resizing\n            if self.generation % self.pop_resize_freq == 0:\n                if self.F.std() < 0.01: #If population is converging quickly, increase population size\n                    self.pop_size = min(self.pop_size * 2, self.dim*10)\n                    self.X, self.F = self.sample(func) #Resample population with new size\n                elif self.F.std() > 1.0: #If population is too diverse, decrease population size\n                    self.pop_size = max(4 + int(3 * np.log(self.dim)), self.pop_size // 2)\n                    self.X, self.F = self.sample(func) #Resample population with new size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridCMAES_SOS scored 0.140 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0746a5e1-4f33-447a-b99b-29395fcb75b0"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid algorithm combining CMA-ES with a modified Symbiotic Organisms Search (SOS) incorporating a self-adaptive learning rate and dynamic population size adjustment.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridCMAES_SOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, sos_prob=0.3, lr=0.1, pop_resize_freq=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population (CMA) / Organisms (SOS)\n        self.F = None  # Population Fitness\n        self.eval_count = 0\n        self.sos_prob = sos_prob  # Probability of performing SOS phases\n        self.lb = -5.0\n        self.ub = 5.0\n        self.lr = lr #Learning rate for CMAES\n        self.pop_resize_freq = pop_resize_freq #frequency for population resizing\n        self.generation = 0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Calculate mutual benefit factor - adaptive based on fitness\n            BF1 = 1 + np.random.rand() * (self.F[j] - self.F[i])  #Adaptive BF1\n            BF2 = 1 + np.random.rand() * (self.F[i] - self.F[j])  #Adaptive BF2\n\n            # Calculate mean of the two organisms\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Generate new solutions based on mutualism\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            # Clip the new solutions to the search space\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            # Evaluate the new solutions\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random organism (excluding itself)\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            # Generate new solution based on commensalism\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n\n            # Clip the new solution to the search space\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            # Evaluate the new solution\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Create a parasite (copy of an organism)\n            parasite = np.copy(self.X[i])\n\n            # Randomly change some dimensions of the parasite - adaptive change\n            num_changes = np.random.randint(1, int(np.sqrt(self.dim)) + 1) #fewer changes\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            # Select a random organism to be the host\n            j = np.random.randint(0, self.pop_size)\n\n            # Evaluate the parasite\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                # Replace the host if the parasite is better\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            self.generation += 1\n\n            # SOS phases with probability sos_prob\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                #Mutation and Crossover (Differential Evolution) - CMA part\n\n                mutated_X = np.zeros_like(self.X)\n                for i in range(self.pop_size):\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.X[idxs]\n                    mutated_X[i] = self.X[i] + self.lr * (x_r1 - x_r2)  #DE Mutation - Adaptive Learning Rate\n\n                cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n                trial_X = np.where(cross_points, mutated_X, self.X)\n                trial_X = np.clip(trial_X, self.lb, self.ub)\n\n                # Evaluation\n                trial_F = np.array([func(x) for x in trial_X])\n                self.eval_count += self.pop_size\n\n                # Selection\n                for i in range(self.pop_size):\n                    if trial_F[i] < self.F[i]:\n                        self.X[i] = trial_X[i]\n                        self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n            \n            #Adaptive Learning Rate Adjustment\n            if self.generation % 10 == 0:\n                improvement = self.f_opt - self.F[best_idx]\n                if improvement > 0:\n                    self.lr *= 1.05 #Increase learning rate if improving\n                else:\n                    self.lr *= 0.95 #Decrease learning rate if not improving\n\n            #Population resizing\n            if self.generation % self.pop_resize_freq == 0:\n                if self.F.std() < 0.01: #If population is converging quickly, increase population size\n                    self.pop_size = min(self.pop_size * 2, self.dim*10)\n                    self.X, self.F = self.sample(func) #Resample population with new size\n                elif self.F.std() > 1.0: #If population is too diverse, decrease population size\n                    self.pop_size = max(4 + int(3 * np.log(self.dim)), self.pop_size // 2)\n                    self.X, self.F = self.sample(func) #Resample population with new size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16707023257893072, 0.25162000778846727, 0], "operator": "mutation", "theta_sampled": 0.1631380448822228, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "998cb61e-4607-4ac1-93a2-c1f66a5559f6", "fitness": 0.3271688877553856, "name": "HybridCMAES_ASOS", "description": "A hybrid algorithm combining Covariance Matrix Adaptation with Adaptive Symbiotic Organisms Search for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCMAES_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None\n        self.F = None\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Symbiotic Organisms Search Phases\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridCMAES_ASOS scored 0.327 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "7d8de8ed-1f4f-4f28-8a0a-67e58429af75"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Covariance Matrix Adaptation with Adaptive Symbiotic Organisms Search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None\n        self.F = None\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Symbiotic Organisms Search Phases\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1253625608074591, 0.17703344377758623, 0.31135554851619895, 0.4266976218283345, 0.25752863371552526, 0.27292789688992547, 0.2755304892945344, 0.2878371677360868, 0.24756732183025842, 0.16278472350642914, 0.20090756431459522, 0.9728875877126277, 0.2580259830312578, 0.22835230663081607, 0.6691858084635653, 0.3531850775161576, 0.2837229452840433, 0.3687162110804535, 0.20668823483762366, 0.45708062833423324], "operator": "crossover", "theta_sampled": 0.22527174017375398, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "ff3e4712-412e-4157-a0e4-392644074ec8", "fitness": 0.33269226379843253, "name": "HybridCMA_DE_ASOS", "description": "A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Adaptive Symbiotic Organisms Search for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCMA_DE_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob = 0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim)) #CMA-ES + DE\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate #ASOS\n        self.mutation_decay = mutation_decay #ASOS\n        self.BF_prob = BF_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialization (CMA-ES)\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, self.lb, self.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            self.eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n            # Symbiotic Organisms Search (ASOS) phases\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n           \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridCMA_DE_ASOS scored 0.333 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "7d8de8ed-1f4f-4f28-8a0a-67e58429af75"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Adaptive Symbiotic Organisms Search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMA_DE_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob = 0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim)) #CMA-ES + DE\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate #ASOS\n        self.mutation_decay = mutation_decay #ASOS\n        self.BF_prob = BF_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialization (CMA-ES)\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + 0.5 * (x_r1 - x_r2)  #DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5 #Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, self.lb, self.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            self.eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n            # Symbiotic Organisms Search (ASOS) phases\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n           \n        return self.f_opt, self.x_opt\n```", "aucs": [0.10416850484534534, 0.22381502327738523, 0.287190794481622, 0.220909917698478, 0.2800882492095783, 0.2494198147563671, 0.29397326817019, 0.30699148473590754, 0.3243640576723834, 0.16033883351891798, 0.2959321949318853, 0.992891625221827, 0.25501590856394707, 0.22977225613659313, 0.7035422246670591, 0.39748029545396824, 0.2743605077966298, 0.3663984563343834, 0.19853673624301726, 0.48865512225316565], "operator": "crossover", "theta_sampled": 0.1275303864343008, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "d42fe26a-a6ba-4261-bc35-c2c7f95cbca4", "fitness": 0.573138409615035, "name": "AdaptivePSO_DE", "description": "A population-based algorithm that uses a simplified particle swarm optimization (PSO) variant with adaptive velocity clamping and a local search operator based on differential evolution mutation to improve exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSO_DE scored 0.573 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a simplified particle swarm optimization (PSO) variant with adaptive velocity clamping and a local search operator based on differential evolution mutation to improve exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.14778357779423335, 0.5807582972413969, 0.6709866750819944, 0.8715768704094911, 0.7227694129348363, 0.7750606053828453, 0.3227495030314218, 0.5099431544227593, 0.7182649985487395, 0.2327488063579719, 0.847470557130034, 0.9972629552845176, 0.2715621324286883, 0.27108250119384436, 0.6697237165112913, 0.6244647899160709, 0.6344352261040387, 0.8567707872760966, 0.25282239999687606, 0.48453122525355297], "operator": "random_new", "theta_sampled": 0.0255170151366588, "reward": 0.041829864347013634, "generation": 6}, "task_prompt": ""}
{"id": "eb51c6a6-eaae-45a8-a589-e7004b44e9ae", "fitness": 0.4077283461874218, "name": "AdaptiveSOS_SaDE", "description": "Integrates a self-adaptive differential evolution (SaDE) strategy within the Symbiotic Organisms Search (SOS) framework, dynamically adjusting mutation strategies based on their recent success.", "code": "import numpy as np\n\nclass AdaptiveSOS_SaDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sos_prob=0.3, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sos_prob = sos_prob  # Probability of performing SOS phases\n        self.lr = lr  # Learning rate for SaDE probabilities\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.X = None\n        self.F = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # SaDE parameters: probabilities for each DE strategy\n        self.p_strategies = np.array([0.3, 0.3, 0.4])  # Initial probabilities for 3 strategies\n\n        self.successful_strategies = [[] for _ in range(3)]\n        self.memory_size = 10\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.X = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.F = np.array([func(x) for x in self.X])\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n                    self.update_best(self.X[i], self.F[i])\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n                    self.update_best(self.X[j], self.F[j])\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n                    self.update_best(self.X[i], self.F[i])\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n\n            parasite = np.copy(self.X[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n                    self.update_best(self.X[j], self.F[j])\n\n    def sade_phase(self, func):\n        trial_vectors = np.zeros((self.pop_size, self.dim))\n        trial_fitness = np.zeros(self.pop_size)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n            # Strategy selection\n            strategy_index = np.random.choice(len(self.p_strategies), p=self.p_strategies)\n\n            if strategy_index == 0:\n                # DE/rand/1\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_vector = x_r1 + 0.5 * (x_r2 - x_r3)\n            elif strategy_index == 1:\n                # DE/current-to-rand/1\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.X[idxs]\n                mutated_vector = self.X[i] + np.random.rand()*(x_r1 - self.X[i]) + np.random.rand()*(x_r2 - self.X[i])\n            else:\n                # DE/best/1\n                best_idx = np.argmin(self.F)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.X[idxs]\n                mutated_vector = self.X[best_idx] + 0.5 * (x_r1 - x_r2)\n\n            mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n\n            # Crossover (Binomial)\n            cross_points = np.random.rand(self.dim) < 0.5\n            trial_vector = np.where(cross_points, mutated_vector, self.X[i])\n            trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n            # Evaluation\n            fitness = func(trial_vector)\n            self.eval_count += 1\n\n            if fitness < self.F[i]:\n                trial_vectors[i] = trial_vector\n                trial_fitness[i] = fitness\n                self.successful_strategies[strategy_index].append(1)  # Reward strategy\n            else:\n                self.successful_strategies[strategy_index].append(0)  # Penalize strategy\n\n            if len(self.successful_strategies[strategy_index]) > self.memory_size:\n                self.successful_strategies[strategy_index].pop(0)  # Keep memory size bounded\n\n        # Selection\n        for i in range(self.pop_size):\n            if trial_vectors[i].any() and trial_fitness[i] < self.F[i]:\n                self.X[i] = trial_vectors[i]\n                self.F[i] = trial_fitness[i]\n                self.update_best(self.X[i], self.F[i])\n\n        # Update strategy probabilities\n        self.update_strategy_probabilities()\n\n    def update_strategy_probabilities(self):\n        rewards = np.array([np.mean(s) if s else 0 for s in self.successful_strategies])\n        sum_rewards = np.sum(rewards)\n\n        if sum_rewards > 0:\n            new_p_strategies = rewards / sum_rewards\n        else:\n             new_p_strategies = np.ones_like(self.p_strategies) / len(self.p_strategies)\n\n\n        self.p_strategies = (1 - self.lr) * self.p_strategies + self.lr * new_p_strategies\n        self.p_strategies /= np.sum(self.p_strategies) # Normalize\n\n    def update_best(self, x, f):\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.successful_strategies = [[] for _ in range(3)]\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                self.sade_phase(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveSOS_SaDE scored 0.408 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0746a5e1-4f33-447a-b99b-29395fcb75b0"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a self-adaptive differential evolution (SaDE) strategy within the Symbiotic Organisms Search (SOS) framework, dynamically adjusting mutation strategies based on their recent success.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveSOS_SaDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sos_prob=0.3, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sos_prob = sos_prob  # Probability of performing SOS phases\n        self.lr = lr  # Learning rate for SaDE probabilities\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.X = None\n        self.F = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # SaDE parameters: probabilities for each DE strategy\n        self.p_strategies = np.array([0.3, 0.3, 0.4])  # Initial probabilities for 3 strategies\n\n        self.successful_strategies = [[] for _ in range(3)]\n        self.memory_size = 10\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.X = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.F = np.array([func(x) for x in self.X])\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            BF1 = np.random.choice([1, 2])\n            BF2 = np.random.choice([1, 2])\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n                    self.update_best(self.X[i], self.F[i])\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n                    self.update_best(self.X[j], self.F[j])\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n                    self.update_best(self.X[i], self.F[i])\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n\n            parasite = np.copy(self.X[i])\n            num_changes = np.random.randint(1, self.dim + 1)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n                    self.update_best(self.X[j], self.F[j])\n\n    def sade_phase(self, func):\n        trial_vectors = np.zeros((self.pop_size, self.dim))\n        trial_fitness = np.zeros(self.pop_size)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n            # Strategy selection\n            strategy_index = np.random.choice(len(self.p_strategies), p=self.p_strategies)\n\n            if strategy_index == 0:\n                # DE/rand/1\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_vector = x_r1 + 0.5 * (x_r2 - x_r3)\n            elif strategy_index == 1:\n                # DE/current-to-rand/1\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.X[idxs]\n                mutated_vector = self.X[i] + np.random.rand()*(x_r1 - self.X[i]) + np.random.rand()*(x_r2 - self.X[i])\n            else:\n                # DE/best/1\n                best_idx = np.argmin(self.F)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.X[idxs]\n                mutated_vector = self.X[best_idx] + 0.5 * (x_r1 - x_r2)\n\n            mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n\n            # Crossover (Binomial)\n            cross_points = np.random.rand(self.dim) < 0.5\n            trial_vector = np.where(cross_points, mutated_vector, self.X[i])\n            trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n            # Evaluation\n            fitness = func(trial_vector)\n            self.eval_count += 1\n\n            if fitness < self.F[i]:\n                trial_vectors[i] = trial_vector\n                trial_fitness[i] = fitness\n                self.successful_strategies[strategy_index].append(1)  # Reward strategy\n            else:\n                self.successful_strategies[strategy_index].append(0)  # Penalize strategy\n\n            if len(self.successful_strategies[strategy_index]) > self.memory_size:\n                self.successful_strategies[strategy_index].pop(0)  # Keep memory size bounded\n\n        # Selection\n        for i in range(self.pop_size):\n            if trial_vectors[i].any() and trial_fitness[i] < self.F[i]:\n                self.X[i] = trial_vectors[i]\n                self.F[i] = trial_fitness[i]\n                self.update_best(self.X[i], self.F[i])\n\n        # Update strategy probabilities\n        self.update_strategy_probabilities()\n\n    def update_strategy_probabilities(self):\n        rewards = np.array([np.mean(s) if s else 0 for s in self.successful_strategies])\n        sum_rewards = np.sum(rewards)\n\n        if sum_rewards > 0:\n            new_p_strategies = rewards / sum_rewards\n        else:\n             new_p_strategies = np.ones_like(self.p_strategies) / len(self.p_strategies)\n\n\n        self.p_strategies = (1 - self.lr) * self.p_strategies + self.lr * new_p_strategies\n        self.p_strategies /= np.sum(self.p_strategies) # Normalize\n\n    def update_best(self, x, f):\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.successful_strategies = [[] for _ in range(3)]\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.sos_prob:\n                self.mutualism_phase(func)\n                self.commensalism_phase(func)\n                self.parasitism_phase(func)\n            else:\n                self.sade_phase(func)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.15502638864915774, 0.2537400808219762, 0.34172581366445376, 0.20332498734017934, 0.48627568509932717, 0.32066455595647947, 0.3275281296881768, 0.27162890437571763, 0.32965194635486816, 0.37749477797798736, 0.24780480016698914, 0.9954897581880503, 0.45806409050223107, 0.2434144369777299, 0.7377472513678083, 0.5534900624793913, 0.5128551162970436, 0.6045087426404349, 0.2457125392547378, 0.48841885594569656], "operator": "mutation", "theta_sampled": 0.15313283709161873, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "6f5ce12f-5cde-487f-9bae-ca0ea2ea29ef", "fitness": 0.0, "name": "HybridCovarianceAdaptiveSOS", "description": "Integrates Covariance Matrix Adaptation with Adaptive Symbiotic Organisms Search for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCovarianceAdaptiveSOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n    \n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n\n            # SOS phases\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Covariance Matrix Adaptation (CMA) - Simplified - after SOS\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            # Resample if necessary\n            self.X, self.F = self.sample(func)\n            self.eval_count += self.pop_size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridCovarianceAdaptiveSOS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "7d8de8ed-1f4f-4f28-8a0a-67e58429af75"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Covariance Matrix Adaptation with Adaptive Symbiotic Organisms Search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCovarianceAdaptiveSOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n    \n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def mutualism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n            # Adaptive BF1 and BF2\n            if np.random.rand() < self.BF_prob:\n                BF1 = 1\n            else:\n                BF1 = np.random.choice([1, 2])\n            if np.random.rand() < self.BF_prob:\n                BF2 = 1\n            else:\n                BF2 = np.random.choice([1, 2])\n\n\n            new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n            new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n            new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n            new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n            if self.eval_count < self.budget:\n                fitness_j = func(new_organism_j)\n                self.eval_count += 1\n                if fitness_j < self.F[j]:\n                    self.X[j] = new_organism_j\n                    self.F[j] = fitness_j\n\n    def commensalism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            j = i\n            while j == i:\n                j = np.random.randint(0, self.pop_size)\n\n            new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n            new_organism = np.clip(new_organism, self.lb, self.ub)\n\n            if self.eval_count < self.budget:\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            parasite = np.copy(self.X[i])\n\n            # Self-adaptive mutation\n            num_changes = np.random.binomial(self.dim, self.mutation_rate)\n            indices = np.random.choice(self.dim, num_changes, replace=False)\n            parasite[indices] = np.random.uniform(self.lb, self.ub, num_changes)\n\n            j = np.random.randint(0, self.pop_size)\n\n            if self.eval_count < self.budget:\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n        \n        self.mutation_rate *= self.mutation_decay  # Reduce mutation rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        self.eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n\n            # SOS phases\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n\n            # Covariance Matrix Adaptation (CMA) - Simplified - after SOS\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n            \n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma*(1 + self.c_cov* np.linalg.norm(diff))\n\n            # Resample if necessary\n            self.X, self.F = self.sample(func)\n            self.eval_count += self.pop_size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.05924387125880817, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "a9b381bc-c925-43f5-91ae-3c655e3f68ef", "fitness": 0.24453936608344334, "name": "HybridCovarianceDE_ASOS", "description": "A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Adaptive Symbiotic Organisms Search with a focus on adaptive parameter control and population diversity.", "code": "import numpy as np\n\nclass HybridCovarianceDE_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1,\n                 mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5, de_cr=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n        self.de_cr = de_cr # Crossover rate for Differential Evolution\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample(self, func):\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, self.lb, self.ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Adaptive Symbiotic Organisms Search Phases\n\n            # Mutualism Phase with Covariance Adaptation\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                j = i\n                while j == i:\n                    j = np.random.randint(0, self.pop_size)\n\n                mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n                # Adaptive BF1 and BF2\n                BF1 = 1 if np.random.rand() < self.BF_prob else np.random.choice([1, 2])\n                BF2 = 1 if np.random.rand() < self.BF_prob else np.random.choice([1, 2])\n\n                new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n                new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n                new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n                new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n                if self.eval_count < self.budget:\n                    fitness_j = func(new_organism_j)\n                    self.eval_count += 1\n                    if fitness_j < self.F[j]:\n                        self.X[j] = new_organism_j\n                        self.F[j] = fitness_j\n\n                # Simplified CMA update after Mutualism\n                x_mean = np.mean(self.X, axis=0)\n                self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n                diff = self.mu - x_mean\n                self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            # Commensalism Phase\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                j = i\n                while j == i:\n                    j = np.random.randint(0, self.pop_size)\n\n                new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n                new_organism = np.clip(new_organism, self.lb, self.ub)\n\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n            # Parasitism Phase with Differential Evolution Mutation\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                #DE Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_organism = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.de_cr\n                parasite = np.where(cross_points, mutated_organism, self.X[i])\n                parasite = np.clip(parasite, self.lb, self.ub)\n                \n                j = np.random.randint(0, self.pop_size)\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n\n            # Adaptive Mutation Rate Update\n            self.mutation_rate *= self.mutation_decay\n\n            # Update Best Solution\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridCovarianceDE_ASOS scored 0.245 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278", "7d8de8ed-1f4f-4f28-8a0a-67e58429af75"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Covariance Matrix Adaptation, Differential Evolution, and Adaptive Symbiotic Organisms Search with a focus on adaptive parameter control and population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCovarianceDE_ASOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1,\n                 mutation_rate=0.1, mutation_decay=0.995, BF_prob=0.5, de_cr=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.eval_count = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_decay = mutation_decay\n        self.BF_prob = BF_prob\n        self.de_cr = de_cr # Crossover rate for Differential Evolution\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample(self, func):\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, self.lb, self.ub)\n        F = np.array([func(x) for x in X])\n        self.eval_count += self.pop_size\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            # Adaptive Symbiotic Organisms Search Phases\n\n            # Mutualism Phase with Covariance Adaptation\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                j = i\n                while j == i:\n                    j = np.random.randint(0, self.pop_size)\n\n                mean_vector = 0.5 * (self.X[i] + self.X[j])\n\n                # Adaptive BF1 and BF2\n                BF1 = 1 if np.random.rand() < self.BF_prob else np.random.choice([1, 2])\n                BF2 = 1 if np.random.rand() < self.BF_prob else np.random.choice([1, 2])\n\n                new_organism_i = self.X[i] + np.random.rand(self.dim) * (mean_vector - BF1 * self.X[j])\n                new_organism_j = self.X[j] + np.random.rand(self.dim) * (mean_vector - BF2 * self.X[i])\n\n                new_organism_i = np.clip(new_organism_i, self.lb, self.ub)\n                new_organism_j = np.clip(new_organism_j, self.lb, self.ub)\n\n                fitness_i = func(new_organism_i)\n                self.eval_count += 1\n                if fitness_i < self.F[i]:\n                    self.X[i] = new_organism_i\n                    self.F[i] = fitness_i\n\n                if self.eval_count < self.budget:\n                    fitness_j = func(new_organism_j)\n                    self.eval_count += 1\n                    if fitness_j < self.F[j]:\n                        self.X[j] = new_organism_j\n                        self.F[j] = fitness_j\n\n                # Simplified CMA update after Mutualism\n                x_mean = np.mean(self.X, axis=0)\n                self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n                diff = self.mu - x_mean\n                self.sigma = self.sigma * (1 + self.c_cov * np.linalg.norm(diff))\n\n            # Commensalism Phase\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                j = i\n                while j == i:\n                    j = np.random.randint(0, self.pop_size)\n\n                new_organism = self.X[i] + np.random.rand(self.dim) * (self.X[j] - self.X[i])\n                new_organism = np.clip(new_organism, self.lb, self.ub)\n\n                fitness = func(new_organism)\n                self.eval_count += 1\n                if fitness < self.F[i]:\n                    self.X[i] = new_organism\n                    self.F[i] = fitness\n\n            # Parasitism Phase with Differential Evolution Mutation\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                #DE Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_organism = self.X[i] + 0.5 * (x_r1 - x_r2)  # DE Mutation\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.de_cr\n                parasite = np.where(cross_points, mutated_organism, self.X[i])\n                parasite = np.clip(parasite, self.lb, self.ub)\n                \n                j = np.random.randint(0, self.pop_size)\n                fitness_parasite = func(parasite)\n                self.eval_count += 1\n\n                if fitness_parasite < self.F[j]:\n                    self.X[j] = parasite\n                    self.F[j] = fitness_parasite\n\n            # Adaptive Mutation Rate Update\n            self.mutation_rate *= self.mutation_decay\n\n            # Update Best Solution\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07126985972555266, 0.17639834652847652, 0.34039742993826916, 0.15313924637540877, 0.20420886462255283, 0.15077727658249074, 0.2468855305822093, 0.1762534304013852, 0.16697135534291008, 0.1757461444108882, 0.16878981111431257, 0.9686845829209176, 0.2615259984175521, 0.1450952317250216, 0.16915629057395343, 0.2423309772312532, 0.2124538252960788, 0.17755431879030825, 0.19198056125997254, 0.49116823982935287], "operator": "crossover", "theta_sampled": 0.3988747263258756, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "78040b14-eda7-47a8-8b8a-d11226d00e25", "fitness": 0.5333509213091064, "name": "AdaptiveCovarianceMatrixDE", "description": "Adaptively adjusts mutation strength based on population diversity and employs a self-adaptive step size for exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, F=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.F_val = F # DE mutation factor\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Adaptive Mutation Factor\n            diversity = np.std(self.F)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + self.F_val * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5)) #Self-adaptive step size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveCovarianceMatrixDE scored 0.533 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d00e589b-dadd-45dd-8632-bb26e5b4f278"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively adjusts mutation strength based on population diversity and employs a self-adaptive step size for exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, F=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.F_val = F # DE mutation factor\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Adaptive Mutation Factor\n            diversity = np.std(self.F)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + self.F_val * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5)) #Self-adaptive step size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.12799224762691686, 0.3127747884370242, 0.6898470350516841, 0.9378669508966821, 0.2379964576038609, 0.8137283497748108, 0.34314043958734086, 0.3058081598386163, 0.7904580394440742, 0.19330902170901698, 0.7333049477664012, 0.9877377482481494, 0.29006334087094154, 0.35630175666550157, 0.9266500528867456, 0.7501392258973758, 0.2628742758409681, 0.88011551173986, 0.23523309473091403, 0.4916769815652431], "operator": "mutation", "theta_sampled": 0.12428924751181136, "reward": 0.0020423760410850367, "generation": 6}, "task_prompt": ""}
{"id": "db2ba513-6986-4c85-9d35-9f003050e2ff", "fitness": 0.473238861519025, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines elements of particle swarm optimization (PSO) with differential evolution (DE), using a dynamically adjusted exploration-exploitation balance based on population diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, c1=1.5, c2=1.5, de_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate  # Probability of applying DE mutation\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Discount initial evaluations.\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate population diversity (standard deviation across dimensions)\n            diversity = np.std(population)\n\n            # Adjust exploration-exploitation balance based on diversity\n            exploration_prob = np.clip(diversity / (func.bounds.ub[0] - func.bounds.lb[0]), 0.1, 0.9)  # Scale diversity to a probability\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Apply PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n\n                population[i] += velocities[i]\n\n                # Apply DE mutation with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    # DE mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[indices]\n                    mutation = x1 + 0.5 * (x2 - x3) # DE/rand/1 mutation\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < exploration_prob # Probabilistic crossover based on diversity\n                    population[i] = np.where(crossover_mask, mutation, population[i]) # Either use the mutated or original value\n                \n                # Clip to bounds\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                f = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if f < global_best_fitness:\n                    global_best_fitness = f\n                    global_best_position = population[i].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE scored 0.473 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of particle swarm optimization (PSO) with differential evolution (DE), using a dynamically adjusted exploration-exploitation balance based on population diversity.\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, c1=1.5, c2=1.5, de_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate  # Probability of applying DE mutation\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Discount initial evaluations.\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate population diversity (standard deviation across dimensions)\n            diversity = np.std(population)\n\n            # Adjust exploration-exploitation balance based on diversity\n            exploration_prob = np.clip(diversity / (func.bounds.ub[0] - func.bounds.lb[0]), 0.1, 0.9)  # Scale diversity to a probability\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Apply PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n\n                population[i] += velocities[i]\n\n                # Apply DE mutation with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    # DE mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[indices]\n                    mutation = x1 + 0.5 * (x2 - x3) # DE/rand/1 mutation\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < exploration_prob # Probabilistic crossover based on diversity\n                    population[i] = np.where(crossover_mask, mutation, population[i]) # Either use the mutated or original value\n                \n                # Clip to bounds\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                f = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if f < global_best_fitness:\n                    global_best_fitness = f\n                    global_best_position = population[i].copy()\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.21036936453249444, 0.4712640323548227, 0.5508594762511654, 0.767776430124615, 0.3976548939715032, 0.5159526473073248, 0.32074730683253105, 0.4796785613535701, 0.4741544044983167, 0.224918457796774, 0.5527984488396047, 0.998687425243719, 0.2849071499850344, 0.307701455142527, 0.6774259363029476, 0.3541259551380668, 0.46092230415430235, 0.6294201530438261, 0.29016518264878643, 0.4952476448585693], "operator": "random_new", "theta_sampled": 0.012798533852650729, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "599a21e0-fe57-4c73-aa9f-52fe1c19954d", "fitness": 0.09315141926644599, "name": "DiffusionOptimization", "description": "A population-based algorithm that simulates a diffusion process, where particles randomly move and interact with each other, exploring the search space and converging towards optima.", "code": "import numpy as np\n\nclass DiffusionOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, diffusion_rate=0.1, interaction_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.diffusion_rate = diffusion_rate\n        self.interaction_radius = interaction_radius\n\n    def __call__(self, func):\n        # Initialize the population randomly\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        eval_count = self.population_size  # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            # Diffusion step: each particle moves randomly\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                diffusion_vector = np.random.normal(0, self.diffusion_rate, self.dim)\n                new_position = population[i] + diffusion_vector\n                \n                # Clip the position to stay within the bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                eval_count += 1\n\n                # Interaction step: interact with neighbors\n                for j in range(self.population_size):\n                    if i != j:\n                        distance = np.linalg.norm(population[i] - population[j])\n                        if distance < self.interaction_radius:\n                            # If neighbor is better, move slightly towards it\n                            if fitness[j] < new_fitness:\n                                new_position = new_position + 0.1 * (population[j] - new_position)\n                                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                                new_fitness = func(new_position)\n                                eval_count += 1\n                                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n                    \n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DiffusionOptimization scored 0.093 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that simulates a diffusion process, where particles randomly move and interact with each other, exploring the search space and converging towards optima.\n# Code: \n```python\nimport numpy as np\n\nclass DiffusionOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, diffusion_rate=0.1, interaction_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.diffusion_rate = diffusion_rate\n        self.interaction_radius = interaction_radius\n\n    def __call__(self, func):\n        # Initialize the population randomly\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        eval_count = self.population_size  # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            # Diffusion step: each particle moves randomly\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                diffusion_vector = np.random.normal(0, self.diffusion_rate, self.dim)\n                new_position = population[i] + diffusion_vector\n                \n                # Clip the position to stay within the bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                eval_count += 1\n\n                # Interaction step: interact with neighbors\n                for j in range(self.population_size):\n                    if i != j:\n                        distance = np.linalg.norm(population[i] - population[j])\n                        if distance < self.interaction_radius:\n                            # If neighbor is better, move slightly towards it\n                            if fitness[j] < new_fitness:\n                                new_position = new_position + 0.1 * (population[j] - new_position)\n                                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                                new_fitness = func(new_position)\n                                eval_count += 1\n                                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n                    \n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n                    \n        return self.f_opt, self.x_opt\n```", "aucs": [0.1041027337593492, 0.17535152403998877, 0], "operator": "random_new", "theta_sampled": 0.027126371280758795, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "69eb3d57-efc7-430d-a6a2-e36612c80a8a", "fitness": 0.578174682580002, "name": "AdaptiveHybridPSO_CMA_DE", "description": "Integrates Adaptive PSO with Covariance Matrix Adaptation DE, dynamically adjusting PSO parameters and leveraging CMA for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSO_CMA_DE scored 0.578 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d42fe26a-a6ba-4261-bc35-c2c7f95cbca4", "78040b14-eda7-47a8-8b8a-d11226d00e25"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Adaptive PSO with Covariance Matrix Adaptation DE, dynamically adjusting PSO parameters and leveraging CMA for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.22484448726582562, 0.38296173963715563, 0.7327460833774295, 0.2582400695554087, 0.701490497284301, 0.7697700747668197, 0.31082478400839364, 0.6121473508361766, 0.7275373591754402, 0.6913283315469494, 0.8366320977012546, 0.9900744081302056, 0.35011140951972197, 0.28311852413973515, 0.6441979344040154, 0.7056786878911523, 0.37863987563772095, 0.805697008237796, 0.678174332060724, 0.47927859642381576], "operator": "crossover", "theta_sampled": 0.032595931515944025, "reward": 0.0050362729649670035, "generation": 7}, "task_prompt": ""}
{"id": "fd222ac8-b213-4835-abd0-4098c1a15599", "fitness": 0.0, "name": "HybridAdaptivePSO_DE", "description": "A hybrid PSO-DE algorithm with adaptive parameters and covariance matrix adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, c_cov=0.1, cs=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.c_cov = c_cov # CMA parameter\n        self.cs = cs # CMA parameter\n\n        self.mu = np.zeros(self.dim) # Mean for CMA\n        self.sigma = 0.5 * np.ones(self.dim) # Step size for CMA\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Adaptive Inertia Weight\n            w = self.w_init - (self.w_init - self.w_end) * (1 - self.budget / 10000)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            x_mean = np.mean(pop, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5)) #Self-adaptive step size\n\n            # Sample new individuals around the global best\n            num_new_samples = int(self.pop_size * 0.2) #Replace 20% of the population\n            new_samples = np.random.normal(loc=global_best_pos, scale=self.sigma, size=(num_new_samples, self.dim))\n            new_samples = np.clip(new_samples, func.bounds.lb, func.bounds.ub)\n\n            new_fitnesses = np.array([func(x) for x in new_samples])\n            self.budget -= num_new_samples\n\n            # Replace worst individuals with new samples if they're better\n            worst_indices = np.argsort(fitness)[-num_new_samples:]\n            for j in range(num_new_samples):\n                if new_fitnesses[j] < fitness[worst_indices[j]]:\n                    pop[worst_indices[j]] = new_samples[j]\n                    fitness[worst_indices[j]] = new_fitnesses[j]\n                    \n                    # Update personal best if necessary\n                    if new_fitnesses[j] < personal_best_fitness[worst_indices[j]]:\n                        personal_best_fitness[worst_indices[j]] = new_fitnesses[j]\n                        personal_best_pos[worst_indices[j]] = new_samples[j].copy()\n                    \n                    #Update global best\n                    if new_fitnesses[j] < global_best_fitness:\n                        global_best_fitness = new_fitnesses[j]\n                        global_best_pos = new_samples[j].copy()\n\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridAdaptivePSO_DE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d42fe26a-a6ba-4261-bc35-c2c7f95cbca4", "78040b14-eda7-47a8-8b8a-d11226d00e25"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid PSO-DE algorithm with adaptive parameters and covariance matrix adaptation for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, c_cov=0.1, cs=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.c_cov = c_cov # CMA parameter\n        self.cs = cs # CMA parameter\n\n        self.mu = np.zeros(self.dim) # Mean for CMA\n        self.sigma = 0.5 * np.ones(self.dim) # Step size for CMA\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Adaptive Inertia Weight\n            w = self.w_init - (self.w_init - self.w_end) * (1 - self.budget / 10000)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            x_mean = np.mean(pop, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5)) #Self-adaptive step size\n\n            # Sample new individuals around the global best\n            num_new_samples = int(self.pop_size * 0.2) #Replace 20% of the population\n            new_samples = np.random.normal(loc=global_best_pos, scale=self.sigma, size=(num_new_samples, self.dim))\n            new_samples = np.clip(new_samples, func.bounds.lb, func.bounds.ub)\n\n            new_fitnesses = np.array([func(x) for x in new_samples])\n            self.budget -= num_new_samples\n\n            # Replace worst individuals with new samples if they're better\n            worst_indices = np.argsort(fitness)[-num_new_samples:]\n            for j in range(num_new_samples):\n                if new_fitnesses[j] < fitness[worst_indices[j]]:\n                    pop[worst_indices[j]] = new_samples[j]\n                    fitness[worst_indices[j]] = new_fitnesses[j]\n                    \n                    # Update personal best if necessary\n                    if new_fitnesses[j] < personal_best_fitness[worst_indices[j]]:\n                        personal_best_fitness[worst_indices[j]] = new_fitnesses[j]\n                        personal_best_pos[worst_indices[j]] = new_samples[j].copy()\n                    \n                    #Update global best\n                    if new_fitnesses[j] < global_best_fitness:\n                        global_best_fitness = new_fitnesses[j]\n                        global_best_pos = new_samples[j].copy()\n\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.002006393454418327, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "03faf49b-7e69-4df6-bc51-3c38df126508", "fitness": 0.0, "name": "NovelHybridOptimizer", "description": "Population-based algorithm that uses a combination of differential evolution mutation and a simplified covariance matrix adaptation, with a focus on population diversity and exploration, promoting solutions towards the best one while adapting the step size.", "code": "import numpy as np\n\nclass NovelHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr=0.7, f=0.5, sigma_init=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr  # Crossover rate\n        self.f = f    # Mutation factor\n        self.sigma = sigma_init # Step size / standard deviation\n        self.archive_rate = 0.1\n        \n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.eval_count = self.pop_size\n\n        self.archive = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                x_mutated = self.pop[i] + self.f * (x_r1 - x_r2) + np.random.normal(0, self.sigma * (x_r2 - x_r3))\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Boundary Handling\n                x_trial = np.clip(x_trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(x_trial)\n                self.eval_count += 1\n                \n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        # Adaptive sigma\n                        self.sigma *= 0.95\n                else:\n                    # Archive less promising solutions\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i])\n\n                if self.eval_count >= self.budget:\n                  break\n\n\n            # Simplified Covariance Matrix Adaptation (CMA)\n            # Adjust the population based on the best solution\n            mean = np.mean(self.pop, axis=0)\n            diff = self.pop - self.x_opt\n            self.pop = self.x_opt + np.random.normal(0, self.sigma, size=(self.pop_size, self.dim))\n\n            # Boundary Handling for the new population\n            self.pop = np.clip(self.pop, lb, ub)\n            \n            # Re-evaluate the population\n            self.fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            \n            # Update the best solution found\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n            \n            # Increase sigma if stuck to encourage exploration.\n            if np.std(self.fitness) < 1e-6:\n                self.sigma *= 1.1\n                self.sigma = min(self.sigma, (ub - lb) / 2) # Avoid sigma becoming too large\n\n\n            if self.eval_count >= self.budget:\n                break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: scale < 0", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that uses a combination of differential evolution mutation and a simplified covariance matrix adaptation, with a focus on population diversity and exploration, promoting solutions towards the best one while adapting the step size.\n# Code:\n```python\nimport numpy as np\n\nclass NovelHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr=0.7, f=0.5, sigma_init=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr  # Crossover rate\n        self.f = f    # Mutation factor\n        self.sigma = sigma_init # Step size / standard deviation\n        self.archive_rate = 0.1\n        \n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.eval_count = self.pop_size\n\n        self.archive = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                x_mutated = self.pop[i] + self.f * (x_r1 - x_r2) + np.random.normal(0, self.sigma * (x_r2 - x_r3))\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Boundary Handling\n                x_trial = np.clip(x_trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(x_trial)\n                self.eval_count += 1\n                \n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        # Adaptive sigma\n                        self.sigma *= 0.95\n                else:\n                    # Archive less promising solutions\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i])\n\n                if self.eval_count >= self.budget:\n                  break\n\n\n            # Simplified Covariance Matrix Adaptation (CMA)\n            # Adjust the population based on the best solution\n            mean = np.mean(self.pop, axis=0)\n            diff = self.pop - self.x_opt\n            self.pop = self.x_opt + np.random.normal(0, self.sigma, size=(self.pop_size, self.dim))\n\n            # Boundary Handling for the new population\n            self.pop = np.clip(self.pop, lb, ub)\n            \n            # Re-evaluate the population\n            self.fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            \n            # Update the best solution found\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n            \n            # Increase sigma if stuck to encourage exploration.\n            if np.std(self.fitness) < 1e-6:\n                self.sigma *= 1.1\n                self.sigma = min(self.sigma, (ub - lb) / 2) # Avoid sigma becoming too large\n\n\n            if self.eval_count >= self.budget:\n                break\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.049918496821783315, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "d157f95a-c833-4d0f-aa4b-5ea01e57f2c4", "fitness": 0.5103666369062425, "name": "HybridPSO_CMA_DE", "description": "Hybrid algorithm combining Adaptive PSO with DE local search and Covariance Matrix Adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_CMA_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1, c_cov=0.1, cs=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate\n        self.c_cov = c_cov\n        self.cs = cs\n        self.mu = np.zeros(self.dim)\n        self.sigma = 0.5 * np.ones(self.dim)\n        self.F_val = 0.5  # DE mutation factor\n        self.personal_best_fitness = np.inf * np.ones(self.pop_size)\n        self.personal_best_pos = np.zeros((self.pop_size, self.dim))\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Initialize personal bests\n        self.personal_best_pos = pop.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        # Initialize velocities\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n\n        while self.budget > 0:\n            # Update velocities and positions (PSO)\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (self.personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n\n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n\n                # Update position\n                new_pos = pop[i] + velocities[i]\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n                # DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n\n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_pos[i] = new_pos.copy()\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                # Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n                \n            # Covariance Matrix Adaptation (CMA) - Simplified adaptation of mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n            # Update the mean position using population mean\n            x_mean = np.mean(pop, axis=0)\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5)) #Self-adaptive step size\n\n            # Dynamically adapt v_max\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_CMA_DE scored 0.510 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d42fe26a-a6ba-4261-bc35-c2c7f95cbca4", "78040b14-eda7-47a8-8b8a-d11226d00e25"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid algorithm combining Adaptive PSO with DE local search and Covariance Matrix Adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_CMA_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1, c_cov=0.1, cs=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate\n        self.c_cov = c_cov\n        self.cs = cs\n        self.mu = np.zeros(self.dim)\n        self.sigma = 0.5 * np.ones(self.dim)\n        self.F_val = 0.5  # DE mutation factor\n        self.personal_best_fitness = np.inf * np.ones(self.pop_size)\n        self.personal_best_pos = np.zeros((self.pop_size, self.dim))\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Initialize personal bests\n        self.personal_best_pos = pop.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        # Initialize velocities\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n\n        while self.budget > 0:\n            # Update velocities and positions (PSO)\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (self.personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n\n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n\n                # Update position\n                new_pos = pop[i] + velocities[i]\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n                # DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n\n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_pos[i] = new_pos.copy()\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                # Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n                \n            # Covariance Matrix Adaptation (CMA) - Simplified adaptation of mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n            # Update the mean position using population mean\n            x_mean = np.mean(pop, axis=0)\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            #Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5)) #Self-adaptive step size\n\n            # Dynamically adapt v_max\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.17523958774857096, 0.38662822050338896, 0.6704264690655759, 0.2063815303389619, 0.519160628815026, 0.7736656549777012, 0.31869507442477407, 0.634274586207038, 0.7085309523525346, 0.23100755845196663, 0.8442891063524602, 0.9970286651332861, 0.2828550058292183, 0.2863863644281571, 0.7281063436252208, 0.7245906669552339, 0.6118721606244342, 0.3768343157564462, 0.21531667926018028, 0.5160431672746761], "operator": "crossover", "theta_sampled": 0.0007833909974199829, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "dbb8e4d6-8dd1-45dd-b82f-23a14a966b0e", "fitness": 0.46929880044953654, "name": "StarClusterOptimization", "description": "Population-based algorithm simulating the formation and collapse of star clusters, using gravitational attraction for exploration and a shrinking radius for exploitation.", "code": "import numpy as np\n\nclass StarClusterOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, attraction_constant=1.0, collapse_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.attraction_constant = attraction_constant\n        self.collapse_rate = collapse_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        cluster_radius = (func.bounds.ub[0] - func.bounds.lb[0]) / 2  # Initial radius\n\n        while self.budget > 0:\n            # Calculate gravitational attraction towards the best solution\n            attraction_forces = self.attraction_constant * (self.x_opt - population) / (cluster_radius + 1e-8) #Avoid division by zero\n\n            # Move particles based on attraction and random perturbation\n            new_population = population + attraction_forces + np.random.normal(0, cluster_radius/10, size=(self.population_size, self.dim)) # Scale random noise by current radius\n\n            # Clip to bounds\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness of new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.population_size\n            if self.budget < 0:\n                new_fitness = new_fitness[:self.population_size + self.budget]\n                new_population = new_population[:self.population_size + self.budget]\n                \n            # Update best solution\n            for i in range(len(new_fitness)): #Correctly handle budgets that do not align with population size\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_population[i]\n\n            # Update population (replace if better) - optional: tournament selection?\n            for i in range(len(new_fitness)):\n              if new_fitness[i] < fitness[i]:\n                fitness[i] = new_fitness[i]\n                population[i] = new_population[i]\n                \n            # Reduce the cluster radius - simulate collapse for exploitation\n            cluster_radius *= self.collapse_rate\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm StarClusterOptimization scored 0.469 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm simulating the formation and collapse of star clusters, using gravitational attraction for exploration and a shrinking radius for exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass StarClusterOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, attraction_constant=1.0, collapse_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.attraction_constant = attraction_constant\n        self.collapse_rate = collapse_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        cluster_radius = (func.bounds.ub[0] - func.bounds.lb[0]) / 2  # Initial radius\n\n        while self.budget > 0:\n            # Calculate gravitational attraction towards the best solution\n            attraction_forces = self.attraction_constant * (self.x_opt - population) / (cluster_radius + 1e-8) #Avoid division by zero\n\n            # Move particles based on attraction and random perturbation\n            new_population = population + attraction_forces + np.random.normal(0, cluster_radius/10, size=(self.population_size, self.dim)) # Scale random noise by current radius\n\n            # Clip to bounds\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness of new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.population_size\n            if self.budget < 0:\n                new_fitness = new_fitness[:self.population_size + self.budget]\n                new_population = new_population[:self.population_size + self.budget]\n                \n            # Update best solution\n            for i in range(len(new_fitness)): #Correctly handle budgets that do not align with population size\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_population[i]\n\n            # Update population (replace if better) - optional: tournament selection?\n            for i in range(len(new_fitness)):\n              if new_fitness[i] < fitness[i]:\n                fitness[i] = new_fitness[i]\n                population[i] = new_population[i]\n                \n            # Reduce the cluster radius - simulate collapse for exploitation\n            cluster_radius *= self.collapse_rate\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2131297857828165, 0.31552000252967605, 0.452715417962546, 0.8120238493792462, 0.4013261632588818, 0.4860878794038813, 0.2987780710883994, 0.404851450895243, 0.40889968846443703, 0.23834612081959627, 0.813577771286119, 0.9903575803192328, 0.2771190468107422, 0.42536448950518346, 0.7984684592370611, 0.3497874357928997, 0.4063240112584272, 0.5889170377472189, 0.20283939243538485, 0.5015423550137379], "operator": "random_new", "theta_sampled": 0.00648601479653731, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "a98ed15b-5937-43fb-bd52-775661c7e35e", "fitness": 0.0, "name": "SOM_LevyOptimizer", "description": "Population-based algorithm employing Lvy flights for exploration and a self-organizing map (SOM) for population diversity maintenance and focused exploitation around promising regions.", "code": "import numpy as np\nfrom scipy.stats import levy\nfrom minisom import MiniSom\n\nclass SOM_LevyOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=50, som_grid_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.som_grid_size = som_grid_size  # Size of the SOM grid (e.g., 10x10)\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def levy_flight(self, beta=1.5):\n        \"\"\"\n        Generate a Lvy flight step.\n\n        Args:\n            beta: Lvy distribution parameter.\n\n        Returns:\n            A random step vector.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def som_update(self, func):\n        \"\"\"\n        Update the population using a Self-Organizing Map to maintain diversity and exploit promising regions.\n        \"\"\"\n        # Train the SOM on the current population\n        som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        som.train(self.population, 100)  # Train for a fixed number of iterations\n\n        # For each individual in the population, find its closest neuron in the SOM\n        for i in range(self.population_size):\n            winner = som.winner(self.population[i])\n            # Generate a new solution based on the SOM neuron's weight vector\n            new_solution = som.get_weights()[winner[0], winner[1]]\n\n            # Mutate the new solution using a small random perturbation\n            mutation = np.random.uniform(-0.1, 0.1, size=self.dim)  # Adjust mutation strength as needed\n            new_solution = np.clip(new_solution + mutation, func.bounds.lb, func.bounds.ub)\n\n\n            # Evaluate the new solution\n            new_fitness = func(new_solution)\n\n            # Replace the individual if the new solution is better\n            if new_fitness < self.fitness[i]:\n                self.population[i] = new_solution\n                self.fitness[i] = new_fitness\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_solution\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Apply Lvy flights to explore the search space\n            for i in range(self.population_size):\n                step = self.levy_flight()\n                new_solution = self.population[i] + step\n                new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                new_fitness = func(new_solution)\n                eval_count += 1\n                if eval_count > self.budget:\n                   break\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_solution\n                    self.fitness[i] = new_fitness\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_solution\n            \n            if eval_count > self.budget:\n                break\n\n            self.som_update(func)\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: No module named 'minisom'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm employing Lvy flights for exploration and a self-organizing map (SOM) for population diversity maintenance and focused exploitation around promising regions.\n# Code: \n```python\nimport numpy as np\nfrom scipy.stats import levy\nfrom minisom import MiniSom\n\nclass SOM_LevyOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=50, som_grid_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.som_grid_size = som_grid_size  # Size of the SOM grid (e.g., 10x10)\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def levy_flight(self, beta=1.5):\n        \"\"\"\n        Generate a Lvy flight step.\n\n        Args:\n            beta: Lvy distribution parameter.\n\n        Returns:\n            A random step vector.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def som_update(self, func):\n        \"\"\"\n        Update the population using a Self-Organizing Map to maintain diversity and exploit promising regions.\n        \"\"\"\n        # Train the SOM on the current population\n        som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        som.train(self.population, 100)  # Train for a fixed number of iterations\n\n        # For each individual in the population, find its closest neuron in the SOM\n        for i in range(self.population_size):\n            winner = som.winner(self.population[i])\n            # Generate a new solution based on the SOM neuron's weight vector\n            new_solution = som.get_weights()[winner[0], winner[1]]\n\n            # Mutate the new solution using a small random perturbation\n            mutation = np.random.uniform(-0.1, 0.1, size=self.dim)  # Adjust mutation strength as needed\n            new_solution = np.clip(new_solution + mutation, func.bounds.lb, func.bounds.ub)\n\n\n            # Evaluate the new solution\n            new_fitness = func(new_solution)\n\n            # Replace the individual if the new solution is better\n            if new_fitness < self.fitness[i]:\n                self.population[i] = new_solution\n                self.fitness[i] = new_fitness\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_solution\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Apply Lvy flights to explore the search space\n            for i in range(self.population_size):\n                step = self.levy_flight()\n                new_solution = self.population[i] + step\n                new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                new_fitness = func(new_solution)\n                eval_count += 1\n                if eval_count > self.budget:\n                   break\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_solution\n                    self.fitness[i] = new_fitness\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_solution\n            \n            if eval_count > self.budget:\n                break\n\n            self.som_update(func)\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.005434619318534626, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "8b81376b-509e-4aeb-9097-1ec1728adf28", "fitness": 0.0, "name": "SimplexDE", "description": "A population-based algorithm that combines aspects of differential evolution with a simplex-based search, adapting the simplex size and DE parameters based on population diversity.", "code": "import numpy as np\n\nclass SimplexDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.7, simplex_size_init=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.simplex_size = simplex_size_init  # Initial size of the simplex\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            # Mutation\n            v = x_r1 + self.de_rate * (x_r2 - x_r3)\n            v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < 0.1 or j == j_rand: # Crossover rate of 0.1.\n                    u[j] = v[j]\n\n            # Selection\n            f_u = func(u)\n            self.budget -= 1\n            if f_u < self.fitness[i]:\n                self.population[i] = u\n                self.fitness[i] = f_u\n                \n    def simplex_search(self, func):\n        # Find the worst and best individuals in the population\n        worst_idx = np.argmax(self.fitness)\n        best_idx = np.argmin(self.fitness)\n        \n        # Create a simplex around the best individual\n        simplex = np.copy(self.population[best_idx]) + self.simplex_size * np.random.randn(self.dim)\n        simplex = np.clip(simplex, func.bounds.lb, func.bounds.ub)\n        \n        f_simplex = func(simplex)\n        self.budget -= 1\n        \n        # Replace the worst individual with the simplex point if it's better\n        if f_simplex < self.fitness[worst_idx] and self.budget > 0:\n            self.population[worst_idx] = simplex\n            self.fitness[worst_idx] = f_simplex\n\n    def update_parameters(self):\n        # Adjust simplex size based on population diversity\n        diversity = np.std(self.population)\n        self.simplex_size = 0.1 * diversity\n\n        # Adjust DE rate based on population diversity.\n        self.de_rate = 0.5 + 0.5 * np.exp(-diversity)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.budget > 0:\n            self.differential_evolution(func)\n            self.simplex_search(func)\n            self.update_parameters()  # Adapt simplex size and DE rate\n        \n        best_idx = np.argmin(self.fitness)\n        return self.fitness[best_idx], self.population[best_idx]", "configspace": "", "generation": 7, "feedback": "The algorithm SimplexDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution with a simplex-based search, adapting the simplex size and DE parameters based on population diversity.\n# Code:\n```python\nimport numpy as np\n\nclass SimplexDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.7, simplex_size_init=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.simplex_size = simplex_size_init  # Initial size of the simplex\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            # Mutation\n            v = x_r1 + self.de_rate * (x_r2 - x_r3)\n            v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < 0.1 or j == j_rand: # Crossover rate of 0.1.\n                    u[j] = v[j]\n\n            # Selection\n            f_u = func(u)\n            self.budget -= 1\n            if f_u < self.fitness[i]:\n                self.population[i] = u\n                self.fitness[i] = f_u\n                \n    def simplex_search(self, func):\n        # Find the worst and best individuals in the population\n        worst_idx = np.argmax(self.fitness)\n        best_idx = np.argmin(self.fitness)\n        \n        # Create a simplex around the best individual\n        simplex = np.copy(self.population[best_idx]) + self.simplex_size * np.random.randn(self.dim)\n        simplex = np.clip(simplex, func.bounds.lb, func.bounds.ub)\n        \n        f_simplex = func(simplex)\n        self.budget -= 1\n        \n        # Replace the worst individual with the simplex point if it's better\n        if f_simplex < self.fitness[worst_idx] and self.budget > 0:\n            self.population[worst_idx] = simplex\n            self.fitness[worst_idx] = f_simplex\n\n    def update_parameters(self):\n        # Adjust simplex size based on population diversity\n        diversity = np.std(self.population)\n        self.simplex_size = 0.1 * diversity\n\n        # Adjust DE rate based on population diversity.\n        self.de_rate = 0.5 + 0.5 * np.exp(-diversity)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.budget > 0:\n            self.differential_evolution(func)\n            self.simplex_search(func)\n            self.update_parameters()  # Adapt simplex size and DE rate\n        \n        best_idx = np.argmin(self.fitness)\n        return self.fitness[best_idx], self.population[best_idx]\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.00952308662144049, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "5fa6a7f1-7852-4cd7-9368-1d5df138d187", "fitness": 0.0, "name": "AdaptiveCovarianceMatrixDE_Orthogonal", "description": "An adaptive Differential Evolution strategy with covariance matrix adaptation using orthogonal learning to improve population diversity and convergence.", "code": "import numpy as np\n\nclass AdaptiveCovarianceMatrixDE_Orthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, F=0.5, orthogonal_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.F_val = F  # DE mutation factor\n        self.orthogonal_trials = orthogonal_trials\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def orthogonal_design(self, x, func):\n        \"\"\"Generates orthogonal trial points around a given point x.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        trials = []\n        for _ in range(self.orthogonal_trials):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n            step_size = np.random.uniform(0.01, 0.1) * (ub - lb) # Adaptive step size\n            trial = x + step_size * direction\n            trial = np.clip(trial, lb, ub)\n            trials.append(trial)\n\n        return trials\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Adaptive Mutation Factor\n            diversity = np.std(self.F)\n            if diversity > 0.1:  # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1 * np.random.rand()\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + self.F_val * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection and Orthogonal Learning\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n                else: #Orthogonal learning around the current best\n                     orthogonal_trials = self.orthogonal_design(self.X[i], func)\n                     orthogonal_fitness = [func(trial) for trial in orthogonal_trials]\n                     eval_count += len(orthogonal_trials)\n                     best_orthogonal_idx = np.argmin(orthogonal_fitness)\n                     if orthogonal_fitness[best_orthogonal_idx] < self.F[i]:\n                         self.X[i] = orthogonal_trials[best_orthogonal_idx]\n                         self.F[i] = orthogonal_fitness[best_orthogonal_idx]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))  # Self-adaptive step size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveCovarianceMatrixDE_Orthogonal scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["78040b14-eda7-47a8-8b8a-d11226d00e25"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution strategy with covariance matrix adaptation using orthogonal learning to improve population diversity and convergence.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCovarianceMatrixDE_Orthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, F=0.5, orthogonal_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.F_val = F  # DE mutation factor\n        self.orthogonal_trials = orthogonal_trials\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def orthogonal_design(self, x, func):\n        \"\"\"Generates orthogonal trial points around a given point x.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        trials = []\n        for _ in range(self.orthogonal_trials):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n            step_size = np.random.uniform(0.01, 0.1) * (ub - lb) # Adaptive step size\n            trial = x + step_size * direction\n            trial = np.clip(trial, lb, ub)\n            trials.append(trial)\n\n        return trials\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Adaptive Mutation Factor\n            diversity = np.std(self.F)\n            if diversity > 0.1:  # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1 * np.random.rand()\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + self.F_val * (x_r1 - x_r2)  # DE Mutation\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < 0.5  # Crossover Probability\n            trial_X = np.where(cross_points, mutated_X, self.X)\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection and Orthogonal Learning\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n                else: #Orthogonal learning around the current best\n                     orthogonal_trials = self.orthogonal_design(self.X[i], func)\n                     orthogonal_fitness = [func(trial) for trial in orthogonal_trials]\n                     eval_count += len(orthogonal_trials)\n                     best_orthogonal_idx = np.argmin(orthogonal_fitness)\n                     if orthogonal_fitness[best_orthogonal_idx] < self.F[i]:\n                         self.X[i] = orthogonal_trials[best_orthogonal_idx]\n                         self.F[i] = orthogonal_fitness[best_orthogonal_idx]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Update the step size\n            diff = self.mu - x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))  # Self-adaptive step size\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.0009233406451656126, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "53603a9e-232a-42a7-982b-cb2caf422b84", "fitness": 0.30914605686684327, "name": "AdaptiveCovarianceMatrixDE", "description": "Adaptive Covariance Matrix Differential Evolution with orthogonal crossover and a more robust step-size adaptation.", "code": "import numpy as np\n\nclass AdaptiveCovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, F=0.5, orthogonal_crossover_rate = 0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.F_val = F # DE mutation factor\n        self.orthogonal_crossover_rate = orthogonal_crossover_rate\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def orthogonal_crossover(self, x1, x2):\n        \"\"\"Performs orthogonal crossover between two individuals.\"\"\"\n        if np.random.rand() < self.orthogonal_crossover_rate:\n            alpha = np.random.rand()\n            return alpha * x1 + (1 - alpha) * x2\n        else:\n            return x1  # Or x2, or a random combination, to ensure diversity\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Adaptive Mutation Factor\n            diversity = np.std(self.F)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + self.F_val * (x_r1 - x_r2)  # DE Mutation\n\n            # Apply orthogonal crossover\n            trial_X = np.array([self.orthogonal_crossover(mutated_X[i], self.X[i]) for i in range(self.pop_size)])\n\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Robust Step-size Adaptation using exponential moving average\n            diff = self.mu - x_mean\n            norm_diff = np.linalg.norm(diff)\n            # Update the sigma with exponential moving average\n            self.sigma = 0.9 * self.sigma + 0.1 * (self.sigma * np.exp(self.c_cov * (norm_diff - 0.5)))\n            self.sigma = np.maximum(self.sigma, 1e-6) # Avoid sigma becoming zero.\n\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveCovarianceMatrixDE scored 0.309 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["78040b14-eda7-47a8-8b8a-d11226d00e25"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Covariance Matrix Differential Evolution with orthogonal crossover and a more robust step-size adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma=None, cs=0.3, c_cov=0.1, F=0.5, orthogonal_crossover_rate = 0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else np.zeros(self.dim)\n        self.sigma = sigma if sigma is not None else 0.5 * np.ones(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.X = None  # Population\n        self.F = None  # Population Fitness\n        self.F_val = F # DE mutation factor\n        self.orthogonal_crossover_rate = orthogonal_crossover_rate\n\n    def sample(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        X = np.random.normal(loc=self.mu, scale=self.sigma, size=(self.pop_size, self.dim))\n        X = np.clip(X, lb, ub)\n        F = np.array([func(x) for x in X])\n        return X, F\n\n    def orthogonal_crossover(self, x1, x2):\n        \"\"\"Performs orthogonal crossover between two individuals.\"\"\"\n        if np.random.rand() < self.orthogonal_crossover_rate:\n            alpha = np.random.rand()\n            return alpha * x1 + (1 - alpha) * x2\n        else:\n            return x1  # Or x2, or a random combination, to ensure diversity\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialization\n        self.X, self.F = self.sample(func)\n        eval_count += self.pop_size\n\n        best_idx = np.argmin(self.F)\n        self.f_opt = self.F[best_idx]\n        self.x_opt = self.X[best_idx]\n\n        while eval_count < self.budget:\n            # Adaptive Mutation Factor\n            diversity = np.std(self.F)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n\n            # Mutation and Crossover (Differential Evolution)\n            mutated_X = np.zeros_like(self.X)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.X[idxs]\n                mutated_X[i] = self.X[i] + self.F_val * (x_r1 - x_r2)  # DE Mutation\n\n            # Apply orthogonal crossover\n            trial_X = np.array([self.orthogonal_crossover(mutated_X[i], self.X[i]) for i in range(self.pop_size)])\n\n            trial_X = np.clip(trial_X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            trial_F = np.array([func(x) for x in trial_X])\n            eval_count += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_F[i] < self.F[i]:\n                    self.X[i] = trial_X[i]\n                    self.F[i] = trial_F[i]\n\n            # Covariance Matrix Adaptation (CMA) - Simplified\n            best_idx = np.argmin(self.F)\n            x_mean = np.mean(self.X, axis=0)\n\n            # Update the mean\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n\n            # Robust Step-size Adaptation using exponential moving average\n            diff = self.mu - x_mean\n            norm_diff = np.linalg.norm(diff)\n            # Update the sigma with exponential moving average\n            self.sigma = 0.9 * self.sigma + 0.1 * (self.sigma * np.exp(self.c_cov * (norm_diff - 0.5)))\n            self.sigma = np.maximum(self.sigma, 1e-6) # Avoid sigma becoming zero.\n\n\n            best_idx = np.argmin(self.F)\n            if self.F[best_idx] < self.f_opt:\n                self.f_opt = self.F[best_idx]\n                self.x_opt = self.X[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07004186034258242, 0.38070215108963634, 0.6614484304796411, 0.14979828575080245, 0.18196564664521853, 0.3442554071394833, 0.1913858911916655, 0.2296252360230816, 0.3615864333017549, 0.19087318858091717, 0.19942932846331407, 0.9783010245176754, 0.27329202713183964, 0.18935064455372586, 0.26590609765857665, 0.332221715599577, 0.25678951593809174, 0.2894811755537653, 0.18411513002178537, 0.4523519473537314], "operator": "mutation", "theta_sampled": 0.00019922837458461568, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "347de3a4-ba92-47f9-8323-1e524ec59a13", "fitness": 0.0, "name": "SobolSimplex", "description": "A novel algorithm that combines a global exploration phase using a Sobol sequence-based sampling with a local search refinement using a Nelder-Mead Simplex method on promising regions, adaptively adjusting the simplex size based on function value improvement.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolSimplex:\n    def __init__(self, budget=10000, dim=10, sobol_seed=None):\n        self.budget = budget\n        self.dim = dim\n        self.sobol_seed = sobol_seed\n        self.sobol_seq = self._generate_sobol_sequence(budget, dim, seed=sobol_seed)  # Pre-generate Sobol sequence\n        self.simplex_size = 0.1  # Initial simplex size\n        self.success_history = []\n\n\n    def _generate_sobol_sequence(self, n, d, seed=None):\n        \"\"\"Generates a Sobol sequence using a simple implementation.\"\"\"\n        V = np.zeros((n, d), dtype=float)\n        if seed is not None:\n            np.random.seed(seed) # needed for proper testing\n\n        m = np.arange(1, 32)\n        C = np.bitwise_xor(np.right_shift(1, m), 1)\n\n        X = np.random.randint(1, 2**31-1, d) # Initialization for each dimension\n\n        for i in range(n):\n            V[i] = X / 2**31\n            X = np.bitwise_xor(X, np.right_shift(X, 1))\n            X = np.bitwise_xor(X, np.left_shift(X, 10))\n            X = np.bitwise_xor(X, np.left_shift(X, 3))\n            X = np.bitwise_xor(X, np.left_shift(X, 11))\n        return V\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        n_local_searches = 0\n\n\n        # Global exploration using Sobol sequence\n        for i in range(min(self.budget, len(self.sobol_seq))):\n            x = func.bounds.lb + self.sobol_seq[i] * (func.bounds.ub - func.bounds.lb) # Map Sobol sequence to bounds\n            f = func(x)\n            eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n                # Local search refinement (Nelder-Mead)\n                if eval_count < self.budget:\n                    n_local_searches += 1\n                    initial_simplex = np.zeros((self.dim + 1, self.dim))\n\n                    # Create a simplex around the current best\n                    initial_simplex[0] = self.x_opt\n                    for j in range(self.dim):\n                      x_temp = np.copy(self.x_opt)\n                      x_temp[j] += self.simplex_size\n                      x_temp[j] = np.clip(x_temp[j], func.bounds.lb[j], func.bounds.ub[j])  # Ensure bounds are respected\n                      initial_simplex[j+1] = x_temp\n                    \n                    # Local search objective function wrapper to track evaluations\n                    def local_objective(x):\n                      nonlocal eval_count\n                      if eval_count >= self.budget:\n                        return np.inf\n                      eval_count += 1\n                      return func(x)\n                    \n                    res = minimize(local_objective, self.x_opt, method='Nelder-Mead', options={'maxfev': self.budget - eval_count, 'initial_simplex': initial_simplex})\n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n                        # Adjust simplex size based on improvement. Reduce it to allow finer exploration in subsequent searches\n                        self.simplex_size *= 0.9  # Shrink if we found a better solution.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A novel algorithm that combines a global exploration phase using a Sobol sequence-based sampling with a local search refinement using a Nelder-Mead Simplex method on promising regions, adaptively adjusting the simplex size based on function value improvement.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolSimplex:\n    def __init__(self, budget=10000, dim=10, sobol_seed=None):\n        self.budget = budget\n        self.dim = dim\n        self.sobol_seed = sobol_seed\n        self.sobol_seq = self._generate_sobol_sequence(budget, dim, seed=sobol_seed)  # Pre-generate Sobol sequence\n        self.simplex_size = 0.1  # Initial simplex size\n        self.success_history = []\n\n\n    def _generate_sobol_sequence(self, n, d, seed=None):\n        \"\"\"Generates a Sobol sequence using a simple implementation.\"\"\"\n        V = np.zeros((n, d), dtype=float)\n        if seed is not None:\n            np.random.seed(seed) # needed for proper testing\n\n        m = np.arange(1, 32)\n        C = np.bitwise_xor(np.right_shift(1, m), 1)\n\n        X = np.random.randint(1, 2**31-1, d) # Initialization for each dimension\n\n        for i in range(n):\n            V[i] = X / 2**31\n            X = np.bitwise_xor(X, np.right_shift(X, 1))\n            X = np.bitwise_xor(X, np.left_shift(X, 10))\n            X = np.bitwise_xor(X, np.left_shift(X, 3))\n            X = np.bitwise_xor(X, np.left_shift(X, 11))\n        return V\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        n_local_searches = 0\n\n\n        # Global exploration using Sobol sequence\n        for i in range(min(self.budget, len(self.sobol_seq))):\n            x = func.bounds.lb + self.sobol_seq[i] * (func.bounds.ub - func.bounds.lb) # Map Sobol sequence to bounds\n            f = func(x)\n            eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n                # Local search refinement (Nelder-Mead)\n                if eval_count < self.budget:\n                    n_local_searches += 1\n                    initial_simplex = np.zeros((self.dim + 1, self.dim))\n\n                    # Create a simplex around the current best\n                    initial_simplex[0] = self.x_opt\n                    for j in range(self.dim):\n                      x_temp = np.copy(self.x_opt)\n                      x_temp[j] += self.simplex_size\n                      x_temp[j] = np.clip(x_temp[j], func.bounds.lb[j], func.bounds.ub[j])  # Ensure bounds are respected\n                      initial_simplex[j+1] = x_temp\n                    \n                    # Local search objective function wrapper to track evaluations\n                    def local_objective(x):\n                      nonlocal eval_count\n                      if eval_count >= self.budget:\n                        return np.inf\n                      eval_count += 1\n                      return func(x)\n                    \n                    res = minimize(local_objective, self.x_opt, method='Nelder-Mead', options={'maxfev': self.budget - eval_count, 'initial_simplex': initial_simplex})\n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n                        # Adjust simplex size based on improvement. Reduce it to allow finer exploration in subsequent searches\n                        self.simplex_size *= 0.9  # Shrink if we found a better solution.\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.009023982132277755, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "50f4d720-febf-472d-87bb-81c8e38e95a9", "fitness": 0.5498590701259853, "name": "AdaptiveHybridPSO_CMA_DE_v2", "description": "An adaptive hybrid algorithm combining PSO, DE, and CMA for enhanced exploration and exploitation with dynamic parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, F_val_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs # Learning rate for CMA mean\n        self.c_cov = c_cov # Learning rate for CMA sigma\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = F_val_init #DE mutation factor\n        self.F_val_init = F_val_init # Store initial F_val for reset\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / 10000) #use 10000 as normalization, not self.budget since the latter changes\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget, original version uses 10000\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n            # Periodically reset F_val to its initial value to avoid stagnation\n            if eval_count % (self.pop_size * 5) == 0:\n                self.F_val = self.F_val_init\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_CMA_DE_v2 scored 0.550 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69eb3d57-efc7-430d-a6a2-e36612c80a8a", "d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm combining PSO, DE, and CMA for enhanced exploration and exploitation with dynamic parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, F_val_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs # Learning rate for CMA mean\n        self.c_cov = c_cov # Learning rate for CMA sigma\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = F_val_init #DE mutation factor\n        self.F_val_init = F_val_init # Store initial F_val for reset\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / 10000) #use 10000 as normalization, not self.budget since the latter changes\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget, original version uses 10000\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n            # Periodically reset F_val to its initial value to avoid stagnation\n            if eval_count % (self.pop_size * 5) == 0:\n                self.F_val = self.F_val_init\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.1904528193830729, 0.22246209073833334, 0.675891310392628, 0.8261792366034776, 0.2513145196214027, 0.710520853817759, 0.31269659724690946, 0.6342336436790872, 0.668609151339629, 0.6389161586432999, 0.8312348710497052, 0.9946415989140346, 0.34698574320888953, 0.7047388249962097, 0.7201868624017711, 0.7126204008076087, 0.381954583967849, 0.37707780523879075, 0.29648908483723857, 0.4999752456320109], "operator": "crossover", "theta_sampled": 0.0015851836099827037, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "e4e2d565-ed5e-4ca9-959a-f41f6f671c56", "fitness": 0.570043841028645, "name": "AdaptiveHybridPSO_DE_CMA_LS", "description": "Adaptively combines PSO, DE, and CMA with dynamic parameter adjustments and a self-adaptive local search based on fitness landscape characteristics.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, ls_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n        self.ls_prob = ls_prob #probability of local search\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n                # Self-Adaptive Local Search\n                if np.random.rand() < self.ls_prob:\n                    # Perturb the current solution based on fitness landscape\n                    delta = np.random.normal(0, self.sigma, self.dim) # Use CMA's sigma for perturbation scale\n                    ls_pos = new_pos + delta\n                    ls_pos = np.clip(ls_pos, func.bounds.lb, func.bounds.ub)\n                    ls_fitness = func(ls_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n\n                    if ls_fitness < new_fitness:\n                        pop[i] = ls_pos\n                        fitness[i] = ls_fitness\n                        if ls_fitness < personal_best_fitness[i]:\n                            personal_best_fitness[i] = ls_fitness\n                            personal_best_pos[i] = ls_pos.copy()\n                        if ls_fitness < global_best_fitness:\n                            global_best_fitness = ls_fitness\n                            global_best_pos = ls_pos.copy()\n\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n            #Adapt local search probability\n            if eval_count % 1000 == 0: # Adjust local search probability every 1000 evaluations\n                if np.std(fitness) < 0.01: # low diversity\n                    self.ls_prob = min(self.ls_prob * 1.2, 0.5) # increase exploration\n                else:\n                    self.ls_prob = max(self.ls_prob * 0.8, 0.01) # decrease exploration\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_DE_CMA_LS scored 0.570 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69eb3d57-efc7-430d-a6a2-e36612c80a8a", "d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO, DE, and CMA with dynamic parameter adjustments and a self-adaptive local search based on fitness landscape characteristics.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, ls_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n        self.ls_prob = ls_prob #probability of local search\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n                # Self-Adaptive Local Search\n                if np.random.rand() < self.ls_prob:\n                    # Perturb the current solution based on fitness landscape\n                    delta = np.random.normal(0, self.sigma, self.dim) # Use CMA's sigma for perturbation scale\n                    ls_pos = new_pos + delta\n                    ls_pos = np.clip(ls_pos, func.bounds.lb, func.bounds.ub)\n                    ls_fitness = func(ls_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n\n                    if ls_fitness < new_fitness:\n                        pop[i] = ls_pos\n                        fitness[i] = ls_fitness\n                        if ls_fitness < personal_best_fitness[i]:\n                            personal_best_fitness[i] = ls_fitness\n                            personal_best_pos[i] = ls_pos.copy()\n                        if ls_fitness < global_best_fitness:\n                            global_best_fitness = ls_fitness\n                            global_best_pos = ls_pos.copy()\n\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n            #Adapt local search probability\n            if eval_count % 1000 == 0: # Adjust local search probability every 1000 evaluations\n                if np.std(fitness) < 0.01: # low diversity\n                    self.ls_prob = min(self.ls_prob * 1.2, 0.5) # increase exploration\n                else:\n                    self.ls_prob = max(self.ls_prob * 0.8, 0.01) # decrease exploration\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.19325531267660878, 0.4294670459689621, 0.7068137915433049, 0.8257802995904381, 0.2637298553767311, 0.7473274350909519, 0.318523356038225, 0.692789440942069, 0.7204394892568098, 0.6771468184913849, 0.8199452503086742, 0.9956015886808081, 0.311193685832283, 0.4781865049470372, 0.7120983578846096, 0.750131515815576, 0.3792863568838789, 0.677502260682937, 0.2152537163749636, 0.4864047381866461], "operator": "crossover", "theta_sampled": 0.0004965530965051446, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "34595d98-7e4f-42ce-9283-2bea1f226cbf", "fitness": 0.0, "name": "AdaptiveHybridPSO_CMA_DE_Restart", "description": "A hybrid algorithm combining PSO with CMA for parameter adaptation and DE for local search, further enhanced with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n        self.restart_trigger = restart_trigger\n        self.no_improve_count = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n        self.best_fitness_history.append(global_best_fitness)\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    self.no_improve_count = 0  # Reset counter\n                else:\n                    self.no_improve_count += 1  # Increment counter\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n            # Restart mechanism if no improvement for a while\n            if self.no_improve_count > self.restart_trigger:\n                # Re-initialize population (excluding the best individual)\n                pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                pop[0] = global_best_pos.copy()  # Keep the best solution\n\n                velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= (self.pop_size -1) #account for re-evaluation (best already evaluated)\n                eval_count+= (self.pop_size - 1)\n                personal_best_pos = pop.copy()\n                personal_best_fitness = fitness.copy()\n\n                # Update global best (just in case re-init introduced a better solution)\n                global_best_idx = np.argmin(fitness)\n                if fitness[global_best_idx] < global_best_fitness:\n                    global_best_fitness = fitness[global_best_idx]\n                    global_best_pos = pop[global_best_idx].copy()\n\n                self.no_improve_count = 0  # Reset counter\n                self.mu = np.mean(pop, axis=0) #re-initialize CMA mean\n                self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Re-initialize sigma\n\n\n            self.best_fitness_history.append(global_best_fitness)\n            if len(self.best_fitness_history) > 100:\n                self.best_fitness_history.pop(0)\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_CMA_DE_Restart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69eb3d57-efc7-430d-a6a2-e36612c80a8a", "d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining PSO with CMA for parameter adaptation and DE for local search, further enhanced with a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n        self.restart_trigger = restart_trigger\n        self.no_improve_count = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n        self.best_fitness_history.append(global_best_fitness)\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    self.no_improve_count = 0  # Reset counter\n                else:\n                    self.no_improve_count += 1  # Increment counter\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n            # Restart mechanism if no improvement for a while\n            if self.no_improve_count > self.restart_trigger:\n                # Re-initialize population (excluding the best individual)\n                pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                pop[0] = global_best_pos.copy()  # Keep the best solution\n\n                velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= (self.pop_size -1) #account for re-evaluation (best already evaluated)\n                eval_count+= (self.pop_size - 1)\n                personal_best_pos = pop.copy()\n                personal_best_fitness = fitness.copy()\n\n                # Update global best (just in case re-init introduced a better solution)\n                global_best_idx = np.argmin(fitness)\n                if fitness[global_best_idx] < global_best_fitness:\n                    global_best_fitness = fitness[global_best_idx]\n                    global_best_pos = pop[global_best_idx].copy()\n\n                self.no_improve_count = 0  # Reset counter\n                self.mu = np.mean(pop, axis=0) #re-initialize CMA mean\n                self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Re-initialize sigma\n\n\n            self.best_fitness_history.append(global_best_fitness)\n            if len(self.best_fitness_history) > 100:\n                self.best_fitness_history.pop(0)\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.002145725922317704, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "7286ef7f-1a87-4714-98c2-078c7b71c316", "fitness": 0.10179127650050912, "name": "AdaptiveNichingPSO_DE", "description": "Combines PSO with adaptive DE and a niching strategy based on crowding distance to maintain diversity and escape local optima.", "code": "import numpy as np\n\nclass AdaptiveNichingPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.niche_radius = niche_radius # Radius of the niche for crowding\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            # Niching strategy: Crowding distance\n            crowding_distances = self.calculate_crowding_distance(pop)\n\n            # Identify worst particle within a niche\n            for i in range(self.pop_size):\n                distances = np.linalg.norm(pop - pop[i], axis=1)\n                niche_members = np.where(distances < self.niche_radius)[0]\n\n                if len(niche_members) > 1:\n                    #Select member with worst crowding distance within the niche\n                    worst_member = niche_members[np.argmax(crowding_distances[niche_members])]\n\n                    # Replace the worst member with a random particle\n                    pop[worst_member] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[worst_member] = func(pop[worst_member])\n                    self.budget -= 1\n\n                    personal_best_pos[worst_member] = pop[worst_member].copy()\n                    personal_best_fitness[worst_member] = fitness[worst_member]\n\n\n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos\n\n    def calculate_crowding_distance(self, pop):\n        \"\"\"Calculates the crowding distance for each particle in the population.\"\"\"\n        distances = np.zeros(self.pop_size)\n\n        for m in range(self.dim):  # Iterate through each dimension\n            # Sort population based on the m-th dimension\n            sorted_indices = np.argsort(pop[:, m])\n\n            # Boundary particles get maximum distance\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            # Calculate crowding distance for intermediate particles\n            for i in range(1, self.pop_size - 1):\n                distances[sorted_indices[i]] += (pop[sorted_indices[i+1], m] - pop[sorted_indices[i-1], m])\n\n        return distances", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveNichingPSO_DE scored 0.102 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines PSO with adaptive DE and a niching strategy based on crowding distance to maintain diversity and escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveNichingPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.niche_radius = niche_radius # Radius of the niche for crowding\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            # Niching strategy: Crowding distance\n            crowding_distances = self.calculate_crowding_distance(pop)\n\n            # Identify worst particle within a niche\n            for i in range(self.pop_size):\n                distances = np.linalg.norm(pop - pop[i], axis=1)\n                niche_members = np.where(distances < self.niche_radius)[0]\n\n                if len(niche_members) > 1:\n                    #Select member with worst crowding distance within the niche\n                    worst_member = niche_members[np.argmax(crowding_distances[niche_members])]\n\n                    # Replace the worst member with a random particle\n                    pop[worst_member] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[worst_member] = func(pop[worst_member])\n                    self.budget -= 1\n\n                    personal_best_pos[worst_member] = pop[worst_member].copy()\n                    personal_best_fitness[worst_member] = fitness[worst_member]\n\n\n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos\n\n    def calculate_crowding_distance(self, pop):\n        \"\"\"Calculates the crowding distance for each particle in the population.\"\"\"\n        distances = np.zeros(self.pop_size)\n\n        for m in range(self.dim):  # Iterate through each dimension\n            # Sort population based on the m-th dimension\n            sorted_indices = np.argsort(pop[:, m])\n\n            # Boundary particles get maximum distance\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            # Calculate crowding distance for intermediate particles\n            for i in range(1, self.pop_size - 1):\n                distances[sorted_indices[i]] += (pop[sorted_indices[i+1], m] - pop[sorted_indices[i-1], m])\n\n        return distances\n```", "aucs": [0.20358255300101824, 0], "operator": "mutation", "theta_sampled": 0.0017015337020217988, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "10ce32e3-33be-42a8-b5c1-b4ce9585b85a", "fitness": 0.55662404836451, "name": "HybridAdaptivePSO_CMA_DE", "description": "Combines Adaptive PSO with CMA-ES-inspired parameter adaptation and DE for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_CMA_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, F_val_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs # CMA learning rate for mean\n        self.c_cov = c_cov # CMA learning rate for sigma\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = F_val_init #DE mutation factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridAdaptivePSO_CMA_DE scored 0.557 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69eb3d57-efc7-430d-a6a2-e36612c80a8a", "d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive PSO with CMA-ES-inspired parameter adaptation and DE for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_CMA_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, F_val_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs # CMA learning rate for mean\n        self.c_cov = c_cov # CMA learning rate for sigma\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = F_val_init #DE mutation factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.21286083029347502, 0.6413673148656844, 0.7347638189022379, 0.8333087630261737, 0.724944182989762, 0.29545476731183373, 0.3070453305295602, 0.48785399085488423, 0.7292955059875537, 0.7005351407481115, 0.7676388676985472, 0.9962707464314507, 0.2642951481009691, 0.2727032621920452, 0.7226945732823602, 0.7619716332534237, 0.4119752729235906, 0.37213023375346155, 0.3717436915853265, 0.5236278925597483], "operator": "crossover", "theta_sampled": -0.00010490957155894398, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "1012ffda-3d66-4511-8361-e3a30d1e981d", "fitness": 0.5082635527882927, "name": "AdaptiveHybridPSO_CMA_DE_v2", "description": "An adaptive hybrid algorithm combining PSO with CMA parameter adaptation and DE mutation, dynamically adjusting parameters based on diversity and budget.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, F_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = F_init #DE mutation factor\n        self.F_init = F_init\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    # Apply a slightly different DE mutation\n                    mutated_pos = new_pos + self.F_val * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor based on diversity and budget\n            diversity = np.std(fitness)\n            remaining_budget_ratio = self.budget / 10000\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = self.F_init + 0.3 * np.random.rand() * remaining_budget_ratio\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand() * remaining_budget_ratio\n\n            self.F_val = np.clip(self.F_val, 0.1, 0.9) #Clip to ensure reasonable values\n\n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * remaining_budget_ratio\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridPSO_CMA_DE_v2 scored 0.508 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69eb3d57-efc7-430d-a6a2-e36612c80a8a", "d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm combining PSO with CMA parameter adaptation and DE mutation, dynamically adjusting parameters based on diversity and budget.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_CMA_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, F_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = F_init #DE mutation factor\n        self.F_init = F_init\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size #keep track of evaluations\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    # Apply a slightly different DE mutation\n                    mutated_pos = new_pos + self.F_val * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor based on diversity and budget\n            diversity = np.std(fitness)\n            remaining_budget_ratio = self.budget / 10000\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = self.F_init + 0.3 * np.random.rand() * remaining_budget_ratio\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand() * remaining_budget_ratio\n\n            self.F_val = np.clip(self.F_val, 0.1, 0.9) #Clip to ensure reasonable values\n\n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * remaining_budget_ratio\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.3135320368725183, 0.3252982613713129, 0.7278110540508897, 0.8475544077562527, 0.29658764570561746, 0.2808965461089309, 0.31888518724078363, 0.46767638864372263, 0.7245813350322423, 0.22336212801343314, 0.7807725682519913, 0.9956048488456538, 0.2237901625322003, 0.2516561476323117, 0.6447470878218509, 0.7474635500245461, 0.6559067248724195, 0.28901131634164445, 0.5701842004025686, 0.47994945824496393], "operator": "crossover", "theta_sampled": 0.0009034865888274978, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "ce1be778-e6df-4a56-b17c-f4caff1d7af1", "fitness": 0.23257811479764676, "name": "AdaptivePopulationSearch", "description": "Population-based search with adaptive step size control inspired by the \"success history adaptation\" mechanism from CMA-ES, combined with a local search component triggered periodically.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr_init=0.1, local_search_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr_init  # Initial learning rate for step size adaptation\n        self.lr_min = 1e-6 # Minimum learning rate\n        self.lr_max = 0.5 # Maximum learning rate\n        self.success_history = []\n        self.success_history_length = 10\n        self.local_search_freq = local_search_freq\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.population[best_idx].copy()\n\n\n        while self.budget > 0:\n            # 1. Select parents (e.g., using tournament selection)\n            parents_idx = self._tournament_selection(num_parents=self.pop_size)\n            parents = self.population[parents_idx]\n\n            # 2. Generate offspring by adding adaptive noise to the parents\n            offspring = parents + self.lr * np.random.randn(self.pop_size, self.dim)\n            offspring = np.clip(offspring, lb, ub) # clip values\n            \n            # 3. Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # 4. Update population (replace parents with better offspring)\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < self.fitness[parents_idx[i]]:\n                    self.population[parents_idx[i]] = offspring[i].copy()\n                    self.fitness[parents_idx[i]] = offspring_fitness[i]\n                    self.success_history.append(1)\n                else:\n                    self.success_history.append(0)\n\n\n            # 5. Update best solution\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx].copy()\n\n            # 6. Adaptive Step Size Control (Success History Adaptation)\n            self._update_learning_rate()\n            \n            #7. Local search\n            if self.budget > 0 and (self.budget % self.local_search_freq) < self.pop_size:\n                self._local_search(func)\n\n        return self.f_opt, self.x_opt\n\n    def _tournament_selection(self, tournament_size=3, num_parents=None):\n        if num_parents is None:\n            num_parents = self.pop_size\n        \n        selected_indices = []\n        for _ in range(num_parents):\n            participants = np.random.choice(self.pop_size, size=tournament_size, replace=False)\n            winner = participants[np.argmin(self.fitness[participants])]\n            selected_indices.append(winner)\n        return np.array(selected_indices)\n\n\n    def _update_learning_rate(self):\n        if len(self.success_history) > self.success_history_length:\n            self.success_history = self.success_history[-self.success_history_length:]\n        \n        if len(self.success_history) == 0:\n            return # Cannot update yet\n\n        success_rate = np.mean(self.success_history)\n\n        if success_rate > 0.6:\n            self.lr *= 1.2  # Increase learning rate\n        elif success_rate < 0.4:\n            self.lr *= 0.8  # Decrease learning rate\n\n        self.lr = np.clip(self.lr, self.lr_min, self.lr_max) # Clip the learning rate\n\n\n    def _local_search(self, func, num_steps=10):\n        # Perform a simple local search around the best solution\n        step_size = self.lr / 2 # Reduced step size for local search\n\n        x_current = self.x_opt.copy()\n        f_current = self.f_opt\n        \n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for _ in range(num_steps):\n            if self.budget <= 0:\n                break\n\n            x_new = x_current + step_size * np.random.randn(self.dim)\n            x_new = np.clip(x_new, lb, ub)\n\n            f_new = func(x_new)\n            self.budget -=1\n\n            if f_new < f_current:\n                x_current = x_new.copy()\n                f_current = f_new\n                self.x_opt = x_new.copy()\n                self.f_opt = f_new", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptivePopulationSearch scored 0.233 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search with adaptive step size control inspired by the \"success history adaptation\" mechanism from CMA-ES, combined with a local search component triggered periodically.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr_init=0.1, local_search_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr_init  # Initial learning rate for step size adaptation\n        self.lr_min = 1e-6 # Minimum learning rate\n        self.lr_max = 0.5 # Maximum learning rate\n        self.success_history = []\n        self.success_history_length = 10\n        self.local_search_freq = local_search_freq\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.population[best_idx].copy()\n\n\n        while self.budget > 0:\n            # 1. Select parents (e.g., using tournament selection)\n            parents_idx = self._tournament_selection(num_parents=self.pop_size)\n            parents = self.population[parents_idx]\n\n            # 2. Generate offspring by adding adaptive noise to the parents\n            offspring = parents + self.lr * np.random.randn(self.pop_size, self.dim)\n            offspring = np.clip(offspring, lb, ub) # clip values\n            \n            # 3. Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # 4. Update population (replace parents with better offspring)\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < self.fitness[parents_idx[i]]:\n                    self.population[parents_idx[i]] = offspring[i].copy()\n                    self.fitness[parents_idx[i]] = offspring_fitness[i]\n                    self.success_history.append(1)\n                else:\n                    self.success_history.append(0)\n\n\n            # 5. Update best solution\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx].copy()\n\n            # 6. Adaptive Step Size Control (Success History Adaptation)\n            self._update_learning_rate()\n            \n            #7. Local search\n            if self.budget > 0 and (self.budget % self.local_search_freq) < self.pop_size:\n                self._local_search(func)\n\n        return self.f_opt, self.x_opt\n\n    def _tournament_selection(self, tournament_size=3, num_parents=None):\n        if num_parents is None:\n            num_parents = self.pop_size\n        \n        selected_indices = []\n        for _ in range(num_parents):\n            participants = np.random.choice(self.pop_size, size=tournament_size, replace=False)\n            winner = participants[np.argmin(self.fitness[participants])]\n            selected_indices.append(winner)\n        return np.array(selected_indices)\n\n\n    def _update_learning_rate(self):\n        if len(self.success_history) > self.success_history_length:\n            self.success_history = self.success_history[-self.success_history_length:]\n        \n        if len(self.success_history) == 0:\n            return # Cannot update yet\n\n        success_rate = np.mean(self.success_history)\n\n        if success_rate > 0.6:\n            self.lr *= 1.2  # Increase learning rate\n        elif success_rate < 0.4:\n            self.lr *= 0.8  # Decrease learning rate\n\n        self.lr = np.clip(self.lr, self.lr_min, self.lr_max) # Clip the learning rate\n\n\n    def _local_search(self, func, num_steps=10):\n        # Perform a simple local search around the best solution\n        step_size = self.lr / 2 # Reduced step size for local search\n\n        x_current = self.x_opt.copy()\n        f_current = self.f_opt\n        \n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for _ in range(num_steps):\n            if self.budget <= 0:\n                break\n\n            x_new = x_current + step_size * np.random.randn(self.dim)\n            x_new = np.clip(x_new, lb, ub)\n\n            f_new = func(x_new)\n            self.budget -=1\n\n            if f_new < f_current:\n                x_current = x_new.copy()\n                f_current = f_new\n                self.x_opt = x_new.copy()\n                self.f_opt = f_new\n```", "aucs": [0.09764937284407627, 0.1632440634361938, 0.23134963139209785, 0.145556104590446, 0.12209980083787864, 0.15337189173267674, 0.208593784591676, 0.13285364503439434, 0.15937122432908035, 0.13809889286866528, 0.18715652019080964, 0.9995592770199381, 0.3201098828279604, 0.16736215265745014, 0.2165125706616785, 0.2642035677426803, 0.21214064501791574, 0.17666898522395347, 0.12761551732930643, 0.42804476562405736], "operator": "random_new", "theta_sampled": 0.018146983519457573, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "128cb7a3-f6d6-4592-8db2-f8fc0a987d0b", "fitness": 0.539831266777874, "name": "AdaptiveExplorationPSO_DE", "description": "A population-based algorithm combining elements of Particle Swarm Optimization (PSO) with differential evolution (DE) and a Cauchy mutation to enhance exploration, adaptively adjusting exploration rates based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveExplorationPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.exploration_rate = 0.1  # Initial exploration rate\n        self.exploration_decay = 0.995 # Decay exploration rate over time\n        self.min_exploration_rate = 0.01\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pop = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        \n        while self.budget > 0:\n            # Diversity calculation (standard deviation of population)\n            diversity = np.std(pop)\n            # Adjust exploration rate based on diversity\n            self.exploration_rate = max(self.exploration_rate * self.exploration_decay, self.min_exploration_rate)\n            \n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (pbest_pop[i] - pop[i]) +\n                                 self.c2 * r2 * (gbest_pop - pop[i]))\n                \n                new_pos = pop[i] + velocities[i]\n\n                # DE mutation\n                if np.random.rand() < self.exploration_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs[0]], pop[idxs[1]], pop[idxs[2]]\n                    \n                    #Cauchy mutation\n                    mutation = x1 + self.f * (x2 - x3) + 0.1 * np.random.standard_cauchy(size=self.dim)\n                    \n                    \n                    cross_mask = np.random.rand(self.dim) < self.cr\n                    new_pos = np.where(cross_mask, mutation, new_pos) # crossover\n                \n\n                # Boundary handling (clip values)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pop = new_pos.copy()\n\n                pop[i] = new_pos.copy()\n\n            \n\n        return gbest_fitness, gbest_pop", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveExplorationPSO_DE scored 0.540 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm combining elements of Particle Swarm Optimization (PSO) with differential evolution (DE) and a Cauchy mutation to enhance exploration, adaptively adjusting exploration rates based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveExplorationPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.exploration_rate = 0.1  # Initial exploration rate\n        self.exploration_decay = 0.995 # Decay exploration rate over time\n        self.min_exploration_rate = 0.01\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(fitness)\n        gbest_pop = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        \n        while self.budget > 0:\n            # Diversity calculation (standard deviation of population)\n            diversity = np.std(pop)\n            # Adjust exploration rate based on diversity\n            self.exploration_rate = max(self.exploration_rate * self.exploration_decay, self.min_exploration_rate)\n            \n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (pbest_pop[i] - pop[i]) +\n                                 self.c2 * r2 * (gbest_pop - pop[i]))\n                \n                new_pos = pop[i] + velocities[i]\n\n                # DE mutation\n                if np.random.rand() < self.exploration_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs[0]], pop[idxs[1]], pop[idxs[2]]\n                    \n                    #Cauchy mutation\n                    mutation = x1 + self.f * (x2 - x3) + 0.1 * np.random.standard_cauchy(size=self.dim)\n                    \n                    \n                    cross_mask = np.random.rand(self.dim) < self.cr\n                    new_pos = np.where(cross_mask, mutation, new_pos) # crossover\n                \n\n                # Boundary handling (clip values)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_pop[i] = new_pos.copy()\n\n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_pop = new_pos.copy()\n\n                pop[i] = new_pos.copy()\n\n            \n\n        return gbest_fitness, gbest_pop\n```", "aucs": [0.1387554523892477, 0.37793083214800205, 0.6221344732301552, 0.8260676976271865, 0.34642764521140035, 0.6382122988451461, 0.31689822579194415, 0.5301341092629641, 0.6429906257813702, 0.2337707830747262, 0.7824622986456592, 0.9958195743430128, 0.3434786569755621, 0.2857785843354541, 0.800705661094703, 0.7497213446742956, 0.5215661841598946, 0.826565761905999, 0.3214853145040294, 0.4957198115567264], "operator": "random_new", "theta_sampled": 0.006479489769103008, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "62ff3fcc-cbae-4d78-a6e6-d5ae7aba0c40", "fitness": 0.2677266055423355, "name": "GradientEnhancedStochasticSearch", "description": "Population-based algorithm using a combination of gradient estimation via finite differences and stochastic search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass GradientEnhancedStochasticSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, grad_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.grad_samples = grad_samples\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Gradient estimation via finite differences\n                grad_est = np.zeros(self.dim)\n                for d in range(self.dim):\n                    x_plus = population[i].copy()\n                    x_minus = population[i].copy()\n\n                    #Perturb each dimension multiple times and average to get estimate\n                    f_plus_sum = 0\n                    f_minus_sum = 0\n                    for _ in range(self.grad_samples):\n                        x_plus[d] += self.step_size\n                        x_minus[d] -= self.step_size\n\n                        #Bound the new points\n                        x_plus[d] = np.clip(x_plus[d], func.bounds.lb[d], func.bounds.ub[d])\n                        x_minus[d] = np.clip(x_minus[d], func.bounds.lb[d], func.bounds.ub[d])\n                    \n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        \n                        f_plus_sum += f_plus\n                        f_minus_sum += f_minus\n\n                        eval_count += 2\n                        if eval_count >= self.budget:\n                            break\n                    \n                    grad_est[d] = (f_plus_sum/self.grad_samples - f_minus_sum/self.grad_samples) / (2 * self.step_size)\n                    if eval_count >= self.budget:\n                        break\n                if eval_count >= self.budget:\n                    break\n\n                # Gradient-based move\n                new_x = population[i] - self.step_size * grad_est\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                new_f = func(new_x)\n                eval_count += 1\n\n                # Stochastic move (exploration)\n                rand_x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                rand_f = func(rand_x)\n                eval_count += 1\n\n                # Selection: greedy\n                if new_f < fitness[i]:\n                    population[i] = new_x\n                    fitness[i] = new_f\n                elif rand_f < fitness[i]:\n                     population[i] = rand_x\n                     fitness[i] = rand_f\n                 \n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n                if rand_f < self.f_opt:\n                    self.f_opt = rand_f\n                    self.x_opt = rand_x\n\n                if eval_count >= self.budget:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm GradientEnhancedStochasticSearch scored 0.268 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of gradient estimation via finite differences and stochastic search to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass GradientEnhancedStochasticSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, grad_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.grad_samples = grad_samples\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Gradient estimation via finite differences\n                grad_est = np.zeros(self.dim)\n                for d in range(self.dim):\n                    x_plus = population[i].copy()\n                    x_minus = population[i].copy()\n\n                    #Perturb each dimension multiple times and average to get estimate\n                    f_plus_sum = 0\n                    f_minus_sum = 0\n                    for _ in range(self.grad_samples):\n                        x_plus[d] += self.step_size\n                        x_minus[d] -= self.step_size\n\n                        #Bound the new points\n                        x_plus[d] = np.clip(x_plus[d], func.bounds.lb[d], func.bounds.ub[d])\n                        x_minus[d] = np.clip(x_minus[d], func.bounds.lb[d], func.bounds.ub[d])\n                    \n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        \n                        f_plus_sum += f_plus\n                        f_minus_sum += f_minus\n\n                        eval_count += 2\n                        if eval_count >= self.budget:\n                            break\n                    \n                    grad_est[d] = (f_plus_sum/self.grad_samples - f_minus_sum/self.grad_samples) / (2 * self.step_size)\n                    if eval_count >= self.budget:\n                        break\n                if eval_count >= self.budget:\n                    break\n\n                # Gradient-based move\n                new_x = population[i] - self.step_size * grad_est\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                new_f = func(new_x)\n                eval_count += 1\n\n                # Stochastic move (exploration)\n                rand_x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                rand_f = func(rand_x)\n                eval_count += 1\n\n                # Selection: greedy\n                if new_f < fitness[i]:\n                    population[i] = new_x\n                    fitness[i] = new_f\n                elif rand_f < fitness[i]:\n                     population[i] = rand_x\n                     fitness[i] = rand_f\n                 \n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n                if rand_f < self.f_opt:\n                    self.f_opt = rand_f\n                    self.x_opt = rand_x\n\n                if eval_count >= self.budget:\n                    break\n                    \n        return self.f_opt, self.x_opt\n```", "aucs": [0.10249661642352259, 0.17770330173595283, 0.24136539320855932, 0.20675359910311608, 0.1890993796874575, 0.22693772912936727, 0.2291735563207571, 0.24090839343995896, 0.21469613140477606, 0.15000129359610692, 0.2041473559346091, 0.999519883222875, 0.2539573706755581, 0.1796405357899643, 0.4244476935507272, 0.28188245599754047, 0.20976237098163952, 0.22092519648166475, 0.16662898063519693, 0.4344848735273594], "operator": "random_new", "theta_sampled": 0.0010435386826857715, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "c11b0a48-b338-4ace-9f74-68f3ec440e0a", "fitness": 0.6880798328575554, "name": "AdaptiveDE_NM", "description": "A population-based algorithm that uses a combination of global search with differential evolution and local search with a Nelder-Mead simplex, adaptively adjusting the balance between exploration and exploitation based on population diversity.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': self.budget - self.eval_count})  # Limit FE calls\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n              break\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size // self.nm_freq ) // self.nm_freq : #self.eval_count % self.nm_freq == 0: # Perform NM every nm_freq evaluations\n                self.nelder_mead_local_search(func)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDE_NM scored 0.688 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of global search with differential evolution and local search with a Nelder-Mead simplex, adaptively adjusting the balance between exploration and exploitation based on population diversity.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': self.budget - self.eval_count})  # Limit FE calls\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n              break\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size // self.nm_freq ) // self.nm_freq : #self.eval_count % self.nm_freq == 0: # Perform NM every nm_freq evaluations\n                self.nelder_mead_local_search(func)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2351698986141485, 0.6233163630915002, 0.7006243095095397, 0.8373153910338667, 0.7904997971614298, 0.8133366668842795, 0.6680802957569111, 0.6800283312503201, 0.7710484999640195, 0.7298616680449175, 0.8572302389691695, 0.9889071896569459, 0.43214064870246427, 0.7052331115688055, 0.9046345151012454, 0.8159207929752833, 0.6159095649732265, 0.839029501500428, 0.22989873132521654, 0.5234111410673911], "operator": "random_new", "theta_sampled": 0.0020596810798100985, "reward": 0.10990515027755332, "generation": 9}, "task_prompt": ""}
{"id": "4a97d087-ba48-4f3b-948a-662077779dd9", "fitness": 0.0, "name": "DynamicResourceAllocation", "description": "Population-based algorithm with dynamic resource allocation, where promising individuals receive more function evaluations and resources based on their recent performance.", "code": "import numpy as np\n\nclass DynamicResourceAllocation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, selection_pressure=2, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.selection_pressure = selection_pressure\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def selection(self):\n        indices = np.random.choice(self.pop_size, size=self.selection_pressure, replace=False)\n        selected_fitness = self.fitness[indices]\n        winner_index = indices[np.argmin(selected_fitness)]\n        return winner_index\n\n    def crossover(self, parent1_index, parent2_index):\n        parent1 = self.population[parent1_index]\n        parent2 = self.population[parent2_index]\n        alpha = np.random.rand(self.dim)\n        child = alpha * parent1 + (1 - alpha) * parent2\n        child = np.clip(child, self.lb, self.ub)\n        return child\n\n    def mutation(self, individual):\n        mutation_rate = 0.1\n        mutation_mask = np.random.rand(self.dim) < mutation_rate\n        mutation = np.random.normal(0, 0.1, size=self.dim)\n        mutated_individual = individual + mutation * mutation_mask\n        mutated_individual = np.clip(mutated_individual, self.lb, self.ub)\n        return mutated_individual\n\n    def local_search(self, individual, func, iterations):\n        best_individual = individual.copy()\n        best_fitness = func(individual)\n        \n        for _ in range(iterations):\n            neighbour = self.mutation(individual)\n            neighbour_fitness = func(neighbour)\n            self.budget -= 1\n            \n            if neighbour_fitness < best_fitness:\n                best_fitness = neighbour_fitness\n                best_individual = neighbour.copy()\n                \n        return best_individual, best_fitness\n\n    def allocate_resources(self):\n        # Rank individuals based on fitness\n        ranked_indices = np.argsort(self.fitness)\n        \n        # Assign resources (local search iterations) based on rank\n        resource_allocation = np.linspace(self.local_search_iterations, 1, self.pop_size)  # More iterations for better individuals\n        resource_allocation = resource_allocation.astype(int)\n\n        return ranked_indices, resource_allocation\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        while self.budget > 0:\n            # Selection and reproduction\n            new_population = []\n            new_fitness = []\n            \n            for _ in range(self.pop_size):\n                parent1_index = self.selection()\n                parent2_index = self.selection()\n                child = self.crossover(parent1_index, parent2_index)\n                child = self.mutation(child)\n                new_population.append(child)\n            \n            new_population = np.array(new_population)\n            \n            # Dynamic resource allocation\n            ranked_indices, resource_allocation = self.allocate_resources()\n            \n            # Local search with allocated resources\n            for i in range(self.pop_size):\n                individual_index = ranked_indices[i]\n                allocated_iterations = resource_allocation[i]\n                \n                best_individual, best_fitness = self.local_search(self.population[individual_index], func, allocated_iterations)\n                self.population[individual_index] = best_individual\n                self.fitness[individual_index] = best_fitness\n            \n            # Update f_opt and x_opt\n            current_best_fitness = np.min(self.fitness)\n            current_best_index = np.argmin(self.fitness)\n            \n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[current_best_index]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm DynamicResourceAllocation scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with dynamic resource allocation, where promising individuals receive more function evaluations and resources based on their recent performance.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicResourceAllocation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, selection_pressure=2, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.selection_pressure = selection_pressure\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def selection(self):\n        indices = np.random.choice(self.pop_size, size=self.selection_pressure, replace=False)\n        selected_fitness = self.fitness[indices]\n        winner_index = indices[np.argmin(selected_fitness)]\n        return winner_index\n\n    def crossover(self, parent1_index, parent2_index):\n        parent1 = self.population[parent1_index]\n        parent2 = self.population[parent2_index]\n        alpha = np.random.rand(self.dim)\n        child = alpha * parent1 + (1 - alpha) * parent2\n        child = np.clip(child, self.lb, self.ub)\n        return child\n\n    def mutation(self, individual):\n        mutation_rate = 0.1\n        mutation_mask = np.random.rand(self.dim) < mutation_rate\n        mutation = np.random.normal(0, 0.1, size=self.dim)\n        mutated_individual = individual + mutation * mutation_mask\n        mutated_individual = np.clip(mutated_individual, self.lb, self.ub)\n        return mutated_individual\n\n    def local_search(self, individual, func, iterations):\n        best_individual = individual.copy()\n        best_fitness = func(individual)\n        \n        for _ in range(iterations):\n            neighbour = self.mutation(individual)\n            neighbour_fitness = func(neighbour)\n            self.budget -= 1\n            \n            if neighbour_fitness < best_fitness:\n                best_fitness = neighbour_fitness\n                best_individual = neighbour.copy()\n                \n        return best_individual, best_fitness\n\n    def allocate_resources(self):\n        # Rank individuals based on fitness\n        ranked_indices = np.argsort(self.fitness)\n        \n        # Assign resources (local search iterations) based on rank\n        resource_allocation = np.linspace(self.local_search_iterations, 1, self.pop_size)  # More iterations for better individuals\n        resource_allocation = resource_allocation.astype(int)\n\n        return ranked_indices, resource_allocation\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        while self.budget > 0:\n            # Selection and reproduction\n            new_population = []\n            new_fitness = []\n            \n            for _ in range(self.pop_size):\n                parent1_index = self.selection()\n                parent2_index = self.selection()\n                child = self.crossover(parent1_index, parent2_index)\n                child = self.mutation(child)\n                new_population.append(child)\n            \n            new_population = np.array(new_population)\n            \n            # Dynamic resource allocation\n            ranked_indices, resource_allocation = self.allocate_resources()\n            \n            # Local search with allocated resources\n            for i in range(self.pop_size):\n                individual_index = ranked_indices[i]\n                allocated_iterations = resource_allocation[i]\n                \n                best_individual, best_fitness = self.local_search(self.population[individual_index], func, allocated_iterations)\n                self.population[individual_index] = best_individual\n                self.fitness[individual_index] = best_fitness\n            \n            # Update f_opt and x_opt\n            current_best_fitness = np.min(self.fitness)\n            current_best_index = np.argmin(self.fitness)\n            \n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[current_best_index]\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.035593420640205056, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "51e5d469-e641-4fab-a1f2-9e914e2e026e", "fitness": 0.16685476017376838, "name": "SpiralOptimization", "description": "A population-based algorithm that uses a spiral trajectory inspired by bacterial chemotaxis to explore the search space.", "code": "import numpy as np\n\nclass SpiralOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, spiral_const=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.spiral_const = spiral_const\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.F = np.array([func(x) for x in self.X])\n        self.n_evals = self.pop_size\n        \n        while self.n_evals < self.budget:\n            # Find the best solution so far\n            best_idx = np.argmin(self.F)\n            x_best = self.X[best_idx]\n            f_best = self.F[best_idx]\n            \n            if f_best < self.f_opt:\n                self.f_opt = f_best\n                self.x_opt = x_best\n            \n            # Update the position of each individual based on a spiral trajectory\n            for i in range(self.pop_size):\n                # Calculate the distance to the best solution\n                distance = self.X[i] - x_best\n                \n                # Update the position using a spiral trajectory\n                r = np.linalg.norm(distance)\n                theta = np.arctan2(distance[1], distance[0]) if self.dim >=2 else 0\n\n                if self.dim>2:\n                    theta_z = np.arctan2(distance[2], np.sqrt(distance[0]**2+distance[1]**2))\n\n                rotation_matrix = np.eye(self.dim)\n\n                if self.dim >= 2:\n                  rotation_matrix[0,0] = np.cos(self.spiral_const * theta)\n                  rotation_matrix[0,1] = -np.sin(self.spiral_const * theta)\n                  rotation_matrix[1,0] = np.sin(self.spiral_const * theta)\n                  rotation_matrix[1,1] = np.cos(self.spiral_const * theta)\n                \n                if self.dim > 2:\n                  rotation_matrix[2,2] = np.cos(self.spiral_const * theta_z)\n                  rotation_matrix[2,0] = -np.sin(self.spiral_const * theta_z)\n                  rotation_matrix[0,2] = np.sin(self.spiral_const * theta_z)\n                  rotation_matrix[0,0] = np.cos(self.spiral_const * theta_z)\n\n                new_x = x_best + np.dot(rotation_matrix, distance) #x_best + distance * np.exp(self.spiral_const * np.random.randn()) * np.cos(2 * np.pi * np.random.rand(self.dim))\n                \n\n                # Clip the new position to the bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate the new solution\n                new_f = func(new_x)\n                self.n_evals += 1\n                \n                # Update the population if the new solution is better\n                if new_f < self.F[i]:\n                    self.X[i] = new_x\n                    self.F[i] = new_f\n                    \n                if self.n_evals >= self.budget:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm SpiralOptimization scored 0.167 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a spiral trajectory inspired by bacterial chemotaxis to explore the search space.\n# Code: \n```python\nimport numpy as np\n\nclass SpiralOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, spiral_const=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.spiral_const = spiral_const\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.F = np.array([func(x) for x in self.X])\n        self.n_evals = self.pop_size\n        \n        while self.n_evals < self.budget:\n            # Find the best solution so far\n            best_idx = np.argmin(self.F)\n            x_best = self.X[best_idx]\n            f_best = self.F[best_idx]\n            \n            if f_best < self.f_opt:\n                self.f_opt = f_best\n                self.x_opt = x_best\n            \n            # Update the position of each individual based on a spiral trajectory\n            for i in range(self.pop_size):\n                # Calculate the distance to the best solution\n                distance = self.X[i] - x_best\n                \n                # Update the position using a spiral trajectory\n                r = np.linalg.norm(distance)\n                theta = np.arctan2(distance[1], distance[0]) if self.dim >=2 else 0\n\n                if self.dim>2:\n                    theta_z = np.arctan2(distance[2], np.sqrt(distance[0]**2+distance[1]**2))\n\n                rotation_matrix = np.eye(self.dim)\n\n                if self.dim >= 2:\n                  rotation_matrix[0,0] = np.cos(self.spiral_const * theta)\n                  rotation_matrix[0,1] = -np.sin(self.spiral_const * theta)\n                  rotation_matrix[1,0] = np.sin(self.spiral_const * theta)\n                  rotation_matrix[1,1] = np.cos(self.spiral_const * theta)\n                \n                if self.dim > 2:\n                  rotation_matrix[2,2] = np.cos(self.spiral_const * theta_z)\n                  rotation_matrix[2,0] = -np.sin(self.spiral_const * theta_z)\n                  rotation_matrix[0,2] = np.sin(self.spiral_const * theta_z)\n                  rotation_matrix[0,0] = np.cos(self.spiral_const * theta_z)\n\n                new_x = x_best + np.dot(rotation_matrix, distance) #x_best + distance * np.exp(self.spiral_const * np.random.randn()) * np.cos(2 * np.pi * np.random.rand(self.dim))\n                \n\n                # Clip the new position to the bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate the new solution\n                new_f = func(new_x)\n                self.n_evals += 1\n                \n                # Update the population if the new solution is better\n                if new_f < self.F[i]:\n                    self.X[i] = new_x\n                    self.F[i] = new_f\n                    \n                if self.n_evals >= self.budget:\n                    break\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.07720085724613002, 0.1575369183479779, 0.235371363858509, 0.12709732940735397, 0.10897719190646626, 0.1872131794549533, 0.18678422365927883, 0.14571482093897703, 0.15096232951269717, 0.1262099764936685, 0.13732801303972864, 0.19904382439097312, 0.14784509708314075, 0.1322907651813353, 0.13552797027436758, 0.21689850214709328, 0.1744738330546246, 0.15520134795150475, 0.11639516139452355, 0.4190224981320637], "operator": "random_new", "theta_sampled": 0.017911615907624422, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "0668ea9a-8138-4755-988b-3011d72dd499", "fitness": 0.40568885864624127, "name": "CauchyMutationES", "description": "A population-based algorithm employing a Cauchy mutation and a selection mechanism favoring diversity and exploration, with adaptive step size.", "code": "import numpy as np\n\nclass CauchyMutationES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, sigma0=0.1, tau=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma0 = sigma0\n        if tau is None:\n            self.tau = 1 / np.sqrt(2 * dim)\n        else:\n            self.tau = tau\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.population = None\n        self.fitness = None\n        self.sigmas = None\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.sigmas = np.full((self.pop_size, self.dim), self.sigma0)\n        self.fitness = np.array([func(x) for x in self.population])\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n\n    def mutate(self):\n        # Adapt step sizes\n        self.sigmas = self.sigmas * np.exp(self.tau * np.random.normal(0, 1, size=(self.pop_size, self.dim)))\n        self.sigmas = np.clip(self.sigmas, 1e-6, 1)  # Avoid too small or too large sigma\n        \n        # Cauchy mutation\n        z = np.random.standard_cauchy(size=(self.pop_size, self.dim))\n        children = self.population + self.sigmas * z\n\n        return children\n\n\n    def select(self, func, children):\n        child_fitness = np.array([func(x) for x in children])\n        \n        # Combine parents and children\n        combined_population = np.concatenate((self.population, children))\n        combined_fitness = np.concatenate((self.fitness, child_fitness))\n        \n        # Sort by fitness\n        sorted_indices = np.argsort(combined_fitness)\n        \n        # Select top individuals, but promote diversity\n        new_population = []\n        new_fitness = []\n        selected_indices = []\n        \n        for i in sorted_indices:\n            if len(new_population) < self.pop_size:\n                individual = combined_population[i]\n                \n                # Check for diversity: if too similar to existing population, skip\n                too_similar = False\n                if len(new_population) > 0:\n                    distances = np.linalg.norm(np.array(new_population) - individual, axis=1)\n                    if np.any(distances < 0.1):  # Threshold for similarity\n                        too_similar = True\n                \n                if not too_similar:\n                    new_population.append(individual)\n                    new_fitness.append(combined_fitness[i])\n                    selected_indices.append(i)\n        \n        # If diversity selection removed too many individuals, pad with the best from those removed\n        if len(new_population) < self.pop_size:\n            remaining_indices = sorted_indices[~np.isin(sorted_indices, selected_indices)]\n            num_to_add = self.pop_size - len(new_population)\n            for i in remaining_indices[:num_to_add]:\n                 new_population.append(combined_population[i])\n                 new_fitness.append(combined_fitness[i])\n        \n        self.population = np.array(new_population)\n        self.fitness = np.array(new_fitness)\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        evals = self.pop_size  # Account for initial population evaluation\n        while evals < self.budget:\n            remaining_budget = self.budget - evals\n            children = self.mutate()\n\n            # Ensure children stay within bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            children = np.clip(children, lb, ub)\n            \n            # Limit the number of evaluations of the function to the remaining budget\n            num_children_to_evaluate = min(self.pop_size, remaining_budget)\n\n            # Evaluate only a subset of the generated children\n            self.select(func, children[:num_children_to_evaluate])  \n            \n            evals += num_children_to_evaluate # Increment evaluation counter\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm CauchyMutationES scored 0.406 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm employing a Cauchy mutation and a selection mechanism favoring diversity and exploration, with adaptive step size.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyMutationES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, sigma0=0.1, tau=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma0 = sigma0\n        if tau is None:\n            self.tau = 1 / np.sqrt(2 * dim)\n        else:\n            self.tau = tau\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.population = None\n        self.fitness = None\n        self.sigmas = None\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.sigmas = np.full((self.pop_size, self.dim), self.sigma0)\n        self.fitness = np.array([func(x) for x in self.population])\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n\n    def mutate(self):\n        # Adapt step sizes\n        self.sigmas = self.sigmas * np.exp(self.tau * np.random.normal(0, 1, size=(self.pop_size, self.dim)))\n        self.sigmas = np.clip(self.sigmas, 1e-6, 1)  # Avoid too small or too large sigma\n        \n        # Cauchy mutation\n        z = np.random.standard_cauchy(size=(self.pop_size, self.dim))\n        children = self.population + self.sigmas * z\n\n        return children\n\n\n    def select(self, func, children):\n        child_fitness = np.array([func(x) for x in children])\n        \n        # Combine parents and children\n        combined_population = np.concatenate((self.population, children))\n        combined_fitness = np.concatenate((self.fitness, child_fitness))\n        \n        # Sort by fitness\n        sorted_indices = np.argsort(combined_fitness)\n        \n        # Select top individuals, but promote diversity\n        new_population = []\n        new_fitness = []\n        selected_indices = []\n        \n        for i in sorted_indices:\n            if len(new_population) < self.pop_size:\n                individual = combined_population[i]\n                \n                # Check for diversity: if too similar to existing population, skip\n                too_similar = False\n                if len(new_population) > 0:\n                    distances = np.linalg.norm(np.array(new_population) - individual, axis=1)\n                    if np.any(distances < 0.1):  # Threshold for similarity\n                        too_similar = True\n                \n                if not too_similar:\n                    new_population.append(individual)\n                    new_fitness.append(combined_fitness[i])\n                    selected_indices.append(i)\n        \n        # If diversity selection removed too many individuals, pad with the best from those removed\n        if len(new_population) < self.pop_size:\n            remaining_indices = sorted_indices[~np.isin(sorted_indices, selected_indices)]\n            num_to_add = self.pop_size - len(new_population)\n            for i in remaining_indices[:num_to_add]:\n                 new_population.append(combined_population[i])\n                 new_fitness.append(combined_fitness[i])\n        \n        self.population = np.array(new_population)\n        self.fitness = np.array(new_fitness)\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        evals = self.pop_size  # Account for initial population evaluation\n        while evals < self.budget:\n            remaining_budget = self.budget - evals\n            children = self.mutate()\n\n            # Ensure children stay within bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            children = np.clip(children, lb, ub)\n            \n            # Limit the number of evaluations of the function to the remaining budget\n            num_children_to_evaluate = min(self.pop_size, remaining_budget)\n\n            # Evaluate only a subset of the generated children\n            self.select(func, children[:num_children_to_evaluate])  \n            \n            evals += num_children_to_evaluate # Increment evaluation counter\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.18059607841782876, 0.3453539139769265, 0.3867290577236193, 0.5772931318961521, 0.31829305485546944, 0.4177753694509818, 0.31485273626500887, 0.34003289582406593, 0.32580378511518193, 0.21265036071883614, 0.5013343235675539, 0.9880165213016902, 0.268556055156163, 0.32140209331030933, 0.7171544307984392, 0.3833700849056314, 0.3305393304470978, 0.44654842526135163, 0.229920631164804, 0.5075548927677145], "operator": "random_new", "theta_sampled": 0.0038452425821433166, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "b8bad4e6-7a82-453a-8319-d7433cbcac09", "fitness": 0.0, "name": "AdaptiveHybridDE_PSO_NM", "description": "Integrates Adaptive Differential Evolution with Nelder-Mead local search, momentum-based PSO, and dynamic parameter adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.velocities = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.F_val = 0.5\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_idx = np.argmin(self.fitness)\n        self.global_best_pos = self.pop[self.global_best_idx].copy()\n        self.global_best_fitness = self.fitness[self.global_best_idx]\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_pos\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = x_trial\n                    self.global_best_idx = i\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_pos[i] = x_trial\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})\n\n            n_fev = res.nfev\n            self.eval_count += n_fev\n            if res.success and res.fun < self.fitness[i]:\n                self.fitness[i] = res.fun\n                self.pop[i] = res.x\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.global_best_fitness = res.fun\n                    self.global_best_pos = res.x\n                    self.global_best_idx = i\n                    self.personal_best_fitness[i] = res.fun\n                    self.personal_best_pos[i] = res.x\n\n    def particle_swarm_optimization(self, func):\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            new_velocity = (w * self.velocities[i]\n                            + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                            + self.c2 * r2 * (self.global_best_pos - self.pop[i]))\n\n            new_velocity = np.clip(new_velocity, -v_max, v_max)\n            self.velocities[i] = new_velocity\n\n            new_pos = self.pop[i] + self.velocities[i]\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            if np.random.rand() < self.de_rate:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                mutated_pos = new_pos + self.F_val * (x2 - x3)\n                mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n                new_pos = mutated_pos\n\n            new_fitness = func(new_pos)\n            self.eval_count += 1\n            \n            if new_fitness < self.fitness[i]:\n                self.fitness[i] = new_fitness\n                self.pop[i] = new_pos\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_pos[i] = new_pos.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_pos = new_pos.copy()\n                        self.f_opt = new_fitness\n                        self.x_opt = new_pos\n                        self.global_best_idx = i\n\n        # Adapt DE mutation factor\n        diversity = np.std(self.fitness)\n        if diversity > 0.1:\n            self.F_val = 0.5 + 0.3 * np.random.rand()\n        else:\n            self.F_val = 0.1 + 0.1* np.random.rand()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.particle_swarm_optimization(func)\n\n            if self.eval_count >= self.budget:\n                break\n\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n                break\n\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size) // self.nm_freq:\n                self.nelder_mead_local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["c11b0a48-b338-4ace-9f74-68f3ec440e0a", "69eb3d57-efc7-430d-a6a2-e36612c80a8a"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Adaptive Differential Evolution with Nelder-Mead local search, momentum-based PSO, and dynamic parameter adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.velocities = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.F_val = 0.5\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_idx = np.argmin(self.fitness)\n        self.global_best_pos = self.pop[self.global_best_idx].copy()\n        self.global_best_fitness = self.fitness[self.global_best_idx]\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_pos\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = x_trial\n                    self.global_best_idx = i\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_pos[i] = x_trial\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})\n\n            n_fev = res.nfev\n            self.eval_count += n_fev\n            if res.success and res.fun < self.fitness[i]:\n                self.fitness[i] = res.fun\n                self.pop[i] = res.x\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.global_best_fitness = res.fun\n                    self.global_best_pos = res.x\n                    self.global_best_idx = i\n                    self.personal_best_fitness[i] = res.fun\n                    self.personal_best_pos[i] = res.x\n\n    def particle_swarm_optimization(self, func):\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            new_velocity = (w * self.velocities[i]\n                            + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                            + self.c2 * r2 * (self.global_best_pos - self.pop[i]))\n\n            new_velocity = np.clip(new_velocity, -v_max, v_max)\n            self.velocities[i] = new_velocity\n\n            new_pos = self.pop[i] + self.velocities[i]\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            if np.random.rand() < self.de_rate:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                mutated_pos = new_pos + self.F_val * (x2 - x3)\n                mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n                new_pos = mutated_pos\n\n            new_fitness = func(new_pos)\n            self.eval_count += 1\n            \n            if new_fitness < self.fitness[i]:\n                self.fitness[i] = new_fitness\n                self.pop[i] = new_pos\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_pos[i] = new_pos.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_pos = new_pos.copy()\n                        self.f_opt = new_fitness\n                        self.x_opt = new_pos\n                        self.global_best_idx = i\n\n        # Adapt DE mutation factor\n        diversity = np.std(self.fitness)\n        if diversity > 0.1:\n            self.F_val = 0.5 + 0.3 * np.random.rand()\n        else:\n            self.F_val = 0.1 + 0.1* np.random.rand()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.particle_swarm_optimization(func)\n\n            if self.eval_count >= self.budget:\n                break\n\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n                break\n\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size) // self.nm_freq:\n                self.nelder_mead_local_search(func)\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.0016216552246724706, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "6fca9aa7-bff0-4360-8b58-e251da14ef19", "fitness": 0.0, "name": "PerturbedDifferentialEvolution", "description": "A population-based algorithm that combines aspects of differential evolution with a novel local search strategy based on perturbing the best solution with decreasing magnitude.", "code": "import numpy as np\n\nclass PerturbedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9, ls_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.ls_iterations = ls_iterations\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Optimization loop\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial[cross_points] = mutant[cross_points]\n\n                # Evaluation\n                f = func(trial)\n                self.eval_count += 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Local Search around best solution\n            perturbation_strength = 0.1 * (1 - (self.eval_count / self.budget)) # Decreasing perturbation\n            for _ in range(self.ls_iterations):\n                perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, size=self.dim)\n                perturbed_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                f_perturbed = func(perturbed_x)\n                self.eval_count += 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = perturbed_x\n\n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm PerturbedDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution with a novel local search strategy based on perturbing the best solution with decreasing magnitude.\n# Code: \n```python\nimport numpy as np\n\nclass PerturbedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9, ls_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.ls_iterations = ls_iterations\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Optimization loop\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial[cross_points] = mutant[cross_points]\n\n                # Evaluation\n                f = func(trial)\n                self.eval_count += 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Local Search around best solution\n            perturbation_strength = 0.1 * (1 - (self.eval_count / self.budget)) # Decreasing perturbation\n            for _ in range(self.ls_iterations):\n                perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, size=self.dim)\n                perturbed_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                f_perturbed = func(perturbed_x)\n                self.eval_count += 1\n\n                if f_perturbed < self.f_opt:\n                    self.f_opt = f_perturbed\n                    self.x_opt = perturbed_x\n\n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.0033247079674007408, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "d95348fc-03e1-4fa6-91b0-8d0386826432", "fitness": 0.0, "name": "AdaptiveHybridDE_PSO_NM", "description": "A hybrid algorithm combining adaptive Differential Evolution with Nelder-Mead local search and CMA-PSO's velocity update mechanism for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.de_rate = de_rate  # Rate of applying DE mutation within PSO loop\n        self.mu_init_sigma = mu_init_sigma\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.velocities = None\n        self.mu = None\n        self.sigma = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.global_best_fitness = self.fitness[self.best_idx]\n        self.global_best_pos = self.pop[self.best_idx].copy()\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.mu = np.mean(self.pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n    def pso_velocity_update(self, w, func):\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            new_velocity = (w * self.velocities[i]\n                            + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                            + self.c2 * r2 * (self.global_best_pos - self.pop[i]))\n            self.velocities[i] = np.clip(new_velocity, -v_max, v_max)\n\n    def pso_position_update(self, func):\n        for i in range(self.pop_size):\n            new_pos = self.pop[i] + self.velocities[i]\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE mutation within PSO loop\n            if np.random.rand() < self.de_rate:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                mutated_pos = new_pos + self.de_f * (x2 - x3)\n                mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n                mutated_fitness = func(mutated_pos)\n                self.eval_count += 1\n                if mutated_fitness < self.fitness[i]:\n                    new_pos = mutated_pos\n\n            new_fitness = func(new_pos)\n            self.eval_count += 1\n\n            if new_fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness\n                self.personal_best_pos[i] = new_pos.copy()\n\n            if new_fitness < self.global_best_fitness:\n                self.global_best_fitness = new_fitness\n                self.global_best_pos = new_pos.copy()\n\n            self.pop[i] = new_pos\n            self.fitness[i] = new_fitness\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': max(1, self.budget - self.eval_count)})\n\n            if res.success:\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev\n                self.eval_count += n_fev\n\n                if f_val < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_val\n                    self.personal_best_pos[i] = x_val\n\n                if f_val < self.global_best_fitness:\n                    self.global_best_fitness = f_val\n                    self.global_best_pos = x_val.copy()\n\n                self.fitness[i] = f_val\n                self.pop[i] = x_val\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Update inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.pso_velocity_update(w, func)\n            self.pso_position_update(func)\n\n            if self.eval_count // self.nm_freq != (self.eval_count - 1) // self.nm_freq:\n                self.nelder_mead_local_search(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["c11b0a48-b338-4ace-9f74-68f3ec440e0a", "69eb3d57-efc7-430d-a6a2-e36612c80a8a"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining adaptive Differential Evolution with Nelder-Mead local search and CMA-PSO's velocity update mechanism for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.de_rate = de_rate  # Rate of applying DE mutation within PSO loop\n        self.mu_init_sigma = mu_init_sigma\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.velocities = None\n        self.mu = None\n        self.sigma = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.global_best_fitness = self.fitness[self.best_idx]\n        self.global_best_pos = self.pop[self.best_idx].copy()\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.mu = np.mean(self.pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n    def pso_velocity_update(self, w, func):\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            new_velocity = (w * self.velocities[i]\n                            + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                            + self.c2 * r2 * (self.global_best_pos - self.pop[i]))\n            self.velocities[i] = np.clip(new_velocity, -v_max, v_max)\n\n    def pso_position_update(self, func):\n        for i in range(self.pop_size):\n            new_pos = self.pop[i] + self.velocities[i]\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE mutation within PSO loop\n            if np.random.rand() < self.de_rate:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                mutated_pos = new_pos + self.de_f * (x2 - x3)\n                mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n                mutated_fitness = func(mutated_pos)\n                self.eval_count += 1\n                if mutated_fitness < self.fitness[i]:\n                    new_pos = mutated_pos\n\n            new_fitness = func(new_pos)\n            self.eval_count += 1\n\n            if new_fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness\n                self.personal_best_pos[i] = new_pos.copy()\n\n            if new_fitness < self.global_best_fitness:\n                self.global_best_fitness = new_fitness\n                self.global_best_pos = new_pos.copy()\n\n            self.pop[i] = new_pos\n            self.fitness[i] = new_fitness\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': max(1, self.budget - self.eval_count)})\n\n            if res.success:\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev\n                self.eval_count += n_fev\n\n                if f_val < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_val\n                    self.personal_best_pos[i] = x_val\n\n                if f_val < self.global_best_fitness:\n                    self.global_best_fitness = f_val\n                    self.global_best_pos = x_val.copy()\n\n                self.fitness[i] = f_val\n                self.pop[i] = x_val\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Update inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.pso_velocity_update(w, func)\n            self.pso_position_update(func)\n\n            if self.eval_count // self.nm_freq != (self.eval_count - 1) // self.nm_freq:\n                self.nelder_mead_local_search(func)\n\n        return self.global_best_fitness, self.global_best_pos\n```", "operator": "crossover", "theta_sampled": 0.0002927934813542996, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "6f4a242d-8918-4bfe-abb4-0660f25b1274", "fitness": 0.2985848113688948, "name": "AdaptiveHybridPSO_DE_Diversity", "description": "A population-based algorithm that combines elements of particle swarm optimization and differential evolution, adaptively adjusting parameters based on population diversity and individual success.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Diversity:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, cr_init=0.5, f_init=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Inertia weight\n        self.c1_init = c1_init  # Cognitive coefficient\n        self.c2_init = c2_init  # Social coefficient\n        self.cr_init = cr_init  # Crossover rate\n        self.f_init = f_init  # Mutation factor\n\n        self.w = self.w_init\n        self.c1 = self.c1_init\n        self.c2 = self.c2_init\n        self.cr = self.cr_init\n        self.f = self.f_init\n\n        self.pop = None\n        self.fitness = None\n        self.velocity = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n\n        self.func_evals = 0\n        self.diversity_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb)  # Initialize velocities\n\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def calculate_diversity(self):\n         # Calculate the average distance of each particle from the population centroid\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n        \n\n    def update_parameters(self):\n        # Adaptive parameter control based on population diversity\n        diversity = self.calculate_diversity()\n        self.diversity_history.append(diversity)\n\n        # Normalize the diversity value\n        normalized_diversity = (diversity - np.min(self.diversity_history)) / (np.max(self.diversity_history) - np.min(self.diversity_history) + 1e-8)\n\n        # Adjust parameters based on normalized diversity\n        self.w = self.w_init * (1 - normalized_diversity)  # Decrease inertia weight with increasing diversity\n        self.c1 = self.c1_init * (0.5 + normalized_diversity/2)   # Slightly increase cognitive coefficient with increasing diversity\n        self.c2 = self.c2_init * (0.5 + normalized_diversity/2) # Slightly increase social coefficient with increasing diversity\n        self.cr = self.cr_init * (0.5 + normalized_diversity/2)    # Slightly increase crossover rate with increasing diversity\n        self.f = self.f_init * (0.5 + normalized_diversity/2)     # Slightly increase mutation factor with increasing diversity\n    \n\n\n    def __call__(self, func):\n        self.global_best_fitness = np.inf\n        self.initialize_population(func)\n\n        while self.func_evals < self.budget:\n            self.update_parameters()\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocity[i] = self.w * self.velocity[i] + \\\n                                self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_pos - self.pop[i])\n\n                # DE update\n                donor_vector = self.pop[i].copy()\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                mutant_vector = self.pop[a] + self.f * (self.pop[b] - self.pop[c])\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        donor_vector[j] = mutant_vector[j]\n\n\n                # Combined update (PSO + DE)\n                new_x = self.pop[i] + self.velocity[i] # Consider PSO update as well\n\n                # Clip the solution within the bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                new_f = func(new_x)\n                self.func_evals += 1\n\n                if new_f < self.fitness[i]:\n                    self.pop[i] = new_x\n                    self.fitness[i] = new_f\n\n                    if new_f < self.personal_best_fitness[i]:\n                        self.personal_best_pos[i] = new_x\n                        self.personal_best_fitness[i] = new_f\n\n                        if new_f < self.global_best_fitness:\n                            self.global_best_pos = new_x\n                            self.global_best_fitness = new_f\n\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridPSO_DE_Diversity scored 0.299 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of particle swarm optimization and differential evolution, adaptively adjusting parameters based on population diversity and individual success.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Diversity:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, cr_init=0.5, f_init=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Inertia weight\n        self.c1_init = c1_init  # Cognitive coefficient\n        self.c2_init = c2_init  # Social coefficient\n        self.cr_init = cr_init  # Crossover rate\n        self.f_init = f_init  # Mutation factor\n\n        self.w = self.w_init\n        self.c1 = self.c1_init\n        self.c2 = self.c2_init\n        self.cr = self.cr_init\n        self.f = self.f_init\n\n        self.pop = None\n        self.fitness = None\n        self.velocity = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n\n        self.func_evals = 0\n        self.diversity_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb)  # Initialize velocities\n\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def calculate_diversity(self):\n         # Calculate the average distance of each particle from the population centroid\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n        \n\n    def update_parameters(self):\n        # Adaptive parameter control based on population diversity\n        diversity = self.calculate_diversity()\n        self.diversity_history.append(diversity)\n\n        # Normalize the diversity value\n        normalized_diversity = (diversity - np.min(self.diversity_history)) / (np.max(self.diversity_history) - np.min(self.diversity_history) + 1e-8)\n\n        # Adjust parameters based on normalized diversity\n        self.w = self.w_init * (1 - normalized_diversity)  # Decrease inertia weight with increasing diversity\n        self.c1 = self.c1_init * (0.5 + normalized_diversity/2)   # Slightly increase cognitive coefficient with increasing diversity\n        self.c2 = self.c2_init * (0.5 + normalized_diversity/2) # Slightly increase social coefficient with increasing diversity\n        self.cr = self.cr_init * (0.5 + normalized_diversity/2)    # Slightly increase crossover rate with increasing diversity\n        self.f = self.f_init * (0.5 + normalized_diversity/2)     # Slightly increase mutation factor with increasing diversity\n    \n\n\n    def __call__(self, func):\n        self.global_best_fitness = np.inf\n        self.initialize_population(func)\n\n        while self.func_evals < self.budget:\n            self.update_parameters()\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocity[i] = self.w * self.velocity[i] + \\\n                                self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_pos - self.pop[i])\n\n                # DE update\n                donor_vector = self.pop[i].copy()\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                mutant_vector = self.pop[a] + self.f * (self.pop[b] - self.pop[c])\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        donor_vector[j] = mutant_vector[j]\n\n\n                # Combined update (PSO + DE)\n                new_x = self.pop[i] + self.velocity[i] # Consider PSO update as well\n\n                # Clip the solution within the bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                new_f = func(new_x)\n                self.func_evals += 1\n\n                if new_f < self.fitness[i]:\n                    self.pop[i] = new_x\n                    self.fitness[i] = new_f\n\n                    if new_f < self.personal_best_fitness[i]:\n                        self.personal_best_pos[i] = new_x\n                        self.personal_best_fitness[i] = new_f\n\n                        if new_f < self.global_best_fitness:\n                            self.global_best_pos = new_x\n                            self.global_best_fitness = new_f\n\n\n        return self.global_best_fitness, self.global_best_pos\n```", "aucs": [0.1129463685106522, 0.15792628169138256, 0.2920273583944981, 0.22186147494963715, 0.22238730423854824, 0.2655107744355648, 0.2474487311363821, 0.23842294106506845, 0.20623889779633198, 0.1816057279436054, 0.28175268913636387, 0.9987596161804723, 0.19930216212658347, 0.2394641909629338, 0.635580036384451, 0.30544025813096154, 0.22693995399332345, 0.28762369174491076, 0.1938900395865506, 0.45656772896967435], "operator": "random_new", "theta_sampled": 0.0018046935513756236, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "a4d5c49a-fedd-45d4-ba23-f19bc2254db4", "fitness": 0.0, "name": "LevyDE", "description": "A population-based algorithm that uses a combination of global exploration with Levy flights and local exploitation with differential evolution, adaptively adjusting the balance between them based on population diversity.", "code": "import numpy as np\n\nclass LevyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, de_cross_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.de_cross_rate = de_cross_rate\n\n    def levy_flight(self, x, lb, ub):\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / self.levy_exponent)\n        new_x = x + 0.01 * step  # Step size scaling\n\n        # Clip values to remain within bounds\n        new_x = np.clip(new_x, lb, ub)\n        return new_x\n\n    def differential_evolution(self, population, fitness, lb, ub, func):\n        for i in range(self.pop_size):\n            idxs = list(range(self.pop_size))\n            idxs.remove(i)\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = population[a] + 0.5 * (population[b] - population[c]) # scaling factor 0.5\n            mutant = np.clip(mutant, lb, ub)\n\n            # Crossover\n            trial = np.copy(population[i])\n            for d in range(self.dim):\n                if np.random.rand() < self.de_cross_rate:\n                    trial[d] = mutant[d]\n\n            f_trial = func(trial)\n\n            if f_trial < fitness[i]:\n                population[i] = trial\n                fitness[i] = f_trial\n\n        return population, fitness\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size  # Track function evaluations\n\n        f_opt = np.min(fitness)\n        x_opt = population[np.argmin(fitness)]\n\n        while evals < self.budget:\n            # Adaptive balance between Levy flight and DE\n            if np.std(fitness) > 0.1 * np.mean(fitness):  # High diversity -> explore with Levy flights\n                for i in range(self.pop_size):\n                    if evals < self.budget:\n                        new_x = self.levy_flight(population[i], lb, ub)\n                        f_new = func(new_x)\n                        evals += 1\n\n                        if f_new < fitness[i]:\n                            population[i] = new_x\n                            fitness[i] = f_new\n\n                            if f_new < f_opt:\n                                f_opt = f_new\n                                x_opt = new_x\n                    else:\n                        break # Budget exceeded in Levy flight\n            else:  # Low diversity -> exploit with DE\n                population, fitness = self.differential_evolution(population, fitness, lb, ub, func)\n                evals += self.pop_size\n                \n                current_best_idx = np.argmin(fitness)\n                if fitness[current_best_idx] < f_opt:\n                    f_opt = fitness[current_best_idx]\n                    x_opt = population[current_best_idx]\n\n        return f_opt, x_opt", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of global exploration with Levy flights and local exploitation with differential evolution, adaptively adjusting the balance between them based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass LevyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, de_cross_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.de_cross_rate = de_cross_rate\n\n    def levy_flight(self, x, lb, ub):\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / self.levy_exponent)\n        new_x = x + 0.01 * step  # Step size scaling\n\n        # Clip values to remain within bounds\n        new_x = np.clip(new_x, lb, ub)\n        return new_x\n\n    def differential_evolution(self, population, fitness, lb, ub, func):\n        for i in range(self.pop_size):\n            idxs = list(range(self.pop_size))\n            idxs.remove(i)\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = population[a] + 0.5 * (population[b] - population[c]) # scaling factor 0.5\n            mutant = np.clip(mutant, lb, ub)\n\n            # Crossover\n            trial = np.copy(population[i])\n            for d in range(self.dim):\n                if np.random.rand() < self.de_cross_rate:\n                    trial[d] = mutant[d]\n\n            f_trial = func(trial)\n\n            if f_trial < fitness[i]:\n                population[i] = trial\n                fitness[i] = f_trial\n\n        return population, fitness\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size  # Track function evaluations\n\n        f_opt = np.min(fitness)\n        x_opt = population[np.argmin(fitness)]\n\n        while evals < self.budget:\n            # Adaptive balance between Levy flight and DE\n            if np.std(fitness) > 0.1 * np.mean(fitness):  # High diversity -> explore with Levy flights\n                for i in range(self.pop_size):\n                    if evals < self.budget:\n                        new_x = self.levy_flight(population[i], lb, ub)\n                        f_new = func(new_x)\n                        evals += 1\n\n                        if f_new < fitness[i]:\n                            population[i] = new_x\n                            fitness[i] = f_new\n\n                            if f_new < f_opt:\n                                f_opt = f_new\n                                x_opt = new_x\n                    else:\n                        break # Budget exceeded in Levy flight\n            else:  # Low diversity -> exploit with DE\n                population, fitness = self.differential_evolution(population, fitness, lb, ub, func)\n                evals += self.pop_size\n                \n                current_best_idx = np.argmin(fitness)\n                if fitness[current_best_idx] < f_opt:\n                    f_opt = fitness[current_best_idx]\n                    x_opt = population[current_best_idx]\n\n        return f_opt, x_opt\n```", "operator": "random_new", "theta_sampled": 0.02013192026124722, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "fffd9461-6d9d-4021-9f7e-515ef17c1ca6", "fitness": 0.06804908256194858, "name": "EnhancedAdaptiveHybrid", "description": "A hybrid PSO-DE-CMA-LS algorithm with enhanced adaptive parameter control, using orthogonal learning to improve population diversity and local search intensification, incorporating a mirrored sampling strategy and distance-based mutation for better exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, ls_prob=0.1, ol_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma\n        self.mu = None\n        self.sigma = None\n        self.F_val = 0.5\n        self.ls_prob = ls_prob\n        self.ol_rate = ol_rate # Orthogonal learning rate\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling: Mirrored Sampling\n                oob_indices = (new_pos < func.bounds.lb) | (new_pos > func.bounds.ub)\n                new_pos[oob_indices] = 2 * (func.bounds.lb + func.bounds.ub)[oob_indices] - new_pos[oob_indices]\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    \n                    # Distance-based mutation factor\n                    dist = np.linalg.norm(x2 - x3)\n                    adaptive_F = self.F_val * (1 + 0.2 * np.random.randn()) * (1 + dist) #scale by distance\n                    adaptive_F = np.clip(adaptive_F, 0.1, 1.0) # clip to range\n                    \n                    mutated_pos = new_pos + adaptive_F * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n                \n                 # Orthogonal Learning\n                if np.random.rand() < self.ol_rate:\n                    # Select design matrix (e.g., Latin Hypercube Sampling)\n                    design_matrix = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim)) # simplified LH\n\n                    # Evaluate the solutions in the design matrix\n                    design_fitness = np.array([func(design_matrix[j]) for j in range(self.dim + 1)])\n                    self.budget -= (self.dim + 1)\n                    eval_count += (self.dim + 1)\n\n                    if self.budget <= 0:\n                        break\n                    \n                    # Find the best solution in the design matrix\n                    best_design_idx = np.argmin(design_fitness)\n                    best_design_pos = design_matrix[best_design_idx]\n\n                    # Replace the current solution with the best design solution if it's better\n                    if design_fitness[best_design_idx] < fitness[i]:\n                        pop[i] = best_design_pos\n                        fitness[i] = design_fitness[best_design_idx]\n                        personal_best_fitness[i] = design_fitness[best_design_idx]\n                        personal_best_pos[i] = best_design_pos.copy()\n                        if design_fitness[best_design_idx] < global_best_fitness:\n                            global_best_fitness = design_fitness[best_design_idx]\n                            global_best_pos = best_design_pos.copy()\n\n                # Self-Adaptive Local Search\n                if np.random.rand() < self.ls_prob:\n                    # Perturb the current solution based on fitness landscape\n                    delta = np.random.normal(0, self.sigma, self.dim) # Use CMA's sigma for perturbation scale\n                    ls_pos = new_pos + delta\n                    ls_pos = np.clip(ls_pos, func.bounds.lb, func.bounds.ub)\n                    ls_fitness = func(ls_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n\n                    if ls_fitness < new_fitness:\n                        pop[i] = ls_pos\n                        fitness[i] = ls_fitness\n                        if ls_fitness < personal_best_fitness[i]:\n                            personal_best_fitness[i] = ls_fitness\n                            personal_best_pos[i] = ls_pos.copy()\n                        if ls_fitness < global_best_fitness:\n                            global_best_fitness = ls_fitness\n                            global_best_pos = ls_pos.copy()\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n            #Adapt local search probability\n            if eval_count % 1000 == 0: # Adjust local search probability every 1000 evaluations\n                if np.std(fitness) < 0.01: # low diversity\n                    self.ls_prob = min(self.ls_prob * 1.2, 0.5) # increase exploration\n                else:\n                    self.ls_prob = max(self.ls_prob * 0.8, 0.01) # decrease exploration\n            \n            #Adapt Orthogonal learning rate\n            if eval_count % 1500 == 0:\n                if np.std(fitness) < 0.005: # decrease OL if there is not much diversity\n                    self.ol_rate = max(self.ol_rate * 0.7, 0.01)\n                else:\n                    self.ol_rate = min(self.ol_rate * 1.1, 0.3) # adapt rate\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedAdaptiveHybrid scored 0.068 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e4e2d565-ed5e-4ca9-959a-f41f6f671c56"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid PSO-DE-CMA-LS algorithm with enhanced adaptive parameter control, using orthogonal learning to improve population diversity and local search intensification, incorporating a mirrored sampling strategy and distance-based mutation for better exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, ls_prob=0.1, ol_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.de_rate = de_rate\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma\n        self.mu = None\n        self.sigma = None\n        self.F_val = 0.5\n        self.ls_prob = ls_prob\n        self.ol_rate = ol_rate # Orthogonal learning rate\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n        eval_count = self.pop_size\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling: Mirrored Sampling\n                oob_indices = (new_pos < func.bounds.lb) | (new_pos > func.bounds.ub)\n                new_pos[oob_indices] = 2 * (func.bounds.lb + func.bounds.ub)[oob_indices] - new_pos[oob_indices]\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    \n                    # Distance-based mutation factor\n                    dist = np.linalg.norm(x2 - x3)\n                    adaptive_F = self.F_val * (1 + 0.2 * np.random.randn()) * (1 + dist) #scale by distance\n                    adaptive_F = np.clip(adaptive_F, 0.1, 1.0) # clip to range\n                    \n                    mutated_pos = new_pos + adaptive_F * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n                \n                 # Orthogonal Learning\n                if np.random.rand() < self.ol_rate:\n                    # Select design matrix (e.g., Latin Hypercube Sampling)\n                    design_matrix = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim)) # simplified LH\n\n                    # Evaluate the solutions in the design matrix\n                    design_fitness = np.array([func(design_matrix[j]) for j in range(self.dim + 1)])\n                    self.budget -= (self.dim + 1)\n                    eval_count += (self.dim + 1)\n\n                    if self.budget <= 0:\n                        break\n                    \n                    # Find the best solution in the design matrix\n                    best_design_idx = np.argmin(design_fitness)\n                    best_design_pos = design_matrix[best_design_idx]\n\n                    # Replace the current solution with the best design solution if it's better\n                    if design_fitness[best_design_idx] < fitness[i]:\n                        pop[i] = best_design_pos\n                        fitness[i] = design_fitness[best_design_idx]\n                        personal_best_fitness[i] = design_fitness[best_design_idx]\n                        personal_best_pos[i] = best_design_pos.copy()\n                        if design_fitness[best_design_idx] < global_best_fitness:\n                            global_best_fitness = design_fitness[best_design_idx]\n                            global_best_pos = best_design_pos.copy()\n\n                # Self-Adaptive Local Search\n                if np.random.rand() < self.ls_prob:\n                    # Perturb the current solution based on fitness landscape\n                    delta = np.random.normal(0, self.sigma, self.dim) # Use CMA's sigma for perturbation scale\n                    ls_pos = new_pos + delta\n                    ls_pos = np.clip(ls_pos, func.bounds.lb, func.bounds.ub)\n                    ls_fitness = func(ls_pos)\n                    self.budget -= 1\n                    eval_count+=1\n                    if self.budget <= 0:\n                        break\n\n                    if ls_fitness < new_fitness:\n                        pop[i] = ls_pos\n                        fitness[i] = ls_fitness\n                        if ls_fitness < personal_best_fitness[i]:\n                            personal_best_fitness[i] = ls_fitness\n                            personal_best_pos[i] = ls_pos.copy()\n                        if ls_fitness < global_best_fitness:\n                            global_best_fitness = ls_fitness\n                            global_best_pos = ls_pos.copy()\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n            # Dynamically adapt v_max (linearly)\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) \n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n\n            #Adapt local search probability\n            if eval_count % 1000 == 0: # Adjust local search probability every 1000 evaluations\n                if np.std(fitness) < 0.01: # low diversity\n                    self.ls_prob = min(self.ls_prob * 1.2, 0.5) # increase exploration\n                else:\n                    self.ls_prob = max(self.ls_prob * 0.8, 0.01) # decrease exploration\n            \n            #Adapt Orthogonal learning rate\n            if eval_count % 1500 == 0:\n                if np.std(fitness) < 0.005: # decrease OL if there is not much diversity\n                    self.ol_rate = max(self.ol_rate * 0.7, 0.01)\n                else:\n                    self.ol_rate = min(self.ol_rate * 1.1, 0.3) # adapt rate\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.13609816512389716, 0], "operator": "mutation", "theta_sampled": -0.00047824545443522954, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "c22425dd-dd2d-4465-974e-53c528d441fb", "fitness": 0.3088623457315022, "name": "AdaptiveDifferentialEvolutionRestart", "description": "A population-based algorithm that adaptively adjusts mutation strength and crossover probability based on population diversity and success rate, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.restart_prob = restart_prob # Probability of restarting if population converges\n        self.archive = [] # Archive for storing promising solutions\n        self.archive_size = 10 # Maximum size of the archive\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Find the best initial solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Adaptive F and CR\n            F = self.F * (1 + 0.1 * np.random.randn())\n            CR = self.CR * (1 + 0.1 * np.random.randn())\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.clip(CR, 0.1, 1.0)\n\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                \n                mutant = population[i] + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                if f_trial < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f_trial\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append((trial_vector, f_trial))\n                    else:\n                        worst_archive_index = np.argmax([x[1] for x in self.archive])\n                        if f_trial < self.archive[worst_archive_index][1]:\n                            self.archive[worst_archive_index] = (trial_vector, f_trial)\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        \n            population = new_population\n            fitness = new_fitness\n\n            # Restart mechanism: if population converges, re-initialize\n            if np.std(fitness) < 1e-6 and np.random.rand() < self.restart_prob:\n                # Restart using archive and random individuals\n                n_archive = min(len(self.archive), self.pop_size // 2) # Number of solutions from archive\n                archive_indices = np.random.choice(len(self.archive), n_archive, replace=False)\n                restart_population = [self.archive[i][0] for i in archive_indices]\n\n                remaining = self.pop_size - n_archive\n                restart_population.extend(np.random.uniform(func.bounds.lb, func.bounds.ub, size=(remaining, self.dim)))\n                \n                population = np.array(restart_population)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= remaining\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveDifferentialEvolutionRestart scored 0.309 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that adaptively adjusts mutation strength and crossover probability based on population diversity and success rate, incorporating a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.restart_prob = restart_prob # Probability of restarting if population converges\n        self.archive = [] # Archive for storing promising solutions\n        self.archive_size = 10 # Maximum size of the archive\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Find the best initial solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Adaptive F and CR\n            F = self.F * (1 + 0.1 * np.random.randn())\n            CR = self.CR * (1 + 0.1 * np.random.randn())\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.clip(CR, 0.1, 1.0)\n\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                \n                mutant = population[i] + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                if f_trial < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f_trial\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append((trial_vector, f_trial))\n                    else:\n                        worst_archive_index = np.argmax([x[1] for x in self.archive])\n                        if f_trial < self.archive[worst_archive_index][1]:\n                            self.archive[worst_archive_index] = (trial_vector, f_trial)\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        \n            population = new_population\n            fitness = new_fitness\n\n            # Restart mechanism: if population converges, re-initialize\n            if np.std(fitness) < 1e-6 and np.random.rand() < self.restart_prob:\n                # Restart using archive and random individuals\n                n_archive = min(len(self.archive), self.pop_size // 2) # Number of solutions from archive\n                archive_indices = np.random.choice(len(self.archive), n_archive, replace=False)\n                restart_population = [self.archive[i][0] for i in archive_indices]\n\n                remaining = self.pop_size - n_archive\n                restart_population.extend(np.random.uniform(func.bounds.lb, func.bounds.ub, size=(remaining, self.dim)))\n                \n                population = np.array(restart_population)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= remaining\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                \n        return self.f_opt, self.x_opt\n```", "aucs": [0.1495978824009906, 0.2576433656362658, 0.38455517886050405, 0.47531766430463485, 0.30631275463544694, 0.42829993044486325, 0.29764910311914083, 0.3453439204911949, 0.32110521224690913, 0.2022111643390493, 0.5383119722990268, 0], "operator": "random_new", "theta_sampled": 0.009933845391183688, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "aba4726c-9b2a-441c-8092-905effec9bf0", "fitness": 0.48126455454943545, "name": "AdaptiveHybridDE_PSO_NM", "description": "An adaptive hybrid algorithm combining Differential Evolution, Nelder-Mead local search, and Particle Swarm Optimization with CMA parameter adaptation for efficient exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, pso_rate=0.3, cs=0.3, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.pso_rate = pso_rate\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.velocities = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.mu = None\n        self.sigma = None\n        self.F_val = 0.5\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        # Initialize PSO components\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.mu = np.mean(self.pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.personal_best_fitness[i] = f_trial\n                self.personal_best_pos[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n\n    def particle_swarm_optimization(self, func):\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n\n        # Find global best\n        global_best_idx = np.argmin(self.fitness)\n        global_best_pos = self.pop[global_best_idx].copy()\n        global_best_fitness = self.fitness[global_best_idx]\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Update velocity\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            new_velocity = (w * self.velocities[i]\n                            + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                            + self.c2 * r2 * (global_best_pos - self.pop[i]))\n\n            # Velocity clamping\n            self.velocities[i] = np.clip(new_velocity, -v_max, v_max)\n\n            # Update position\n            new_pos = self.pop[i] + self.velocities[i]\n\n            # Boundary handling\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            new_fitness = func(new_pos)\n            self.eval_count += 1\n\n            # Update personal best\n            if new_fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness\n                self.personal_best_pos[i] = new_pos.copy()\n\n            # Update global best\n            if new_fitness < global_best_fitness:\n                global_best_fitness = new_fitness\n                global_best_pos = new_pos.copy()\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_pos\n                self.best_idx = i\n\n            self.pop[i] = new_pos\n            self.fitness[i] = new_fitness\n\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': max(1,self.budget - self.eval_count)})  # Limit FE calls\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n                  self.personal_best_fitness[i] = f_val\n                  self.personal_best_pos[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.pso_rate:\n                self.particle_swarm_optimization(func)\n            else:\n                self.differential_evolution(func)\n\n            if self.eval_count >= self.budget:\n                break\n\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size // self.nm_freq ) // self.nm_freq:\n                self.nelder_mead_local_search(func)\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(self.pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(self.fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridDE_PSO_NM scored 0.481 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c11b0a48-b338-4ace-9f74-68f3ec440e0a", "69eb3d57-efc7-430d-a6a2-e36612c80a8a"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid algorithm combining Differential Evolution, Nelder-Mead local search, and Particle Swarm Optimization with CMA parameter adaptation for efficient exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, pso_rate=0.3, cs=0.3, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.pso_rate = pso_rate\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.velocities = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.mu = None\n        self.sigma = None\n        self.F_val = 0.5\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        # Initialize PSO components\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.mu = np.mean(self.pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.personal_best_fitness[i] = f_trial\n                self.personal_best_pos[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n\n    def particle_swarm_optimization(self, func):\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n\n        # Find global best\n        global_best_idx = np.argmin(self.fitness)\n        global_best_pos = self.pop[global_best_idx].copy()\n        global_best_fitness = self.fitness[global_best_idx]\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Update velocity\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            new_velocity = (w * self.velocities[i]\n                            + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                            + self.c2 * r2 * (global_best_pos - self.pop[i]))\n\n            # Velocity clamping\n            self.velocities[i] = np.clip(new_velocity, -v_max, v_max)\n\n            # Update position\n            new_pos = self.pop[i] + self.velocities[i]\n\n            # Boundary handling\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            new_fitness = func(new_pos)\n            self.eval_count += 1\n\n            # Update personal best\n            if new_fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness\n                self.personal_best_pos[i] = new_pos.copy()\n\n            # Update global best\n            if new_fitness < global_best_fitness:\n                global_best_fitness = new_fitness\n                global_best_pos = new_pos.copy()\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_pos\n                self.best_idx = i\n\n            self.pop[i] = new_pos\n            self.fitness[i] = new_fitness\n\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': max(1,self.budget - self.eval_count)})  # Limit FE calls\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n                  self.personal_best_fitness[i] = f_val\n                  self.personal_best_pos[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.pso_rate:\n                self.particle_swarm_optimization(func)\n            else:\n                self.differential_evolution(func)\n\n            if self.eval_count >= self.budget:\n                break\n\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size // self.nm_freq ) // self.nm_freq:\n                self.nelder_mead_local_search(func)\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(self.pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Adapt DE mutation factor\n            diversity = np.std(self.fitness)\n            if diversity > 0.1: # dynamic mutation\n                self.F_val = 0.5 + 0.3 * np.random.rand()\n            else:\n                self.F_val = 0.1 + 0.1* np.random.rand()\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19070851771718866, 0.300278111628143, 0.5892644869172787, 0.7504998341169319, 0.6129712176770739, 0.262751024303827, 0.5201702252421275, 0.5188645911250327, 0.6002589580455904, 0.19520528318270403, 0.27629892459855465, 0.998173874213265, 0.2896134593670432, 0.5372117593732897, 0.7140006833263468, 0.6780693340095034, 0.5219284062640217, 0.37676043328095044, 0.21270629099579308, 0.47955567560404366], "operator": "crossover", "theta_sampled": -0.0010760753373740349, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "3173f351-8fa0-44b6-8e20-dcaf15d8bb64", "fitness": 0.0, "name": "PolyCauchyOptimizer", "description": "Population-based algorithm with a combination of global and local search using polynomial mutation and a Cauchy distribution-based perturbation for enhanced exploration.", "code": "import numpy as np\n\nclass PolyCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, polynomial_mutation_rate=0.1, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.polynomial_mutation_rate = polynomial_mutation_rate\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            new_population = population.copy()\n\n            # Polynomial Mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < self.polynomial_mutation_rate:\n                    for j in range(self.dim):\n                        u = np.random.rand()\n                        if u < 0.5:\n                            delta = (2 * u)**(1 / (1 + 2)) - 1\n                        else:\n                            delta = 1 - (2 * (1 - u))**(1 / (1 + 2))\n                        new_population[i, j] = population[i, j] + delta * (func.bounds.ub - func.bounds.lb)\n                        new_population[i, j] = np.clip(new_population[i, j], func.bounds.lb, func.bounds.ub)\n\n            # Cauchy Perturbation (Global Search)\n            cauchy_indices = np.random.choice(self.pop_size, size=int(self.pop_size * 0.2), replace=False)\n            for i in cauchy_indices:\n                cauchy_noise = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n                new_population[i] = population[i] + cauchy_noise\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new population\n            new_fitness = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.budget > 0:\n                    new_fitness[i] = func(new_population[i])\n                    self.budget -= 1\n                else:\n                    new_fitness[i] = np.inf  # Assign a very large value\n\n            # Selection (replace if better)\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a combination of global and local search using polynomial mutation and a Cauchy distribution-based perturbation for enhanced exploration.\n# Code: \n```python\nimport numpy as np\n\nclass PolyCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, polynomial_mutation_rate=0.1, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.polynomial_mutation_rate = polynomial_mutation_rate\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            new_population = population.copy()\n\n            # Polynomial Mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < self.polynomial_mutation_rate:\n                    for j in range(self.dim):\n                        u = np.random.rand()\n                        if u < 0.5:\n                            delta = (2 * u)**(1 / (1 + 2)) - 1\n                        else:\n                            delta = 1 - (2 * (1 - u))**(1 / (1 + 2))\n                        new_population[i, j] = population[i, j] + delta * (func.bounds.ub - func.bounds.lb)\n                        new_population[i, j] = np.clip(new_population[i, j], func.bounds.lb, func.bounds.ub)\n\n            # Cauchy Perturbation (Global Search)\n            cauchy_indices = np.random.choice(self.pop_size, size=int(self.pop_size * 0.2), replace=False)\n            for i in cauchy_indices:\n                cauchy_noise = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n                new_population[i] = population[i] + cauchy_noise\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new population\n            new_fitness = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.budget > 0:\n                    new_fitness[i] = func(new_population[i])\n                    self.budget -= 1\n                else:\n                    new_fitness[i] = np.inf  # Assign a very large value\n\n            # Selection (replace if better)\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i].copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.017963740162807287, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "43bb745b-348e-4d13-bdb9-7f2c2a40e8a9", "fitness": 0.0, "name": "AdaptiveDE_CMA", "description": "An algorithm that uses a combination of differential evolution and a covariance matrix adaptation strategy, periodically re-evaluating the population and adapting the mutation strategy based on the diversity of the population.", "code": "import numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, cma_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.cma_frequency = cma_frequency  # Frequency of CMA-ES step\n        self.F = 0.5  # Differential evolution parameter\n        self.CR = 0.7  # Crossover rate\n        self.sigma = 0.1 # initial step size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        self.C = np.eye(self.dim)  # Covariance matrix for CMA\n        self.mu = self.population[np.argmin(self.fitness)] # Initialize mean for CMA\n\n        while self.evals < self.budget:\n            if self.evals % self.cma_frequency == 0:\n                # CMA-ES step\n                self.mu, self.C, f_val = self.cma_step(func)\n\n                if f_val < self.f_opt:\n                    self.f_opt = f_val\n                    self.x_opt = self.mu.copy()\n\n                # Re-evaluate population around CMA's mean, keeping best\n                new_population = np.random.multivariate_normal(self.mu, self.sigma**2*self.C, size=self.pop_size)\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = np.array([func(x) for x in new_population])\n                self.evals += self.pop_size\n\n                combined_population = np.concatenate((self.population, new_population), axis=0)\n                combined_fitness = np.concatenate((self.fitness, new_fitness))\n                \n                indices = np.argsort(combined_fitness)[:self.pop_size]\n                self.population = combined_population[indices]\n                self.fitness = combined_fitness[indices]\n\n\n            else:\n                # Differential Evolution step\n                for i in range(self.pop_size):\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                    \n                    mutant = a + self.F * (b - c)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n\n                    trial = np.where(cross_points, mutant, self.population[i])\n                    \n                    f = func(trial)\n                    self.evals += 1\n                    \n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.population[i] = trial\n\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = trial.copy()\n\n                    if self.evals >= self.budget:\n                        break\n\n        return self.f_opt, self.x_opt\n\n    def cma_step(self, func):\n        # Simplified CMA-ES step (no evolution path or step-size adaptation)\n        offsprings = np.random.multivariate_normal(self.mu, self.sigma**2*self.C, size=self.pop_size)\n        offsprings = np.clip(offsprings, func.bounds.lb, func.bounds.ub)\n        fitness_values = np.array([func(x) for x in offsprings])\n        \n        best_index = np.argmin(fitness_values)\n        best_offspring = offsprings[best_index]\n\n        # Update covariance matrix (simplified - only rank-one update)\n        z = (best_offspring - self.mu) / self.sigma\n        self.C = (1 - 0.1) * self.C + 0.1 * np.outer(z, z)\n\n        return best_offspring, self.C, fitness_values[best_index]", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDE_CMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that uses a combination of differential evolution and a covariance matrix adaptation strategy, periodically re-evaluating the population and adapting the mutation strategy based on the diversity of the population.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, cma_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.cma_frequency = cma_frequency  # Frequency of CMA-ES step\n        self.F = 0.5  # Differential evolution parameter\n        self.CR = 0.7  # Crossover rate\n        self.sigma = 0.1 # initial step size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        self.C = np.eye(self.dim)  # Covariance matrix for CMA\n        self.mu = self.population[np.argmin(self.fitness)] # Initialize mean for CMA\n\n        while self.evals < self.budget:\n            if self.evals % self.cma_frequency == 0:\n                # CMA-ES step\n                self.mu, self.C, f_val = self.cma_step(func)\n\n                if f_val < self.f_opt:\n                    self.f_opt = f_val\n                    self.x_opt = self.mu.copy()\n\n                # Re-evaluate population around CMA's mean, keeping best\n                new_population = np.random.multivariate_normal(self.mu, self.sigma**2*self.C, size=self.pop_size)\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = np.array([func(x) for x in new_population])\n                self.evals += self.pop_size\n\n                combined_population = np.concatenate((self.population, new_population), axis=0)\n                combined_fitness = np.concatenate((self.fitness, new_fitness))\n                \n                indices = np.argsort(combined_fitness)[:self.pop_size]\n                self.population = combined_population[indices]\n                self.fitness = combined_fitness[indices]\n\n\n            else:\n                # Differential Evolution step\n                for i in range(self.pop_size):\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                    \n                    mutant = a + self.F * (b - c)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n\n                    trial = np.where(cross_points, mutant, self.population[i])\n                    \n                    f = func(trial)\n                    self.evals += 1\n                    \n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.population[i] = trial\n\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = trial.copy()\n\n                    if self.evals >= self.budget:\n                        break\n\n        return self.f_opt, self.x_opt\n\n    def cma_step(self, func):\n        # Simplified CMA-ES step (no evolution path or step-size adaptation)\n        offsprings = np.random.multivariate_normal(self.mu, self.sigma**2*self.C, size=self.pop_size)\n        offsprings = np.clip(offsprings, func.bounds.lb, func.bounds.ub)\n        fitness_values = np.array([func(x) for x in offsprings])\n        \n        best_index = np.argmin(fitness_values)\n        best_offspring = offsprings[best_index]\n\n        # Update covariance matrix (simplified - only rank-one update)\n        z = (best_offspring - self.mu) / self.sigma\n        self.C = (1 - 0.1) * self.C + 0.1 * np.outer(z, z)\n\n        return best_offspring, self.C, fitness_values[best_index]\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.018056877070577588, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "d0b5ef22-b945-4465-a342-f574a4ab3d0a", "fitness": 0.0, "name": "AdaptivePSO_DE_CMAES", "description": "Integrates a self-adaptive differential evolution with a velocity-constrained particle swarm optimizer and CMA-ES local search.", "code": "import numpy as np\n\nclass AdaptivePSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1, cmaes_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cmaes_rate = cmaes_rate # Rate of applying CMA-ES local search\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = self.rng.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = self.rng.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        # Parameters for self-adaptive DE\n        cr = 0.5  # Crossover rate\n        f = 0.7   # Scaling factor\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = self.rng.random(self.dim)\n                r2 = self.rng.random(self.dim)\n                \n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if self.rng.random() < self.de_rate:\n                    idxs = self.rng.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    \n                    # Self-adaptive DE mutation\n                    mutated_pos = x1 + f * (x2 - x3)  # Use x1 instead of new_pos\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n                    \n                    # Crossover\n                    j_rand = self.rng.integers(0, self.dim)\n                    for j in range(self.dim):\n                        if self.rng.random() > cr and j != j_rand:\n                            mutated_pos[j] = new_pos[j]\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                \n                # Apply CMA-ES local search with probability cmaes_rate\n                if self.rng.random() < self.cmaes_rate and self.budget > 10: #Ensure enough budget for CMAES\n                    import cma\n                    es = cma.optimization_tools.ES(new_pos, 0.5, {'bounds': [func.bounds.lb, func.bounds.ub], 'verbose':-9})\n                    es.optimize(func, budget=min(10, self.budget))\n                    \n                    if es.result.fbest < fitness[i]:\n                        new_pos = es.result.xbest\n                    self.budget -= es.counteval -1\n\n\n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n            # Adaptive DE parameters (example: adjust based on success)\n            if self.rng.random() < 0.1: #Small probability to change, otherwise keep current value\n                cr = self.rng.random()\n                f = self.rng.uniform(0.1, 0.9) #Ensure f does not get too close to 0 or 1.\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: No module named 'cma'", "parent_ids": ["d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a self-adaptive differential evolution with a velocity-constrained particle swarm optimizer and CMA-ES local search.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, de_rate=0.1, cmaes_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cmaes_rate = cmaes_rate # Rate of applying CMA-ES local search\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = self.rng.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = self.rng.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        # Parameters for self-adaptive DE\n        cr = 0.5  # Crossover rate\n        f = 0.7   # Scaling factor\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = self.rng.random(self.dim)\n                r2 = self.rng.random(self.dim)\n                \n                new_velocity = (self.w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if self.rng.random() < self.de_rate:\n                    idxs = self.rng.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    \n                    # Self-adaptive DE mutation\n                    mutated_pos = x1 + f * (x2 - x3)  # Use x1 instead of new_pos\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n                    \n                    # Crossover\n                    j_rand = self.rng.integers(0, self.dim)\n                    for j in range(self.dim):\n                        if self.rng.random() > cr and j != j_rand:\n                            mutated_pos[j] = new_pos[j]\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                \n                # Apply CMA-ES local search with probability cmaes_rate\n                if self.rng.random() < self.cmaes_rate and self.budget > 10: #Ensure enough budget for CMAES\n                    import cma\n                    es = cma.optimization_tools.ES(new_pos, 0.5, {'bounds': [func.bounds.lb, func.bounds.ub], 'verbose':-9})\n                    es.optimize(func, budget=min(10, self.budget))\n                    \n                    if es.result.fbest < fitness[i]:\n                        new_pos = es.result.xbest\n                    self.budget -= es.counteval -1\n\n\n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n            # Adaptive DE parameters (example: adjust based on success)\n            if self.rng.random() < 0.1: #Small probability to change, otherwise keep current value\n                cr = self.rng.random()\n                f = self.rng.uniform(0.1, 0.9) #Ensure f does not get too close to 0 or 1.\n\n        return global_best_fitness, global_best_pos\n```", "operator": "mutation", "theta_sampled": 0.0009120272464048835, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "c0d3122c-9697-4170-b59c-6da48bf36aec", "fitness": 0.4696097209206015, "name": "AdaptivePSO_DE", "description": "Adaptive PSO-DE with aging, dynamic inertia weight, and a restarting mechanism for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.2, c1=1.5, c2=1.5, de_rate=0.1, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Max inertia weight\n        self.w_min = w_min  # Min inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.age_limit = age_limit # Maximum age before restart\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Age of particles (initially 0)\n        ages = np.zeros(self.pop_size)\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                    ages[i] = 0 #reset age\n                else:\n                    ages[i] += 1 #increment age\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            # Restart aging particles\n            for i in range(self.pop_size):\n                if ages[i] > self.age_limit:\n                    pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    personal_best_pos[i] = pop[i].copy()\n                    personal_best_fitness[i] = fitness[i]\n                    velocities[i] = np.random.uniform(-1, 1, size=self.dim) #reinitialize velocity\n                    ages[i] = 0  # Reset age\n\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptivePSO_DE scored 0.470 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive PSO-DE with aging, dynamic inertia weight, and a restarting mechanism for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.2, c1=1.5, c2=1.5, de_rate=0.1, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Max inertia weight\n        self.w_min = w_min  # Min inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.age_limit = age_limit # Maximum age before restart\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Age of particles (initially 0)\n        ages = np.zeros(self.pop_size)\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                    ages[i] = 0 #reset age\n                else:\n                    ages[i] += 1 #increment age\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n            # Restart aging particles\n            for i in range(self.pop_size):\n                if ages[i] > self.age_limit:\n                    pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    personal_best_pos[i] = pop[i].copy()\n                    personal_best_fitness[i] = fitness[i]\n                    velocities[i] = np.random.uniform(-1, 1, size=self.dim) #reinitialize velocity\n                    ages[i] = 0  # Reset age\n\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n\n        return global_best_fitness, global_best_pos\n```", "aucs": [0.1878111720511958, 0.27181816597552766, 0.6508577766049161, 0.7867547456226877, 0.25948759109578823, 0.7351149460361497, 0.31657180334864454, 0.6345175186105498, 0.6683078440673818, 0.2310352596163675, 0.7600602380309469, 0.9997336876783555, 0.22077583487653707, 0.26222166025838356, 0.6444707460583305, 0.3538262657184639, 0], "operator": "mutation", "theta_sampled": 0.0006596542614257873, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "8253c7a9-d96c-40f5-ae56-1f6f5d2b01a3", "fitness": 0.0, "name": "AdaptiveHybridDE_PSO_NM_CMA", "description": "Adaptively combines DE, Nelder-Mead, and PSO with CMA-inspired parameter adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.mu = None\n        self.sigma = None\n        self.v_max = None  # Initialize v_max\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) #PSO initialization\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_idx = np.argmin(self.fitness)\n        self.global_best_pos = self.pop[self.global_best_idx].copy()\n        self.global_best_fitness = self.fitness[self.global_best_idx]\n        self.eval_count = self.pop_size\n        self.mu = np.mean(self.pop, axis=0) # CMA initialization\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n        # Initialize v_max (using a function call for flexibility)\n        self.update_v_max(func)\n\n    def update_v_max(self, func):\n        self.v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 #or other adaptive strategy\n\n    def differential_evolution(self, func, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n\n        x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n        x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n        j_rand = np.random.randint(self.dim)\n        x_trial = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.de_cr or j == j_rand:\n                x_trial[j] = x_mutated[j]\n\n        return x_trial\n\n    def pso_update(self, i, func):\n        # Update inertia weight (linearly decreasing)\n        w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n        # Update velocity\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        new_velocity = (w * self.velocities[i]\n                        + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                        + self.c2 * r2 * (self.global_best_pos - self.pop[i]))\n        self.velocities[i] = np.clip(new_velocity, -self.v_max, self.v_max)\n        new_pos = self.pop[i] + self.velocities[i]\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n        return new_pos\n\n    def nelder_mead_local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead',\n                       options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})\n        n_fev = res.nfev\n        self.eval_count += n_fev\n        return res.fun, res.x, n_fev\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # PSO update\n                new_pos = self.pso_update(i, func)\n\n                # DE crossover with PSO result\n                x_trial = self.differential_evolution(func, i)\n                \n                # Evaluate trial position\n                f_trial = func(x_trial)\n                self.eval_count += 1\n                \n                # Greedy selection\n                if f_trial < self.fitness[i]:\n                    new_pos = x_trial  # Replace PSO position with DE if better\n\n                # Evaluate new position (after DE crossover)\n                new_fitness = func(new_pos)\n                self.eval_count += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_pos[i] = new_pos.copy()\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_pos = new_pos.copy()\n\n                self.pop[i] = new_pos\n                self.fitness[i] = new_fitness\n\n            # CMA-inspired adaptation (simplified)\n            x_mean = np.mean(self.pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.c_cov) * self.mu + self.c_cov * x_mean #Use c_cov as learning rate\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Nelder-Mead local search every nm_freq evaluations\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size) // self.nm_freq:\n                best_idx = np.argmin(self.fitness)\n                f_nm, x_nm, n_fev = self.nelder_mead_local_search(func, self.pop[best_idx])\n\n                if f_nm < self.global_best_fitness:\n                    self.global_best_fitness = f_nm\n                    self.global_best_pos = x_nm.copy()\n                    self.pop[best_idx] = x_nm.copy()\n                    self.fitness[best_idx] = f_nm\n                    self.personal_best_fitness[best_idx] = f_nm\n                    self.personal_best_pos[best_idx] = x_nm.copy()\n\n            self.update_v_max(func) #adaptive v_max\n\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["c11b0a48-b338-4ace-9f74-68f3ec440e0a", "69eb3d57-efc7-430d-a6a2-e36612c80a8a"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines DE, Nelder-Mead, and PSO with CMA-inspired parameter adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_PSO_NM_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100,\n                 w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.mu = None\n        self.sigma = None\n        self.v_max = None  # Initialize v_max\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) #PSO initialization\n        self.personal_best_pos = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_idx = np.argmin(self.fitness)\n        self.global_best_pos = self.pop[self.global_best_idx].copy()\n        self.global_best_fitness = self.fitness[self.global_best_idx]\n        self.eval_count = self.pop_size\n        self.mu = np.mean(self.pop, axis=0) # CMA initialization\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n        # Initialize v_max (using a function call for flexibility)\n        self.update_v_max(func)\n\n    def update_v_max(self, func):\n        self.v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 #or other adaptive strategy\n\n    def differential_evolution(self, func, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n\n        x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n        x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n        j_rand = np.random.randint(self.dim)\n        x_trial = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.de_cr or j == j_rand:\n                x_trial[j] = x_mutated[j]\n\n        return x_trial\n\n    def pso_update(self, i, func):\n        # Update inertia weight (linearly decreasing)\n        w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n        # Update velocity\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        new_velocity = (w * self.velocities[i]\n                        + self.c1 * r1 * (self.personal_best_pos[i] - self.pop[i])\n                        + self.c2 * r2 * (self.global_best_pos - self.pop[i]))\n        self.velocities[i] = np.clip(new_velocity, -self.v_max, self.v_max)\n        new_pos = self.pop[i] + self.velocities[i]\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n        return new_pos\n\n    def nelder_mead_local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead',\n                       options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})\n        n_fev = res.nfev\n        self.eval_count += n_fev\n        return res.fun, res.x, n_fev\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # PSO update\n                new_pos = self.pso_update(i, func)\n\n                # DE crossover with PSO result\n                x_trial = self.differential_evolution(func, i)\n                \n                # Evaluate trial position\n                f_trial = func(x_trial)\n                self.eval_count += 1\n                \n                # Greedy selection\n                if f_trial < self.fitness[i]:\n                    new_pos = x_trial  # Replace PSO position with DE if better\n\n                # Evaluate new position (after DE crossover)\n                new_fitness = func(new_pos)\n                self.eval_count += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_pos[i] = new_pos.copy()\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_pos = new_pos.copy()\n\n                self.pop[i] = new_pos\n                self.fitness[i] = new_fitness\n\n            # CMA-inspired adaptation (simplified)\n            x_mean = np.mean(self.pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.c_cov) * self.mu + self.c_cov * x_mean #Use c_cov as learning rate\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n            # Nelder-Mead local search every nm_freq evaluations\n            if self.eval_count // self.nm_freq != (self.eval_count - self.pop_size) // self.nm_freq:\n                best_idx = np.argmin(self.fitness)\n                f_nm, x_nm, n_fev = self.nelder_mead_local_search(func, self.pop[best_idx])\n\n                if f_nm < self.global_best_fitness:\n                    self.global_best_fitness = f_nm\n                    self.global_best_pos = x_nm.copy()\n                    self.pop[best_idx] = x_nm.copy()\n                    self.fitness[best_idx] = f_nm\n                    self.personal_best_fitness[best_idx] = f_nm\n                    self.personal_best_pos[best_idx] = x_nm.copy()\n\n            self.update_v_max(func) #adaptive v_max\n\n\n        return self.global_best_fitness, self.global_best_pos\n```", "operator": "crossover", "theta_sampled": -0.00037523970774008494, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "f420a0a6-9e2f-4558-84f0-503e9d6616e2", "fitness": 0.0, "name": "LevyCMAES", "description": "Population-based algorithm with adaptive exploration-exploitation balance using a levy flight-based mutation and covariance matrix adaptation.", "code": "import numpy as np\n\nclass LevyCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        \n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n\n        self.m = None  # Mean of the population\n        self.C = None  # Covariance matrix\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.chiN = None\n\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_mu = None\n        self.eigeneval = 0\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def levy_flight(self, beta=1.5):\n        \"\"\"Generate a levy flight step.\"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n    \n    def initialize(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2))) # expectation of ||N(0,I)||\n\n        self.c_sigma = (self.mu / (self.dim + self.mu)) # learning rate for sigma\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.c_sigma # damping for sigma\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2 * self.mu/self.dim) # learning rate for C\n        self.c_mu = min(1 - self.c_c, self.mu * self.weights[0]**2 * (self.dim + 2) / ((self.dim + 3 * 2) * self.mu)) # learning rate for rank mu updates\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n            x = self.m + self.sigma0 * z\n            \n            # Clip individuals to bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n\n            if np.any(f < self.f_opt):\n                self.x_opt = x[np.argmin(f)]\n                self.f_opt = np.min(f)\n\n            # Sort offspring by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[idx]\n\n            # Selection and recombination\n            x_mu = x[:self.mu]\n            z_mu = z[:self.mu]\n            \n            delta_m = np.sum(self.weights[:,None] * z_mu, axis=0) # weighted recombination of the z values\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * delta_m\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2*(used_budget//self.pop_size))) < self.chiN * (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * delta_m\n            \n            # Update covariance matrix\n            self.C = (1 - self.c_c - self.c_mu) * self.C + self.c_mu * (self.weights[:,None] * z_mu).T @ z_mu + self.c_c * self.pc[:,None] @ self.pc[None,:]\n\n            # Update mean\n            levy_step = self.levy_flight()\n            adaptive_lr = 0.1 + 0.9 * np.exp(-8*self.f_opt) # Learning rate adaptation\n            self.m = self.m + self.sigma0 * delta_m + adaptive_lr * levy_step * (ub - lb)\n\n            # Update step size\n            self.sigma0 = self.sigma0 * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive exploration-exploitation balance using a levy flight-based mutation and covariance matrix adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass LevyCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        \n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n\n        self.m = None  # Mean of the population\n        self.C = None  # Covariance matrix\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.chiN = None\n\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_mu = None\n        self.eigeneval = 0\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def levy_flight(self, beta=1.5):\n        \"\"\"Generate a levy flight step.\"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n    \n    def initialize(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2))) # expectation of ||N(0,I)||\n\n        self.c_sigma = (self.mu / (self.dim + self.mu)) # learning rate for sigma\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.c_sigma # damping for sigma\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2 * self.mu/self.dim) # learning rate for C\n        self.c_mu = min(1 - self.c_c, self.mu * self.weights[0]**2 * (self.dim + 2) / ((self.dim + 3 * 2) * self.mu)) # learning rate for rank mu updates\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n            x = self.m + self.sigma0 * z\n            \n            # Clip individuals to bounds\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n\n            if np.any(f < self.f_opt):\n                self.x_opt = x[np.argmin(f)]\n                self.f_opt = np.min(f)\n\n            # Sort offspring by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[idx]\n\n            # Selection and recombination\n            x_mu = x[:self.mu]\n            z_mu = z[:self.mu]\n            \n            delta_m = np.sum(self.weights[:,None] * z_mu, axis=0) # weighted recombination of the z values\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * delta_m\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2*(used_budget//self.pop_size))) < self.chiN * (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * delta_m\n            \n            # Update covariance matrix\n            self.C = (1 - self.c_c - self.c_mu) * self.C + self.c_mu * (self.weights[:,None] * z_mu).T @ z_mu + self.c_c * self.pc[:,None] @ self.pc[None,:]\n\n            # Update mean\n            levy_step = self.levy_flight()\n            adaptive_lr = 0.1 + 0.9 * np.exp(-8*self.f_opt) # Learning rate adaptation\n            self.m = self.m + self.sigma0 * delta_m + adaptive_lr * levy_step * (ub - lb)\n\n            # Update step size\n            self.sigma0 = self.sigma0 * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0005982339029369562, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "bff63bfc-94bf-4dbc-931c-c46526ace64c", "fitness": 0.0, "name": "VoronoiGradientSearch", "description": "Population-based algorithm using a Voronoi-based mutation operator for exploration and a gradient-based local search for exploitation, adaptively balancing exploration and exploitation.", "code": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nfrom scipy.optimize import minimize\n\nclass VoronoiGradientSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, voronoi_neighbors=5, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.voronoi_neighbors = voronoi_neighbors\n        self.local_search_iterations = local_search_iterations\n\n        self.exploration_prob = 0.7  # Probability of using Voronoi-based mutation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Voronoi-based mutation\n                    if self.pop_size > 1:\n                        vor = Voronoi(population)\n                        \n                        # Find indices of voronoi neighbors\n                        distances = np.linalg.norm(population - population[i], axis=1)\n                        neighbor_indices = np.argsort(distances)[1:self.voronoi_neighbors+1] # Exclude itself.\n\n                        # Choose a random neighbor\n                        neighbor_index = np.random.choice(neighbor_indices)\n                        \n                        # Create new candidate by moving towards neighbor\n                        candidate = population[i] + np.random.rand() * (population[neighbor_index] - population[i])\n                    else:\n                        candidate = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Fallback: Random initialization\n\n                else:\n                    # Gradient-based local search\n                    x0 = population[i].copy() # Start from the individuals pos\n                    \n                    def objective(x):\n                        return func(x)\n\n                    bounds = [(func.bounds.lb[j], func.bounds.ub[j]) for j in range(self.dim)]\n                    res = minimize(objective, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': self.local_search_iterations}) # Number of iterations set at initialization.\n                    candidate = res.x\n                \n                # Ensure candidate stays within bounds\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate candidate\n                f_candidate = func(candidate)\n                self.budget -= 1\n                \n                # Update population if budget allows\n                if f_candidate < fitness[i]:\n                    fitness[i] = f_candidate\n                    population[i] = candidate\n\n                    # Update global best\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n                \n                if self.budget <= 0:\n                    break\n                    \n            #Adapt exploration probability\n            if iteration % 10 == 0:\n                #If there has not been improvement in the last 10 iterations:\n                if np.min(fitness) >= self.f_opt:\n                    self.exploration_prob = min(1.0, self.exploration_prob + 0.1) #increase exploration\n                else:\n                    self.exploration_prob = max(0.1, self.exploration_prob - 0.1) #increase exploitation\n                self.f_opt = np.min(fitness) #reset the value for determining improvement.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: name 'Voronoi' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a Voronoi-based mutation operator for exploration and a gradient-based local search for exploitation, adaptively balancing exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nfrom scipy.optimize import minimize\n\nclass VoronoiGradientSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, voronoi_neighbors=5, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.voronoi_neighbors = voronoi_neighbors\n        self.local_search_iterations = local_search_iterations\n\n        self.exploration_prob = 0.7  # Probability of using Voronoi-based mutation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Voronoi-based mutation\n                    if self.pop_size > 1:\n                        vor = Voronoi(population)\n                        \n                        # Find indices of voronoi neighbors\n                        distances = np.linalg.norm(population - population[i], axis=1)\n                        neighbor_indices = np.argsort(distances)[1:self.voronoi_neighbors+1] # Exclude itself.\n\n                        # Choose a random neighbor\n                        neighbor_index = np.random.choice(neighbor_indices)\n                        \n                        # Create new candidate by moving towards neighbor\n                        candidate = population[i] + np.random.rand() * (population[neighbor_index] - population[i])\n                    else:\n                        candidate = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Fallback: Random initialization\n\n                else:\n                    # Gradient-based local search\n                    x0 = population[i].copy() # Start from the individuals pos\n                    \n                    def objective(x):\n                        return func(x)\n\n                    bounds = [(func.bounds.lb[j], func.bounds.ub[j]) for j in range(self.dim)]\n                    res = minimize(objective, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': self.local_search_iterations}) # Number of iterations set at initialization.\n                    candidate = res.x\n                \n                # Ensure candidate stays within bounds\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate candidate\n                f_candidate = func(candidate)\n                self.budget -= 1\n                \n                # Update population if budget allows\n                if f_candidate < fitness[i]:\n                    fitness[i] = f_candidate\n                    population[i] = candidate\n\n                    # Update global best\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n                \n                if self.budget <= 0:\n                    break\n                    \n            #Adapt exploration probability\n            if iteration % 10 == 0:\n                #If there has not been improvement in the last 10 iterations:\n                if np.min(fitness) >= self.f_opt:\n                    self.exploration_prob = min(1.0, self.exploration_prob + 0.1) #increase exploration\n                else:\n                    self.exploration_prob = max(0.1, self.exploration_prob - 0.1) #increase exploitation\n                self.f_opt = np.min(fitness) #reset the value for determining improvement.\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.011364117671130994, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "a7d5c7bc-7f8a-48ee-9933-ee1b904d5a13", "fitness": 0.11234822966647333, "name": "SimplexGradientDescent", "description": "A gradient-free optimization algorithm that estimates the local gradient using a simplex-like method and moves towards the estimated minimum, with adaptive step size control.", "code": "import numpy as np\n\nclass SimplexGradientDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, step_size_reduction=0.5, step_size_increase=1.2, simplex_size=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_size_reduction = step_size_reduction\n        self.step_size_increase = step_size_increase\n        self.simplex_size = simplex_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.step_size = self.initial_step_size\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # 1. Estimate Gradient using a Simplex\n            simplex = []\n            fx = func(self.x_opt)\n            eval_count += 1\n            if fx < self.f_opt:\n                self.f_opt = fx\n            simplex.append((self.x_opt, fx))\n            \n            for i in range(self.dim):\n                direction = np.zeros(self.dim)\n                direction[i] = self.simplex_size\n                x_neighbor = self.x_opt + direction\n                \n                # Clip to boundaries\n                x_neighbor = np.clip(x_neighbor, func.bounds.lb, func.bounds.ub)\n                \n                f_neighbor = func(x_neighbor)\n                eval_count += 1\n                if f_neighbor < self.f_opt:\n                    self.f_opt = f_neighbor\n                simplex.append((x_neighbor, f_neighbor))\n                \n                if eval_count >= self.budget:\n                    return self.f_opt, self.x_opt\n\n\n            # 2. Calculate approximate gradient\n            gradient = np.zeros(self.dim)\n            for i in range(1, len(simplex)):\n                gradient += (simplex[i][1] - simplex[0][1]) * (simplex[i][0] - simplex[0][0])\n                \n            # 3. Move against gradient (descent)\n            x_new = self.x_opt - self.step_size * gradient\n            \n            # Clip to boundaries\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            eval_count += 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                self.step_size *= self.step_size_increase  # Increase step size if successful\n            else:\n                self.step_size *= self.step_size_reduction  # Reduce step size if unsuccessful\n                \n            if eval_count >= self.budget:\n                return self.f_opt, self.x_opt\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm SimplexGradientDescent scored 0.112 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A gradient-free optimization algorithm that estimates the local gradient using a simplex-like method and moves towards the estimated minimum, with adaptive step size control.\n# Code: \n```python\nimport numpy as np\n\nclass SimplexGradientDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, step_size_reduction=0.5, step_size_increase=1.2, simplex_size=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_size_reduction = step_size_reduction\n        self.step_size_increase = step_size_increase\n        self.simplex_size = simplex_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.step_size = self.initial_step_size\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # 1. Estimate Gradient using a Simplex\n            simplex = []\n            fx = func(self.x_opt)\n            eval_count += 1\n            if fx < self.f_opt:\n                self.f_opt = fx\n            simplex.append((self.x_opt, fx))\n            \n            for i in range(self.dim):\n                direction = np.zeros(self.dim)\n                direction[i] = self.simplex_size\n                x_neighbor = self.x_opt + direction\n                \n                # Clip to boundaries\n                x_neighbor = np.clip(x_neighbor, func.bounds.lb, func.bounds.ub)\n                \n                f_neighbor = func(x_neighbor)\n                eval_count += 1\n                if f_neighbor < self.f_opt:\n                    self.f_opt = f_neighbor\n                simplex.append((x_neighbor, f_neighbor))\n                \n                if eval_count >= self.budget:\n                    return self.f_opt, self.x_opt\n\n\n            # 2. Calculate approximate gradient\n            gradient = np.zeros(self.dim)\n            for i in range(1, len(simplex)):\n                gradient += (simplex[i][1] - simplex[0][1]) * (simplex[i][0] - simplex[0][0])\n                \n            # 3. Move against gradient (descent)\n            x_new = self.x_opt - self.step_size * gradient\n            \n            # Clip to boundaries\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            eval_count += 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                self.step_size *= self.step_size_increase  # Increase step size if successful\n            else:\n                self.step_size *= self.step_size_reduction  # Reduce step size if unsuccessful\n                \n            if eval_count >= self.budget:\n                return self.f_opt, self.x_opt\n\n        return self.f_opt, self.x_opt\n```", "aucs": [9.999999999998899e-05, 0.08791527412694777, 0.17637971859508472, 0.07458929437688444, 0.12998486972961132, 0.08943007626738109, 0.1442991599762945, 0.029041184710430934, 0.14722052905110816, 0.054401104228056996, 0.07941925458311594, 0.20070697187342068, 0.2009539679796687, 0.09525548490646674, 0.11912026318088209, 0.16006406408586915, 0.16558244331381633, 0.09826965442679159, 0.0336488057528701, 0.16058247216476518], "operator": "random_new", "theta_sampled": 0.0041782906388954585, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "e82aee69-23ed-4d5b-87cd-1b60472d95f9", "fitness": 0.3279787831108266, "name": "AdaptivePSO_DE_CMA", "description": "An adaptive PSO-DE hybrid with self-adaptive parameters and covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1_init=1.5, c1_end=2.0, c2_init=1.5, c2_end=0.5, de_rate=0.1, cma_decay=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end    # Final inertia weight\n        self.c1_init = c1_init # Initial cognitive coefficient\n        self.c1_end = c1_end   # Final cognitive coefficient\n        self.c2_init = c2_init # Initial social coefficient\n        self.c2_end = c2_end   # Final social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cma_decay = cma_decay #Decay rate for CMA variance\n\n        self.mean = None #Mean used for CMA\n        self.sigma = 1.0  # CMA step size\n        self.C = np.eye(dim)  # CMA covariance matrix\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        if self.mean is None:\n            self.mean = np.mean(pop, axis=0)\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Adaptive PSO parameters\n                w = self.w_init - (self.w_init - self.w_end) * (1 - self.budget / 10000)\n                c1 = self.c1_init + (self.c1_end - self.c1_init) * (1 - self.budget / 10000)\n                c2 = self.c2_init + (self.c2_end - self.c2_init) * (1 - self.budget / 10000)\n\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                #Evaluate with CMA\n                new_pos = self.sample_cma(new_pos)\n\n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n            self.update_cma(pop, fitness)\n\n        return global_best_fitness, global_best_pos\n    \n    def sample_cma(self, x):\n        z = np.random.randn(self.dim)\n        y = self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n        new_x = x + y\n        new_x = np.clip(new_x, -5.0, 5.0)  # Clip to bounds\n        return new_x\n\n    def update_cma(self, pop, fitness):\n        # Sort population based on fitness\n        sorted_indices = np.argsort(fitness)\n        mu = self.pop_size // 4  # Selection of top individuals\n        selected_pop = pop[sorted_indices[:mu]]\n\n        # Update mean\n        self.mean = np.mean(selected_pop, axis=0)\n\n        # Update covariance matrix\n        diff = selected_pop - self.mean\n        self.C = self.cma_decay * self.C + (1 - self.cma_decay) * (1/mu) * np.sum([np.outer(diff[i], diff[i]) for i in range(mu)], axis=0)\n\n        # Ensure covariance matrix is positive definite\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)  # Reset if not positive definite", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptivePSO_DE_CMA scored 0.328 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d42fe26a-a6ba-4261-bc35-c2c7f95cbca4"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive PSO-DE hybrid with self-adaptive parameters and covariance matrix adaptation for enhanced exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePSO_DE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1_init=1.5, c1_end=2.0, c2_init=1.5, c2_end=0.5, de_rate=0.1, cma_decay=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end    # Final inertia weight\n        self.c1_init = c1_init # Initial cognitive coefficient\n        self.c1_end = c1_end   # Final cognitive coefficient\n        self.c2_init = c2_init # Initial social coefficient\n        self.c2_end = c2_end   # Final social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cma_decay = cma_decay #Decay rate for CMA variance\n\n        self.mean = None #Mean used for CMA\n        self.sigma = 1.0  # CMA step size\n        self.C = np.eye(dim)  # CMA covariance matrix\n\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        if self.mean is None:\n            self.mean = np.mean(pop, axis=0)\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions (initially the same as initial positions)\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0 # initial max velocity\n        \n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Adaptive PSO parameters\n                w = self.w_init - (self.w_init - self.w_end) * (1 - self.budget / 10000)\n                c1 = self.c1_init + (self.c1_end - self.c1_init) * (1 - self.budget / 10000)\n                c2 = self.c2_init + (self.c2_end - self.c2_init) * (1 - self.budget / 10000)\n\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping to dynamically adjust exploration\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling (clip or bounce)\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search with probability de_rate\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + 0.5 * (x2 - x3)\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                #Evaluate with CMA\n                new_pos = self.sample_cma(new_pos)\n\n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n                    \n                #Update pop and fitness\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n            \n            # Dynamically adapt v_max to adjust exploration\n            v_max = np.abs(func.bounds.ub - func.bounds.lb) * (self.budget/10000) #Scale v_max linearly with remaining budget\n            v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0) #Ensure minimum and maximum\n            self.update_cma(pop, fitness)\n\n        return global_best_fitness, global_best_pos\n    \n    def sample_cma(self, x):\n        z = np.random.randn(self.dim)\n        y = self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n        new_x = x + y\n        new_x = np.clip(new_x, -5.0, 5.0)  # Clip to bounds\n        return new_x\n\n    def update_cma(self, pop, fitness):\n        # Sort population based on fitness\n        sorted_indices = np.argsort(fitness)\n        mu = self.pop_size // 4  # Selection of top individuals\n        selected_pop = pop[sorted_indices[:mu]]\n\n        # Update mean\n        self.mean = np.mean(selected_pop, axis=0)\n\n        # Update covariance matrix\n        diff = selected_pop - self.mean\n        self.C = self.cma_decay * self.C + (1 - self.cma_decay) * (1/mu) * np.sum([np.outer(diff[i], diff[i]) for i in range(mu)], axis=0)\n\n        # Ensure covariance matrix is positive definite\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)  # Reset if not positive definite\n```", "aucs": [0.13675374151217623, 0.19909681137848512, 0.2936018525035372, 0.3159211642529469, 0.25760091405560304, 0.2938343004987536, 0.2822600867199375, 0.2454232883479036, 0.23874780645337734, 0.1917650161030463, 0.2783450634276764, 0.9979818325695032, 0.2947519722916472, 0.2712216112303979, 0.6662850876700199, 0.3150913530828787, 0.2594349476761012, 0.369126953232094, 0.17879035490939765, 0.4735415043010498], "operator": "mutation", "theta_sampled": 0.00011973451192231941, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "82c8fafc-ec89-4c25-be44-c5b1f62656a3", "fitness": 0.2943616249418529, "name": "SelfOrganizingParticles", "description": "A self-organizing particle system where particles adjust their behavior based on local neighborhood performance, dynamically switching between exploration and exploitation.", "code": "import numpy as np\n\nclass SelfOrganizingParticles:\n    def __init__(self, budget=10000, dim=10, num_particles=20, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.neighborhood_size = neighborhood_size\n        self.particles = np.random.uniform(-5, 5, size=(num_particles, dim))\n        self.velocities = np.random.uniform(-1, 1, size=(num_particles, dim))  # Initialize velocities\n        self.fitness = np.full(num_particles, np.inf)\n        self.best_positions = self.particles.copy()  # Personal best positions\n        self.best_fitness = np.full(num_particles, np.inf)\n        self.global_best_index = None\n        self.exploration_rate = 0.5  # Initial exploration rate\n        self.exploitation_rate = 0.5 # Initial exploitation rate\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.function_evaluations = 0\n\n    def initialize(self, func):\n        # Initialize fitness for all particles\n        for i in range(self.num_particles):\n            self.fitness[i] = func(self.particles[i])\n            self.function_evaluations += 1\n            self.best_positions[i] = self.particles[i]\n            self.best_fitness[i] = self.fitness[i]\n        self.global_best_index = np.argmin(self.fitness)\n\n    def update_neighborhood(self, particle_index):\n        # Find neighborhood of a particle (including itself)\n        distances = np.linalg.norm(self.particles - self.particles[particle_index], axis=1)\n        neighbors = np.argsort(distances)[:self.neighborhood_size]\n        return neighbors\n    \n    def update_exploration_exploitation_rates(self):\n        # Dynamically adjust exploration and exploitation rates based on global best fitness improvement.\n        # If the global best hasn't improved much, increase exploration.  If it has, increase exploitation.\n        if self.function_evaluations > self.budget // 2:\n           recent_improvement = self.best_fitness[self.global_best_index] - np.min(self.best_fitness) #Simple improvement metric\n           if recent_improvement < 1e-5:  #Low improvement\n               self.exploration_rate = min(1.0, self.exploration_rate * 1.1)\n               self.exploitation_rate = max(0.0, self.exploitation_rate * 0.9)\n           else:\n               self.exploration_rate = max(0.0, self.exploration_rate * 0.9)\n               self.exploitation_rate = min(1.0, self.exploitation_rate * 1.1)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize(func)\n        \n        while self.function_evaluations < self.budget:\n            self.update_exploration_exploitation_rates()\n\n            for i in range(self.num_particles):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia_weight * self.velocities[i]\n                                      + self.cognitive_coeff * r1 * (self.best_positions[i] - self.particles[i])\n                                      + self.social_coeff * r2 * (self.particles[self.global_best_index] - self.particles[i]))\n\n                # Apply exploration/exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random movement within bounds\n                    self.particles[i] = np.random.uniform(-5, 5, size=self.dim)\n                else:\n                    # Exploitation: Move based on velocity\n                    self.particles[i] = self.particles[i] + self.velocities[i]\n                    self.particles[i] = np.clip(self.particles[i], -5, 5) # Clip to bounds\n\n                # Evaluate fitness\n                f = func(self.particles[i])\n                self.function_evaluations += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n\n                    if f < self.best_fitness[i]:\n                        self.best_fitness[i] = f\n                        self.best_positions[i] = self.particles[i]\n\n                # Update global best\n                if self.best_fitness[i] < self.best_fitness[self.global_best_index]:\n                    self.global_best_index = i\n\n                if self.fitness[i] < self.f_opt:\n                   self.f_opt = self.fitness[i]\n                   self.x_opt = self.particles[i]\n\n                if self.function_evaluations >= self.budget:\n                  break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm SelfOrganizingParticles scored 0.294 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-organizing particle system where particles adjust their behavior based on local neighborhood performance, dynamically switching between exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass SelfOrganizingParticles:\n    def __init__(self, budget=10000, dim=10, num_particles=20, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.neighborhood_size = neighborhood_size\n        self.particles = np.random.uniform(-5, 5, size=(num_particles, dim))\n        self.velocities = np.random.uniform(-1, 1, size=(num_particles, dim))  # Initialize velocities\n        self.fitness = np.full(num_particles, np.inf)\n        self.best_positions = self.particles.copy()  # Personal best positions\n        self.best_fitness = np.full(num_particles, np.inf)\n        self.global_best_index = None\n        self.exploration_rate = 0.5  # Initial exploration rate\n        self.exploitation_rate = 0.5 # Initial exploitation rate\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.function_evaluations = 0\n\n    def initialize(self, func):\n        # Initialize fitness for all particles\n        for i in range(self.num_particles):\n            self.fitness[i] = func(self.particles[i])\n            self.function_evaluations += 1\n            self.best_positions[i] = self.particles[i]\n            self.best_fitness[i] = self.fitness[i]\n        self.global_best_index = np.argmin(self.fitness)\n\n    def update_neighborhood(self, particle_index):\n        # Find neighborhood of a particle (including itself)\n        distances = np.linalg.norm(self.particles - self.particles[particle_index], axis=1)\n        neighbors = np.argsort(distances)[:self.neighborhood_size]\n        return neighbors\n    \n    def update_exploration_exploitation_rates(self):\n        # Dynamically adjust exploration and exploitation rates based on global best fitness improvement.\n        # If the global best hasn't improved much, increase exploration.  If it has, increase exploitation.\n        if self.function_evaluations > self.budget // 2:\n           recent_improvement = self.best_fitness[self.global_best_index] - np.min(self.best_fitness) #Simple improvement metric\n           if recent_improvement < 1e-5:  #Low improvement\n               self.exploration_rate = min(1.0, self.exploration_rate * 1.1)\n               self.exploitation_rate = max(0.0, self.exploitation_rate * 0.9)\n           else:\n               self.exploration_rate = max(0.0, self.exploration_rate * 0.9)\n               self.exploitation_rate = min(1.0, self.exploitation_rate * 1.1)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize(func)\n        \n        while self.function_evaluations < self.budget:\n            self.update_exploration_exploitation_rates()\n\n            for i in range(self.num_particles):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia_weight * self.velocities[i]\n                                      + self.cognitive_coeff * r1 * (self.best_positions[i] - self.particles[i])\n                                      + self.social_coeff * r2 * (self.particles[self.global_best_index] - self.particles[i]))\n\n                # Apply exploration/exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random movement within bounds\n                    self.particles[i] = np.random.uniform(-5, 5, size=self.dim)\n                else:\n                    # Exploitation: Move based on velocity\n                    self.particles[i] = self.particles[i] + self.velocities[i]\n                    self.particles[i] = np.clip(self.particles[i], -5, 5) # Clip to bounds\n\n                # Evaluate fitness\n                f = func(self.particles[i])\n                self.function_evaluations += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n\n                    if f < self.best_fitness[i]:\n                        self.best_fitness[i] = f\n                        self.best_positions[i] = self.particles[i]\n\n                # Update global best\n                if self.best_fitness[i] < self.best_fitness[self.global_best_index]:\n                    self.global_best_index = i\n\n                if self.fitness[i] < self.f_opt:\n                   self.f_opt = self.fitness[i]\n                   self.x_opt = self.particles[i]\n\n                if self.function_evaluations >= self.budget:\n                  break\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.1333282955895374, 0.17811918386183057, 0.27791265003672927, 0.221895342267037, 0.21679495835671414, 0.23388759495327094, 0.2304165328735659, 0.25401720859314014, 0.19504663820950308, 0.15747635004367044, 0.21331262151642982, 0.997773760004332, 0.23887431806028803, 0.22744697545261106, 0.6322339415655831, 0.27938979826706745, 0.2608229203841853, 0.2809938907412006, 0.18391672472383191, 0.47357279333653035], "operator": "random_new", "theta_sampled": 0.00861809013847924, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "d12c4a0c-9195-454a-99c0-d431684ed79f", "fitness": 0.17434708610644223, "name": "AntColonyOptimization", "description": "Bio-inspired algorithm mimicking foraging ants with pheromone trails and dynamic step size.", "code": "import numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, n_ants=20, evaporation_rate=0.1, pheromone_influence=1.0, step_size_reduction=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.n_ants = n_ants\n        self.evaporation_rate = evaporation_rate\n        self.pheromone_influence = pheromone_influence\n        self.step_size_reduction = step_size_reduction\n        self.pheromone = np.zeros(dim)\n        self.step_size = 1.0 # Initial step size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        pheromone = np.zeros(self.dim)\n\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_ants, self.dim))\n        fitness = np.array([func(ant) for ant in ants])\n        self.budget -= self.n_ants\n\n        best_ant_index = np.argmin(fitness)\n        self.f_opt = fitness[best_ant_index]\n        self.x_opt = ants[best_ant_index]\n        \n        while self.budget > 0:\n            for i in range(self.n_ants):\n                # Pheromone-guided movement with dynamic step size\n                direction = np.sign(pheromone) * self.step_size\n                new_ant = ants[i] + direction\n                \n                # Ensure boundaries are respected\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)\n                \n                f = func(new_ant)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_ant\n                        \n            # Update pheromone based on ant performance\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.n_ants):\n                delta_pheromone += (self.x_opt - ants[i]) * (self.f_opt - fitness[i])  # Reward good ants for approaching the best location\n                \n            pheromone = (1 - self.evaporation_rate) * pheromone + self.pheromone_influence * delta_pheromone\n            \n            # Reduce step size to refine search\n            self.step_size *= self.step_size_reduction\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AntColonyOptimization scored 0.174 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Bio-inspired algorithm mimicking foraging ants with pheromone trails and dynamic step size.\n# Code:\n```python\nimport numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, n_ants=20, evaporation_rate=0.1, pheromone_influence=1.0, step_size_reduction=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.n_ants = n_ants\n        self.evaporation_rate = evaporation_rate\n        self.pheromone_influence = pheromone_influence\n        self.step_size_reduction = step_size_reduction\n        self.pheromone = np.zeros(dim)\n        self.step_size = 1.0 # Initial step size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        pheromone = np.zeros(self.dim)\n\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_ants, self.dim))\n        fitness = np.array([func(ant) for ant in ants])\n        self.budget -= self.n_ants\n\n        best_ant_index = np.argmin(fitness)\n        self.f_opt = fitness[best_ant_index]\n        self.x_opt = ants[best_ant_index]\n        \n        while self.budget > 0:\n            for i in range(self.n_ants):\n                # Pheromone-guided movement with dynamic step size\n                direction = np.sign(pheromone) * self.step_size\n                new_ant = ants[i] + direction\n                \n                # Ensure boundaries are respected\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)\n                \n                f = func(new_ant)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_ant\n                        \n            # Update pheromone based on ant performance\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.n_ants):\n                delta_pheromone += (self.x_opt - ants[i]) * (self.f_opt - fitness[i])  # Reward good ants for approaching the best location\n                \n            pheromone = (1 - self.evaporation_rate) * pheromone + self.pheromone_influence * delta_pheromone\n            \n            # Reduce step size to refine search\n            self.step_size *= self.step_size_reduction\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07999221277881985, 0.17488516233013873, 0.21204315788453998, 0.15141044919185975, 0.09116547293454313, 0.16300118228631832, 0.21356766476595912, 0.15452224620852195, 0.16370312253927366, 0.1184439612253414, 0.16222563204957474, 0.24428071970422938, 0.24161416373557643, 0.18237101578911852, 0.14220068045696066, 0.2685649280504583, 0.2215071095794584, 0.1837914050216527, 0.13003048213207458, 0.18762095346442542], "operator": "random_new", "theta_sampled": 0.005778193108274146, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "89ef5734-0a3c-499b-8d46-860c767b4373", "fitness": 0.17901710829817344, "name": "DynamicCovarianceDE", "description": "A population-based algorithm that combines elements of differential evolution and covariance matrix adaptation, using a dynamic population size and learning rate annealing.", "code": "import numpy as np\n\nclass DynamicCovarianceDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, lr_init=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.lr_init = lr_init\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        pop_size = self.pop_size_init\n        population = np.random.uniform(self.lb, self.ub, size=(pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= pop_size\n\n        # Initialize CMA-ES-like parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.1\n        C = np.eye(self.dim)\n\n        # Optimization loop\n        generation = 0\n        lr = self.lr_init\n        while self.budget > 0:\n            generation += 1\n            \n            # Differential Evolution Mutation\n            mutated = np.zeros_like(population)\n            for i in range(pop_size):\n                idxs = np.random.choice(pop_size, 3, replace=False)\n                mutated[i] = population[idxs[0]] + lr * (population[idxs[1]] - population[idxs[2]])\n                mutated[i] = np.clip(mutated[i], self.lb, self.ub)  # Clip to bounds\n\n            # Recombination (Crossover)\n            crossover_rate = 0.7\n            trial_vectors = np.where(np.random.rand(pop_size, self.dim) < crossover_rate, mutated, population)\n            \n            # Evaluate trial vectors\n            trial_fitness = np.array([func(x) for x in trial_vectors])\n            self.budget -= pop_size\n            if self.budget <= 0:\n                break\n            \n            # Selection\n            improved = trial_fitness < fitness\n            population[improved] = trial_vectors[improved]\n            fitness[improved] = trial_fitness[improved]\n            \n            # Update mean and covariance matrix (Simplified CMA-ES update)\n            mean = np.mean(population, axis=0)\n            \n            # Rank-one update (Simplified, but maintaining positive definiteness)\n            diff = population - mean\n            C = (1 - lr) * C + lr * np.cov(diff.T)\n            \n            # Ensure covariance matrix is positive definite by adding a small identity matrix.\n            C = (C + C.T) / 2  # Ensure symmetry\n            C = C + np.eye(self.dim) * 1e-6 # add small value for positive definiteness\n\n\n            # Dynamic population size adjustment (simple heuristic)\n            if generation % 10 == 0:\n                if np.std(fitness) < 1e-3:\n                    pop_size = min(self.pop_size_init * 2, 200)\n                else:\n                    pop_size = self.pop_size_init\n                \n                if pop_size != population.shape[0]:\n                    population = np.random.uniform(self.lb, self.ub, size=(pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= pop_size\n                    if self.budget <= 0:\n                        break\n                    mean = np.mean(population, axis=0) # reinitialize mean as well\n                    C = np.eye(self.dim) # reinitialize covariance matrix as well\n\n            # Learning rate annealing\n            lr = self.lr_init * (1 - generation / (self.budget / self.pop_size_init + generation))  # Linear annealing\n\n        # Return best solution found\n        best_index = np.argmin(fitness)\n        return fitness[best_index], population[best_index]", "configspace": "", "generation": 12, "feedback": "The algorithm DynamicCovarianceDE scored 0.179 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of differential evolution and covariance matrix adaptation, using a dynamic population size and learning rate annealing.\n# Code: \n```python\nimport numpy as np\n\nclass DynamicCovarianceDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, lr_init=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.lr_init = lr_init\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        pop_size = self.pop_size_init\n        population = np.random.uniform(self.lb, self.ub, size=(pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= pop_size\n\n        # Initialize CMA-ES-like parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.1\n        C = np.eye(self.dim)\n\n        # Optimization loop\n        generation = 0\n        lr = self.lr_init\n        while self.budget > 0:\n            generation += 1\n            \n            # Differential Evolution Mutation\n            mutated = np.zeros_like(population)\n            for i in range(pop_size):\n                idxs = np.random.choice(pop_size, 3, replace=False)\n                mutated[i] = population[idxs[0]] + lr * (population[idxs[1]] - population[idxs[2]])\n                mutated[i] = np.clip(mutated[i], self.lb, self.ub)  # Clip to bounds\n\n            # Recombination (Crossover)\n            crossover_rate = 0.7\n            trial_vectors = np.where(np.random.rand(pop_size, self.dim) < crossover_rate, mutated, population)\n            \n            # Evaluate trial vectors\n            trial_fitness = np.array([func(x) for x in trial_vectors])\n            self.budget -= pop_size\n            if self.budget <= 0:\n                break\n            \n            # Selection\n            improved = trial_fitness < fitness\n            population[improved] = trial_vectors[improved]\n            fitness[improved] = trial_fitness[improved]\n            \n            # Update mean and covariance matrix (Simplified CMA-ES update)\n            mean = np.mean(population, axis=0)\n            \n            # Rank-one update (Simplified, but maintaining positive definiteness)\n            diff = population - mean\n            C = (1 - lr) * C + lr * np.cov(diff.T)\n            \n            # Ensure covariance matrix is positive definite by adding a small identity matrix.\n            C = (C + C.T) / 2  # Ensure symmetry\n            C = C + np.eye(self.dim) * 1e-6 # add small value for positive definiteness\n\n\n            # Dynamic population size adjustment (simple heuristic)\n            if generation % 10 == 0:\n                if np.std(fitness) < 1e-3:\n                    pop_size = min(self.pop_size_init * 2, 200)\n                else:\n                    pop_size = self.pop_size_init\n                \n                if pop_size != population.shape[0]:\n                    population = np.random.uniform(self.lb, self.ub, size=(pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= pop_size\n                    if self.budget <= 0:\n                        break\n                    mean = np.mean(population, axis=0) # reinitialize mean as well\n                    C = np.eye(self.dim) # reinitialize covariance matrix as well\n\n            # Learning rate annealing\n            lr = self.lr_init * (1 - generation / (self.budget / self.pop_size_init + generation))  # Linear annealing\n\n        # Return best solution found\n        best_index = np.argmin(fitness)\n        return fitness[best_index], population[best_index]\n```", "aucs": [0.2248905108567657, 0.31216081403775464, 0], "operator": "random_new", "theta_sampled": 0.00502475710835325, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "a51aab7e-97d2-43ca-809c-520c1e515ef9", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMA_LS", "description": "A hybrid PSO with CMA-ES and DE, using a decaying exploration rate and adaptive parameter control for improved convergence and exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, ls_prob=0.1, adapt_freq=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n        self.ls_prob = ls_prob #probability of local search\n        self.adapt_freq = adapt_freq # Frequency of adapting parameters\n        self.eval_count = 0 #Counter for evaluations\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        self.eval_count += self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / 10000)\n            w = np.clip(w, self.w_end, self.w_init) #Ensure w is within bounds\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    self.eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                self.eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n                # Self-Adaptive Local Search\n                if np.random.rand() < self.ls_prob:\n                    # Perturb the current solution based on fitness landscape\n                    delta = np.random.normal(0, self.sigma, self.dim) # Use CMA's sigma for perturbation scale\n                    ls_pos = new_pos + delta\n                    ls_pos = np.clip(ls_pos, func.bounds.lb, func.bounds.ub)\n                    ls_fitness = func(ls_pos)\n                    self.budget -= 1\n                    self.eval_count+=1\n                    if self.budget <= 0:\n                        break\n\n                    if ls_fitness < new_fitness:\n                        pop[i] = ls_pos\n                        fitness[i] = ls_fitness\n                        if ls_fitness < personal_best_fitness[i]:\n                            personal_best_fitness[i] = ls_fitness\n                            personal_best_pos[i] = ls_pos.copy()\n                        if ls_fitness < global_best_fitness:\n                            global_best_fitness = ls_fitness\n                            global_best_pos = ls_pos.copy()\n\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n            self.sigma = np.clip(self.sigma, 1e-6, abs(func.bounds.ub - func.bounds.lb)/2) # Clip sigma to prevent it from becoming too small or large\n\n            # Adapt DE mutation factor and v_max every adapt_freq evaluations\n            if self.eval_count % self.adapt_freq == 0:\n                diversity = np.std(fitness)\n                if diversity > 0.1: # dynamic mutation\n                    self.F_val = 0.5 + 0.3 * np.random.rand()\n                else:\n                    self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n                # Dynamically adapt v_max (linearly decaying)\n                v_max = np.abs(func.bounds.ub - func.bounds.lb) * (1 - (self.eval_count/self.budget))\n                v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n                \n\n                #Adapt local search probability\n                if np.std(fitness) < 0.01: # low diversity\n                    self.ls_prob = min(self.ls_prob * 1.2, 0.5) # increase exploration\n                else:\n                    self.ls_prob = max(self.ls_prob * 0.8, 0.01) # decrease exploration\n\n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 12, "feedback": "", "error": "Evaluation error: division by zero", "parent_ids": ["e4e2d565-ed5e-4ca9-959a-f41f6f671c56"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid PSO with CMA-ES and DE, using a decaying exploration rate and adaptive parameter control for improved convergence and exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_CMA_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.2, c1=1.5, c2=1.5, de_rate=0.1, cs=0.3, c_cov=0.1, mu_init_sigma=0.5, ls_prob=0.1, adapt_freq=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight\n        self.w_end = w_end  # Final inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Rate of applying DE local search\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu_init_sigma = mu_init_sigma #initial sigma for mu updates (before any actual covariance update)\n        self.mu = None # Mean for CMA\n        self.sigma = None # Step size for CMA\n        self.F_val = 0.5 #DE mutation factor\n        self.ls_prob = ls_prob #probability of local search\n        self.adapt_freq = adapt_freq # Frequency of adapting parameters\n        self.eval_count = 0 #Counter for evaluations\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        self.eval_count += self.pop_size\n\n        # Find global best\n        global_best_idx = np.argmin(fitness)\n        global_best_pos = pop[global_best_idx].copy()\n        global_best_fitness = fitness[global_best_idx]\n\n        # Personal best positions\n        personal_best_pos = pop.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize CMA parameters\n        self.mu = np.mean(pop, axis=0) # Initialize mu with the mean of the initial population\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)  # Initialize sigma\n\n        # Adaptive velocity clamping\n        v_max = np.abs(func.bounds.ub - func.bounds.lb) / 2.0\n        \n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / 10000)\n            w = np.clip(w, self.w_end, self.w_init) #Ensure w is within bounds\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (w * velocities[i]\n                                + self.c1 * r1 * (personal_best_pos[i] - pop[i])\n                                + self.c2 * r2 * (global_best_pos - pop[i]))\n                                \n                # Velocity clamping\n                velocities[i] = np.clip(new_velocity, -v_max, v_max)\n                \n                # Update position\n                new_pos = pop[i] + velocities[i]\n                \n                # Boundary handling\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # Apply DE mutation for local search\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    mutated_pos = new_pos + self.F_val * (x2 - x3) #use F_val as DE mutation factor\n                    mutated_pos = np.clip(mutated_pos, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate mutated position and use if better\n                    mutated_fitness = func(mutated_pos)\n                    self.budget -= 1\n                    self.eval_count+=1\n                    if self.budget <= 0:\n                        break\n                    \n                    if mutated_fitness < fitness[i]:\n                        new_pos = mutated_pos\n                        \n                # Evaluate new position\n                new_fitness = func(new_pos)\n                self.budget -= 1\n                self.eval_count+=1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_pos[i] = new_pos.copy()\n                \n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_pos = new_pos.copy()\n\n                pop[i] = new_pos\n                fitness[i] = new_fitness\n\n                # Self-Adaptive Local Search\n                if np.random.rand() < self.ls_prob:\n                    # Perturb the current solution based on fitness landscape\n                    delta = np.random.normal(0, self.sigma, self.dim) # Use CMA's sigma for perturbation scale\n                    ls_pos = new_pos + delta\n                    ls_pos = np.clip(ls_pos, func.bounds.lb, func.bounds.ub)\n                    ls_fitness = func(ls_pos)\n                    self.budget -= 1\n                    self.eval_count+=1\n                    if self.budget <= 0:\n                        break\n\n                    if ls_fitness < new_fitness:\n                        pop[i] = ls_pos\n                        fitness[i] = ls_fitness\n                        if ls_fitness < personal_best_fitness[i]:\n                            personal_best_fitness[i] = ls_fitness\n                            personal_best_pos[i] = ls_pos.copy()\n                        if ls_fitness < global_best_fitness:\n                            global_best_fitness = ls_fitness\n                            global_best_pos = ls_pos.copy()\n\n\n            #Covariance Matrix Adaptation (CMA) - Simplified and applied to update PSO parameters\n            x_mean = np.mean(pop, axis=0)\n            diff = x_mean - self.mu\n            self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n            self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n            self.sigma = np.clip(self.sigma, 1e-6, abs(func.bounds.ub - func.bounds.lb)/2) # Clip sigma to prevent it from becoming too small or large\n\n            # Adapt DE mutation factor and v_max every adapt_freq evaluations\n            if self.eval_count % self.adapt_freq == 0:\n                diversity = np.std(fitness)\n                if diversity > 0.1: # dynamic mutation\n                    self.F_val = 0.5 + 0.3 * np.random.rand()\n                else:\n                    self.F_val = 0.1 + 0.1* np.random.rand()\n                    \n                # Dynamically adapt v_max (linearly decaying)\n                v_max = np.abs(func.bounds.ub - func.bounds.lb) * (1 - (self.eval_count/self.budget))\n                v_max = np.clip(v_max, 0.001, np.abs(func.bounds.ub - func.bounds.lb) / 2.0)\n                \n\n                #Adapt local search probability\n                if np.std(fitness) < 0.01: # low diversity\n                    self.ls_prob = min(self.ls_prob * 1.2, 0.5) # increase exploration\n                else:\n                    self.ls_prob = max(self.ls_prob * 0.8, 0.01) # decrease exploration\n\n        return global_best_fitness, global_best_pos\n```", "operator": "mutation", "theta_sampled": 0.0011201823574440827, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "9a33fca9-3147-4ed5-9048-a85d3fea023b", "fitness": 0.5458586438738002, "name": "AdaptiveDE_NM", "description": "Adaptive Differential Evolution with Nelder-Mead local search, dynamically adjusting DE parameters and NM frequency based on function evaluation progress.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100, cr_adapt=True, f_adapt=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.cr_adapt = cr_adapt\n        self.f_adapt = f_adapt\n        self.cr_history = []\n        self.f_history = []\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.cr_history.append(1)\n                self.f_history.append(abs(f_trial - self.fitness[i]))\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n            else:\n                self.cr_history.append(0)\n\n            if self.cr_adapt and len(self.cr_history) > 50:\n                success_rate = np.mean(self.cr_history[-50:])\n                self.de_cr = np.clip(success_rate + np.random.normal(0, 0.1), 0.1, 0.9)\n            \n            if self.f_adapt and len(self.f_history) > 50:\n                avg_improvement = np.mean(self.f_history[-50:])\n                self.de_f = np.clip(self.de_f + np.random.normal(0, 0.05), 0.1, 0.9)\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})  # Limit FE calls, increased to nm_freq\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n              break\n            \n            #Dynamically adjust NM frequency\n            remaining_budget = self.budget - self.eval_count\n            self.nm_freq = min(100 + (self.budget - remaining_budget)//1000 * 10 , 500) # Increase nm_freq with evaluation count\n            if self.eval_count // (self.nm_freq//2) != (self.eval_count - self.pop_size // (self.nm_freq//2) ) // (self.nm_freq//2) :\n            #if self.eval_count % self.nm_freq == 0: # Perform NM every nm_freq evaluations\n                self.nelder_mead_local_search(func)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDE_NM scored 0.546 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c11b0a48-b338-4ace-9f74-68f3ec440e0a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Nelder-Mead local search, dynamically adjusting DE parameters and NM frequency based on function evaluation progress.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100, cr_adapt=True, f_adapt=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.cr_adapt = cr_adapt\n        self.f_adapt = f_adapt\n        self.cr_history = []\n        self.f_history = []\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.cr_history.append(1)\n                self.f_history.append(abs(f_trial - self.fitness[i]))\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n            else:\n                self.cr_history.append(0)\n\n            if self.cr_adapt and len(self.cr_history) > 50:\n                success_rate = np.mean(self.cr_history[-50:])\n                self.de_cr = np.clip(success_rate + np.random.normal(0, 0.1), 0.1, 0.9)\n            \n            if self.f_adapt and len(self.f_history) > 50:\n                avg_improvement = np.mean(self.f_history[-50:])\n                self.de_f = np.clip(self.de_f + np.random.normal(0, 0.05), 0.1, 0.9)\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})  # Limit FE calls, increased to nm_freq\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n              break\n            \n            #Dynamically adjust NM frequency\n            remaining_budget = self.budget - self.eval_count\n            self.nm_freq = min(100 + (self.budget - remaining_budget)//1000 * 10 , 500) # Increase nm_freq with evaluation count\n            if self.eval_count // (self.nm_freq//2) != (self.eval_count - self.pop_size // (self.nm_freq//2) ) // (self.nm_freq//2) :\n            #if self.eval_count % self.nm_freq == 0: # Perform NM every nm_freq evaluations\n                self.nelder_mead_local_search(func)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16691364138737208, 0.20302592222305582, 0.5719345934010858, 0.6858637032575707, 0.5782503897342185, 0.7677036814482177, 0.3457715280015179, 0.5214650994771142, 0.6243284412002665, 0.5048305518419454, 0.6351117608228294, 0.9988610401908506, 0.27563796321371814, 0.5074859136543441, 0.7777810138693653, 0.7793988127250769, 0.4230369437013983, 0.8097461449435024, 0.2261839130984138, 0.5138418192841427], "operator": "mutation", "theta_sampled": 0.0023897588418396727, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "8bec77dd-a7ff-4251-9054-72763070a087", "fitness": 0.09109489691622616, "name": "GradientEstimationSearch", "description": "Gradient Estimation with Random Restarts: Estimates the gradient using random perturbations and takes steps in the estimated negative gradient direction, restarting randomly if progress stalls.", "code": "import numpy as np\n\nclass GradientEstimationSearch:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, num_estimates=10, restart_patience=1000):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.num_estimates = num_estimates\n        self.restart_patience = restart_patience\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Initialize randomly\n        self.f_opt = func(self.x_opt)\n        \n        eval_count = 1\n        patience_counter = 0\n\n        while eval_count < self.budget:\n            \n            # Estimate gradient\n            gradient_estimate = np.zeros(self.dim)\n            for _ in range(self.num_estimates):\n                if eval_count >= self.budget:\n                    break\n\n                perturbation = np.random.normal(0, 0.01, self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub) # Ensure within bounds\n                f_perturbed = func(x_perturbed)\n                eval_count += 1\n\n                gradient_estimate += (f_perturbed - self.f_opt) * perturbation\n\n            gradient_estimate /= self.num_estimates\n            \n            # Take a step in the negative gradient direction\n            x_new = self.x_opt - self.step_size * gradient_estimate\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)  # Ensure within bounds\n            f_new = func(x_new)\n            eval_count += 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                patience_counter = 0\n            else:\n                patience_counter += 1\n\n            # Restart if progress stalls\n            if patience_counter > self.restart_patience:\n                self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                self.f_opt = func(self.x_opt)\n                eval_count += 1\n                patience_counter = 0\n                self.step_size *= 0.9 # Reduce step size after restart for finer search\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm GradientEstimationSearch scored 0.091 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Gradient Estimation with Random Restarts: Estimates the gradient using random perturbations and takes steps in the estimated negative gradient direction, restarting randomly if progress stalls.\n# Code: \n```python\nimport numpy as np\n\nclass GradientEstimationSearch:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, num_estimates=10, restart_patience=1000):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.num_estimates = num_estimates\n        self.restart_patience = restart_patience\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Initialize randomly\n        self.f_opt = func(self.x_opt)\n        \n        eval_count = 1\n        patience_counter = 0\n\n        while eval_count < self.budget:\n            \n            # Estimate gradient\n            gradient_estimate = np.zeros(self.dim)\n            for _ in range(self.num_estimates):\n                if eval_count >= self.budget:\n                    break\n\n                perturbation = np.random.normal(0, 0.01, self.dim)\n                x_perturbed = self.x_opt + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub) # Ensure within bounds\n                f_perturbed = func(x_perturbed)\n                eval_count += 1\n\n                gradient_estimate += (f_perturbed - self.f_opt) * perturbation\n\n            gradient_estimate /= self.num_estimates\n            \n            # Take a step in the negative gradient direction\n            x_new = self.x_opt - self.step_size * gradient_estimate\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)  # Ensure within bounds\n            f_new = func(x_new)\n            eval_count += 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                patience_counter = 0\n            else:\n                patience_counter += 1\n\n            # Restart if progress stalls\n            if patience_counter > self.restart_patience:\n                self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                self.f_opt = func(self.x_opt)\n                eval_count += 1\n                patience_counter = 0\n                self.step_size *= 0.9 # Reduce step size after restart for finer search\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.007784669192912763, 0.06129549083232122, 0.1427409716555319, 0.11469612620205427, 0.05513224109589776, 0.0978316984831703, 0.06186375272532896, 0.04558344866732622, 0.15581531208452015, 0.07404209025827657, 0.11688602018536953, 0.09708954059437658, 0.07659064338542687, 0.08395831636726925, 0.09886858399097387, 0.10672103872261962, 0.1340694437156752, 0.10151781627579226, 0.07718082873777299, 0.11222990515190723], "operator": "random_new", "theta_sampled": 0.005004755463753601, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "e7b896b0-7049-4116-b9e4-32c4dfaf9175", "fitness": 0.0, "name": "AdaptiveHybridDE_NM_CMA", "description": "A hybrid algorithm combining adaptive differential evolution, Nelder-Mead local search, and a simplified covariance matrix adaptation (CMA) strategy for parameter control.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_NM_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100, cs=0.3, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.cs = cs # Learning rate for CMA mean update\n        self.c_cov = c_cov # Learning rate for CMA step size update\n        self.mu_init_sigma = mu_init_sigma #Initial step size for CMA mean\n        self.mu = None # Mean for CMA\n        self.sigma = None  # Step size for CMA\n        self.F_val = 0.5 # DE mutation factor - initialized\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n        self.mu = np.mean(self.pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})  # Limit FE calls\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n    def update_cma_parameters(self):\n        x_mean = np.mean(self.pop, axis=0)\n        diff = x_mean - self.mu\n        self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n        self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n    def adapt_de_mutation_factor(self):\n        diversity = np.std(self.fitness)\n        if diversity > 0.1: # dynamic mutation\n            self.F_val = 0.5 + 0.3 * np.random.rand()\n        else:\n            self.F_val = 0.1 + 0.1* np.random.rand()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n              break\n            if self.eval_count // self.nm_freq != (self.eval_count - 1) // self.nm_freq : #self.eval_count % self.nm_freq == 0: # Perform NM every nm_freq evaluations\n                self.nelder_mead_local_search(func)\n                \n            self.update_cma_parameters()\n            self.adapt_de_mutation_factor()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["c11b0a48-b338-4ace-9f74-68f3ec440e0a", "69eb3d57-efc7-430d-a6a2-e36612c80a8a"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining adaptive differential evolution, Nelder-Mead local search, and a simplified covariance matrix adaptation (CMA) strategy for parameter control.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDE_NM_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.7, de_f=0.5, nm_freq=100, cs=0.3, c_cov=0.1, mu_init_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.nm_freq = nm_freq  # Frequency of Nelder-Mead local search\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.cs = cs # Learning rate for CMA mean update\n        self.c_cov = c_cov # Learning rate for CMA step size update\n        self.mu_init_sigma = mu_init_sigma #Initial step size for CMA mean\n        self.mu = None # Mean for CMA\n        self.sigma = None  # Step size for CMA\n        self.F_val = 0.5 # DE mutation factor - initialized\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n        self.mu = np.mean(self.pop, axis=0)\n        self.sigma = self.mu_init_sigma * np.ones(self.dim)\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = np.copy(self.pop[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.best_idx = i\n\n    def nelder_mead_local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Start Nelder-Mead from the current individual\n            res = minimize(func, self.pop[i], method='Nelder-Mead',\n                           options={'maxfev': min(self.nm_freq, self.budget - self.eval_count)})  # Limit FE calls\n\n            if res.success:  # Check if optimization was successful\n                f_val = res.fun\n                x_val = res.x\n                n_fev = res.nfev  # Number of function evaluations used by Nelder-Mead\n                \n                self.eval_count += n_fev\n                if f_val < self.fitness[i]:\n                  self.fitness[i] = f_val\n                  self.pop[i] = x_val\n\n                  if f_val < self.f_opt:\n                      self.f_opt = f_val\n                      self.x_opt = x_val\n                      self.best_idx = i\n\n    def update_cma_parameters(self):\n        x_mean = np.mean(self.pop, axis=0)\n        diff = x_mean - self.mu\n        self.mu = (1 - self.cs) * self.mu + self.cs * x_mean\n        self.sigma = self.sigma * np.exp(self.c_cov * (np.linalg.norm(diff) - 0.5))\n\n    def adapt_de_mutation_factor(self):\n        diversity = np.std(self.fitness)\n        if diversity > 0.1: # dynamic mutation\n            self.F_val = 0.5 + 0.3 * np.random.rand()\n        else:\n            self.F_val = 0.1 + 0.1* np.random.rand()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            if self.eval_count >= self.budget:\n              break\n            if self.eval_count // self.nm_freq != (self.eval_count - 1) // self.nm_freq : #self.eval_count % self.nm_freq == 0: # Perform NM every nm_freq evaluations\n                self.nelder_mead_local_search(func)\n                \n            self.update_cma_parameters()\n            self.adapt_de_mutation_factor()\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.002001645601596138, "reward": 0.0, "generation": 12}, "task_prompt": ""}
