{"id": "d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "fitness": 0.7025737296471294, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a Population Archive and stochastic ranking.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.703 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with a Population Archive and stochastic ranking.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3690933554947571, 0.7228627921449411, 0.6504759610410419, 0.8680152069551315, 0.7563572570944015, 0.797330075715674, 0.5935912326164989, 0.6922491460403062, 0.7349162444157894, 0.6769013336401781, 0.8664718798575972, 0.9952495331182764, 0.6711175686849055, 0.731249586623707, 0.9256526113716464, 0.776701988505526, 0.6119255290955485, 0.8363069524583034, 0.27376729153309476, 0.5012390465352623], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "0c937d38-010c-458a-a121-a7e35c8db411", "fitness": 0.3787909056630498, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with archive and mutation factor adaptation based on success rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9 # Initial crossover rate\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n\n        # Evaluate initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, size=3, replace=False)\n\n\n                x_r1, x_r2, x_r3 = population[indices]\n\n                mutant = population[i] + self.F * (x_r1 - x_r2)  # DE/rand/1 mutation\n\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    successful_mutations += 1\n\n\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n\n            # Adapt F based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.379 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with archive and mutation factor adaptation based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9 # Initial crossover rate\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n\n        # Evaluate initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, size=3, replace=False)\n\n\n                x_r1, x_r2, x_r3 = population[indices]\n\n                mutant = population[i] + self.F * (x_r1 - x_r2)  # DE/rand/1 mutation\n\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    successful_mutations += 1\n\n\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n\n            # Adapt F based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14795879219184938, 0.2589603871198066, 0.38381227968226705, 0.3627442025344412, 0.2632913143064297, 0.3702929684596967, 0.2840559473538642, 0.3104190856191261, 0.2711019794896463, 0.19088003291293498, 0.49300320496279215, 0.99060165706512, 0.40593571794130967, 0.26101280843879726, 0.7241965187345618, 0.39928025588772886, 0.3239531775627724, 0.4666531165196217, 0.18942913217849022, 0.4782355342997404], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "71785ef1-fe7d-4022-b059-58669c728f8d", "fitness": 0.0, "name": "AdaptivePopulationSearch", "description": "Population-based algorithm that adapts its search strategy based on the observed performance of individuals, biasing exploration towards promising regions and exploiting local optima.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def mutate(self, individual, func):\n        for i in range(self.dim):\n            if np.random.rand() < self.mutation_rate:\n                individual[i] += np.random.normal(0, 0.1 * (func.bounds.ub - func.bounds.lb)) #mutation step size is proportional to the range of the input variables.\n                individual[i] = np.clip(individual[i], func.bounds.lb, func.bounds.ub)\n        return individual\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim)\n            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        else:\n            child = parent1.copy()  # No crossover\n        return child\n\n    def selection(self, population, fitness, num_parents):\n        indices = np.argsort(fitness)[:num_parents]\n        return population[indices]\n\n    def __call__(self, func):\n        population, fitness = self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluation\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while eval_count < self.budget:\n            # Selection (select best individuals as parents)\n            num_parents = self.pop_size // 2  # Example: select half the population\n            parents = self.selection(population, fitness, num_parents)\n\n            new_population = []\n            new_fitness = []\n\n            # Create new population through crossover and mutation\n            for i in range(self.pop_size):\n                parent1 = parents[np.random.randint(0, len(parents))]\n                parent2 = parents[np.random.randint(0, len(parents))]\n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child, func)\n\n                f = func(child)\n                eval_count += 1\n\n                new_population.append(child)\n                new_fitness.append(f)\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = child\n\n                if eval_count >= self.budget:\n                    break\n\n            population = np.array(new_population)\n            fitness = np.array(new_fitness)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Population-based algorithm that adapts its search strategy based on the observed performance of individuals, biasing exploration towards promising regions and exploiting local optima.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def mutate(self, individual, func):\n        for i in range(self.dim):\n            if np.random.rand() < self.mutation_rate:\n                individual[i] += np.random.normal(0, 0.1 * (func.bounds.ub - func.bounds.lb)) #mutation step size is proportional to the range of the input variables.\n                individual[i] = np.clip(individual[i], func.bounds.lb, func.bounds.ub)\n        return individual\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim)\n            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        else:\n            child = parent1.copy()  # No crossover\n        return child\n\n    def selection(self, population, fitness, num_parents):\n        indices = np.argsort(fitness)[:num_parents]\n        return population[indices]\n\n    def __call__(self, func):\n        population, fitness = self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluation\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while eval_count < self.budget:\n            # Selection (select best individuals as parents)\n            num_parents = self.pop_size // 2  # Example: select half the population\n            parents = self.selection(population, fitness, num_parents)\n\n            new_population = []\n            new_fitness = []\n\n            # Create new population through crossover and mutation\n            for i in range(self.pop_size):\n                parent1 = parents[np.random.randint(0, len(parents))]\n                parent2 = parents[np.random.randint(0, len(parents))]\n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child, func)\n\n                f = func(child)\n                eval_count += 1\n\n                new_population.append(child)\n                new_fitness.append(f)\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = child\n\n                if eval_count >= self.budget:\n                    break\n\n            population = np.array(new_population)\n            fitness = np.array(new_fitness)\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "7970086a-eac5-4a35-947e-ce57c4e11bf4", "fitness": 0.0, "name": "AdaptiveDE_LS", "description": "A population-based algorithm using a combination of differential evolution and a local search strategy, with adaptive parameter control to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, ls_prob=0.1):\n        \"\"\"\n        Initialize the Adaptive DE with Local Search algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): Differential evolution parameter F (mutation factor).\n            Cr (float): Differential evolution parameter Cr (crossover rate).\n            ls_prob (float): Probability of performing a local search after DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.ls_prob = ls_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the black box function using the Adaptive DE with Local Search algorithm.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        # Find the initial best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                # Local Search (with probability ls_prob)\n                if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                    x_ls = self.local_search(func, population[i], lb, ub)\n                    f_ls = func(x_ls)\n                    self.eval_count += 1\n\n                    if f_ls < fitness[i]:\n                        fitness[i] = f_ls\n                        population[i] = x_ls\n                        if f_ls < self.f_opt:\n                            self.f_opt = f_ls\n                            self.x_opt = x_ls\n\n            # Adaptive parameter control (example: linearly reduce F and Cr)\n            self.F = 0.5 * (1 - self.eval_count / self.budget) + 0.5 # Reduce F over time\n            self.Cr = 0.9 * (1 - self.eval_count / self.budget) + 0.1 # Reduce Cr over time\n\n\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, lb, ub, radius=0.1):\n        \"\"\"\n        Perform a local search around a given solution.\n\n        Args:\n            func (callable): The black box function to optimize.\n            x (np.ndarray): The current solution.\n            lb (np.ndarray): Lower bounds of the search space.\n            ub (np.ndarray): Upper bounds of the search space.\n            radius (float): The radius of the local search.\n\n        Returns:\n            np.ndarray: The improved solution found by local search.\n        \"\"\"\n        x_ls = x.copy()\n        for i in range(self.dim):\n            # Explore both sides of each dimension\n            delta = np.random.uniform(-radius, radius)\n            x_new = np.clip(x_ls[i] + delta, lb[i], ub[i])\n            x_ls[i] = x_new\n        return x_ls", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm using a combination of differential evolution and a local search strategy, with adaptive parameter control to balance exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, ls_prob=0.1):\n        \"\"\"\n        Initialize the Adaptive DE with Local Search algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): Differential evolution parameter F (mutation factor).\n            Cr (float): Differential evolution parameter Cr (crossover rate).\n            ls_prob (float): Probability of performing a local search after DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.ls_prob = ls_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the black box function using the Adaptive DE with Local Search algorithm.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        # Find the initial best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                # Local Search (with probability ls_prob)\n                if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                    x_ls = self.local_search(func, population[i], lb, ub)\n                    f_ls = func(x_ls)\n                    self.eval_count += 1\n\n                    if f_ls < fitness[i]:\n                        fitness[i] = f_ls\n                        population[i] = x_ls\n                        if f_ls < self.f_opt:\n                            self.f_opt = f_ls\n                            self.x_opt = x_ls\n\n            # Adaptive parameter control (example: linearly reduce F and Cr)\n            self.F = 0.5 * (1 - self.eval_count / self.budget) + 0.5 # Reduce F over time\n            self.Cr = 0.9 * (1 - self.eval_count / self.budget) + 0.1 # Reduce Cr over time\n\n\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, lb, ub, radius=0.1):\n        \"\"\"\n        Perform a local search around a given solution.\n\n        Args:\n            func (callable): The black box function to optimize.\n            x (np.ndarray): The current solution.\n            lb (np.ndarray): Lower bounds of the search space.\n            ub (np.ndarray): Upper bounds of the search space.\n            radius (float): The radius of the local search.\n\n        Returns:\n            np.ndarray: The improved solution found by local search.\n        \"\"\"\n        x_ls = x.copy()\n        for i in range(self.dim):\n            # Explore both sides of each dimension\n            delta = np.random.uniform(-radius, radius)\n            x_new = np.clip(x_ls[i] + delta, lb[i], ub[i])\n            x_ls[i] = x_new\n        return x_ls\n```", "aucs": [0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "20643208-96b1-43ab-92ca-cf353c91ffc2", "fitness": 0.32548842623752466, "name": "RepulsiveSwarm", "description": "Population-based search with fitness-based exploration radius and repulsive forces between individuals to encourage diversity.", "code": "import numpy as np\n\nclass RepulsiveSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration radius based on fitness rank.  Better solutions have smaller radii\n                rank = np.argsort(fitness)[i]\n                exploration_radius = (func.bounds.ub - func.bounds.lb) * (rank / self.pop_size)\n                \n                # Generate a candidate solution\n                candidate = population[i] + np.random.uniform(-exploration_radius, exploration_radius, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                # Repulsion from other individuals\n                repulsion_force = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = np.linalg.norm(population[i] - population[j])\n                        if distance > 0:\n                             repulsion_force += (population[i] - population[j]) / (distance**2 + 1e-8) #avoid division by zero\n                \n                candidate = candidate + self.repulsion_factor * repulsion_force\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n\n                f_candidate = func(candidate)\n                self.budget -= 1\n                \n                if f_candidate < fitness[i]:\n                    fitness[i] = f_candidate\n                    population[i] = candidate\n                    \n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm RepulsiveSwarm scored 0.325 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search with fitness-based exploration radius and repulsive forces between individuals to encourage diversity.\n# Code: \n```python\nimport numpy as np\n\nclass RepulsiveSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration radius based on fitness rank.  Better solutions have smaller radii\n                rank = np.argsort(fitness)[i]\n                exploration_radius = (func.bounds.ub - func.bounds.lb) * (rank / self.pop_size)\n                \n                # Generate a candidate solution\n                candidate = population[i] + np.random.uniform(-exploration_radius, exploration_radius, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                # Repulsion from other individuals\n                repulsion_force = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = np.linalg.norm(population[i] - population[j])\n                        if distance > 0:\n                             repulsion_force += (population[i] - population[j]) / (distance**2 + 1e-8) #avoid division by zero\n                \n                candidate = candidate + self.repulsion_factor * repulsion_force\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n\n                f_candidate = func(candidate)\n                self.budget -= 1\n                \n                if f_candidate < fitness[i]:\n                    fitness[i] = f_candidate\n                    population[i] = candidate\n                    \n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0.13702819948206746, 0.24305788635322068, 0.29895324520322697, 0.28397740919065817, 0.2374023288379007, 0.305695291934196, 0.25563176809767163, 0.27024937334250776, 0.2326477901440165, 0.17495487648984176, 0.2879000231710185, 0.9951736481558965, 0.28636688973387925, 0.25391108594883705, 0.6889493121344149, 0.31132531642886063, 0.26793970531128997, 0.33657926862425924, 0.16576418398654602, 0.476260922180183], "operator": "random_new", "theta_sampled": 0.20531823364794174, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "4fbef25f-b698-424e-98c6-92e70076f23a", "fitness": 0.6122032360875312, "name": "CMAESOrthogonal", "description": "Covariance Matrix Adaptation Evolution Strategy with orthogonal sampling for improved exploration and exploitation.", "code": "import numpy as np\n\nclass CMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMAESOrthogonal scored 0.612 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with orthogonal sampling for improved exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass CMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2608604152466527, 0.18516439210796054, 0.9265533424606824, 0.19922231168022986, 0.9410099113694039, 0.9465875486611633, 0.31056264117282506, 0.9267127349898766, 0.9333569223015681, 0.15911833921607033, 0.9677126276138018, 0.9999359380724192, 0.25308232600111014, 0.9341951735851033, 0.8699580664524678, 0.753076215354355, 0.42714972070262325, 0.9564594772630043, 0.09240267867725338, 0.2009439388220553], "operator": "random_new", "theta_sampled": 0.3723624517718154, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "8d120809-48bb-4556-9403-7262994a14df", "fitness": 0.365941657749529, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with jittering and archive-based mutation to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9 # Initial crossover rate\n        self.archive = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n\n        # Evaluate initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, size=2, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, size=2, replace=False)\n\n                x_r1, x_r2 = population[indices]\n\n                # Use archive if available\n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance to use archive\n                    x_r3 = self.archive[np.random.randint(0, len(self.archive))]\n                else:\n                    index3 = np.random.randint(0, self.pop_size)\n                    while index3 == i or index3 in indices:\n                        index3 = np.random.randint(0, self.pop_size)\n                    x_r3 = population[index3]\n\n                # Jittering\n                F_current = self.F * (0.5 + np.random.rand() * 0.5) # Jitter F\n                mutant = population[i] + F_current * (x_r1 - x_r2)  # DE/rand/1 mutation\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    successful_mutations += 1\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(0, self.archive_size)] = population[i].copy()\n\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n\n            # Adapt F based on success rate and generation\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n            # Adapt CR\n            self.CR = 0.9 * np.exp(-generation / 100)  # Reduce CR over time\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.366 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0c937d38-010c-458a-a121-a7e35c8db411"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with jittering and archive-based mutation to enhance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9 # Initial crossover rate\n        self.archive = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n\n        # Evaluate initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, size=2, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, size=2, replace=False)\n\n                x_r1, x_r2 = population[indices]\n\n                # Use archive if available\n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance to use archive\n                    x_r3 = self.archive[np.random.randint(0, len(self.archive))]\n                else:\n                    index3 = np.random.randint(0, self.pop_size)\n                    while index3 == i or index3 in indices:\n                        index3 = np.random.randint(0, self.pop_size)\n                    x_r3 = population[index3]\n\n                # Jittering\n                F_current = self.F * (0.5 + np.random.rand() * 0.5) # Jitter F\n                mutant = population[i] + F_current * (x_r1 - x_r2)  # DE/rand/1 mutation\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    successful_mutations += 1\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(0, self.archive_size)] = population[i].copy()\n\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n\n            # Adapt F based on success rate and generation\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n            # Adapt CR\n            self.CR = 0.9 * np.exp(-generation / 100)  # Reduce CR over time\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13862312306638547, 0.24136698243505883, 0.4020925693397126, 0.3394387825685633, 0.28806244796140446, 0.36000418317982386, 0.2622836110833138, 0.32797382283872045, 0.2837271207777535, 0.19083813213531575, 0.42660976166052056, 0.9966339241171179, 0.3409594532575827, 0.23597467327514066, 0.7280207046064168, 0.32508528510330326, 0.3054813687925534, 0.44859213365117667, 0.18945074166976772, 0.48761433347094874], "operator": "mutation", "theta_sampled": 0.1724198036776807, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "bfad18ae-f787-44d1-9bd1-2e05d4744371", "fitness": 0.0, "name": "ClusteringAdaptiveES", "description": "Population-based algorithm with clustering and adaptive step size control, focusing on exploration and exploitation of promising regions.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass ClusteringAdaptiveES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, num_clusters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_clusters = num_clusters\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = 100\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        # Main loop\n        while self.budget > 0:\n            # Clustering\n            kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init='auto').fit(population)\n            clusters = [population[kmeans.labels_ == i] for i in range(self.num_clusters)]\n            cluster_fitness = [fitness[kmeans.labels_ == i] for i in range(self.num_clusters)]\n\n            # Adaptive step size control\n            step_sizes = np.zeros(self.num_clusters)\n            for i in range(self.num_clusters):\n                if len(cluster_fitness[i]) > 1:\n                    step_sizes[i] = np.std(cluster_fitness[i])\n                else:\n                    step_sizes[i] = 0.1  # Default step size\n\n            # Generate offspring\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Select parent cluster based on fitness\n                cluster_index = np.argmin([np.mean(f) if len(f) > 0 else np.inf for f in cluster_fitness])\n\n                # Select a parent from the selected cluster\n                if len(clusters[cluster_index]) > 0:\n                    parent = clusters[cluster_index][np.random.randint(len(clusters[cluster_index]))]\n                else:\n                    parent = np.random.uniform(self.lb, self.ub, self.dim)\n\n\n                # Mutation\n                mutation = np.random.normal(0, step_sizes[cluster_index], self.dim)\n                child = parent + mutation\n                child = np.clip(child, self.lb, self.ub)\n\n                # Evaluation\n                offspring[i] = child\n                offspring_fitness[i] = func(child)\n                self.budget -= 1\n\n                # Update Archive\n                self.archive_x.append(child)\n                self.archive_f.append(offspring_fitness[i])\n\n                if len(self.archive_x) > self.archive_size:\n                    self.archive_x.pop(0)\n                    self.archive_f.pop(0)\n\n\n                if offspring_fitness[i] < self.f_opt:\n                    self.f_opt = offspring_fitness[i]\n                    self.x_opt = child\n\n                if self.budget <= 0:\n                    break\n\n            # Selection (replace worst individuals in population)\n            worst_indices = np.argsort(fitness)[-self.pop_size//2:]\n            population[worst_indices] = offspring[:self.pop_size//2]\n            fitness[worst_indices] = offspring_fitness[:self.pop_size//2]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: name 'KMeans' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with clustering and adaptive step size control, focusing on exploration and exploitation of promising regions.\n# Code: \n```python\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass ClusteringAdaptiveES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, num_clusters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_clusters = num_clusters\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = 100\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        # Main loop\n        while self.budget > 0:\n            # Clustering\n            kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init='auto').fit(population)\n            clusters = [population[kmeans.labels_ == i] for i in range(self.num_clusters)]\n            cluster_fitness = [fitness[kmeans.labels_ == i] for i in range(self.num_clusters)]\n\n            # Adaptive step size control\n            step_sizes = np.zeros(self.num_clusters)\n            for i in range(self.num_clusters):\n                if len(cluster_fitness[i]) > 1:\n                    step_sizes[i] = np.std(cluster_fitness[i])\n                else:\n                    step_sizes[i] = 0.1  # Default step size\n\n            # Generate offspring\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Select parent cluster based on fitness\n                cluster_index = np.argmin([np.mean(f) if len(f) > 0 else np.inf for f in cluster_fitness])\n\n                # Select a parent from the selected cluster\n                if len(clusters[cluster_index]) > 0:\n                    parent = clusters[cluster_index][np.random.randint(len(clusters[cluster_index]))]\n                else:\n                    parent = np.random.uniform(self.lb, self.ub, self.dim)\n\n\n                # Mutation\n                mutation = np.random.normal(0, step_sizes[cluster_index], self.dim)\n                child = parent + mutation\n                child = np.clip(child, self.lb, self.ub)\n\n                # Evaluation\n                offspring[i] = child\n                offspring_fitness[i] = func(child)\n                self.budget -= 1\n\n                # Update Archive\n                self.archive_x.append(child)\n                self.archive_f.append(offspring_fitness[i])\n\n                if len(self.archive_x) > self.archive_size:\n                    self.archive_x.pop(0)\n                    self.archive_f.pop(0)\n\n\n                if offspring_fitness[i] < self.f_opt:\n                    self.f_opt = offspring_fitness[i]\n                    self.x_opt = child\n\n                if self.budget <= 0:\n                    break\n\n            # Selection (replace worst individuals in population)\n            worst_indices = np.argsort(fitness)[-self.pop_size//2:]\n            population[worst_indices] = offspring[:self.pop_size//2]\n            fitness[worst_indices] = offspring_fitness[:self.pop_size//2]\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.2878454924353026, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "751e6e85-9b13-4bdd-83a2-059ee8160910", "fitness": 0.5479271205702154, "name": "AdaptiveDEHybrid", "description": "Adaptive Differential Evolution with Archive and stochastic ranking, dynamically adapting F and CR parameters based on success rate.", "code": "import numpy as np\n\nclass AdaptiveDEHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        successful_mutations = 0\n\n        while self.budget > 0:\n            generation += 1\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                x_trial = np.where(cross_points, x_mutated, self.population[i])\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Adapt F and CR based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 0.95 # Reduce CR\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 1.05 # Increase CR\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDEHybrid scored 0.548 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "0c937d38-010c-458a-a121-a7e35c8db411"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Archive and stochastic ranking, dynamically adapting F and CR parameters based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        successful_mutations = 0\n\n        while self.budget > 0:\n            generation += 1\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                x_trial = np.where(cross_points, x_mutated, self.population[i])\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Adapt F and CR based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 0.95 # Reduce CR\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 1.05 # Increase CR\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2762818011805004, 0.5617209941674988, 0.3948411043494331, 0.8129901528715564, 0.5277177607562136, 0.6743462891220464, 0.3983671520748647, 0.4485553744346654, 0.6073021146158907, 0.5310632976952638, 0.557742462742342, 0.9968170562909282, 0.5051049430354544, 0.49206345750732094, 0.7665851872185265, 0.4005198010325496, 0.4199734136589971, 0.6248186440198243, 0.464093789667271, 0.49763761496316217], "operator": "crossover", "theta_sampled": 0.3493782462904422, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "837454d2-6bec-4bb0-b9f9-f3c47d0680b4", "fitness": 0.0, "name": "AdaptiveDE_LS_NM", "description": "Adaptive Differential Evolution with a more sophisticated local search (Nelder-Mead Simplex) to refine promising solutions and adaptive population sizing based on the optimization progress.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_LS_NM:\n    def __init__(self, budget=10000, dim=10, pop_size_min=10, pop_size_max=50, F=0.5, Cr=0.9, ls_prob=0.1):\n        \"\"\"\n        Initialize the Adaptive DE with Nelder-Mead Local Search and Adaptive Population Size algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_min (int): Minimum population size.\n            pop_size_max (int): Maximum population size.\n            F (float): Differential evolution parameter F (mutation factor).\n            Cr (float): Differential evolution parameter Cr (crossover rate).\n            ls_prob (float): Probability of performing a local search after DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.F = F\n        self.Cr = Cr\n        self.ls_prob = ls_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.pop_size = self.pop_size_max # Initial population size\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the black box function using the Adaptive DE with Local Search algorithm.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        # Find the initial best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adjust population size\n            progress = self.eval_count / self.budget\n            self.pop_size = int(self.pop_size_max - (self.pop_size_max - self.pop_size_min) * progress)\n            if self.pop_size < self.pop_size_min:\n                self.pop_size = self.pop_size_min\n\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                # Local Search (with probability ls_prob)\n                if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                    x_ls = self.local_search(func, population[i], lb, ub)\n                    f_ls = func(x_ls)\n                    self.eval_count += 1\n\n                    if f_ls < fitness[i]:\n                        fitness[i] = f_ls\n                        population[i] = x_ls\n                        if f_ls < self.f_opt:\n                            self.f_opt = f_ls\n                            self.x_opt = x_ls\n\n            # Adaptive parameter control (example: linearly reduce F and Cr)\n            self.F = 0.5 * (1 - self.eval_count / self.budget) + 0.5 # Reduce F over time\n            self.Cr = 0.9 * (1 - self.eval_count / self.budget) + 0.1 # Reduce Cr over time\n\n\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, lb, ub):\n        \"\"\"\n        Perform a local search around a given solution using Nelder-Mead.\n\n        Args:\n            func (callable): The black box function to optimize.\n            x (np.ndarray): The current solution.\n            lb (np.ndarray): Lower bounds of the search space.\n            ub (np.ndarray): Upper bounds of the search space.\n\n        Returns:\n            np.ndarray: The improved solution found by local search.\n        \"\"\"\n\n        bounds = [(lb[i], ub[i]) for i in range(self.dim)]\n        res = minimize(func, x, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(50, self.budget - self.eval_count)})  # Limit FE calls\n        self.eval_count += res.nfev\n        return res.x", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["7970086a-eac5-4a35-947e-ce57c4e11bf4"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with a more sophisticated local search (Nelder-Mead Simplex) to refine promising solutions and adaptive population sizing based on the optimization progress.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_LS_NM:\n    def __init__(self, budget=10000, dim=10, pop_size_min=10, pop_size_max=50, F=0.5, Cr=0.9, ls_prob=0.1):\n        \"\"\"\n        Initialize the Adaptive DE with Nelder-Mead Local Search and Adaptive Population Size algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_min (int): Minimum population size.\n            pop_size_max (int): Maximum population size.\n            F (float): Differential evolution parameter F (mutation factor).\n            Cr (float): Differential evolution parameter Cr (crossover rate).\n            ls_prob (float): Probability of performing a local search after DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.F = F\n        self.Cr = Cr\n        self.ls_prob = ls_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.pop_size = self.pop_size_max # Initial population size\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the black box function using the Adaptive DE with Local Search algorithm.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        # Find the initial best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adjust population size\n            progress = self.eval_count / self.budget\n            self.pop_size = int(self.pop_size_max - (self.pop_size_max - self.pop_size_min) * progress)\n            if self.pop_size < self.pop_size_min:\n                self.pop_size = self.pop_size_min\n\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                # Local Search (with probability ls_prob)\n                if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                    x_ls = self.local_search(func, population[i], lb, ub)\n                    f_ls = func(x_ls)\n                    self.eval_count += 1\n\n                    if f_ls < fitness[i]:\n                        fitness[i] = f_ls\n                        population[i] = x_ls\n                        if f_ls < self.f_opt:\n                            self.f_opt = f_ls\n                            self.x_opt = x_ls\n\n            # Adaptive parameter control (example: linearly reduce F and Cr)\n            self.F = 0.5 * (1 - self.eval_count / self.budget) + 0.5 # Reduce F over time\n            self.Cr = 0.9 * (1 - self.eval_count / self.budget) + 0.1 # Reduce Cr over time\n\n\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, lb, ub):\n        \"\"\"\n        Perform a local search around a given solution using Nelder-Mead.\n\n        Args:\n            func (callable): The black box function to optimize.\n            x (np.ndarray): The current solution.\n            lb (np.ndarray): Lower bounds of the search space.\n            ub (np.ndarray): Upper bounds of the search space.\n\n        Returns:\n            np.ndarray: The improved solution found by local search.\n        \"\"\"\n\n        bounds = [(lb[i], ub[i]) for i in range(self.dim)]\n        res = minimize(func, x, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(50, self.budget - self.eval_count)})  # Limit FE calls\n        self.eval_count += res.nfev\n        return res.x\n```", "operator": "mutation", "theta_sampled": 0.47725896083059605, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "6c3b1d96-e4f5-484d-9ed8-9df6ee1f6a93", "fitness": 0.0, "name": "RingTopologyEvolutionaryAlgorithm", "description": "A population-based algorithm with a ring topology and a selection mechanism biased towards better solutions, combined with a local search operator.", "code": "import numpy as np\n\nclass RingTopologyEvolutionaryAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, ls_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.ls_trials = ls_trials\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n    def local_search(self, x, func):\n        x_best = x\n        f_best = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.ls_trials):\n            x_new = x + np.random.normal(0, self.lr, self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            if f_new < f_best:\n                f_best = f_new\n                x_best = x_new\n\n        return f_best, x_best\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Ring topology selection: select a neighbor\n                neighbor_index = (i + 1) % self.pop_size\n\n                # Biased selection: favor the better solution\n                if self.fitness[i] < self.fitness[neighbor_index]:\n                    parent = self.population[i]\n                else:\n                    parent = self.population[neighbor_index]\n\n                # Mutation/Crossover: create an offspring\n                offspring = self.population[i] + self.lr * (parent - self.population[i]) + np.random.normal(0, self.lr, self.dim)\n                offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n                #Local Search\n                f_offspring, offspring = self.local_search(offspring, func)\n                \n                if self.eval_count >= self.budget:\n                    break\n\n                # Replacement: replace the current individual if the offspring is better\n                if f_offspring < self.fitness[i]:\n                    self.fitness[i] = f_offspring\n                    self.population[i] = offspring\n                    \n                    if f_offspring < self.f_opt:\n                        self.f_opt = f_offspring\n                        self.x_opt = offspring\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm RingTopologyEvolutionaryAlgorithm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with a ring topology and a selection mechanism biased towards better solutions, combined with a local search operator.\n# Code: \n```python\nimport numpy as np\n\nclass RingTopologyEvolutionaryAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, ls_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.ls_trials = ls_trials\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n    def local_search(self, x, func):\n        x_best = x\n        f_best = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.ls_trials):\n            x_new = x + np.random.normal(0, self.lr, self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            if f_new < f_best:\n                f_best = f_new\n                x_best = x_new\n\n        return f_best, x_best\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Ring topology selection: select a neighbor\n                neighbor_index = (i + 1) % self.pop_size\n\n                # Biased selection: favor the better solution\n                if self.fitness[i] < self.fitness[neighbor_index]:\n                    parent = self.population[i]\n                else:\n                    parent = self.population[neighbor_index]\n\n                # Mutation/Crossover: create an offspring\n                offspring = self.population[i] + self.lr * (parent - self.population[i]) + np.random.normal(0, self.lr, self.dim)\n                offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n                #Local Search\n                f_offspring, offspring = self.local_search(offspring, func)\n                \n                if self.eval_count >= self.budget:\n                    break\n\n                # Replacement: replace the current individual if the offspring is better\n                if f_offspring < self.fitness[i]:\n                    self.fitness[i] = f_offspring\n                    self.population[i] = offspring\n                    \n                    if f_offspring < self.f_opt:\n                        self.f_opt = f_offspring\n                        self.x_opt = offspring\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.2930484955017968, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "750de0ce-63d3-4e9f-8b94-e4ac7e14e9f6", "fitness": 0.3301453912941619, "name": "AdaptiveDEHybrid", "description": "An adaptive Differential Evolution algorithm that combines archive-based exploration with dynamic parameter adaptation and stochastic ranking for improved performance.", "code": "import numpy as np\n\nclass AdaptiveDEHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor - can be adaptive\n        self.CR = 0.9 # Crossover rate - can be adaptive\n        self.archive = []\n        self.archive_fitness = []\n        self.success_history_F = []\n        self.success_history_CR = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Adapt F and CR\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 1.1\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 0.9\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDEHybrid scored 0.330 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "0c937d38-010c-458a-a121-a7e35c8db411"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution algorithm that combines archive-based exploration with dynamic parameter adaptation and stochastic ranking for improved performance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor - can be adaptive\n        self.CR = 0.9 # Crossover rate - can be adaptive\n        self.archive = []\n        self.archive_fitness = []\n        self.success_history_F = []\n        self.success_history_CR = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Adapt F and CR\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 1.1\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 0.9\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1895626980478805, 0.2112700705749846, 0.3070108305916289, 0.3003894123860452, 0.22021679129373284, 0.2503715645939043, 0.2749837868380025, 0.2581026193454391, 0.27270396741669256, 0.21184314074785993, 0.287590942320162, 0.9917526294375627, 0.32054814340009374, 0.2871009378181695, 0.5208579177914736, 0.322439071633431, 0.28101949780616997, 0.4329547534929489, 0.2038604292299988, 0.45832862111705786], "operator": "crossover", "theta_sampled": 0.23507536751978828, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "fa8e833b-4d2b-4d9b-a595-0b5921398479", "fitness": 0.3983245266668709, "name": "AdaptiveDEHybridOrtho", "description": "Adaptive Differential Evolution with a self-adjusting archive and orthogonal crossover strategies.", "code": "import numpy as np\n\nclass AdaptiveDEHybridOrtho:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, ortho_groups=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.ortho_groups = ortho_groups if ortho_groups is not None else int(np.sqrt(dim)) # Adaptive Orthogonal Crossover\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        successful_mutations = 0\n\n        while self.budget > 0:\n            generation += 1\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                x_trial = np.copy(self.population[i])\n                \n                # Divide dimensions into groups for orthogonal crossover\n                group_size = self.dim // self.ortho_groups\n                for group in range(self.ortho_groups):\n                    start = group * group_size\n                    end = (group + 1) * group_size if group < self.ortho_groups - 1 else self.dim\n                    \n                    if np.random.rand() < self.CR:  # Apply crossover with probability CR\n                        x_trial[start:end] = x_mutated[start:end]\n                \n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution if worse than current solution\n                            if self.fitness[i] < np.max(self.archive_fitness):\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution if worse than current solution\n                            if self.fitness[i] < np.max(self.archive_fitness):\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Adapt F and CR based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 0.95 # Reduce CR\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 1.05 # Increase CR\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            #Adaptive archive size. If the success rate is very low, reduce archive size\n            if success_rate < 0.05 and self.archive_size > 1:\n              self.archive_size = int(self.archive_size * 0.9)\n              if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n                self.archive_fitness = self.archive_fitness[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDEHybridOrtho scored 0.398 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["751e6e85-9b13-4bdd-83a2-059ee8160910"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with a self-adjusting archive and orthogonal crossover strategies.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDEHybridOrtho:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, ortho_groups=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.ortho_groups = ortho_groups if ortho_groups is not None else int(np.sqrt(dim)) # Adaptive Orthogonal Crossover\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        successful_mutations = 0\n\n        while self.budget > 0:\n            generation += 1\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                x_trial = np.copy(self.population[i])\n                \n                # Divide dimensions into groups for orthogonal crossover\n                group_size = self.dim // self.ortho_groups\n                for group in range(self.ortho_groups):\n                    start = group * group_size\n                    end = (group + 1) * group_size if group < self.ortho_groups - 1 else self.dim\n                    \n                    if np.random.rand() < self.CR:  # Apply crossover with probability CR\n                        x_trial[start:end] = x_mutated[start:end]\n                \n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution if worse than current solution\n                            if self.fitness[i] < np.max(self.archive_fitness):\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        successful_mutations += 1\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution if worse than current solution\n                            if self.fitness[i] < np.max(self.archive_fitness):\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Adapt F and CR based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 0.95 # Reduce CR\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 1.05 # Increase CR\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            #Adaptive archive size. If the success rate is very low, reduce archive size\n            if success_rate < 0.05 and self.archive_size > 1:\n              self.archive_size = int(self.archive_size * 0.9)\n              if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n                self.archive_fitness = self.archive_fitness[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19613983811535174, 0.30409717631899735, 0.3585139924130558, 0.474807243418641, 0.35929808751814063, 0.34715400292764564, 0.32220363504738003, 0.29852906327653894, 0.39909218627631193, 0.20390580874121456, 0.3772199234286219, 0.9979538236064514, 0.2983029416764873, 0.35124755369184546, 0.7011489260618133, 0.5561559209596965, 0.3023466680209287, 0.39759612915789244, 0.23349650474019057, 0.48728110794021284], "operator": "mutation", "theta_sampled": 0.27943883659295354, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "76e9ce8e-bbab-45c4-a73c-3dba58fa7927", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "Adaptively adjusts the covariance matrix and step size using a rank-one update based on successful steps, combined with a population-weighted recombination and dynamic population size adjustment.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, cs=0.1, cc=0.1, c1=0.1, cmu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.cc = cc\n        self.c1 = c1\n        self.cmu = cmu\n\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        used_budget = 0\n        \n        archive_x = []\n        archive_f = []\n\n        while used_budget < self.budget:\n            # Sample population\n            z = np.random.randn(self.popsize, self.dim)\n            x = self.m + self.sigma * (z @ np.linalg.cholesky(self.C).T)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            archive_x.extend(x)\n            archive_f.extend(f)\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            zmean = (xmean - self.m) / self.sigma\n            \n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * zmean\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :])\n            self.C += self.cmu * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.cs / self.dim) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n\n            # Keep C positive definite\n            try:\n                _ = np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)  # Regularize\n\n            # Adaptive Population Size\n            if used_budget < self.budget / 2:\n                if len(archive_f) > 10 * self.dim:\n                    std_dev = np.std(archive_f[-10*self.dim:])\n                    if std_dev < 1e-6:\n                        self.popsize = min(self.popsize + 2, int(10 + 4*np.log(self.dim)))  # Increase if converging\n                    elif std_dev > 1e-3:\n                        self.popsize = max(4 + int(3*np.log(self.dim)), self.popsize - 1) # decrease popsize if not converging\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4fbef25f-b698-424e-98c6-92e70076f23a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively adjusts the covariance matrix and step size using a rank-one update based on successful steps, combined with a population-weighted recombination and dynamic population size adjustment.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, cs=0.1, cc=0.1, c1=0.1, cmu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.cc = cc\n        self.c1 = c1\n        self.cmu = cmu\n\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        used_budget = 0\n        \n        archive_x = []\n        archive_f = []\n\n        while used_budget < self.budget:\n            # Sample population\n            z = np.random.randn(self.popsize, self.dim)\n            x = self.m + self.sigma * (z @ np.linalg.cholesky(self.C).T)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            archive_x.extend(x)\n            archive_f.extend(f)\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            zmean = (xmean - self.m) / self.sigma\n            \n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * zmean\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :])\n            self.C += self.cmu * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.cs / self.dim) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n\n            # Keep C positive definite\n            try:\n                _ = np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)  # Regularize\n\n            # Adaptive Population Size\n            if used_budget < self.budget / 2:\n                if len(archive_f) > 10 * self.dim:\n                    std_dev = np.std(archive_f[-10*self.dim:])\n                    if std_dev < 1e-6:\n                        self.popsize = min(self.popsize + 2, int(10 + 4*np.log(self.dim)))  # Increase if converging\n                    elif std_dev > 1e-3:\n                        self.popsize = max(4 + int(3*np.log(self.dim)), self.popsize - 1) # decrease popsize if not converging\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.09791901120153668, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "c9fd65bb-fe16-4639-821a-c5ba91b784ea", "fitness": 0.21371447609909405, "name": "AdaptiveCrossoverMutation", "description": "Population-based algorithm using a combination of crossover and mutation operators, dynamically adjusting its parameters based on success rate.", "code": "import numpy as np\n\nclass AdaptiveCrossoverMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = 0.5  # Initial crossover rate\n        self.mut = 0.1 # Initial mutation rate\n        self.cr_learn_rate = 0.1\n        self.mut_learn_rate = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Generate offspring\n            offspring = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Crossover\n                j = np.random.randint(self.pop_size)\n                offspring[i] = population[i].copy()\n                if np.random.rand() < self.cr:\n                    offspring[i] = population[j].copy()  # Crossover with random individual\n\n                # Mutation\n                mutation_indices = np.random.choice(self.dim, size=int(self.mut * self.dim), replace=False)\n                offspring[i, mutation_indices] += np.random.normal(0, 0.1, size=len(mutation_indices)) # Mutate with small gaussian noise\n\n                # Clip to bounds\n                offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Selection\n            successful_cr = 0\n            successful_mut = 0\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    fitness[i] = offspring_fitness[i]\n                    population[i] = offspring[i]\n                    successful_cr += 1\n                    successful_mut += 1\n\n            # Update optimal solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Adjust parameters\n            success_rate_cr = successful_cr / self.pop_size\n            success_rate_mut = successful_mut / self.pop_size\n            self.cr = self.cr + self.cr_learn_rate * (success_rate_cr - 0.5)\n            self.mut = self.mut + self.mut_learn_rate * (success_rate_mut-0.5)\n            self.cr = np.clip(self.cr, 0.1, 0.9)\n            self.mut = np.clip(self.mut, 0.01, 0.5)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCrossoverMutation scored 0.214 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of crossover and mutation operators, dynamically adjusting its parameters based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCrossoverMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = 0.5  # Initial crossover rate\n        self.mut = 0.1 # Initial mutation rate\n        self.cr_learn_rate = 0.1\n        self.mut_learn_rate = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Generate offspring\n            offspring = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Crossover\n                j = np.random.randint(self.pop_size)\n                offspring[i] = population[i].copy()\n                if np.random.rand() < self.cr:\n                    offspring[i] = population[j].copy()  # Crossover with random individual\n\n                # Mutation\n                mutation_indices = np.random.choice(self.dim, size=int(self.mut * self.dim), replace=False)\n                offspring[i, mutation_indices] += np.random.normal(0, 0.1, size=len(mutation_indices)) # Mutate with small gaussian noise\n\n                # Clip to bounds\n                offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Selection\n            successful_cr = 0\n            successful_mut = 0\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    fitness[i] = offspring_fitness[i]\n                    population[i] = offspring[i]\n                    successful_cr += 1\n                    successful_mut += 1\n\n            # Update optimal solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Adjust parameters\n            success_rate_cr = successful_cr / self.pop_size\n            success_rate_mut = successful_mut / self.pop_size\n            self.cr = self.cr + self.cr_learn_rate * (success_rate_cr - 0.5)\n            self.mut = self.mut + self.mut_learn_rate * (success_rate_mut-0.5)\n            self.cr = np.clip(self.cr, 0.1, 0.9)\n            self.mut = np.clip(self.mut, 0.01, 0.5)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07000177967548116, 0.1262287841695412, 0.2471548689463633, 0.15541484255561722, 0.14172878479801143, 0.16914800214495973, 0.18022017225814435, 0.20202558409868587, 0.16038447538933465, 0.12920611252034864, 0.16352449695723137, 0.9993465998579664, 0.07770358321457971, 0.192528600031037, 0.1426759400491232, 0.2168231891730622, 0.18179535720595974, 0.17753121514288672, 0.12055321543126296, 0.4202939183622847], "operator": "random_new", "theta_sampled": 0.05258666589584924, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "994324dc-3c95-4a31-86b2-2b8a7592fdea", "fitness": 0.05852707165746035, "name": "JumpingParticles", "description": "Population-based search using a combination of local search and random jumps, adaptively adjusting jump sizes based on success rate.", "code": "import numpy as np\n\nclass JumpingParticles:\n    def __init__(self, budget=10000, dim=10, pop_size=20, jump_prob=0.1, initial_jump_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.jump_prob = jump_prob\n        self.initial_jump_size = initial_jump_size\n        self.positions = None\n        self.fitness = None\n        self.jump_size = np.full(pop_size, initial_jump_size)\n        self.success_rate = np.zeros(pop_size)\n        self.success_history = [[] for _ in range(pop_size)]\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self):\n        self.positions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.positions[i])\n\n    def local_search(self, func, index):\n        x = self.positions[index].copy()\n        f = self.fitness[index]\n        for _ in range(3):  # Perform a few local steps\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n            step_size = np.random.uniform(0, self.jump_size[index])\n            new_x = x + step_size * direction\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n\n            if new_f < f:\n                x = new_x\n                f = new_f\n                self.positions[index] = x\n                self.fitness[index] = f\n                self.success_history[index].append(1)\n            else:\n                 self.success_history[index].append(0)\n\n    def random_jump(self, index):\n        new_position = np.random.uniform(self.lb, self.ub)\n        self.positions[index] = new_position\n        return new_position\n\n    def update_jump_size(self, index):\n        history = self.success_history[index]\n        if len(history) > 20:\n            recent_success_rate = np.mean(history[-20:])\n            if recent_success_rate > 0.6:\n                self.jump_size[index] *= 1.1  # Increase jump size if successful\n            elif recent_success_rate < 0.2:\n                self.jump_size[index] *= 0.9  # Decrease jump size if unsuccessful\n            self.jump_size[index] = np.clip(self.jump_size[index], 0.01, 1.0)  # Clamp\n            \n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population()\n        self.evaluate_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                if np.random.rand() < self.jump_prob:\n                    x = self.random_jump(i)\n                    f = func(x)\n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.success_history[i].append(1)\n                    else:\n                        self.success_history[i].append(0)\n                    eval_count += 1\n                else:\n                    self.local_search(func, i)\n                    eval_count += 3 #Approximate\n\n                self.update_jump_size(i)\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.positions[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm JumpingParticles scored 0.059 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search using a combination of local search and random jumps, adaptively adjusting jump sizes based on success rate.\n# Code:\n```python\nimport numpy as np\n\nclass JumpingParticles:\n    def __init__(self, budget=10000, dim=10, pop_size=20, jump_prob=0.1, initial_jump_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.jump_prob = jump_prob\n        self.initial_jump_size = initial_jump_size\n        self.positions = None\n        self.fitness = None\n        self.jump_size = np.full(pop_size, initial_jump_size)\n        self.success_rate = np.zeros(pop_size)\n        self.success_history = [[] for _ in range(pop_size)]\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self):\n        self.positions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.positions[i])\n\n    def local_search(self, func, index):\n        x = self.positions[index].copy()\n        f = self.fitness[index]\n        for _ in range(3):  # Perform a few local steps\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n            step_size = np.random.uniform(0, self.jump_size[index])\n            new_x = x + step_size * direction\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n\n            if new_f < f:\n                x = new_x\n                f = new_f\n                self.positions[index] = x\n                self.fitness[index] = f\n                self.success_history[index].append(1)\n            else:\n                 self.success_history[index].append(0)\n\n    def random_jump(self, index):\n        new_position = np.random.uniform(self.lb, self.ub)\n        self.positions[index] = new_position\n        return new_position\n\n    def update_jump_size(self, index):\n        history = self.success_history[index]\n        if len(history) > 20:\n            recent_success_rate = np.mean(history[-20:])\n            if recent_success_rate > 0.6:\n                self.jump_size[index] *= 1.1  # Increase jump size if successful\n            elif recent_success_rate < 0.2:\n                self.jump_size[index] *= 0.9  # Decrease jump size if unsuccessful\n            self.jump_size[index] = np.clip(self.jump_size[index], 0.01, 1.0)  # Clamp\n            \n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population()\n        self.evaluate_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                if np.random.rand() < self.jump_prob:\n                    x = self.random_jump(i)\n                    f = func(x)\n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.success_history[i].append(1)\n                    else:\n                        self.success_history[i].append(0)\n                    eval_count += 1\n                else:\n                    self.local_search(func, i)\n                    eval_count += 3 #Approximate\n\n                self.update_jump_size(i)\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.positions[i]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1170541433149207, 0], "operator": "random_new", "theta_sampled": 0.26899858144380784, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "25154dd1-0a12-4bd0-a671-0b8ddaeac0ed", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "An adaptive covariance matrix adaptation evolution strategy with a population-based approach, dynamically adjusting parameters based on the fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))  # default from CMA-ES\n        else:\n            self.popsize = popsize\n\n        self.mu = self.popsize // 2  # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialization\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        invCsqrt = np.eye(self.dim) # Initial Identity matrix\n        B = np.eye(self.dim) # rotation matrix\n        D = np.ones(self.dim)\n        \n        used_budget = 0\n        while used_budget < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            y = B @ (D * z)\n            x = mean[:, np.newaxis] + sigma * y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub) # Clip to bounds\n            \n            fitness = np.array([func(xi) for xi in x.T])\n            used_budget += self.popsize\n\n            # Sort offspring by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[:, idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0].copy() # make a copy\n            \n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights * x[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y_mean = np.mean(y[:, :self.mu], axis=1) # weighted mean already included in definition of weights\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (B @ y_mean)\n            \n            \n            hsig = (np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**(2 * used_budget / self.popsize)) / self.chiN) < (1.4 + 2/(self.dim + 1))\n            \n            pc = (1-self.damps) * pc + hsig * np.sqrt(self.damps * (2 - self.damps) * self.mueff) * (mean - mean_old) / sigma\n            \n\n            # Update covariance matrix\n            C = (1 - self.cs) * C + self.cs * (pc[:, np.newaxis] @ pc[np.newaxis, :])\n            \n            # Adapt step size sigma\n            sigma *= np.exp(min(0.5, (np.linalg.norm(ps) / self.chiN - 1) * self.cs / self.damps ))\n\n            # Update B and D from covariance matrix C\n            if used_budget % (self.popsize * 10) == 0: # only recompute every N iterations, to save time\n              try:\n                C = np.triu(C) + np.transpose(np.triu(C,1))\n                D, B = np.linalg.eigh(C)\n                D = np.sqrt(D)\n              except:\n                D = np.ones(self.dim)\n                B = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,) (2,6) ", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive covariance matrix adaptation evolution strategy with a population-based approach, dynamically adjusting parameters based on the fitness landscape.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))  # default from CMA-ES\n        else:\n            self.popsize = popsize\n\n        self.mu = self.popsize // 2  # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialization\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        invCsqrt = np.eye(self.dim) # Initial Identity matrix\n        B = np.eye(self.dim) # rotation matrix\n        D = np.ones(self.dim)\n        \n        used_budget = 0\n        while used_budget < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            y = B @ (D * z)\n            x = mean[:, np.newaxis] + sigma * y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub) # Clip to bounds\n            \n            fitness = np.array([func(xi) for xi in x.T])\n            used_budget += self.popsize\n\n            # Sort offspring by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[:, idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0].copy() # make a copy\n            \n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights * x[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y_mean = np.mean(y[:, :self.mu], axis=1) # weighted mean already included in definition of weights\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (B @ y_mean)\n            \n            \n            hsig = (np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**(2 * used_budget / self.popsize)) / self.chiN) < (1.4 + 2/(self.dim + 1))\n            \n            pc = (1-self.damps) * pc + hsig * np.sqrt(self.damps * (2 - self.damps) * self.mueff) * (mean - mean_old) / sigma\n            \n\n            # Update covariance matrix\n            C = (1 - self.cs) * C + self.cs * (pc[:, np.newaxis] @ pc[np.newaxis, :])\n            \n            # Adapt step size sigma\n            sigma *= np.exp(min(0.5, (np.linalg.norm(ps) / self.chiN - 1) * self.cs / self.damps ))\n\n            # Update B and D from covariance matrix C\n            if used_budget % (self.popsize * 10) == 0: # only recompute every N iterations, to save time\n              try:\n                C = np.triu(C) + np.transpose(np.triu(C,1))\n                D, B = np.linalg.eigh(C)\n                D = np.sqrt(D)\n              except:\n                D = np.ones(self.dim)\n                B = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.22519074249077078, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "95aa9c8b-b192-445c-a976-1d8fd944f09c", "fitness": 0.3258467450515067, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with jitter, archive and periodic restarts.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, restart_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.restart_interval = restart_interval # How often to restart the population\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n        self.generation = 0\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Evaluate initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            self.generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, size=3, replace=False)\n\n                x_r1, x_r2, x_r3 = population[indices]\n\n                # Jitter to avoid stagnation\n                jitter = np.random.uniform(-0.05, 0.05, size=self.dim)\n                mutant = population[i] + self.F * (x_r1 - x_r2) + jitter # DE/rand/1 with jitter\n\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    successful_mutations += 1\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        # Replace a random element in the archive\n                        replace_index = np.random.randint(0, self.archive_size)\n                        self.archive[replace_index] = population[i].copy()\n                else:\n                    # If the trial vector is worse, consider adding x_r1, x_r2, x_r3 into the archive\n                    if len(self.archive) < self.archive_size:\n                        for x_r in [x_r1, x_r2, x_r3]:\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(x_r.copy())\n                            else:\n                                break\n                    else:\n                         # Replace a random element in the archive\n                        for x_r in [x_r1, x_r2, x_r3]:\n                            replace_index = np.random.randint(0, self.archive_size)\n                            self.archive[replace_index] = x_r.copy()\n\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Adapt F and CR based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 0.95\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 1.05\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # Restart population periodically\n            if self.generation % self.restart_interval == 0:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.326 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0c937d38-010c-458a-a121-a7e35c8db411"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with jitter, archive and periodic restarts.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, restart_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.restart_interval = restart_interval # How often to restart the population\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n        self.generation = 0\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Evaluate initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            self.generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, size=3, replace=False)\n\n                x_r1, x_r2, x_r3 = population[indices]\n\n                # Jitter to avoid stagnation\n                jitter = np.random.uniform(-0.05, 0.05, size=self.dim)\n                mutant = population[i] + self.F * (x_r1 - x_r2) + jitter # DE/rand/1 with jitter\n\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    successful_mutations += 1\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        # Replace a random element in the archive\n                        replace_index = np.random.randint(0, self.archive_size)\n                        self.archive[replace_index] = population[i].copy()\n                else:\n                    # If the trial vector is worse, consider adding x_r1, x_r2, x_r3 into the archive\n                    if len(self.archive) < self.archive_size:\n                        for x_r in [x_r1, x_r2, x_r3]:\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(x_r.copy())\n                            else:\n                                break\n                    else:\n                         # Replace a random element in the archive\n                        for x_r in [x_r1, x_r2, x_r3]:\n                            replace_index = np.random.randint(0, self.archive_size)\n                            self.archive[replace_index] = x_r.copy()\n\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Adapt F and CR based on success rate\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.F *= 0.9  # Reduce F if too many successful mutations\n                self.CR *= 0.95\n            elif success_rate < 0.1:\n                self.F *= 1.1  # Increase F if too few successful mutations\n                self.CR *= 1.05\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # Restart population periodically\n            if self.generation % self.restart_interval == 0:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.12069540751064611, 0.23724582422876928, 0.34570211216860547, 0.25010071004367596, 0.23369160432126956, 0.29733036075689157, 0.2528598381685946, 0.28824531914736085, 0.2209310199699741, 0.17736119952607987, 0.31204531954379944, 0.9927387410784251, 0.2746846280302575, 0.2586634964036275, 0.6104279805858794, 0.31632032951881717, 0.29920233685098796, 0.3934657824665566, 0.16302225971933837, 0.47220063099057674], "operator": "mutation", "theta_sampled": 0.07492089001052044, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "24bf95ad-715b-4b2a-9c33-474484f2fe3f", "fitness": 0.0, "name": "AdaptiveDE_CMAES", "description": "Hybrid algorithm combining adaptive differential evolution with covariance matrix adaptation using orthogonal sampling to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, cmaes_popsize=None, sigma0=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n        # CMA-ES parameters\n        self.cmaes_popsize = cmaes_popsize if cmaes_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.cmaes_popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.sigma0 = sigma0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # Initialize CMA-ES parameters\n        self.m = self.x_opt.copy()  # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        de_portion = 0.5 #Portion of budget to be used by DE\n        cmaes_portion = 1 - de_portion #Portion of budget to be used by CMAES\n\n        de_budget = int(self.budget * de_portion)\n        cmaes_budget = self.budget - de_budget\n        \n        \n        # Adaptive DE loop\n        while de_budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                de_budget -= 1\n\n                #Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            if de_budget <= 0:\n                break\n\n        # CMA-ES loop\n        used_budget = 0\n        while used_budget < cmaes_budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.cmaes_popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.cmaes_popsize, self.dim))\n            for k in range(self.cmaes_popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(x_i) for x_i in x])\n            used_budget += self.cmaes_popsize\n\n            if used_budget > cmaes_budget:\n                f = f[:(cmaes_budget - (used_budget - self.cmaes_popsize))]\n                x = x[:(cmaes_budget - (used_budget - self.cmaes_popsize))]\n                self.cmaes_popsize = (cmaes_budget - (used_budget - self.cmaes_popsize))\n                used_budget = cmaes_budget\n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.cmaes_popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:, None, None] * (y[:, :, None] @ y[:, None, :]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T  # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C)  # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)  # Regularize\n                L = np.linalg.cholesky(self.C)  # C = LL'\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE_CMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "4fbef25f-b698-424e-98c6-92e70076f23a"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid algorithm combining adaptive differential evolution with covariance matrix adaptation using orthogonal sampling to improve exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, cmaes_popsize=None, sigma0=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n        # CMA-ES parameters\n        self.cmaes_popsize = cmaes_popsize if cmaes_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.cmaes_popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.sigma0 = sigma0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # Initialize CMA-ES parameters\n        self.m = self.x_opt.copy()  # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        de_portion = 0.5 #Portion of budget to be used by DE\n        cmaes_portion = 1 - de_portion #Portion of budget to be used by CMAES\n\n        de_budget = int(self.budget * de_portion)\n        cmaes_budget = self.budget - de_budget\n        \n        \n        # Adaptive DE loop\n        while de_budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                de_budget -= 1\n\n                #Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            if de_budget <= 0:\n                break\n\n        # CMA-ES loop\n        used_budget = 0\n        while used_budget < cmaes_budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.cmaes_popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.cmaes_popsize, self.dim))\n            for k in range(self.cmaes_popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(x_i) for x_i in x])\n            used_budget += self.cmaes_popsize\n\n            if used_budget > cmaes_budget:\n                f = f[:(cmaes_budget - (used_budget - self.cmaes_popsize))]\n                x = x[:(cmaes_budget - (used_budget - self.cmaes_popsize))]\n                self.cmaes_popsize = (cmaes_budget - (used_budget - self.cmaes_popsize))\n                used_budget = cmaes_budget\n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.cmaes_popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:, None, None] * (y[:, :, None] @ y[:, None, :]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T  # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C)  # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)  # Regularize\n                L = np.linalg.cholesky(self.C)  # C = LL'\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.258116602642469, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "5a555672-5781-4d68-bf57-6ef9810658f5", "fitness": 0.6165908299954298, "name": "AdaptiveCMAESOrthogonal", "description": "CMA-ES with adaptive orthogonal sampling and covariance matrix adaptation using rank-one updates.", "code": "import numpy as np\n\nclass AdaptiveCMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(x_i) for x_i in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])  # Rank-one update based on pc\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCMAESOrthogonal scored 0.617 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4fbef25f-b698-424e-98c6-92e70076f23a"], "operator": "mutation", "metadata": {"llm_response": "# Description: CMA-ES with adaptive orthogonal sampling and covariance matrix adaptation using rank-one updates.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(x_i) for x_i in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])  # Rank-one update based on pc\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.30667058059360064, 0.23217118014996685, 0.832238797254232, 0.8968264595201172, 0.7890077212292927, 0.8347309925944578, 0.3539315888261345, 0.7391570434075034, 0.8076337803910212, 0.189133566053168, 0.8430180711756637, 0.9943164882445519, 0.2551954712858422, 0.7760315403646314, 0.8636488878080726, 0.3308222597074406, 0.7462297899395818, 0.8765251790283344, 0.13756922098579927, 0.5269579813491829], "operator": "mutation", "theta_sampled": 0.3276498728376634, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "7c331624-9901-4990-8afe-8cc6106b6ebf", "fitness": 0.0, "name": "AdaptiveDEOrthogonal", "description": "Adaptive Differential Evolution with orthogonal sampling for improved exploration and CMA-ES-inspired step-size adaptation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, ortho_group_size = 5, sigma0=0.3, cs_factor = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.ortho_group_size = ortho_group_size\n        self.sigma = sigma0\n        self.c_sigma = (0.5 + 2) / (self.dim + 0.5 + 5) * cs_factor #Simplified c_sigma\n\n    def orthogonal_sampling(self, population, func):\n        \"\"\"\n        Apply orthogonal sampling to improve population diversity.\n        \"\"\"\n        new_population = np.copy(population)\n        for i in range(0, self.pop_size, self.ortho_group_size):\n            group_size = min(self.ortho_group_size, self.pop_size - i)\n            group = population[i:i + group_size]\n            \n            # Orthogonalize within the group\n            Q, _ = np.linalg.qr(np.random.randn(self.dim, group_size))\n            \n            for j in range(group_size):\n                x = np.clip(population[i + j] + self.sigma * (Q[:, j]), func.bounds.lb, func.bounds.ub)\n                new_population[i + j] = x\n            \n        return new_population\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Orthogonal sampling to create better candidates\n            self.population = self.orthogonal_sampling(self.population, func)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Step size adaptation inspired by CMA-ES\n            delta_f = np.mean(self.fitness) - self.f_opt\n            self.sigma *= np.exp(self.c_sigma * delta_f / self.f_opt)\n            self.sigma = max(self.sigma, 1e-6)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: index 2 is out of bounds for axis 1 with size 2", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "5a555672-5781-4d68-bf57-6ef9810658f5"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with orthogonal sampling for improved exploration and CMA-ES-inspired step-size adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, ortho_group_size = 5, sigma0=0.3, cs_factor = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.ortho_group_size = ortho_group_size\n        self.sigma = sigma0\n        self.c_sigma = (0.5 + 2) / (self.dim + 0.5 + 5) * cs_factor #Simplified c_sigma\n\n    def orthogonal_sampling(self, population, func):\n        \"\"\"\n        Apply orthogonal sampling to improve population diversity.\n        \"\"\"\n        new_population = np.copy(population)\n        for i in range(0, self.pop_size, self.ortho_group_size):\n            group_size = min(self.ortho_group_size, self.pop_size - i)\n            group = population[i:i + group_size]\n            \n            # Orthogonalize within the group\n            Q, _ = np.linalg.qr(np.random.randn(self.dim, group_size))\n            \n            for j in range(group_size):\n                x = np.clip(population[i + j] + self.sigma * (Q[:, j]), func.bounds.lb, func.bounds.ub)\n                new_population[i + j] = x\n            \n        return new_population\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Orthogonal sampling to create better candidates\n            self.population = self.orthogonal_sampling(self.population, func)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Step size adaptation inspired by CMA-ES\n            delta_f = np.mean(self.fitness) - self.f_opt\n            self.sigma *= np.exp(self.c_sigma * delta_f / self.f_opt)\n            self.sigma = max(self.sigma, 1e-6)\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.15578172883309968, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "c42887d7-326f-483b-b1b9-acb5d7852f43", "fitness": 0.61907451196225, "name": "AdaptiveDECMA", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation, combining DE's exploration with CMA-ES's exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy() # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDECMA scored 0.619 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "5a555672-5781-4d68-bf57-6ef9810658f5"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation, combining DE's exploration with CMA-ES's exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy() # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.26761669922230835, 0.6531737579389227, 0.5514151823805777, 0.8292208058115889, 0.6238706830217622, 0.7065982101516279, 0.4436994298524618, 0.5493393701625232, 0.6815154117914621, 0.5104318886388426, 0.8303801575464522, 0.9988517385760587, 0.4911124273232068, 0.5974010654573059, 0.88781614193096, 0.7108305005605177, 0.47822122299179304, 0.8130819684477694, 0.23643005624436797, 0.5204835211944917], "operator": "crossover", "theta_sampled": 0.27329334182127657, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "ab44e8b9-2e1d-4869-ac42-666bb566f162", "fitness": 0.0, "name": "HybridDECMO", "description": "Hybridizes Adaptive DE with Adaptive CMA-ES using orthogonal sampling and archive, dynamically switching search strategies based on performance metrics.", "code": "import numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, cmaes_popsize=None, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        \n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.cmaes_popsize = cmaes_popsize if cmaes_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.cmaes_popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        \n        self.de_success_rate = 0.5\n        self.cmaes_success_rate = 0.5\n        self.switch_frequency = 100 # Evaluations before potentially switching strategy\n        self.eval_count = 0\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        while self.budget > 0:\n            if self.de_success_rate > self.cmaes_success_rate:\n                # Adaptive DE Step\n                de_improvements = 0\n                for i in range(self.pop_size):\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    x_trial = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x_trial[j] = x_mutated[j]\n\n                    # Selection\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n                    self.eval_count += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        de_improvements +=1\n                    \n                    # Stochastic ranking\n                    if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                        if f_trial < self.fitness[i]:\n                            self.population[i] = x_trial\n                            self.fitness[i] = f_trial\n                            \n                            # Update archive\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(self.population[i])\n                                self.archive_fitness.append(self.fitness[i])\n                            else:\n                                # Replace the worst archived solution\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i]\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        # Assign random probabilities if fitness values have different signs\n                        p_i = np.random.rand()\n                        p_trial = np.random.rand()\n\n                        if p_trial < p_i:\n                            self.population[i] = x_trial\n                            self.fitness[i] = f_trial\n                            \n                            # Update archive\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(self.population[i])\n                                self.archive_fitness.append(self.fitness[i])\n                            else:\n                                # Replace the worst archived solution\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i]\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n                self.de_success_rate = de_improvements / self.pop_size\n            else:\n                # Adaptive CMA-ES Step with orthogonal sampling\n                cmaes_improvements = 0\n                # Sample population using orthogonal sampling\n                z = np.random.randn(self.cmaes_popsize, self.dim)\n                Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n                x = np.zeros((self.cmaes_popsize, self.dim))\n                for k in range(self.cmaes_popsize):\n                    x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                    x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n                f = np.array([func(x_i) for x_i in x])\n                self.budget -= self.cmaes_popsize\n                self.eval_count += self.cmaes_popsize\n                \n                if self.budget < 0:\n                    f = f[:(self.cmaes_popsize + self.budget)]\n                    x = x[:(self.cmaes_popsize + self.budget)]\n                    self.cmaes_popsize = (self.cmaes_popsize + self.budget)  # Adjust popsize\n                \n\n                idx = np.argsort(f)\n                x = x[idx]\n                f = f[idx]\n\n\n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[0]\n                    cmaes_improvements += 1\n                    \n                xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n                # Update evolution path\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.eval_count / self.cmaes_popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                # Update covariance matrix using rank-one update\n                y = (xmean - self.m) / self.sigma\n                self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])  # Rank-one update based on pc\n\n                # Update step size\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = xmean\n                self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n                try:\n                    L = np.linalg.cholesky(self.C) # C = LL'\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                    L = np.linalg.cholesky(self.C) # C = LL'\n                self.cmaes_success_rate = cmaes_improvements / self.cmaes_popsize\n\n            # Adapt strategy every switch_frequency evaluations\n            if self.eval_count % self.switch_frequency == 0:\n                self.de_success_rate = max(0.01, min(0.99, self.de_success_rate))\n                self.cmaes_success_rate = max(0.01, min(0.99, self.cmaes_success_rate))\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDECMO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "5a555672-5781-4d68-bf57-6ef9810658f5"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybridizes Adaptive DE with Adaptive CMA-ES using orthogonal sampling and archive, dynamically switching search strategies based on performance metrics.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, cmaes_popsize=None, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        \n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.cmaes_popsize = cmaes_popsize if cmaes_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.cmaes_popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        \n        self.de_success_rate = 0.5\n        self.cmaes_success_rate = 0.5\n        self.switch_frequency = 100 # Evaluations before potentially switching strategy\n        self.eval_count = 0\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        while self.budget > 0:\n            if self.de_success_rate > self.cmaes_success_rate:\n                # Adaptive DE Step\n                de_improvements = 0\n                for i in range(self.pop_size):\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    x_trial = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x_trial[j] = x_mutated[j]\n\n                    # Selection\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n                    self.eval_count += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        de_improvements +=1\n                    \n                    # Stochastic ranking\n                    if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                        if f_trial < self.fitness[i]:\n                            self.population[i] = x_trial\n                            self.fitness[i] = f_trial\n                            \n                            # Update archive\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(self.population[i])\n                                self.archive_fitness.append(self.fitness[i])\n                            else:\n                                # Replace the worst archived solution\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i]\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        # Assign random probabilities if fitness values have different signs\n                        p_i = np.random.rand()\n                        p_trial = np.random.rand()\n\n                        if p_trial < p_i:\n                            self.population[i] = x_trial\n                            self.fitness[i] = f_trial\n                            \n                            # Update archive\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(self.population[i])\n                                self.archive_fitness.append(self.fitness[i])\n                            else:\n                                # Replace the worst archived solution\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i]\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n                self.de_success_rate = de_improvements / self.pop_size\n            else:\n                # Adaptive CMA-ES Step with orthogonal sampling\n                cmaes_improvements = 0\n                # Sample population using orthogonal sampling\n                z = np.random.randn(self.cmaes_popsize, self.dim)\n                Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n                x = np.zeros((self.cmaes_popsize, self.dim))\n                for k in range(self.cmaes_popsize):\n                    x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                    x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n                f = np.array([func(x_i) for x_i in x])\n                self.budget -= self.cmaes_popsize\n                self.eval_count += self.cmaes_popsize\n                \n                if self.budget < 0:\n                    f = f[:(self.cmaes_popsize + self.budget)]\n                    x = x[:(self.cmaes_popsize + self.budget)]\n                    self.cmaes_popsize = (self.cmaes_popsize + self.budget)  # Adjust popsize\n                \n\n                idx = np.argsort(f)\n                x = x[idx]\n                f = f[idx]\n\n\n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[0]\n                    cmaes_improvements += 1\n                    \n                xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n                # Update evolution path\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.eval_count / self.cmaes_popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                # Update covariance matrix using rank-one update\n                y = (xmean - self.m) / self.sigma\n                self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])  # Rank-one update based on pc\n\n                # Update step size\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = xmean\n                self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n                try:\n                    L = np.linalg.cholesky(self.C) # C = LL'\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                    L = np.linalg.cholesky(self.C) # C = LL'\n                self.cmaes_success_rate = cmaes_improvements / self.cmaes_popsize\n\n            # Adapt strategy every switch_frequency evaluations\n            if self.eval_count % self.switch_frequency == 0:\n                self.de_success_rate = max(0.01, min(0.99, self.de_success_rate))\n                self.cmaes_success_rate = max(0.01, min(0.99, self.cmaes_success_rate))\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.10370157276759007, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "75b04b80-e3d6-4fd2-b9c9-dc228d100d16", "fitness": 0.0, "name": "AntColonyOptimization", "description": "Population-based algorithm inspired by the foraging behavior of ants, using pheromone trails to guide search and a local search operator to improve solutions.", "code": "import numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=20, evaporation_rate=0.1, alpha=1, beta=2, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha  # Pheromone influence\n        self.beta = beta  # Heuristic influence\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        pheromone = np.ones((self.colony_size, self.dim))  # Initial pheromone levels\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ant) for ant in ants])\n            evaluations += self.colony_size\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = ants[np.argmin(fitness)].copy()\n\n            # Pheromone update\n            delta_pheromone = np.zeros((self.colony_size, self.dim))\n            for i in range(self.colony_size):\n                delta_pheromone[i, :] = (self.f_opt / (fitness[i] + 1e-8))  # Higher fitness, more pheromone\n\n            pheromone = (1 - self.evaporation_rate) * pheromone + delta_pheromone\n\n            # Ant movement (probabilistic based on pheromone and heuristic)\n            probabilities = pheromone**self.alpha\n            for i in range(self.colony_size):\n                 probabilities[i] /= np.sum(probabilities[i])\n\n            new_ants = np.zeros((self.colony_size, self.dim))\n            for i in range(self.colony_size):\n                for j in range(self.dim):\n                    # Probabilistically choose a dimension from other ants\n                    chosen_ant_idx = np.random.choice(self.colony_size, p=probabilities[:, j])\n                    new_ants[i, j] = ants[chosen_ant_idx, j] # Copy the coordinate from chosen ant\n                \n                # Local Search\n                for _ in range(self.local_search_iterations):\n                    neighbor = new_ants[i, :] + np.random.normal(0, 0.1, self.dim) # Small random step\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n                    f_neighbor = func(neighbor)\n                    evaluations += 1\n                    if f_neighbor < fitness[i]:\n                        new_ants[i, :] = neighbor.copy()\n                        fitness[i] = f_neighbor\n                        if f_neighbor < self.f_opt:\n                            self.f_opt = f_neighbor\n                            self.x_opt = neighbor.copy()\n                    if evaluations >= self.budget:\n                        break\n\n            ants = new_ants.copy()\n            if evaluations >= self.budget:\n                break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: probabilities do not sum to 1", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm inspired by the foraging behavior of ants, using pheromone trails to guide search and a local search operator to improve solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=20, evaporation_rate=0.1, alpha=1, beta=2, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha  # Pheromone influence\n        self.beta = beta  # Heuristic influence\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        pheromone = np.ones((self.colony_size, self.dim))  # Initial pheromone levels\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ant) for ant in ants])\n            evaluations += self.colony_size\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = ants[np.argmin(fitness)].copy()\n\n            # Pheromone update\n            delta_pheromone = np.zeros((self.colony_size, self.dim))\n            for i in range(self.colony_size):\n                delta_pheromone[i, :] = (self.f_opt / (fitness[i] + 1e-8))  # Higher fitness, more pheromone\n\n            pheromone = (1 - self.evaporation_rate) * pheromone + delta_pheromone\n\n            # Ant movement (probabilistic based on pheromone and heuristic)\n            probabilities = pheromone**self.alpha\n            for i in range(self.colony_size):\n                 probabilities[i] /= np.sum(probabilities[i])\n\n            new_ants = np.zeros((self.colony_size, self.dim))\n            for i in range(self.colony_size):\n                for j in range(self.dim):\n                    # Probabilistically choose a dimension from other ants\n                    chosen_ant_idx = np.random.choice(self.colony_size, p=probabilities[:, j])\n                    new_ants[i, j] = ants[chosen_ant_idx, j] # Copy the coordinate from chosen ant\n                \n                # Local Search\n                for _ in range(self.local_search_iterations):\n                    neighbor = new_ants[i, :] + np.random.normal(0, 0.1, self.dim) # Small random step\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n                    f_neighbor = func(neighbor)\n                    evaluations += 1\n                    if f_neighbor < fitness[i]:\n                        new_ants[i, :] = neighbor.copy()\n                        fitness[i] = f_neighbor\n                        if f_neighbor < self.f_opt:\n                            self.f_opt = f_neighbor\n                            self.x_opt = neighbor.copy()\n                    if evaluations >= self.budget:\n                        break\n\n            ants = new_ants.copy()\n            if evaluations >= self.budget:\n                break\n            \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": -0.04710768343236401, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "ddff1f3d-3bd6-4047-a751-bc9092237521", "fitness": 0.6820605200976347, "name": "AdaptiveCMAESOrthogonal", "description": "CMA-ES with orthogonal sampling and adaptive covariance matrix adaptation based on successful steps.", "code": "import numpy as np\n\nclass AdaptiveCMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCMAESOrthogonal scored 0.682 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4fbef25f-b698-424e-98c6-92e70076f23a"], "operator": "mutation", "metadata": {"llm_response": "# Description: CMA-ES with orthogonal sampling and adaptive covariance matrix adaptation based on successful steps.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23622368031204055, 0.21766223038251997, 0.9210614851182942, 0.9600456709161105, 0.9384049118245967, 0.9528302436478825, 0.3694608508623952, 0.7645728974910777, 0.9443776669062912, 0.1545545192957608, 0.9400192284925636, 0.9879164306291742, 0.2189106039303097, 0.9333789111215347, 0.8983529909808758, 0.36209583024828507, 0.45051734321823045, 0.9581362808007025, 0.9270797011141351, 0.5056089246599138], "operator": "mutation", "theta_sampled": 0.05649133689450439, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "14377bc5-ca63-4703-9ff9-f5ec65ad5389", "fitness": 0.0, "name": "HybridGradientDE", "description": "A population-based algorithm that uses a combination of gradient descent and differential evolution to explore the search space, adaptively adjusting parameters based on the function landscape.", "code": "import numpy as np\n\nclass HybridGradientDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.01, de_rate=0.5, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.de_rate = de_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size # Initial fitness evaluations\n\n        while self.eval_count < self.budget:\n            # 1. Gradient Descent Step (on best individual)\n            best_idx = np.argmin(self.fitness)\n            best_x = self.population[best_idx]\n\n            # Approximate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = best_x.copy()\n                x_minus = best_x.copy()\n                delta = 1e-5  # Small perturbation\n                x_plus[i] += delta\n                x_minus[i] -= delta\n\n                #Respect bounds, if exceeded\n                x_plus[i] = np.clip(x_plus[i], func.bounds.lb[i], func.bounds.ub[i])\n                x_minus[i] = np.clip(x_minus[i], func.bounds.lb[i], func.bounds.ub[i])\n\n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n\n                self.eval_count += 2\n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n\n                if self.eval_count > self.budget:\n                   return self.f_opt, self.x_opt\n\n            # Update the best individual using gradient descent\n            new_best_x = best_x - self.lr * gradient\n            new_best_x = np.clip(new_best_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_best_x)\n            self.eval_count += 1\n            if self.eval_count > self.budget:\n                   return self.f_opt, self.x_opt\n\n\n            if new_f < self.fitness[best_idx]:\n                self.population[best_idx] = new_best_x\n                self.fitness[best_idx] = new_f\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_best_x\n            \n            # 2. Differential Evolution Step\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    x_mutated = self.population[i] + self.de_mutation_factor * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    x_trial = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.de_crossover_rate or j == np.random.randint(0, self.dim):\n                            x_trial[j] = x_mutated[j]\n                        else:\n                            x_trial[j] = self.population[i][j]\n\n                    # Selection\n                    f_trial = func(x_trial)\n                    self.eval_count += 1\n\n                    if self.eval_count > self.budget:\n                         return self.f_opt, self.x_opt\n                    \n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm HybridGradientDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of gradient descent and differential evolution to explore the search space, adaptively adjusting parameters based on the function landscape.\n# Code: \n```python\nimport numpy as np\n\nclass HybridGradientDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.01, de_rate=0.5, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.de_rate = de_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size # Initial fitness evaluations\n\n        while self.eval_count < self.budget:\n            # 1. Gradient Descent Step (on best individual)\n            best_idx = np.argmin(self.fitness)\n            best_x = self.population[best_idx]\n\n            # Approximate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = best_x.copy()\n                x_minus = best_x.copy()\n                delta = 1e-5  # Small perturbation\n                x_plus[i] += delta\n                x_minus[i] -= delta\n\n                #Respect bounds, if exceeded\n                x_plus[i] = np.clip(x_plus[i], func.bounds.lb[i], func.bounds.ub[i])\n                x_minus[i] = np.clip(x_minus[i], func.bounds.lb[i], func.bounds.ub[i])\n\n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n\n                self.eval_count += 2\n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n\n                if self.eval_count > self.budget:\n                   return self.f_opt, self.x_opt\n\n            # Update the best individual using gradient descent\n            new_best_x = best_x - self.lr * gradient\n            new_best_x = np.clip(new_best_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_best_x)\n            self.eval_count += 1\n            if self.eval_count > self.budget:\n                   return self.f_opt, self.x_opt\n\n\n            if new_f < self.fitness[best_idx]:\n                self.population[best_idx] = new_best_x\n                self.fitness[best_idx] = new_f\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_best_x\n            \n            # 2. Differential Evolution Step\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    x_mutated = self.population[i] + self.de_mutation_factor * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    x_trial = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.de_crossover_rate or j == np.random.randint(0, self.dim):\n                            x_trial[j] = x_mutated[j]\n                        else:\n                            x_trial[j] = self.population[i][j]\n\n                    # Selection\n                    f_trial = func(x_trial)\n                    self.eval_count += 1\n\n                    if self.eval_count > self.budget:\n                         return self.f_opt, self.x_opt\n                    \n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.5140906027429686, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "1ee18372-49f4-4f34-9240-a23738d04c6f", "fitness": 0.0, "name": "AdaptiveCMAESOrthogonal", "description": "Adaptive CMA-ES with orthogonal sampling, dynamic population size, covariance matrix adaptation via rank-one updates, and a learning rate control mechanism based on fitness variance.", "code": "import numpy as np\n\nclass AdaptiveCMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one  # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.learning_rate = learning_rate # Add learning rate parameter\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        historical_fitnesses = []\n\n        while used_budget < self.budget:\n            # Adaptive Population Size\n            if len(historical_fitnesses) > 10:\n                fitness_std = np.std(historical_fitnesses[-10:])\n                if fitness_std < 1e-6:  # Convergence detected\n                    self.popsize = max(4, self.popsize // 2)  # Reduce popsize\n                else:\n                    self.popsize = min(self.budget // 10, self.popsize * 1.1) #Increase popsize, but not too high\n\n            self.popsize = int(self.popsize)\n            self.mu = self.popsize // 2 \n            self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n            self.weights = self.weights / np.sum(self.weights)\n            self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n            self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n\n\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(x_i) for x_i in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 self.mu = self.popsize//2\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            historical_fitnesses.extend(f[:self.mu]) #Store only the best fitnesses\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])  # Rank-one update based on pc\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            #Mean Adaptation with learning rate\n            self.m = self.m + self.learning_rate * (xmean - self.m)\n\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: name 'cs_factor' is not defined", "parent_ids": ["5a555672-5781-4d68-bf57-6ef9810658f5"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive CMA-ES with orthogonal sampling, dynamic population size, covariance matrix adaptation via rank-one updates, and a learning rate control mechanism based on fitness variance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAESOrthogonal:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one  # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.learning_rate = learning_rate # Add learning rate parameter\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        historical_fitnesses = []\n\n        while used_budget < self.budget:\n            # Adaptive Population Size\n            if len(historical_fitnesses) > 10:\n                fitness_std = np.std(historical_fitnesses[-10:])\n                if fitness_std < 1e-6:  # Convergence detected\n                    self.popsize = max(4, self.popsize // 2)  # Reduce popsize\n                else:\n                    self.popsize = min(self.budget // 10, self.popsize * 1.1) #Increase popsize, but not too high\n\n            self.popsize = int(self.popsize)\n            self.mu = self.popsize // 2 \n            self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n            self.weights = self.weights / np.sum(self.weights)\n            self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n            self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n\n\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(x_i) for x_i in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 self.mu = self.popsize//2\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            historical_fitnesses.extend(f[:self.mu]) #Store only the best fitnesses\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                \n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])  # Rank-one update based on pc\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            #Mean Adaptation with learning rate\n            self.m = self.m + self.learning_rate * (xmean - self.m)\n\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'            \n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.3246535554729284, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "7c5ca12e-2bcd-418f-af2a-74f5836d780b", "fitness": 0.0, "name": "CooperativeSearch", "description": "Bio-inspired Cooperative Search: A population-based algorithm where individuals cooperate by exchanging information and adapting their search strategies based on the success of their neighbors and their own exploration history, using a novel ranking and selection mechanism.", "code": "import numpy as np\n\nclass CooperativeSearch:\n    def __init__(self, budget=10000, dim=10, population_size=50, cooperation_probability=0.5, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.cooperation_probability = cooperation_probability\n        self.adaptation_rate = adaptation_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.population_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n    def cooperate(self, func):\n        for i in range(self.population_size):\n            if np.random.rand() < self.cooperation_probability:\n                # Select a neighbor (excluding self)\n                neighbors = np.arange(self.population_size)\n                neighbors = neighbors[neighbors != i]\n                neighbor_index = np.random.choice(neighbors)\n\n                # Exchange information (e.g., take average of position)\n                new_x = (self.population[i] + self.population[neighbor_index]) / 2.0\n                \n                # Add a small random perturbation\n                new_x = new_x + self.adaptation_rate * np.random.normal(0, 1, self.dim)\n                \n                # Clip to bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                f = func(new_x)\n                self.eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n\n    def adapt(self, func):\n        # Rank individuals based on fitness\n        ranked_indices = np.argsort(self.fitness)\n\n        # Improve the worst individuals by learning from the best\n        for i in ranked_indices[self.population_size // 2:]:  # Adapt the worst half\n            best_index = ranked_indices[0]\n            \n            # Move towards the best individual with a random step\n            new_x = self.population[i] + self.adaptation_rate * (self.population[best_index] - self.population[i]) + self.adaptation_rate * np.random.normal(0, 1, self.dim)\n            \n            # Clip to bounds\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(new_x)\n            self.eval_count += 1\n            \n            if f < self.fitness[i]:\n                self.population[i] = new_x\n                self.fitness[i] = f\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.cooperate(func)\n            if self.eval_count < self.budget:\n                self.adapt(func)  # Ensure budget constraint\n            else:\n                break  # Exit the loop if the budget is exceeded.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CooperativeSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Bio-inspired Cooperative Search: A population-based algorithm where individuals cooperate by exchanging information and adapting their search strategies based on the success of their neighbors and their own exploration history, using a novel ranking and selection mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass CooperativeSearch:\n    def __init__(self, budget=10000, dim=10, population_size=50, cooperation_probability=0.5, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.cooperation_probability = cooperation_probability\n        self.adaptation_rate = adaptation_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.population_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n    def cooperate(self, func):\n        for i in range(self.population_size):\n            if np.random.rand() < self.cooperation_probability:\n                # Select a neighbor (excluding self)\n                neighbors = np.arange(self.population_size)\n                neighbors = neighbors[neighbors != i]\n                neighbor_index = np.random.choice(neighbors)\n\n                # Exchange information (e.g., take average of position)\n                new_x = (self.population[i] + self.population[neighbor_index]) / 2.0\n                \n                # Add a small random perturbation\n                new_x = new_x + self.adaptation_rate * np.random.normal(0, 1, self.dim)\n                \n                # Clip to bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                f = func(new_x)\n                self.eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n\n    def adapt(self, func):\n        # Rank individuals based on fitness\n        ranked_indices = np.argsort(self.fitness)\n\n        # Improve the worst individuals by learning from the best\n        for i in ranked_indices[self.population_size // 2:]:  # Adapt the worst half\n            best_index = ranked_indices[0]\n            \n            # Move towards the best individual with a random step\n            new_x = self.population[i] + self.adaptation_rate * (self.population[best_index] - self.population[i]) + self.adaptation_rate * np.random.normal(0, 1, self.dim)\n            \n            # Clip to bounds\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(new_x)\n            self.eval_count += 1\n            \n            if f < self.fitness[i]:\n                self.population[i] = new_x\n                self.fitness[i] = f\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.cooperate(func)\n            if self.eval_count < self.budget:\n                self.adapt(func)  # Ensure budget constraint\n            else:\n                break  # Exit the loop if the budget is exceeded.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.0057030112514856015, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "99108523-f151-4ab3-a538-741b2392941e", "fitness": 0.0, "name": "HybridDECMASR", "description": "Hybrid algorithm combining Adaptive DE's mutation and selection with Adaptive CMA-ES's covariance matrix adaptation for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMASR:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy() # Initialize mean with best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        while self.budget > 0:\n            # Sample population using CMA-ES\n            z = np.random.randn(self.pop_size, self.dim)\n            A = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            if self.budget < 0:\n                f = f[:self.pop_size + self.budget]\n                x = x[:self.pop_size + self.budget]\n                self.pop_size += self.budget #pop_size is decreased\n                self.budget = 0\n\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = x[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(x[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection (Stochastic Ranking)\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if self.budget < 0:\n                  break\n\n\n                if (f[i] <= 0 and f_trial <= 0) or (f[i] > 0 and f_trial > 0):\n                    if f_trial < f[i]:\n                        x[i] = x_trial\n                        f[i] = f_trial\n\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        x[i] = x_trial\n                        f[i] = f_trial\n            \n            if self.budget < 0:\n              break\n\n\n            # Archive updating (using entire population)\n            for i in range(self.pop_size):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(x[i])\n                    self.archive_fitness.append(f[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if f[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = x[i]\n                        self.archive_fitness[max_archive_index] = f[i]\n\n\n            # CMA-ES update\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDECMASR scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid algorithm combining Adaptive DE's mutation and selection with Adaptive CMA-ES's covariance matrix adaptation for efficient exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMASR:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy() # Initialize mean with best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        while self.budget > 0:\n            # Sample population using CMA-ES\n            z = np.random.randn(self.pop_size, self.dim)\n            A = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            if self.budget < 0:\n                f = f[:self.pop_size + self.budget]\n                x = x[:self.pop_size + self.budget]\n                self.pop_size += self.budget #pop_size is decreased\n                self.budget = 0\n\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = x[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(x[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection (Stochastic Ranking)\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if self.budget < 0:\n                  break\n\n\n                if (f[i] <= 0 and f_trial <= 0) or (f[i] > 0 and f_trial > 0):\n                    if f_trial < f[i]:\n                        x[i] = x_trial\n                        f[i] = f_trial\n\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        x[i] = x_trial\n                        f[i] = f_trial\n            \n            if self.budget < 0:\n              break\n\n\n            # Archive updating (using entire population)\n            for i in range(self.pop_size):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(x[i])\n                    self.archive_fitness.append(f[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if f[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = x[i]\n                        self.archive_fitness[max_archive_index] = f[i]\n\n\n            # CMA-ES update\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.31063660626473444, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "750a1ec7-11a1-4f3e-875a-a6cdab5697dd", "fitness": 0.0, "name": "AdaptiveDECMA", "description": "Integrates CMA-ES with a self-adaptive Differential Evolution (SaDE) strategy, using multiple mutation operators and learning their success to dynamically adjust mutation probabilities, combined with a mirroring strategy to enhance boundary exploration.", "code": "import numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, lr_p = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.lr_p = lr_p\n\n        # SaDE parameters\n        self.mutation_strategies = [\n            lambda x, xr1, xr2, xr3: x + self.F * (xr1 - xr2),  # DE/rand/1\n            lambda x, xr1, xr2, xr3: xr1 + self.F * (xr2 - xr3),  # DE/best/1\n            lambda x, xr1, xr2, xr3: x + self.F * (xr1 - xr2) + self.F * (xr3 - x), #DE/rand/2\n        ]\n        self.num_strategies = len(self.mutation_strategies)\n        self.success_counts = np.ones(self.num_strategies)  # Initialize success counts\n        self.probabilities = np.ones(self.num_strategies) / self.num_strategies  # Initialize probabilities\n        self.memory_size = 10\n        self.memory_f = np.ones(self.memory_size) * 0.5\n        self.memory_cr = np.ones(self.memory_size) * 0.9\n        self.memory_idx = 0\n        self.F = 0.5\n        self.CR = 0.9\n\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy() # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(self.num_strategies, p=self.probabilities)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n                \n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                # Archive usage\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = mutation_strategy(self.population[i], x_r1, x_r2, x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = mutation_strategy(self.population[i], x_r1, x_r2, x_r3) + self.sigma * (L @ z)\n\n                # Mirroring strategy\n                x_mutated = np.clip(x_mutated, lb, ub)\n                for j in range(self.dim):\n                    if x_mutated[j] == lb or x_mutated[j] == ub:\n                        x_mutated[j] = np.random.uniform(lb, ub)  # Resample if at boundary\n\n\n                # Crossover using memory of CR values\n                cr_i = np.random.choice(self.memory_cr)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                x_trial = np.clip(x_trial, lb, ub) #clip again, numerical errors might occur\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.success_counts[strategy_index] += 1 #Reward\n                    delta_f = self.fitness[i] - f_trial\n                    \n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace the worst archived solution\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = self.population[i]\n                            self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    pass\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Update SaDE probabilities\n            self.probabilities = (1 - self.lr_p) * self.probabilities + self.lr_p * (self.success_counts / np.sum(self.success_counts))\n            self.probabilities /= np.sum(self.probabilities)  # Normalize\n            self.success_counts = np.ones(self.num_strategies)\n\n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": ["c42887d7-326f-483b-b1b9-acb5d7852f43"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates CMA-ES with a self-adaptive Differential Evolution (SaDE) strategy, using multiple mutation operators and learning their success to dynamically adjust mutation probabilities, combined with a mirroring strategy to enhance boundary exploration.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, lr_p = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.lr_p = lr_p\n\n        # SaDE parameters\n        self.mutation_strategies = [\n            lambda x, xr1, xr2, xr3: x + self.F * (xr1 - xr2),  # DE/rand/1\n            lambda x, xr1, xr2, xr3: xr1 + self.F * (xr2 - xr3),  # DE/best/1\n            lambda x, xr1, xr2, xr3: x + self.F * (xr1 - xr2) + self.F * (xr3 - x), #DE/rand/2\n        ]\n        self.num_strategies = len(self.mutation_strategies)\n        self.success_counts = np.ones(self.num_strategies)  # Initialize success counts\n        self.probabilities = np.ones(self.num_strategies) / self.num_strategies  # Initialize probabilities\n        self.memory_size = 10\n        self.memory_f = np.ones(self.memory_size) * 0.5\n        self.memory_cr = np.ones(self.memory_size) * 0.9\n        self.memory_idx = 0\n        self.F = 0.5\n        self.CR = 0.9\n\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy() # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(self.num_strategies, p=self.probabilities)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n                \n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                # Archive usage\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = mutation_strategy(self.population[i], x_r1, x_r2, x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = mutation_strategy(self.population[i], x_r1, x_r2, x_r3) + self.sigma * (L @ z)\n\n                # Mirroring strategy\n                x_mutated = np.clip(x_mutated, lb, ub)\n                for j in range(self.dim):\n                    if x_mutated[j] == lb or x_mutated[j] == ub:\n                        x_mutated[j] = np.random.uniform(lb, ub)  # Resample if at boundary\n\n\n                # Crossover using memory of CR values\n                cr_i = np.random.choice(self.memory_cr)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                x_trial = np.clip(x_trial, lb, ub) #clip again, numerical errors might occur\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.success_counts[strategy_index] += 1 #Reward\n                    delta_f = self.fitness[i] - f_trial\n                    \n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace the worst archived solution\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = self.population[i]\n                            self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    pass\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Update SaDE probabilities\n            self.probabilities = (1 - self.lr_p) * self.probabilities + self.lr_p * (self.success_counts / np.sum(self.success_counts))\n            self.probabilities /= np.sum(self.probabilities)  # Normalize\n            self.success_counts = np.ones(self.num_strategies)\n\n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.24604579123044915, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "c9cebac8-1a11-49c8-8921-151bdc182ed7", "fitness": 0.0, "name": "GradientEnhancedDifferentialEvolution", "description": "Population-based algorithm using a combination of differential evolution and a local search based on gradient estimation.", "code": "import numpy as np\n\nclass GradientEnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Local Search (Gradient Estimation)\n                trial_ls = trial.copy()\n                f_trial = func(trial_ls)\n                self.budget -= 1\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = trial_ls\n                \n                if self.budget <= 0:\n                  return self.f_opt, self.x_opt\n\n                for _ in range(self.local_search_iterations):\n                    # Estimate gradient using finite differences\n                    gradient = np.zeros(self.dim)\n                    delta = 1e-3  # Step size for gradient estimation\n                    for j in range(self.dim):\n                        trial_plus = trial_ls.copy()\n                        trial_minus = trial_ls.copy()\n                        trial_plus[j] += delta\n                        trial_minus[j] -= delta\n                        trial_plus = np.clip(trial_plus, func.bounds.lb, func.bounds.ub)\n                        trial_minus = np.clip(trial_minus, func.bounds.lb, func.bounds.ub)\n                        f_plus = func(trial_plus)\n                        self.budget -= 1\n                        if f_plus < self.f_opt:\n                            self.f_opt = f_plus\n                            self.x_opt = trial_plus\n                            \n                        f_minus = func(trial_minus)\n                        self.budget -= 1\n                        if f_minus < self.f_opt:\n                            self.f_opt = f_minus\n                            self.x_opt = trial_minus\n                            \n                        if self.budget <= 0:\n                          return self.f_opt, self.x_opt\n                        gradient[j] = (f_plus - f_minus) / (2 * delta)\n\n                    # Move in the direction of the negative gradient\n                    trial_ls = trial_ls - 0.01 * gradient  # Small step size\n                    trial_ls = np.clip(trial_ls, func.bounds.lb, func.bounds.ub)\n                    f_trial_ls = func(trial_ls)\n                    self.budget -= 1\n                    if f_trial_ls < self.f_opt:\n                        self.f_opt = f_trial_ls\n                        self.x_opt = trial_ls\n                    if self.budget <= 0:\n                      return self.f_opt, self.x_opt\n\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = trial\n                \n                if self.budget <= 0:\n                  return self.f_opt, self.x_opt\n\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm GradientEnhancedDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of differential evolution and a local search based on gradient estimation.\n# Code: \n```python\nimport numpy as np\n\nclass GradientEnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Local Search (Gradient Estimation)\n                trial_ls = trial.copy()\n                f_trial = func(trial_ls)\n                self.budget -= 1\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = trial_ls\n                \n                if self.budget <= 0:\n                  return self.f_opt, self.x_opt\n\n                for _ in range(self.local_search_iterations):\n                    # Estimate gradient using finite differences\n                    gradient = np.zeros(self.dim)\n                    delta = 1e-3  # Step size for gradient estimation\n                    for j in range(self.dim):\n                        trial_plus = trial_ls.copy()\n                        trial_minus = trial_ls.copy()\n                        trial_plus[j] += delta\n                        trial_minus[j] -= delta\n                        trial_plus = np.clip(trial_plus, func.bounds.lb, func.bounds.ub)\n                        trial_minus = np.clip(trial_minus, func.bounds.lb, func.bounds.ub)\n                        f_plus = func(trial_plus)\n                        self.budget -= 1\n                        if f_plus < self.f_opt:\n                            self.f_opt = f_plus\n                            self.x_opt = trial_plus\n                            \n                        f_minus = func(trial_minus)\n                        self.budget -= 1\n                        if f_minus < self.f_opt:\n                            self.f_opt = f_minus\n                            self.x_opt = trial_minus\n                            \n                        if self.budget <= 0:\n                          return self.f_opt, self.x_opt\n                        gradient[j] = (f_plus - f_minus) / (2 * delta)\n\n                    # Move in the direction of the negative gradient\n                    trial_ls = trial_ls - 0.01 * gradient  # Small step size\n                    trial_ls = np.clip(trial_ls, func.bounds.lb, func.bounds.ub)\n                    f_trial_ls = func(trial_ls)\n                    self.budget -= 1\n                    if f_trial_ls < self.f_opt:\n                        self.f_opt = f_trial_ls\n                        self.x_opt = trial_ls\n                    if self.budget <= 0:\n                      return self.f_opt, self.x_opt\n\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = trial\n                \n                if self.budget <= 0:\n                  return self.f_opt, self.x_opt\n\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.1935025790057391, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "e457d5ff-17b1-43a7-a518-5ea9c4460aa5", "fitness": 0.5842159336221333, "name": "AdaptiveCMAESOrthogonalEigen", "description": "Adaptive CMA-ES with orthogonal sampling and covariance matrix regularization based on eigenvalue clipping, and a more sophisticated adaptation of the step size and covariance matrix learning rates.", "code": "import numpy as np\n\nclass AdaptiveCMAESOrthogonalEigen(object):\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n        self.min_eig = 1e-12 # Minimum eigenvalue for regularization\n        self.cs = 0  # cumulation for sigma (step-size)\n        self.cc = 0  # cumulation for coordinate system\n        self.lambda_ = self.popsize # population size\n\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            y = x[:self.mu] - self.m\n            y_w = np.sum(self.weights[:, None] * y, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Covariance matrix adaptation\n            C_old = self.C.copy()\n            self.C = (1 - self.c_1 - self.c_mu) * self.C \\\n                     + self.c_1 * (self.pc[:, None] @ self.pc[None, :]) \\\n                     + self.c_mu * np.sum(self.weights[:, None, None] * (y[:, :, None] @ y[:, None, :]), axis=0)\n            \n            # Eigenvalue decomposition and clipping\n            try:\n                D, B = np.linalg.eigh(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)\n                D, B = np.linalg.eigh(self.C)\n            \n            D = np.maximum(D, self.min_eig)  # Clip eigenvalues\n            self.C = B @ np.diag(D) @ B.T    # Reconstruct covariance matrix\n           \n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n                self.c_1 *= (1 + self.adaptation_rate)\n                self.c_mu *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n                self.c_1 *= (1 - self.adaptation_rate)\n                self.c_mu *= (1 - self.adaptation_rate)\n\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n            self.c_1 = np.clip(self.c_1, 0.0, 1.0)\n            self.c_mu = np.clip(self.c_mu, 0.0, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveCMAESOrthogonalEigen scored 0.584 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive CMA-ES with orthogonal sampling and covariance matrix regularization based on eigenvalue clipping, and a more sophisticated adaptation of the step size and covariance matrix learning rates.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAESOrthogonalEigen(object):\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n        self.min_eig = 1e-12 # Minimum eigenvalue for regularization\n        self.cs = 0  # cumulation for sigma (step-size)\n        self.cc = 0  # cumulation for coordinate system\n        self.lambda_ = self.popsize # population size\n\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.popsize, self.dim))\n            for k in range(self.popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.popsize\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.popsize))]\n                 x = x[:(self.budget - (used_budget-self.popsize))]\n                 self.popsize = (self.budget - (used_budget-self.popsize))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            y = x[:self.mu] - self.m\n            y_w = np.sum(self.weights[:, None] * y, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Covariance matrix adaptation\n            C_old = self.C.copy()\n            self.C = (1 - self.c_1 - self.c_mu) * self.C \\\n                     + self.c_1 * (self.pc[:, None] @ self.pc[None, :]) \\\n                     + self.c_mu * np.sum(self.weights[:, None, None] * (y[:, :, None] @ y[:, None, :]), axis=0)\n            \n            # Eigenvalue decomposition and clipping\n            try:\n                D, B = np.linalg.eigh(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)\n                D, B = np.linalg.eigh(self.C)\n            \n            D = np.maximum(D, self.min_eig)  # Clip eigenvalues\n            self.C = B @ np.diag(D) @ B.T    # Reconstruct covariance matrix\n           \n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n                self.c_1 *= (1 + self.adaptation_rate)\n                self.c_mu *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n                self.c_1 *= (1 - self.adaptation_rate)\n                self.c_mu *= (1 - self.adaptation_rate)\n\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n            self.c_1 = np.clip(self.c_1, 0.0, 1.0)\n            self.c_mu = np.clip(self.c_mu, 0.0, 1.0)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.26144674848713045, 0.33766141877058686, 0.9239185297393752, 0.1434171841920897, 0.9376598419390362, 0.9434528946248023, 0.37565805286593157, 0.9250148540111329, 0.35715560897685805, 0.12815179261573262, 0.9578736383232741, 0.971642463076693, 0.26187183905994016, 0.8154931476690443, 0.8829539060440622, 0.4303533049732098, 0.44912749954607056, 0.9587898742747782, 0.18038504178897985, 0.44229103146393756], "operator": "mutation", "theta_sampled": 0.31097118873364177, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "323ce08a-643c-4881-b486-85bceab210b0", "fitness": 0.0, "name": "HybridDE_CMAES", "description": "Hybrid algorithm combining adaptive differential evolution with orthogonal sampling CMA-ES for improved exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, cmaes_fraction=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.cmaes_fraction = cmaes_fraction # Fraction of budget allocated to CMA-ES\n        self.cmaes_popsize = max(4, int(3 * np.log(self.dim)))\n        self.mu = self.cmaes_popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # DE Initialization\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        de_budget = int(self.budget * (1 - self.cmaes_fraction))\n        self.budget -= self.pop_size\n        de_budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        # DE Loop\n        while de_budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                de_budget -= 1\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy()  # Initialize mean with the best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        cmaes_budget = self.budget\n\n        # CMA-ES Loop\n        while cmaes_budget > 0:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.cmaes_popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.cmaes_popsize, self.dim))\n            for k in range(self.cmaes_popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            cmaes_budget -= self.cmaes_popsize\n            self.budget -= self.cmaes_popsize\n\n            if self.budget <= 0:\n                return self.f_opt, self.x_opt\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.cmaes_popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 4)", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid algorithm combining adaptive differential evolution with orthogonal sampling CMA-ES for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, cmaes_fraction=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.cmaes_fraction = cmaes_fraction # Fraction of budget allocated to CMA-ES\n        self.cmaes_popsize = max(4, int(3 * np.log(self.dim)))\n        self.mu = self.cmaes_popsize // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # DE Initialization\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        de_budget = int(self.budget * (1 - self.cmaes_fraction))\n        self.budget -= self.pop_size\n        de_budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        # DE Loop\n        while de_budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                de_budget -= 1\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy()  # Initialize mean with the best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        cmaes_budget = self.budget\n\n        # CMA-ES Loop\n        while cmaes_budget > 0:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.cmaes_popsize, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.cmaes_popsize, self.dim))\n            for k in range(self.cmaes_popsize):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            cmaes_budget -= self.cmaes_popsize\n            self.budget -= self.cmaes_popsize\n\n            if self.budget <= 0:\n                return self.f_opt, self.x_opt\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.cmaes_popsize)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.14209308703881648, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "ac2ed263-b7ea-4404-b15e-fbff01cfba5a", "fitness": 0.0, "name": "HybridDE_CMAES", "description": "Hybrid DE with CMA-ES orthogonal sampling and adaptive control of exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n        self.exploration_prob = 0.5 # Probability of using CMA-ES sampling instead of DE mutation\n        self.c_cov = 0.1 # Covariance learning rate\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.L = None  # Cholesky decomposition of C\n\n\n    def initialize_cmaes(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        try:\n            self.L = np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-8 * np.eye(self.dim)\n            self.L = np.linalg.cholesky(self.C)\n\n    def sample_cmaes(self, num_samples, func):\n        z = np.random.randn(num_samples, self.dim)\n        Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n        samples = np.zeros((num_samples, self.dim))\n        for k in range(num_samples):\n            samples[k] = self.m + self.sigma0 * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n            samples[k] = np.clip(samples[k], func.bounds.lb, func.bounds.ub)\n        return samples\n\n\n    def update_cmaes(self, xmean):\n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (xmean - self.m) / self.sigma0\n        hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**2) / self.chiN < 1.4 + 2/(self.dim+1))\n        self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (xmean - self.m) / self.sigma0\n        y = xmean - self.m\n\n        self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])  + 0.01* np.eye(self.dim)\n\n        self.C = np.triu(self.C) + np.triu(self.C,1).T  # Enforce symmetry\n\n        try:\n            self.L = np.linalg.cholesky(self.C) # C = LL'\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n            self.L = np.linalg.cholesky(self.C) # C = LL'\n\n        self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.m = xmean\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.initialize_cmaes(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # CMA-ES orthogonal sampling for exploration\n                    x_trial = self.sample_cmaes(1, func)[0]\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                else:\n                    # DE mutation and crossover\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    x_trial = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x_trial[j] = x_mutated[j]\n\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                # Selection\n                if self.budget <= 0:\n                    break\n\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n            # CMA-ES update based on the best solutions from DE\n            idx = np.argsort(self.fitness)\n            xmean = np.sum(self.weights[:, None] * self.population[idx[:self.mu]], axis=0)\n            self.update_cmaes(xmean)\n\n            # Adaptive control of exploration probability\n            self.success_history.append(1 if self.f_opt < np.min(self.fitness) else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.exploration_prob *= 0.95  # Reduce exploration if successful\n            elif self.success_rate < 0.3:\n                self.exploration_prob *= 1.05  # Increase exploration if unsuccessful\n\n            self.exploration_prob = np.clip(self.exploration_prob, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid DE with CMA-ES orthogonal sampling and adaptive control of exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n        self.exploration_prob = 0.5 # Probability of using CMA-ES sampling instead of DE mutation\n        self.c_cov = 0.1 # Covariance learning rate\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.L = None  # Cholesky decomposition of C\n\n\n    def initialize_cmaes(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        try:\n            self.L = np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-8 * np.eye(self.dim)\n            self.L = np.linalg.cholesky(self.C)\n\n    def sample_cmaes(self, num_samples, func):\n        z = np.random.randn(num_samples, self.dim)\n        Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n        samples = np.zeros((num_samples, self.dim))\n        for k in range(num_samples):\n            samples[k] = self.m + self.sigma0 * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n            samples[k] = np.clip(samples[k], func.bounds.lb, func.bounds.ub)\n        return samples\n\n\n    def update_cmaes(self, xmean):\n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (xmean - self.m) / self.sigma0\n        hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**2) / self.chiN < 1.4 + 2/(self.dim+1))\n        self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (xmean - self.m) / self.sigma0\n        y = xmean - self.m\n\n        self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])  + 0.01* np.eye(self.dim)\n\n        self.C = np.triu(self.C) + np.triu(self.C,1).T  # Enforce symmetry\n\n        try:\n            self.L = np.linalg.cholesky(self.C) # C = LL'\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n            self.L = np.linalg.cholesky(self.C) # C = LL'\n\n        self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.m = xmean\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.initialize_cmaes(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # CMA-ES orthogonal sampling for exploration\n                    x_trial = self.sample_cmaes(1, func)[0]\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                else:\n                    # DE mutation and crossover\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    x_trial = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x_trial[j] = x_mutated[j]\n\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                # Selection\n                if self.budget <= 0:\n                    break\n\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n            # CMA-ES update based on the best solutions from DE\n            idx = np.argsort(self.fitness)\n            xmean = np.sum(self.weights[:, None] * self.population[idx[:self.mu]], axis=0)\n            self.update_cmaes(xmean)\n\n            # Adaptive control of exploration probability\n            self.success_history.append(1 if self.f_opt < np.min(self.fitness) else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.exploration_prob *= 0.95  # Reduce exploration if successful\n            elif self.success_rate < 0.3:\n                self.exploration_prob *= 1.05  # Increase exploration if unsuccessful\n\n            self.exploration_prob = np.clip(self.exploration_prob, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.04419605845723913, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "446e0270-eb44-4d5e-8c15-c7e791e3f4a1", "fitness": 0.619400195290295, "name": "AdaptiveDECMAOrthogonalRestart", "description": "Integrates DE, CMA-ES with orthogonal sampling, and a restart mechanism based on stagnation detection for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMAOrthogonalRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, stagnation_threshold=1e-6, stagnation_iterations=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def orthogonal_sampling(self, n, k):\n        \"\"\"Generate an orthogonal matrix using the Gram-Schmidt process.\"\"\"\n        H = np.random.randn(n, k)\n        Q, _ = np.linalg.qr(H)\n        return Q\n\n    def initialize_cmaes(self, x_opt):\n        self.m = x_opt.copy() # Initialize mean\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES Initialization\n        self.initialize_cmaes(self.x_opt)\n\n        while self.budget > 0:\n            self.iteration += 1\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.last_improvement = self.iteration\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n            # Stagnation check and restart\n            if self.iteration - self.last_improvement > self.stagnation_iterations:\n                # Orthogonal sampling for restart\n                Q = self.orthogonal_sampling(self.dim, self.dim)\n                new_population = self.m + self.sigma0 * Q\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new population\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.dim\n\n                # Replace worst solutions with new solutions if they are better\n                worst_indices = np.argsort(self.fitness)[-self.dim:]\n                for j in range(self.dim):\n                    if new_fitness[j] < self.fitness[worst_indices[j]]:\n                        self.population[worst_indices[j]] = new_population[j]\n                        self.fitness[worst_indices[j]] = new_fitness[j]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[worst_indices[j]])\n                            self.archive_fitness.append(self.fitness[worst_indices[j]])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[worst_indices[j]] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[worst_indices[j]]\n                                self.archive_fitness[max_archive_index] = self.fitness[worst_indices[j]]\n\n                # Update best solution\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                    self.last_improvement = self.iteration\n                \n                self.initialize_cmaes(self.x_opt) # Reinitialize CMA-ES\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDECMAOrthogonalRestart scored 0.619 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c42887d7-326f-483b-b1b9-acb5d7852f43"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates DE, CMA-ES with orthogonal sampling, and a restart mechanism based on stagnation detection for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMAOrthogonalRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, stagnation_threshold=1e-6, stagnation_iterations=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def orthogonal_sampling(self, n, k):\n        \"\"\"Generate an orthogonal matrix using the Gram-Schmidt process.\"\"\"\n        H = np.random.randn(n, k)\n        Q, _ = np.linalg.qr(H)\n        return Q\n\n    def initialize_cmaes(self, x_opt):\n        self.m = x_opt.copy() # Initialize mean\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES Initialization\n        self.initialize_cmaes(self.x_opt)\n\n        while self.budget > 0:\n            self.iteration += 1\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.last_improvement = self.iteration\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n            # Stagnation check and restart\n            if self.iteration - self.last_improvement > self.stagnation_iterations:\n                # Orthogonal sampling for restart\n                Q = self.orthogonal_sampling(self.dim, self.dim)\n                new_population = self.m + self.sigma0 * Q\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new population\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.dim\n\n                # Replace worst solutions with new solutions if they are better\n                worst_indices = np.argsort(self.fitness)[-self.dim:]\n                for j in range(self.dim):\n                    if new_fitness[j] < self.fitness[worst_indices[j]]:\n                        self.population[worst_indices[j]] = new_population[j]\n                        self.fitness[worst_indices[j]] = new_fitness[j]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[worst_indices[j]])\n                            self.archive_fitness.append(self.fitness[worst_indices[j]])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[worst_indices[j]] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[worst_indices[j]]\n                                self.archive_fitness[max_archive_index] = self.fitness[worst_indices[j]]\n\n                # Update best solution\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                    self.last_improvement = self.iteration\n                \n                self.initialize_cmaes(self.x_opt) # Reinitialize CMA-ES\n                \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2958378706540169, 0.604054551459819, 0.5178034317020257, 0.8298827987526279, 0.6410863013022544, 0.6769765689781606, 0.49070373831199665, 0.531104246322158, 0.6286405661757781, 0.5259027882114833, 0.8374015935539616, 0.9926254619989384, 0.5242650799722155, 0.6335196191044663, 0.9039899841358081, 0.7083597519040444, 0.5109128477090896, 0.7901054730088322, 0.22465194187733217, 0.5201792906708913], "operator": "mutation", "theta_sampled": 0.2851182769579856, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "1c319cef-caa2-41bb-98b5-51a6bcd71c56", "fitness": 0.0, "name": "AdaptiveSwarmLocalSearch", "description": "A swarm-based algorithm that combines particle swarm optimization with a local search strategy, adaptively adjusting exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSwarmLocalSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.local_search_radius = local_search_radius\n        self.inertia = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.personal_best_positions = np.copy(self.swarm)\n        self.personal_best_values = np.array([np.inf] * self.swarm_size)\n\n        for i in range(self.swarm_size):\n            f = func(self.swarm[i])\n            self.eval_count += 1\n            if f < self.personal_best_values[i]:\n                self.personal_best_values[i] = f\n                self.personal_best_positions[i] = np.copy(self.swarm[i])\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = np.copy(self.swarm[i])\n\n    def local_search(self, func, x):\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n        \n        for _ in range(5): #small budget local search\n            neighbor = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        self.initialize_swarm(func)\n        \n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                      self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                      self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n                \n                # Update position\n                self.swarm[i] += self.velocities[i]\n                self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n                \n                #Local Search\n                f_local, x_local = self.local_search(func, self.swarm[i])\n                \n                # Evaluate new position (after local search)\n                \n                f = f_local\n                x = x_local\n                \n\n                # Update personal best\n                if f < self.personal_best_values[i]:\n                    self.personal_best_values[i] = f\n                    self.personal_best_positions[i] = np.copy(x)\n                    \n                    # Update global best\n                    if f < self.global_best_value:\n                        self.global_best_value = f\n                        self.global_best_position = np.copy(x)\n\n            if self.global_best_value < self.f_opt:\n                self.f_opt = self.global_best_value\n                self.x_opt = self.global_best_position\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveSwarmLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A swarm-based algorithm that combines particle swarm optimization with a local search strategy, adaptively adjusting exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSwarmLocalSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.local_search_radius = local_search_radius\n        self.inertia = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.personal_best_positions = np.copy(self.swarm)\n        self.personal_best_values = np.array([np.inf] * self.swarm_size)\n\n        for i in range(self.swarm_size):\n            f = func(self.swarm[i])\n            self.eval_count += 1\n            if f < self.personal_best_values[i]:\n                self.personal_best_values[i] = f\n                self.personal_best_positions[i] = np.copy(self.swarm[i])\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = np.copy(self.swarm[i])\n\n    def local_search(self, func, x):\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n        \n        for _ in range(5): #small budget local search\n            neighbor = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n        return best_f, best_x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        self.initialize_swarm(func)\n        \n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                      self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                      self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n                \n                # Update position\n                self.swarm[i] += self.velocities[i]\n                self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n                \n                #Local Search\n                f_local, x_local = self.local_search(func, self.swarm[i])\n                \n                # Evaluate new position (after local search)\n                \n                f = f_local\n                x = x_local\n                \n\n                # Update personal best\n                if f < self.personal_best_values[i]:\n                    self.personal_best_values[i] = f\n                    self.personal_best_positions[i] = np.copy(x)\n                    \n                    # Update global best\n                    if f < self.global_best_value:\n                        self.global_best_value = f\n                        self.global_best_position = np.copy(x)\n\n            if self.global_best_value < self.f_opt:\n                self.f_opt = self.global_best_value\n                self.x_opt = self.global_best_position\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.1982885471399196, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "28d168dc-9a2c-4c79-beb0-10783ed8190f", "fitness": 0.34127451145399657, "name": "CauchyMutationAdaptation", "description": "Population-based algorithm that dynamically adjusts mutation strength based on the population diversity and fitness improvement, using a Cauchy distribution for mutation.", "code": "import numpy as np\n\nclass CauchyMutationAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_mutation_scale = initial_mutation_scale\n        self.mutation_scale = initial_mutation_scale * np.ones(self.dim)\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Cauchy mutation with dynamic scaling\n                cauchy_sample = np.random.standard_cauchy(size=self.dim)\n                mutation = self.mutation_scale * cauchy_sample\n                mutated_individual = population[i] + mutation\n                \n                # Clip to bounds\n                mutated_individual = np.clip(mutated_individual, self.lb, self.ub)\n\n                f_mutated = func(mutated_individual)\n                self.budget -= 1\n\n                if f_mutated < fitness[i]:\n                    fitness[i] = f_mutated\n                    population[i] = mutated_individual\n\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_individual\n            \n            # Adjust mutation scale based on population diversity and fitness improvement\n            diversity = np.std(population, axis=0)\n            fitness_improvement = np.mean(fitness) - np.min(fitness)\n            \n            # Dynamically adjust the mutation scale based on diversity and improvement\n            if fitness_improvement > 0:\n                self.mutation_scale = 0.9 * self.mutation_scale + 0.1 * diversity # Reduce scale when improvement is present\n            else:\n                self.mutation_scale = 1.1 * self.mutation_scale  # Increase when no improvement\n            \n            # Ensure the mutation scale is within reasonable bounds\n            self.mutation_scale = np.clip(self.mutation_scale, 0.0001, 1.0)\n            \n            if self.budget <=0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm CauchyMutationAdaptation scored 0.341 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that dynamically adjusts mutation strength based on the population diversity and fitness improvement, using a Cauchy distribution for mutation.\n# Code:\n```python\nimport numpy as np\n\nclass CauchyMutationAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_mutation_scale = initial_mutation_scale\n        self.mutation_scale = initial_mutation_scale * np.ones(self.dim)\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Cauchy mutation with dynamic scaling\n                cauchy_sample = np.random.standard_cauchy(size=self.dim)\n                mutation = self.mutation_scale * cauchy_sample\n                mutated_individual = population[i] + mutation\n                \n                # Clip to bounds\n                mutated_individual = np.clip(mutated_individual, self.lb, self.ub)\n\n                f_mutated = func(mutated_individual)\n                self.budget -= 1\n\n                if f_mutated < fitness[i]:\n                    fitness[i] = f_mutated\n                    population[i] = mutated_individual\n\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_individual\n            \n            # Adjust mutation scale based on population diversity and fitness improvement\n            diversity = np.std(population, axis=0)\n            fitness_improvement = np.mean(fitness) - np.min(fitness)\n            \n            # Dynamically adjust the mutation scale based on diversity and improvement\n            if fitness_improvement > 0:\n                self.mutation_scale = 0.9 * self.mutation_scale + 0.1 * diversity # Reduce scale when improvement is present\n            else:\n                self.mutation_scale = 1.1 * self.mutation_scale  # Increase when no improvement\n            \n            # Ensure the mutation scale is within reasonable bounds\n            self.mutation_scale = np.clip(self.mutation_scale, 0.0001, 1.0)\n            \n            if self.budget <=0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1520863572651857, 0.20313462230328783, 0.30987723244482934, 0.2778639113210447, 0.2586014639261761, 0.3716130780011667, 0.28855187301078, 0.2903924932510308, 0.25283782851494074, 0.19511421688044972, 0.3001496499635308, 0.989969229143932, 0.2760049898231547, 0.2789013642953513, 0.6809889783630849, 0.33748440768912413, 0.26537035313558976, 0.43823857624743756, 0.186844569038622, 0.4714650344612119], "operator": "random_new", "theta_sampled": 0.17826927091105094, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "58a34c51-cba9-40f5-b879-1b9ba60bdca0", "fitness": 0.3010647304324563, "name": "SwarmDE", "description": "A swarm-based approach that combines particle swarm optimization with a mutation operator inspired by differential evolution to enhance exploration and escape local optima.", "code": "import numpy as np\n\nclass SwarmDE:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))  # Initialize velocities\n        personal_best_positions = swarm.copy()\n        personal_best_values = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_values)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n\n        eval_count = self.swarm_size # Account for initial evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity (PSO component)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n\n                # Update position\n                new_position = swarm[i] + velocities[i]\n                \n                # Apply bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # DE mutation\n                if np.random.rand() < self.cr:\n                  idxs = np.random.choice(self.swarm_size, 3, replace=False)\n                  x1, x2, x3 = swarm[idxs[0]], swarm[idxs[1]], swarm[idxs[2]]\n                  mutated_vector = x1 + self.f * (x2 - x3)\n                  mutated_vector = np.clip(mutated_vector, func.bounds.lb, func.bounds.ub)\n                  \n                  j_rand = np.random.randint(self.dim)\n                  for j in range(self.dim):\n                      if np.random.rand() < self.cr or j == j_rand:\n                          new_position[j] = mutated_vector[j]\n                      \n                \n                new_value = func(new_position)\n                eval_count += 1\n\n                if new_value < personal_best_values[i]:\n                    personal_best_values[i] = new_value\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_value < global_best_value:\n                        global_best_value = new_value\n                        global_best_position = new_position.copy()\n\n                swarm[i] = new_position # update swarm position\n                \n                if eval_count >= self.budget:\n                    break\n\n\n        return global_best_value, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SwarmDE scored 0.301 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A swarm-based approach that combines particle swarm optimization with a mutation operator inspired by differential evolution to enhance exploration and escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass SwarmDE:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))  # Initialize velocities\n        personal_best_positions = swarm.copy()\n        personal_best_values = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_values)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n\n        eval_count = self.swarm_size # Account for initial evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity (PSO component)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n\n                # Update position\n                new_position = swarm[i] + velocities[i]\n                \n                # Apply bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # DE mutation\n                if np.random.rand() < self.cr:\n                  idxs = np.random.choice(self.swarm_size, 3, replace=False)\n                  x1, x2, x3 = swarm[idxs[0]], swarm[idxs[1]], swarm[idxs[2]]\n                  mutated_vector = x1 + self.f * (x2 - x3)\n                  mutated_vector = np.clip(mutated_vector, func.bounds.lb, func.bounds.ub)\n                  \n                  j_rand = np.random.randint(self.dim)\n                  for j in range(self.dim):\n                      if np.random.rand() < self.cr or j == j_rand:\n                          new_position[j] = mutated_vector[j]\n                      \n                \n                new_value = func(new_position)\n                eval_count += 1\n\n                if new_value < personal_best_values[i]:\n                    personal_best_values[i] = new_value\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_value < global_best_value:\n                        global_best_value = new_value\n                        global_best_position = new_position.copy()\n\n                swarm[i] = new_position # update swarm position\n                \n                if eval_count >= self.budget:\n                    break\n\n\n        return global_best_value, global_best_position\n```", "aucs": [0.12289770603081573, 0.20233989294809307, 0.2753121503270025, 0.2460530913646829, 0.23209611978116174, 0.257857031872159, 0.2412034412664945, 0.20371673316644046, 0.20481206987125045, 0.17592822571657785, 0.2711290415821328, 0.9932728679042685, 0.25590610566548133, 0.24109601391296653, 0.6609163754256246, 0.28457921880830195, 0.23265383813286422, 0.29207300968991234, 0.16448454302849846, 0.462967132154397], "operator": "random_new", "theta_sampled": 0.34138200864117313, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "e0c1714c-e69a-412f-9000-3bdc5a5d7f55", "fitness": 0.0, "name": "AdaptiveDECMAOrthogonalRestartSelfAdaptive", "description": "Combines Adaptive DE with CMA-ES using orthogonal design for population initialization and restart, alongside a self-adaptive mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDECMAOrthogonalRestartSelfAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, stagnation_threshold=1e-6, stagnation_iterations=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        \n        # Adaptive F initialization\n        self.F = np.random.uniform(0.1, 0.9, size=self.pop_size)  # Initialize F values for each individual\n        self.F_memory = np.zeros(self.pop_size)\n\n    def orthogonal_sampling(self, n, k):\n        \"\"\"Generate an orthogonal matrix using the Gram-Schmidt process.\"\"\"\n        H = np.random.randn(n, k)\n        Q, _ = np.linalg.qr(H)\n        return Q\n\n    def initialize_cmaes(self, x_opt):\n        self.m = x_opt.copy() # Initialize mean\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def __call__(self, func):\n        # Initial population with orthogonal sampling\n        Q = self.orthogonal_sampling(self.pop_size, self.dim)\n        self.population = self.m + self.sigma0 * Q\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES Initialization\n        self.initialize_cmaes(self.x_opt)\n\n        while self.budget > 0:\n            self.iteration += 1\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        # Success\n                        self.F_memory[i] = self.F[i]  # Store successful F value\n                        self.F[i] = np.random.normal(0.5, 0.3) # Generate new value\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        # Failure, readjust F slightly\n                        self.F[i] = np.random.choice([self.F[i] * 0.9, self.F[i] * 1.1])\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        # Success\n                        self.F_memory[i] = self.F[i]  # Store successful F value\n                        self.F[i] = np.random.normal(0.5, 0.3) # Generate new value\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        # Failure, readjust F slightly\n                        self.F[i] = np.random.choice([self.F[i] * 0.9, self.F[i] * 1.1])\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.last_improvement = self.iteration\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n            # Stagnation check and restart\n            if self.iteration - self.last_improvement > self.stagnation_iterations:\n                # Orthogonal sampling for restart\n                Q = self.orthogonal_sampling(self.dim, self.dim)\n                new_population = self.m + self.sigma0 * Q\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new population\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.dim\n\n                # Replace worst solutions with new solutions if they are better\n                worst_indices = np.argsort(self.fitness)[-self.dim:]\n                for j in range(self.dim):\n                    if new_fitness[j] < self.fitness[worst_indices[j]]:\n                        self.population[worst_indices[j]] = new_population[j]\n                        self.fitness[worst_indices[j]] = new_fitness[j]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[worst_indices[j]])\n                            self.archive_fitness.append(self.fitness[worst_indices[j]])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[worst_indices[j]] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[worst_indices[j]]\n                                self.archive_fitness[max_archive_index] = self.fitness[worst_indices[j]]\n\n                # Update best solution\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                    self.last_improvement = self.iteration\n                \n                self.initialize_cmaes(self.x_opt) # Reinitialize CMA-ES\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: 'AdaptiveDECMAOrthogonalRestartSelfAdaptive' object has no attribute 'm'", "parent_ids": ["446e0270-eb44-4d5e-8c15-c7e791e3f4a1"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Adaptive DE with CMA-ES using orthogonal design for population initialization and restart, alongside a self-adaptive mutation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMAOrthogonalRestartSelfAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, stagnation_threshold=1e-6, stagnation_iterations=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        \n        # Adaptive F initialization\n        self.F = np.random.uniform(0.1, 0.9, size=self.pop_size)  # Initialize F values for each individual\n        self.F_memory = np.zeros(self.pop_size)\n\n    def orthogonal_sampling(self, n, k):\n        \"\"\"Generate an orthogonal matrix using the Gram-Schmidt process.\"\"\"\n        H = np.random.randn(n, k)\n        Q, _ = np.linalg.qr(H)\n        return Q\n\n    def initialize_cmaes(self, x_opt):\n        self.m = x_opt.copy() # Initialize mean\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def __call__(self, func):\n        # Initial population with orthogonal sampling\n        Q = self.orthogonal_sampling(self.pop_size, self.dim)\n        self.population = self.m + self.sigma0 * Q\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.last_improvement = 0\n        self.iteration = 0\n\n        # CMA-ES Initialization\n        self.initialize_cmaes(self.x_opt)\n\n        while self.budget > 0:\n            self.iteration += 1\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        # Success\n                        self.F_memory[i] = self.F[i]  # Store successful F value\n                        self.F[i] = np.random.normal(0.5, 0.3) # Generate new value\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        # Failure, readjust F slightly\n                        self.F[i] = np.random.choice([self.F[i] * 0.9, self.F[i] * 1.1])\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        # Success\n                        self.F_memory[i] = self.F[i]  # Store successful F value\n                        self.F[i] = np.random.normal(0.5, 0.3) # Generate new value\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        # Failure, readjust F slightly\n                        self.F[i] = np.random.choice([self.F[i] * 0.9, self.F[i] * 1.1])\n                        self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    self.last_improvement = self.iteration\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n            # Stagnation check and restart\n            if self.iteration - self.last_improvement > self.stagnation_iterations:\n                # Orthogonal sampling for restart\n                Q = self.orthogonal_sampling(self.dim, self.dim)\n                new_population = self.m + self.sigma0 * Q\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new population\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.dim\n\n                # Replace worst solutions with new solutions if they are better\n                worst_indices = np.argsort(self.fitness)[-self.dim:]\n                for j in range(self.dim):\n                    if new_fitness[j] < self.fitness[worst_indices[j]]:\n                        self.population[worst_indices[j]] = new_population[j]\n                        self.fitness[worst_indices[j]] = new_fitness[j]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[worst_indices[j]])\n                            self.archive_fitness.append(self.fitness[worst_indices[j]])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[worst_indices[j]] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[worst_indices[j]]\n                                self.archive_fitness[max_archive_index] = self.fitness[worst_indices[j]]\n\n                # Update best solution\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                    self.last_improvement = self.iteration\n                \n                self.initialize_cmaes(self.x_opt) # Reinitialize CMA-ES\n                \n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.054509453519125894, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "e344beb5-51ef-4542-b665-db610517aeb4", "fitness": 0.0, "name": "HybridDEPSO", "description": "Population-based algorithm that uses a combination of differential evolution and particle swarm optimization with velocity clamping and adaptive parameter control based on the fitness landscape.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.5, pso_inertia=0.7, pso_c1=1.5, pso_c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_inertia = pso_inertia\n        self.pso_c1 = pso_c1\n        self.pso_c2 = pso_c2\n        self.pop = None\n        self.vel = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.personal_best_fitness = None\n        self.personal_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.vel = np.zeros_like(self.pop)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.personal_best_position = np.copy(self.pop)\n\n        best_index = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[best_index]\n        self.best_position = np.copy(self.pop[best_index])\n\n    def differential_evolution(self, func, lb, ub):\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Apply DE with a probability\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                if i in idxs:\n                    while i in idxs:\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                \n                v_trial = self.pop[i] + self.de_f * (x_r2 - x_r3)\n                \n                trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim) \n                for j in range(self.dim):\n                    if np.random.rand() < self.de_cr or j == j_rand:\n                        trial[j] = v_trial[j]\n\n                trial = np.clip(trial, lb, ub)\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_position[i] = np.copy(trial)\n\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_position = np.copy(trial)\n\n    def particle_swarm_optimization(self, func, lb, ub):\n        v_max = 0.2 * (ub - lb) # velocity clamping\n\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Apply PSO with a probability\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.vel[i] = self.pso_inertia * self.vel[i] + \\\n                              self.pso_c1 * r1 * (self.personal_best_position[i] - self.pop[i]) + \\\n                              self.pso_c2 * r2 * (self.best_position - self.pop[i])\n                \n                # Velocity clamping\n                self.vel[i] = np.clip(self.vel[i], -v_max, v_max)\n\n                self.pop[i] += self.vel[i]\n                self.pop[i] = np.clip(self.pop[i], lb, ub)\n                \n                f = func(self.pop[i])\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    \n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_position[i] = np.copy(self.pop[i])\n                    \n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_position = np.copy(self.pop[i])\n\n    def adaptive_parameter_control(self):\n        # Simple adaptive parameter control based on fitness improvement\n        if np.random.rand() < 0.1: # Apply adaptation with probability 0.1\n            if self.eval_count > self.budget * 0.25:\n              self.de_cr *= 0.95\n              self.de_f *= 1.05\n            if self.eval_count > self.budget * 0.5:\n                self.pso_inertia *= 0.95\n                self.pso_c1 *= 1.02\n                self.pso_c2 *= 1.02\n\n            self.de_cr = np.clip(self.de_cr, 0.1, 0.9)\n            self.de_f = np.clip(self.de_f, 0.1, 2.0)\n            self.pso_inertia = np.clip(self.pso_inertia, 0.1, 1.0)\n            self.pso_c1 = np.clip(self.pso_c1, 1.0, 2.5)\n            self.pso_c2 = np.clip(self.pso_c2, 1.0, 2.5)\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.particle_swarm_optimization(func, lb, ub)\n            self.adaptive_parameter_control()\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridDEPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that uses a combination of differential evolution and particle swarm optimization with velocity clamping and adaptive parameter control based on the fitness landscape.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.5, pso_inertia=0.7, pso_c1=1.5, pso_c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_inertia = pso_inertia\n        self.pso_c1 = pso_c1\n        self.pso_c2 = pso_c2\n        self.pop = None\n        self.vel = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.personal_best_fitness = None\n        self.personal_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.vel = np.zeros_like(self.pop)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.personal_best_position = np.copy(self.pop)\n\n        best_index = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[best_index]\n        self.best_position = np.copy(self.pop[best_index])\n\n    def differential_evolution(self, func, lb, ub):\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Apply DE with a probability\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                if i in idxs:\n                    while i in idxs:\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                \n                v_trial = self.pop[i] + self.de_f * (x_r2 - x_r3)\n                \n                trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim) \n                for j in range(self.dim):\n                    if np.random.rand() < self.de_cr or j == j_rand:\n                        trial[j] = v_trial[j]\n\n                trial = np.clip(trial, lb, ub)\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_position[i] = np.copy(trial)\n\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_position = np.copy(trial)\n\n    def particle_swarm_optimization(self, func, lb, ub):\n        v_max = 0.2 * (ub - lb) # velocity clamping\n\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Apply PSO with a probability\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.vel[i] = self.pso_inertia * self.vel[i] + \\\n                              self.pso_c1 * r1 * (self.personal_best_position[i] - self.pop[i]) + \\\n                              self.pso_c2 * r2 * (self.best_position - self.pop[i])\n                \n                # Velocity clamping\n                self.vel[i] = np.clip(self.vel[i], -v_max, v_max)\n\n                self.pop[i] += self.vel[i]\n                self.pop[i] = np.clip(self.pop[i], lb, ub)\n                \n                f = func(self.pop[i])\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    \n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_position[i] = np.copy(self.pop[i])\n                    \n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_position = np.copy(self.pop[i])\n\n    def adaptive_parameter_control(self):\n        # Simple adaptive parameter control based on fitness improvement\n        if np.random.rand() < 0.1: # Apply adaptation with probability 0.1\n            if self.eval_count > self.budget * 0.25:\n              self.de_cr *= 0.95\n              self.de_f *= 1.05\n            if self.eval_count > self.budget * 0.5:\n                self.pso_inertia *= 0.95\n                self.pso_c1 *= 1.02\n                self.pso_c2 *= 1.02\n\n            self.de_cr = np.clip(self.de_cr, 0.1, 0.9)\n            self.de_f = np.clip(self.de_f, 0.1, 2.0)\n            self.pso_inertia = np.clip(self.pso_inertia, 0.1, 1.0)\n            self.pso_c1 = np.clip(self.pso_c1, 1.0, 2.5)\n            self.pso_c2 = np.clip(self.pso_c2, 1.0, 2.5)\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.particle_swarm_optimization(func, lb, ub)\n            self.adaptive_parameter_control()\n\n\n        return self.best_fitness, self.best_position\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.3052006502883383, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "dd6c5569-da2e-4793-8d27-51c244ccabf4", "fitness": 0.0, "name": "AdaptiveDECMAImproved", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation and population re-sampling based on fitness improvements to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMAImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, resampling_factor = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.resampling_factor = resampling_factor\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy() # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n            # Resampling based on stagnation\n            if np.random.rand() < self.resampling_factor:\n                num_resample = int(self.pop_size * 0.1)\n                idx_worst = np.argsort(self.fitness)[-num_resample:]\n                self.population[idx_worst] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_resample, self.dim))\n                self.fitness[idx_worst] = np.array([func(x) for x in self.population[idx_worst]])\n                self.budget -= num_resample\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDECMAImproved scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c42887d7-326f-483b-b1b9-acb5d7852f43"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation and population re-sampling based on fitness improvements to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMAImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, cs_factor = 0.1, cc_factor = 0.1, c_rank_one = 0.25, resampling_factor = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.resampling_factor = resampling_factor\n\n        # CMA-ES parameters\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5) * cs_factor\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim) * cc_factor\n        self.c_rank_one = c_rank_one # Using rank-one update instead of full covariance matrix update\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.m = self.x_opt.copy() # Initialize mean with best DE solution\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # DE Mutation and Crossover\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # CMA-ES sampling for mutation vector\n                z = np.random.normal(0, 1, size=self.dim)\n                try:\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim)\n                    L = np.linalg.cholesky(self.C)\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3) + self.sigma * (L @ z)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # CMA-ES update\n            idx = np.argsort(self.fitness)\n            x = self.population[idx]\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Update covariance matrix using rank-one update\n            y = (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_rank_one) * self.C + self.c_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n\n            # Resampling based on stagnation\n            if np.random.rand() < self.resampling_factor:\n                num_resample = int(self.pop_size * 0.1)\n                idx_worst = np.argsort(self.fitness)[-num_resample:]\n                self.population[idx_worst] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_resample, self.dim))\n                self.fitness[idx_worst] = np.array([func(x) for x in self.population[idx_worst]])\n                self.budget -= num_resample\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": -0.12182922770493179, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "b6acc09c-f6e5-4859-bbb6-bbc68d94295a", "fitness": 0.6655033487028944, "name": "HybridDECMO", "description": "Combines Adaptive DE's mutation and archive with Adaptive CMA-ES's covariance adaptation and orthogonal sampling for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = self.pop_size\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling based on CMA-ES\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n            # Incorporate DE mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:  # Apply DE mutation with a probability\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = x[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x[i][j] = x_mutated[j]\n                    x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub) # clip again after crossover\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n                \n                # Update archive\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.x_opt)\n                    self.archive_fitness.append(self.f_opt)\n                else:\n                    # Replace the worst archived solution\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.f_opt < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.x_opt\n                        self.archive_fitness[max_archive_index] = self.f_opt\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm HybridDECMO scored 0.666 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive DE's mutation and archive with Adaptive CMA-ES's covariance adaptation and orthogonal sampling for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = self.pop_size\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling based on CMA-ES\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n            # Incorporate DE mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:  # Apply DE mutation with a probability\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = x[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x[i][j] = x_mutated[j]\n                    x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub) # clip again after crossover\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n                \n                # Update archive\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.x_opt)\n                    self.archive_fitness.append(self.f_opt)\n                else:\n                    # Replace the worst archived solution\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.f_opt < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.x_opt\n                        self.archive_fitness[max_archive_index] = self.f_opt\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.22769526237907134, 0.36505388702445385, 0.8637744845211055, 0.14617562686108465, 0.9133652145891847, 0.9310797627807724, 0.30325306881415204, 0.8740913910862456, 0.8980925505398644, 0.19836524572087477, 0.8983642339202512, 0.9945693618079527, 0.2569396630418067, 0.874879359804072, 0.7914967522981716, 0.7615925550775158, 0.7442141093149935, 0.926914040679972, 0.8204230987608881, 0.5197273050354558], "operator": "crossover", "theta_sampled": 0.4077390033856362, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "9bc86d53-5bd7-4696-8204-e57559760cdb", "fitness": 0.2539521172058423, "name": "HybridDECMAS", "description": "Combines Adaptive DE's mutation/crossover with Adaptive CMA-ES's covariance matrix adaptation and orthogonal sampling for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        used_budget += self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling around current population\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                # DE mutation/crossover integrated here\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[k])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                x[k] = self.m + self.sigma * (Q @ (x_trial - self.m))  # Rotate and scale using DE trial point\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            self.budget -= self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            \n            # Stochastic ranking and archive updating (using best \"x\" values after CMA-ES rotation)\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and f[i] <= 0) or (self.fitness[i] > 0 and f[i] > 0):\n                    if f[i] < self.fitness[i]:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm HybridDECMAS scored 0.254 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive DE's mutation/crossover with Adaptive CMA-ES's covariance matrix adaptation and orthogonal sampling for robust exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        used_budget += self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling around current population\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                # DE mutation/crossover integrated here\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[k])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                x[k] = self.m + self.sigma * (Q @ (x_trial - self.m))  # Rotate and scale using DE trial point\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            self.budget -= self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            \n            # Stochastic ranking and archive updating (using best \"x\" values after CMA-ES rotation)\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and f[i] <= 0) or (self.fitness[i] > 0 and f[i] > 0):\n                    if f[i] < self.fitness[i]:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.09309424046617276, 0.13405847233501733, 0.21726964536758642, 0.16963597824052978, 0.15224797448182503, 0.18320354565679686, 0.20398008106414034, 0.1875696842722374, 0.17895400423485774, 0.14064878425995708, 0.17865683384535747, 0.9934399234663003, 0.217155548510233, 0.2110922795147726, 0.550263181578393, 0.25732096985032626, 0.190162817812635, 0.24605249193379886, 0.15317496273043252, 0.42106092449547594], "operator": "crossover", "theta_sampled": 0.09851125103956977, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "c42ea0f6-8138-4442-bf8b-9607f6682e1f", "fitness": 0.0, "name": "AdaptiveShrinkingProbabilisticSearch", "description": "Population-based algorithm that combines a shrinking search space with a probabilistic selection of solutions based on their fitness, promoting exploration in early stages and exploitation in later stages.", "code": "import numpy as np\n\nclass AdaptiveShrinkingProbabilisticSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, shrinking_rate=0.99, initial_exploration_probability=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.shrinking_rate = shrinking_rate\n        self.initial_exploration_probability = initial_exploration_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        current_lb = lb\n        current_ub = ub\n        exploration_probability = self.initial_exploration_probability\n\n        while self.budget > 0:\n            # Probabilistic selection based on fitness\n            normalized_fitness = (np.max(fitness) - fitness) / (np.max(fitness) - np.min(fitness) + 1e-8) # Avoid division by zero\n            probabilities = normalized_fitness / np.sum(normalized_fitness)\n\n            # Generate new solutions around selected individuals\n            new_population = []\n            for i in range(self.population_size):\n                if self.budget <= 0:\n                    break\n\n                # Exploration vs Exploitation\n                if np.random.rand() < exploration_probability:\n                    # Exploration: Random sampling within the shrinking bounds\n                    x = np.random.uniform(current_lb, current_ub, size=self.dim)\n                    new_population.append(x)\n                else:\n                    # Exploitation: Sample around a selected individual\n                    selected_index = np.random.choice(self.population_size, p=probabilities)\n                    selected_solution = population[selected_index]\n                    # Sample from a smaller hypercube centered on the selected solution\n                    width = (current_ub - current_lb) * 0.1\n                    lower_bound = np.maximum(lb, selected_solution - width/2)\n                    upper_bound = np.minimum(ub, selected_solution + width/2)\n                    x = np.random.uniform(lower_bound, upper_bound, size=self.dim)\n                    new_population.append(x)\n                \n                f = func(x)\n                self.budget -= 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                fitness = np.append(fitness,f)\n                population = np.vstack((population,x))\n\n            \n            # Update best solution\n            min_index = np.argmin(fitness)\n            self.f_opt = fitness[min_index]\n            self.x_opt = population[min_index]\n\n\n            # Shrink the search space\n            current_lb = self.x_opt - self.shrinking_rate * (ub - lb) / 2\n            current_ub = self.x_opt + self.shrinking_rate * (ub - lb) / 2\n            current_lb = np.maximum(current_lb, lb)\n            current_ub = np.minimum(current_ub, ub)\n            \n            # Reduce exploration probability over time\n            exploration_probability *= self.shrinking_rate # Gradual decrease\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: 'a' and 'p' must have same size", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines a shrinking search space with a probabilistic selection of solutions based on their fitness, promoting exploration in early stages and exploitation in later stages.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveShrinkingProbabilisticSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, shrinking_rate=0.99, initial_exploration_probability=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.shrinking_rate = shrinking_rate\n        self.initial_exploration_probability = initial_exploration_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        current_lb = lb\n        current_ub = ub\n        exploration_probability = self.initial_exploration_probability\n\n        while self.budget > 0:\n            # Probabilistic selection based on fitness\n            normalized_fitness = (np.max(fitness) - fitness) / (np.max(fitness) - np.min(fitness) + 1e-8) # Avoid division by zero\n            probabilities = normalized_fitness / np.sum(normalized_fitness)\n\n            # Generate new solutions around selected individuals\n            new_population = []\n            for i in range(self.population_size):\n                if self.budget <= 0:\n                    break\n\n                # Exploration vs Exploitation\n                if np.random.rand() < exploration_probability:\n                    # Exploration: Random sampling within the shrinking bounds\n                    x = np.random.uniform(current_lb, current_ub, size=self.dim)\n                    new_population.append(x)\n                else:\n                    # Exploitation: Sample around a selected individual\n                    selected_index = np.random.choice(self.population_size, p=probabilities)\n                    selected_solution = population[selected_index]\n                    # Sample from a smaller hypercube centered on the selected solution\n                    width = (current_ub - current_lb) * 0.1\n                    lower_bound = np.maximum(lb, selected_solution - width/2)\n                    upper_bound = np.minimum(ub, selected_solution + width/2)\n                    x = np.random.uniform(lower_bound, upper_bound, size=self.dim)\n                    new_population.append(x)\n                \n                f = func(x)\n                self.budget -= 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                fitness = np.append(fitness,f)\n                population = np.vstack((population,x))\n\n            \n            # Update best solution\n            min_index = np.argmin(fitness)\n            self.f_opt = fitness[min_index]\n            self.x_opt = population[min_index]\n\n\n            # Shrink the search space\n            current_lb = self.x_opt - self.shrinking_rate * (ub - lb) / 2\n            current_ub = self.x_opt + self.shrinking_rate * (ub - lb) / 2\n            current_lb = np.maximum(current_lb, lb)\n            current_ub = np.minimum(current_ub, ub)\n            \n            # Reduce exploration probability over time\n            exploration_probability *= self.shrinking_rate # Gradual decrease\n            \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.4260007646347035, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "fc8a9392-5503-4b2a-9d5a-8f126861fd20", "fitness": 0.7033439580123837, "name": "HybridDECMO", "description": "Combines Adaptive DE's mutation and selection with Adaptive CMA-ES's covariance matrix adaptation and step size control for a more robust and efficient search.", "code": "import numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = 0.1  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i] # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDECMO scored 0.703 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive DE's mutation and selection with Adaptive CMA-ES's covariance matrix adaptation and step size control for a more robust and efficient search.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = 0.1  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i] # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.35549649720651944, 0.6517926425943088, 0.6970108719186554, 0.8508717236305496, 0.7588036320497829, 0.7800805634700985, 0.6360444376482468, 0.6602052794980902, 0.7317688647665717, 0.7361298687373188, 0.8632470514681772, 0.9996512944379186, 0.6185648448133556, 0.7421845520817449, 0.9172430280794013, 0.7758299459806625, 0.6352427467997834, 0.8512024797335436, 0.27517626387313354, 0.5303325714598107], "operator": "crossover", "theta_sampled": 0.23795087904320145, "reward": 0.0007702283652543107, "generation": 6}, "task_prompt": ""}
{"id": "494b9141-50ab-48d3-94ed-81751e7915dd", "fitness": 0.7022942940805035, "name": "AdaptiveHybridDECMO", "description": "Combines orthogonal sampling, differential evolution with adaptive parameters, CMA-ES-like covariance matrix adaptation, and restart mechanism based on stagnation detection for robust black box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, restart_trigger=1e-9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n        self.restart_trigger = restart_trigger\n        self.last_improvement = 0\n        self.stagnation_counter = 0\n        self.F_adaptation_rate = 0.1\n        self.CR_adaptation_rate = 0.1\n        self.F_memory = []\n        self.CR_memory = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def restart(self, func):\n        # Restart CMA-ES-related variables\n        self.m = self.x_opt.copy()  # Initialize mean with the best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.initialize_population(func)\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population(func)\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = self.pop_size\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling based on CMA-ES\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n            # Incorporate DE mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:  # Apply DE mutation with a probability\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = x[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x[i][j] = x_mutated[j]\n                    x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub) # clip again after crossover\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                delta_f = abs(f[0] - self.f_opt)\n                if delta_f < self.restart_trigger:\n                    self.stagnation_counter +=1\n                else:\n                    self.stagnation_counter = 0\n                \n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n                self.last_improvement = used_budget  # Record when the last improvement occurred\n\n                # Update archive\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.x_opt)\n                    self.archive_fitness.append(self.f_opt)\n                else:\n                    # Replace the worst archived solution\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.f_opt < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.x_opt\n                        self.archive_fitness[max_archive_index] = self.f_opt\n            else:\n                self.stagnation_counter +=1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n            # Adapt F and CR\n            if np.random.rand() < self.F_adaptation_rate:\n                new_F = np.random.normal(0.5, 0.3)\n                new_F = np.clip(new_F, 0.1, 0.9)\n                self.F = new_F\n                self.F_memory.append(self.F)\n                if len(self.F_memory) > 20:\n                    self.F_memory.pop(0)\n\n            if np.random.rand() < self.CR_adaptation_rate:\n                new_CR = np.random.normal(0.9, 0.2)\n                new_CR = np.clip(new_CR, 0.1, 1.0)\n                self.CR = new_CR\n                self.CR_memory.append(self.CR)\n                if len(self.CR_memory) > 20:\n                    self.CR_memory.pop(0)\n            \n            # Restart mechanism based on stagnation\n            if self.stagnation_counter > 50 * self.dim:\n                self.restart(func)\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridDECMO scored 0.702 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b6acc09c-f6e5-4859-bbb6-bbc68d94295a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines orthogonal sampling, differential evolution with adaptive parameters, CMA-ES-like covariance matrix adaptation, and restart mechanism based on stagnation detection for robust black box optimization.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, restart_trigger=1e-9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n        self.restart_trigger = restart_trigger\n        self.last_improvement = 0\n        self.stagnation_counter = 0\n        self.F_adaptation_rate = 0.1\n        self.CR_adaptation_rate = 0.1\n        self.F_memory = []\n        self.CR_memory = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def restart(self, func):\n        # Restart CMA-ES-related variables\n        self.m = self.x_opt.copy()  # Initialize mean with the best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.initialize_population(func)\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population(func)\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best solution found so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = self.pop_size\n        successes = 0\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling based on CMA-ES\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n            # Incorporate DE mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:  # Apply DE mutation with a probability\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = x[idxs]\n\n                    # Add archive member with probability\n                    if np.random.rand() < 0.1 and len(self.archive) > 0:\n                        x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x[i][j] = x_mutated[j]\n                    x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub) # clip again after crossover\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < self.f_opt:\n                delta_f = abs(f[0] - self.f_opt)\n                if delta_f < self.restart_trigger:\n                    self.stagnation_counter +=1\n                else:\n                    self.stagnation_counter = 0\n                \n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n                self.last_improvement = used_budget  # Record when the last improvement occurred\n\n                # Update archive\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.x_opt)\n                    self.archive_fitness.append(self.f_opt)\n                else:\n                    # Replace the worst archived solution\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.f_opt < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.x_opt\n                        self.archive_fitness[max_archive_index] = self.f_opt\n            else:\n                self.stagnation_counter +=1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n            # Adapt F and CR\n            if np.random.rand() < self.F_adaptation_rate:\n                new_F = np.random.normal(0.5, 0.3)\n                new_F = np.clip(new_F, 0.1, 0.9)\n                self.F = new_F\n                self.F_memory.append(self.F)\n                if len(self.F_memory) > 20:\n                    self.F_memory.pop(0)\n\n            if np.random.rand() < self.CR_adaptation_rate:\n                new_CR = np.random.normal(0.9, 0.2)\n                new_CR = np.clip(new_CR, 0.1, 1.0)\n                self.CR = new_CR\n                self.CR_memory.append(self.CR)\n                if len(self.CR_memory) > 20:\n                    self.CR_memory.pop(0)\n            \n            # Restart mechanism based on stagnation\n            if self.stagnation_counter > 50 * self.dim:\n                self.restart(func)\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2106075287571263, 0.7129688256382166, 0.8757320833856608, 0.9576903486824504, 0.9171140249027803, 0.9087948755570928, 0.30317533713178646, 0.8862041805844147, 0.8867146159465972, 0.24152748603382035, 0.921064802057903, 0.9976486625954244, 0.27126484936652984, 0.8638501024055556, 0.7972617126259745, 0.4120218911045709, 0.7265291988734179, 0.9331799345675037, 0.7052948026398301, 0.5172406187534138], "operator": "mutation", "theta_sampled": 0.24860551139924503, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "c9f7e5ac-738e-4b6a-bc96-d08de03ea293", "fitness": 0.0, "name": "GradientEnhancedDifferentialEvolution", "description": "Population-based algorithm that combines local search with adaptive mutation and crossover, focusing on gradient-based exploration within a neighborhood.", "code": "import numpy as np\n\nclass GradientEnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9, lr=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.lr = lr # Learning rate for gradient descent\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Gradient-based Local Search\n                if np.random.rand() < 0.1:  # Apply local search with small probability\n                    # Numerical gradient calculation\n                    h = 1e-5\n                    gradient = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        x_plus_h = trial.copy()\n                        x_minus_h = trial.copy()\n                        x_plus_h[j] += h\n                        x_minus_h[j] -= h\n                        x_plus_h = np.clip(x_plus_h, func.bounds.lb, func.bounds.ub)\n                        x_minus_h = np.clip(x_minus_h, func.bounds.lb, func.bounds.ub)\n                        \n                        if self.budget >=2 :\n                          gradient[j] = (func(x_plus_h) - func(x_minus_h)) / (2 * h)\n                          self.budget -= 2\n                        else:\n                          gradient = np.zeros(self.dim) # terminate local search if not enough budget\n\n                    trial = trial - self.lr * gradient\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub) # Clip back to bounds\n                    \n                    \n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1 # Update Budget\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm GradientEnhancedDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines local search with adaptive mutation and crossover, focusing on gradient-based exploration within a neighborhood.\n# Code: \n```python\nimport numpy as np\n\nclass GradientEnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9, lr=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.lr = lr # Learning rate for gradient descent\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Gradient-based Local Search\n                if np.random.rand() < 0.1:  # Apply local search with small probability\n                    # Numerical gradient calculation\n                    h = 1e-5\n                    gradient = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        x_plus_h = trial.copy()\n                        x_minus_h = trial.copy()\n                        x_plus_h[j] += h\n                        x_minus_h[j] -= h\n                        x_plus_h = np.clip(x_plus_h, func.bounds.lb, func.bounds.ub)\n                        x_minus_h = np.clip(x_minus_h, func.bounds.lb, func.bounds.ub)\n                        \n                        if self.budget >=2 :\n                          gradient[j] = (func(x_plus_h) - func(x_minus_h)) / (2 * h)\n                          self.budget -= 2\n                        else:\n                          gradient = np.zeros(self.dim) # terminate local search if not enough budget\n\n                    trial = trial - self.lr * gradient\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub) # Clip back to bounds\n                    \n                    \n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1 # Update Budget\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.06638810989141346, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "f1d36729-5f90-45d7-8746-24aa6112ca72", "fitness": 0.6490270082538346, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with aging population and self-adaptive parameters, prioritizing exploration in early stages and exploitation later.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9 # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate  # Rate at which individuals are replaced with random ones\n        self.population_age = np.zeros(self.pop_size)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Adapt F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)  # Self-adaptive F\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)  # Self-adaptive CR\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        self.population_age[i] = 0 # Reset age\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.population_age[i] += 1 # Increase age if not improved\n\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        self.population_age[i] = 0 # Reset age\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.population_age[i] += 1 # Increase age if not improved\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.population_age[i] > 1.0/self.aging_rate:\n                   self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                   self.fitness[i] = func(self.population[i])\n                   self.budget -=1\n                   self.population_age[i] = 0  # Reset age\n                   \n                   if self.fitness[i] < self.f_opt:\n                       self.f_opt = self.fitness[i]\n                       self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.649 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with aging population and self-adaptive parameters, prioritizing exploration in early stages and exploitation later.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9 # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.aging_rate = aging_rate  # Rate at which individuals are replaced with random ones\n        self.population_age = np.zeros(self.pop_size)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Adapt F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)  # Self-adaptive F\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)  # Self-adaptive CR\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        self.population_age[i] = 0 # Reset age\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.population_age[i] += 1 # Increase age if not improved\n\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        self.population_age[i] = 0 # Reset age\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.population_age[i] += 1 # Increase age if not improved\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Aging mechanism: replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.population_age[i] > 1.0/self.aging_rate:\n                   self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                   self.fitness[i] = func(self.population[i])\n                   self.budget -=1\n                   self.population_age[i] = 0  # Reset age\n                   \n                   if self.fitness[i] < self.f_opt:\n                       self.f_opt = self.fitness[i]\n                       self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.39705201577648863, 0.7197505346707739, 0.6332987422032417, 0.8686806465207598, 0.7501220058320897, 0.761907289745432, 0.6171116865192187, 0.7181361728458853, 0.7603333696202578, 0.7114719308905767, 0.850459704421291, 0], "operator": "mutation", "theta_sampled": 0.047894291692305704, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "bf5a87fa-4c1c-489c-961b-d8fa62883e9c", "fitness": 0.0, "name": "HybridDECMOAdaptive", "description": "A hybrid DE and CMA-ES algorithm with adaptive parameter control, archive, and orthogonal sampling to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMOAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n        self.c_cov = 0.1 #Covariance adaptation rate\n        self.popsize_cmaes = 4 + int(3 * np.log(self.dim))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES parameters initialization\n        self.m = self.x_opt # Initialize mean with the best solution so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.mu = self.popsize_cmaes // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        while self.budget > 0:\n            # DE part\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # CMA-ES part\n            if self.budget > 0:\n                # Sample population using orthogonal sampling\n                z = np.random.randn(self.popsize_cmaes, self.dim)\n                Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n                x = np.zeros((self.popsize_cmaes, self.dim))\n                for k in range(self.popsize_cmaes):\n                    x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                    x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n                f = np.array([func(xi) for xi in x])\n                used_budget = self.popsize_cmaes\n                \n                if self.budget < used_budget:\n                     f = f[:(self.budget)]\n                     x = x[:(self.budget)]\n                     used_budget = self.budget\n                     self.popsize_cmaes = self.budget\n                self.budget -= used_budget\n\n                idx = np.argsort(f)\n                x = x[idx]\n                f = f[idx]\n\n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[0]\n                    \n\n                xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n                # Update evolution path\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize_cmaes)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                # Update covariance matrix\n                y = x[:self.mu] - self.m\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n                # Update step size\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = xmean\n                self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n                try:\n                    L = np.linalg.cholesky(self.C) # C = LL'\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                    L = np.linalg.cholesky(self.C) # C = LL'\n\n                # Adaptive Covariance Matrix Adaptation\n                self.success_history.append(1 if f[0] < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDECMOAdaptive scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid DE and CMA-ES algorithm with adaptive parameter control, archive, and orthogonal sampling to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMOAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9 # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n        self.c_cov = 0.1 #Covariance adaptation rate\n        self.popsize_cmaes = 4 + int(3 * np.log(self.dim))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES parameters initialization\n        self.m = self.x_opt # Initialize mean with the best solution so far\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.mu = self.popsize_cmaes // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        while self.budget > 0:\n            # DE part\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # CMA-ES part\n            if self.budget > 0:\n                # Sample population using orthogonal sampling\n                z = np.random.randn(self.popsize_cmaes, self.dim)\n                Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n                x = np.zeros((self.popsize_cmaes, self.dim))\n                for k in range(self.popsize_cmaes):\n                    x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                    x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n\n\n                f = np.array([func(xi) for xi in x])\n                used_budget = self.popsize_cmaes\n                \n                if self.budget < used_budget:\n                     f = f[:(self.budget)]\n                     x = x[:(self.budget)]\n                     used_budget = self.budget\n                     self.popsize_cmaes = self.budget\n                self.budget -= used_budget\n\n                idx = np.argsort(f)\n                x = x[idx]\n                f = f[idx]\n\n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[0]\n                    \n\n                xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n                # Update evolution path\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.popsize_cmaes)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n                \n                # Update covariance matrix\n                y = x[:self.mu] - self.m\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n                # Update step size\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = xmean\n                self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n                try:\n                    L = np.linalg.cholesky(self.C) # C = LL'\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                    L = np.linalg.cholesky(self.C) # C = LL'\n\n                # Adaptive Covariance Matrix Adaptation\n                self.success_history.append(1 if f[0] < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.0010688590210469447, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "32bf93e7-e6dc-4c79-bc35-0a287dd02f8c", "fitness": 0.0, "name": "HybridNelderMeadDE", "description": "Population-based algorithm using a combination of Nelder-Mead simplex method for local search and differential evolution for global exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridNelderMeadDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.5, nm_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.nm_rate = nm_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            if np.random.rand() < self.de_rate and self.budget > 0:\n                for i in range(self.pop_size):\n                    if self.budget <= 0:\n                        break\n                    \n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    \n                    mutation = x_r1 + 0.5 * (x_r2 - x_r3)  # Mutation strategy\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < 0.9 #0.7\n                    x_trial = np.where(crossover_mask, mutation, self.population[i])\n\n                    # Boundary handling\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                    if f_trial < self.fitness[i]:\n                        self.fitness[i] = f_trial\n                        self.population[i] = x_trial\n                        \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n\n            # Nelder-Mead Local Search\n            if np.random.rand() < self.nm_rate and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                x_best = self.population[best_idx].copy()\n\n                # Ensure bounds are correctly passed to minimize\n                bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n\n                res = minimize(func, x_best, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(500, self.budget)}) # Reduced maxfev\n\n                n_evals = res.nfev\n                self.budget -= n_evals\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.population[best_idx] = res.x\n                    self.fitness[best_idx] = res.fun\n\n                if self.budget <= 0:\n                  break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of Nelder-Mead simplex method for local search and differential evolution for global exploration.\n\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridNelderMeadDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.5, nm_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.nm_rate = nm_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            if np.random.rand() < self.de_rate and self.budget > 0:\n                for i in range(self.pop_size):\n                    if self.budget <= 0:\n                        break\n                    \n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    \n                    mutation = x_r1 + 0.5 * (x_r2 - x_r3)  # Mutation strategy\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < 0.9 #0.7\n                    x_trial = np.where(crossover_mask, mutation, self.population[i])\n\n                    # Boundary handling\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                    if f_trial < self.fitness[i]:\n                        self.fitness[i] = f_trial\n                        self.population[i] = x_trial\n                        \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n\n            # Nelder-Mead Local Search\n            if np.random.rand() < self.nm_rate and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                x_best = self.population[best_idx].copy()\n\n                # Ensure bounds are correctly passed to minimize\n                bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n\n                res = minimize(func, x_best, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(500, self.budget)}) # Reduced maxfev\n\n                n_evals = res.nfev\n                self.budget -= n_evals\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.population[best_idx] = res.x\n                    self.fitness[best_idx] = res.fun\n\n                if self.budget <= 0:\n                  break\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.023690371286444863, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "48b6136c-4cd6-4ad0-914c-902d1b662bdb", "fitness": 0.29977822865536174, "name": "GaussianDiversitySearch", "description": "Population-based algorithm with Gaussian mutation and selection based on a weighted combination of fitness and diversity.", "code": "import numpy as np\n\nclass GaussianDiversitySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, diversity_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.diversity_weight = diversity_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            # Mutation: Gaussian perturbation\n            mutation_mask = np.random.rand(self.pop_size, self.dim) < self.mutation_rate\n            mutation = np.random.normal(0, 1, size=(self.pop_size, self.dim)) * mutation_mask\n            new_population = population + mutation\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            eval_count += self.pop_size\n\n            # Calculate diversity metric (average distance to centroid)\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n\n            # Weighted selection based on fitness and diversity\n            weighted_fitness = fitness + self.diversity_weight * diversity\n            weighted_new_fitness = new_fitness + self.diversity_weight * diversity\n\n            # Selection: Replace worse individuals with better ones\n            replace = weighted_new_fitness < weighted_fitness\n            population[replace] = new_population[replace]\n            fitness[replace] = new_fitness[replace]\n            \n            # Update optimal solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            if eval_count >= self.budget:\n                eval_count_diff = eval_count - self.budget\n                fitness_list = list(fitness)\n                for i in range(eval_count_diff):\n                    worst_index = np.argmax(fitness)\n                    fitness_list.pop(worst_index)\n                \n                best_index = np.argmin(fitness_list)\n                \n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm GaussianDiversitySearch scored 0.300 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with Gaussian mutation and selection based on a weighted combination of fitness and diversity.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianDiversitySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, diversity_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.diversity_weight = diversity_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            # Mutation: Gaussian perturbation\n            mutation_mask = np.random.rand(self.pop_size, self.dim) < self.mutation_rate\n            mutation = np.random.normal(0, 1, size=(self.pop_size, self.dim)) * mutation_mask\n            new_population = population + mutation\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            eval_count += self.pop_size\n\n            # Calculate diversity metric (average distance to centroid)\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n\n            # Weighted selection based on fitness and diversity\n            weighted_fitness = fitness + self.diversity_weight * diversity\n            weighted_new_fitness = new_fitness + self.diversity_weight * diversity\n\n            # Selection: Replace worse individuals with better ones\n            replace = weighted_new_fitness < weighted_fitness\n            population[replace] = new_population[replace]\n            fitness[replace] = new_fitness[replace]\n            \n            # Update optimal solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            if eval_count >= self.budget:\n                eval_count_diff = eval_count - self.budget\n                fitness_list = list(fitness)\n                for i in range(eval_count_diff):\n                    worst_index = np.argmax(fitness)\n                    fitness_list.pop(worst_index)\n                \n                best_index = np.argmin(fitness_list)\n                \n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0.10819738627331676, 0.1737750099263229, 0.3162876186141306, 0.22985798979407945, 0.2060659255074161, 0.24351242553276164, 0.24525578292307837, 0.24915584846065553, 0.2314913098660969, 0.1754621048667876, 0.26625981101066376, 0.9965107088329118, 0.2692386901653133, 0.21482972861668248, 0.528736146310144, 0.3075787089857488, 0.29342072316645895, 0.32122237956207556, 0.15815750071662737, 0.46054877397596206], "operator": "random_new", "theta_sampled": 0.07604804350812364, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "7d368591-a664-423d-9c7a-fa6f94feb109", "fitness": 0.34794984405906787, "name": "HybridDECMO", "description": "Combines Adaptive DE's archive and stochastic ranking with Adaptive CMA-ES's orthogonal sampling and adaptive covariance matrix.", "code": "import numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor for DE\n        self.CR = 0.9 # Crossover rate for DE\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        used_budget += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n            \n            # DE crossover and mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = x[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(x[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                x[i] = x_trial\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            self.budget -= self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n\n            # Stochastic ranking and archive update\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and f[i] <= 0) or (self.fitness[i] > 0 and f[i] > 0):\n                    if f[i] < self.fitness[i]:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDECMO scored 0.348 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac", "ddff1f3d-3bd6-4047-a751-bc9092237521"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive DE's archive and stochastic ranking with Adaptive CMA-ES's orthogonal sampling and adaptive covariance matrix.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor for DE\n        self.CR = 0.9 # Crossover rate for DE\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.mu = self.pop_size // 2  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2))  # Simplified version\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5  # Initialize success rate\n        self.success_history = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        used_budget = 0\n        successes = 0\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        used_budget += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        while used_budget < self.budget:\n            # Sample population using orthogonal sampling\n            z = np.random.randn(self.pop_size, self.dim)\n            Q, R = np.linalg.qr(z.T)  # Orthogonalize the random vectors\n\n            x = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                x[k] = self.m + self.sigma * (Q @ np.random.normal(0, 1, size=self.dim))  # Rotate and scale\n                x[k] = np.clip(x[k], func.bounds.lb, func.bounds.ub)\n            \n            # DE crossover and mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = x[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(x[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                x[i] = x_trial\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            self.budget -= self.pop_size\n            \n            if used_budget > self.budget:\n                 f = f[:(self.budget - (used_budget-self.pop_size))]\n                 x = x[:(self.budget - (used_budget-self.pop_size))]\n                 self.pop_size = (self.budget - (used_budget-self.pop_size))\n                 used_budget = self.budget\n                 \n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n\n            # Stochastic ranking and archive update\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and f[i] <= 0) or (self.fitness[i] > 0 and f[i] > 0):\n                    if f[i] < self.fitness[i]:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x[i]\n                        self.fitness[i] = f[i]\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                successes += 1\n\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * used_budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            \n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (xmean - self.m) / self.sigma\n            \n            # Update covariance matrix\n            y = x[:self.mu] - self.m\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:,None,None] * (y[:,:,None] @ y[:,None,:]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = xmean\n            self.C = np.triu(self.C) + np.triu(self.C,1).T # enforce symmetry\n\n            try:\n                L = np.linalg.cholesky(self.C) # C = LL'\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim) # Regularize\n                L = np.linalg.cholesky(self.C) # C = LL'\n\n            # Adaptive Covariance Matrix Adaptation\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)  # Increase adaptation rate if successful\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)  # Decrease adaptation rate if unsuccessful\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.1458757533724918, 0.19646214839244336, 0.2991951174233155, 0.4126745636666649, 0.2753797661952344, 0.33480430000312267, 0.2697183820586406, 0.3579160842566437, 0.25378435887394457, 0.16963165634996225, 0.27801225129547635, 0.9999116107083283, 0.2627958843674493, 0.3037563821349113, 0.6175193421264746, 0.3329319900476003, 0.26077377140874547, 0.5435583185787065, 0.16424419881628205, 0.48005100110491905], "operator": "crossover", "theta_sampled": -0.00035402210815073517, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "f2a6fd6d-7de4-4b23-8433-7b43980425ea", "fitness": 0.7114569473113199, "name": "HybridAdaptiveDECMO", "description": "A hybrid Differential Evolution algorithm that incorporates adaptive CMA-ES step size control and covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm HybridAdaptiveDECMO scored 0.711 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc8a9392-5503-4b2a-9d5a-8f126861fd20", "d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid Differential Evolution algorithm that incorporates adaptive CMA-ES step size control and covariance matrix adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.32533117699103054, 0.6412727966643581, 0.7131861570628539, 0.871327155150731, 0.769528321963308, 0.7851894129251585, 0.6965965368956303, 0.6593027637191242, 0.7362817469577553, 0.7254164634923769, 0.8786620946001503, 0.9898514482055908, 0.6612234889556292, 0.7354660935087078, 0.8825732437018294, 0.776083157413289, 0.6409771341294923, 0.8591137572950918, 0.24949199742280503, 0.6322639991714851], "operator": "crossover", "theta_sampled": 0.0006080378314336322, "reward": 0.008112989298936224, "generation": 7}, "task_prompt": ""}
{"id": "0ab67736-4d7c-46d0-b2e5-12628394800b", "fitness": 0.22638656806041763, "name": "BiasedOrthogonalSearch", "description": "Population-based algorithm with adaptive step size and biased exploration towards promising regions, while maintaining diversity through orthogonal learning.", "code": "import numpy as np\n\nclass BiasedOrthogonalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_bias=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_bias = exploration_bias  # Bias towards regions with good solutions\n        self.step_size = 0.1  # Initial step size\n        self.step_size_decay = 0.999  # Decay rate for step size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main loop\n        while self.budget > 0:\n            # Find best individual in population\n            best_index = np.argmin(fitness)\n            best_x = population[best_index]\n            best_f = fitness[best_index]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Generate new population based on biased exploration and orthogonal learning\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Biased exploration: move towards the best solution with a probability\n                if np.random.rand() < self.exploration_bias:\n                    new_x = population[i] + self.step_size * (best_x - population[i]) + np.random.normal(0, self.step_size, self.dim)\n                else:\n                    new_x = population[i] + np.random.normal(0, self.step_size, self.dim)\n\n                # Orthogonal Learning: Generate an orthogonal vector\n                orthogonal_vector = np.random.normal(0, 1, self.dim)\n                orthogonal_vector = orthogonal_vector - np.dot(orthogonal_vector, new_x) / np.dot(new_x, new_x) * new_x\n                orthogonal_vector = orthogonal_vector / np.linalg.norm(orthogonal_vector) if np.linalg.norm(orthogonal_vector) > 0 else np.zeros(self.dim)\n                new_x = new_x + self.step_size * orthogonal_vector #Add small orthogonal component\n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n                new_population[i] = new_x\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Replace worst individuals in the current population\n            worst_indices = np.argsort(fitness)[-self.pop_size // 2:] # Replace half the pop\n            population[worst_indices] = new_population[worst_indices] #Only replace the worst in pop\n            fitness[worst_indices] = new_fitness[worst_indices]\n            \n            #Adapt step size\n            self.step_size *= self.step_size_decay\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm BiasedOrthogonalSearch scored 0.226 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive step size and biased exploration towards promising regions, while maintaining diversity through orthogonal learning.\n# Code: \n```python\nimport numpy as np\n\nclass BiasedOrthogonalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_bias=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_bias = exploration_bias  # Bias towards regions with good solutions\n        self.step_size = 0.1  # Initial step size\n        self.step_size_decay = 0.999  # Decay rate for step size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main loop\n        while self.budget > 0:\n            # Find best individual in population\n            best_index = np.argmin(fitness)\n            best_x = population[best_index]\n            best_f = fitness[best_index]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Generate new population based on biased exploration and orthogonal learning\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Biased exploration: move towards the best solution with a probability\n                if np.random.rand() < self.exploration_bias:\n                    new_x = population[i] + self.step_size * (best_x - population[i]) + np.random.normal(0, self.step_size, self.dim)\n                else:\n                    new_x = population[i] + np.random.normal(0, self.step_size, self.dim)\n\n                # Orthogonal Learning: Generate an orthogonal vector\n                orthogonal_vector = np.random.normal(0, 1, self.dim)\n                orthogonal_vector = orthogonal_vector - np.dot(orthogonal_vector, new_x) / np.dot(new_x, new_x) * new_x\n                orthogonal_vector = orthogonal_vector / np.linalg.norm(orthogonal_vector) if np.linalg.norm(orthogonal_vector) > 0 else np.zeros(self.dim)\n                new_x = new_x + self.step_size * orthogonal_vector #Add small orthogonal component\n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n                new_population[i] = new_x\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Replace worst individuals in the current population\n            worst_indices = np.argsort(fitness)[-self.pop_size // 2:] # Replace half the pop\n            population[worst_indices] = new_population[worst_indices] #Only replace the worst in pop\n            fitness[worst_indices] = new_fitness[worst_indices]\n            \n            #Adapt step size\n            self.step_size *= self.step_size_decay\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.10596988427621978, 0.1632305280700881, 0.24805255581043784, 0.14575042233963253, 0.14133926832973553, 0.16932957920105784, 0.19270945635234105, 0.16063404478717347, 0.17706327998841676, 0.14381514913516913, 0.152070774714546, 0.5464457939234635, 0.24020930566412213, 0.15385801288600265, 0.5971210999544838, 0.23292165302994516, 0.18072839367941018, 0.16070503826594562, 0.1755562333109023, 0.4402208874892589], "operator": "random_new", "theta_sampled": 0.050691086427727274, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "232e9370-ef74-4d27-bb38-e9a0c4478769", "fitness": 0.6894163183488251, "name": "AdaptiveDECrow", "description": "Implements a self-adaptive differential evolution with a diversity maintenance strategy using a crow search inspired approach for offspring selection.", "code": "import numpy as np\n\nclass AdaptiveDECrow:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F=0.5, CR=0.9, pa=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.pa = pa # Awareness probability for crow search\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        F = self.F * np.ones(self.pop_size)\n        CR = self.CR * np.ones(self.pop_size)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                F_i = F[i] + 0.1 * np.random.normal()\n                CR_i = CR[i] + 0.1 * np.random.normal()\n                F_i = np.clip(F_i, 0.1, 0.9)\n                CR_i = np.clip(CR_i, 0.1, 0.9)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR_i or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Crow Search inspired offspring selection for diversity maintenance\n                if np.random.rand() < self.pa:\n                    # Randomly choose a crow (candidate solution)\n                    crow_index = np.random.randint(self.pop_size)\n                    \n                    # Fly towards the crow's position\n                    x_trial = x_trial + np.random.rand() * (self.population[crow_index] - x_trial)\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n                    \n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    F[i] = F_i\n                    CR[i] = CR_i\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace the worst archived solution\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = self.population[i]\n                            self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDECrow scored 0.689 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements a self-adaptive differential evolution with a diversity maintenance strategy using a crow search inspired approach for offspring selection.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECrow:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F=0.5, CR=0.9, pa=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.pa = pa # Awareness probability for crow search\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        F = self.F * np.ones(self.pop_size)\n        CR = self.CR * np.ones(self.pop_size)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                F_i = F[i] + 0.1 * np.random.normal()\n                CR_i = CR[i] + 0.1 * np.random.normal()\n                F_i = np.clip(F_i, 0.1, 0.9)\n                CR_i = np.clip(CR_i, 0.1, 0.9)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR_i or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Crow Search inspired offspring selection for diversity maintenance\n                if np.random.rand() < self.pa:\n                    # Randomly choose a crow (candidate solution)\n                    crow_index = np.random.randint(self.pop_size)\n                    \n                    # Fly towards the crow's position\n                    x_trial = x_trial + np.random.rand() * (self.population[crow_index] - x_trial)\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n                    \n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    F[i] = F_i\n                    CR[i] = CR_i\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace the worst archived solution\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = self.population[i]\n                            self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2806177165853383, 0.7274662095989612, 0.5525024418932016, 0.8412581827104451, 0.7460921001641566, 0.7811389617867075, 0.5830548876335846, 0.6402577520694355, 0.7820163884702696, 0.696988860456498, 0.8438427125029004, 0.9993143705736696, 0.4195839282205992, 0.75097416000628, 0.9015930989485895, 0.8087529594220176, 0.593516273494086, 0.8424961623422901, 0.47780469895816036, 0.5190545011393124], "operator": "mutation", "theta_sampled": 0.1222768590063374, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "e5596f8c-6991-41ed-91fc-75dd80c09d2f", "fitness": 0.704427987336341, "name": "AdaptiveDECMA", "description": "Combines Adaptive DE with CMA-ES-inspired step-size adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDECMA scored 0.704 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc8a9392-5503-4b2a-9d5a-8f126861fd20", "d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive DE with CMA-ES-inspired step-size adaptation for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3399125277695437, 0.6970441573685081, 0.6567296325971581, 0.858890209784493, 0.7602424322469492, 0.7966020180729501, 0.6332831493402632, 0.6624249524672863, 0.7404822505326326, 0.6713325123204266, 0.86903820925452, 0.9968908978143429, 0.6926094038814561, 0.7573772125119501, 0.9177804031744712, 0.7878921344137724, 0.6542386939511959, 0.8387289899486381, 0.23636579855826145, 0.5206941607180032], "operator": "crossover", "theta_sampled": 0.0009486859867262921, "reward": 0.0010840293239573473, "generation": 7}, "task_prompt": ""}
{"id": "86c36ea4-8805-4af1-a175-1bb6a5cafce9", "fitness": 0.671757978437064, "name": "AdaptiveHybridDECMALearning", "description": "Combines Adaptive DE with CMA-ES-inspired step-size adaptation and covariance matrix learning for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMALearning:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = 0.1  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.mu = self.pop_size // 2 # Number of parents/selected individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_m = 1\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1 + self.c_sigma)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + self.mueff + 3)) * (1 - self.c_cov) + self.c_cov\n        self.c_cov_mu = 2 / ((self.dim + np.sqrt(2))**2 + self.mueff)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n\n\n        while self.budget > 0:\n            offspring = []\n            fitness_offspring = []\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring.append(x_trial)\n                fitness_offspring.append(f_trial)\n\n            offspring = np.array(offspring)\n            fitness_offspring = np.array(fitness_offspring)\n\n\n            # Stochastic ranking and archive update (DE part)\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and fitness_offspring[i] <= 0) or (self.fitness[i] > 0 and fitness_offspring[i] > 0):\n                    if fitness_offspring[i] < self.fitness[i]:\n                        self.population[i] = offspring[i]\n                        self.fitness[i] = fitness_offspring[i]\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = offspring[i]\n                        self.fitness[i] = fitness_offspring[i]\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            parents = self.population[idx_sorted[:self.mu]]\n            y = parents - self.m\n            delta_m = np.sum(self.weights[:, None] * y, axis=0)\n\n            # Adapt mean\n            self.m += self.c_m * delta_m\n\n            # Adapt step size\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * delta_m / self.sigma\n            self.sigma *= np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Adapt covariance matrix\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mueff) * delta_m / self.sigma\n            \n            \n            C_temp = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                C_temp += self.c_cov_mu * self.weights[k] * (y[k, :, None] @ y[k, None, :])\n            self.C = C_temp\n                \n            try:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-16))\n                #self.C = self.B @ np.diag(self.D**2) @ self.B.T\n            except np.linalg.LinAlgError:\n                 self.C += 1e-6 * np.eye(self.dim) #adding ridge regression\n                 self.D, self.B = np.linalg.eigh(self.C)\n                 self.D = np.sqrt(np.maximum(self.D, 1e-16))\n                 #self.C = self.B @ np.diag(self.D**2) @ self.B.T\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridDECMALearning scored 0.672 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc8a9392-5503-4b2a-9d5a-8f126861fd20", "d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive DE with CMA-ES-inspired step-size adaptation and covariance matrix learning for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMALearning:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = 0.1  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.mu = self.pop_size // 2 # Number of parents/selected individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_m = 1\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1 + self.c_sigma)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + self.mueff + 3)) * (1 - self.c_cov) + self.c_cov\n        self.c_cov_mu = 2 / ((self.dim + np.sqrt(2))**2 + self.mueff)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n\n\n        while self.budget > 0:\n            offspring = []\n            fitness_offspring = []\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring.append(x_trial)\n                fitness_offspring.append(f_trial)\n\n            offspring = np.array(offspring)\n            fitness_offspring = np.array(fitness_offspring)\n\n\n            # Stochastic ranking and archive update (DE part)\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and fitness_offspring[i] <= 0) or (self.fitness[i] > 0 and fitness_offspring[i] > 0):\n                    if fitness_offspring[i] < self.fitness[i]:\n                        self.population[i] = offspring[i]\n                        self.fitness[i] = fitness_offspring[i]\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = offspring[i]\n                        self.fitness[i] = fitness_offspring[i]\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            parents = self.population[idx_sorted[:self.mu]]\n            y = parents - self.m\n            delta_m = np.sum(self.weights[:, None] * y, axis=0)\n\n            # Adapt mean\n            self.m += self.c_m * delta_m\n\n            # Adapt step size\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * delta_m / self.sigma\n            self.sigma *= np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Adapt covariance matrix\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mueff) * delta_m / self.sigma\n            \n            \n            C_temp = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                C_temp += self.c_cov_mu * self.weights[k] * (y[k, :, None] @ y[k, None, :])\n            self.C = C_temp\n                \n            try:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-16))\n                #self.C = self.B @ np.diag(self.D**2) @ self.B.T\n            except np.linalg.LinAlgError:\n                 self.C += 1e-6 * np.eye(self.dim) #adding ridge regression\n                 self.D, self.B = np.linalg.eigh(self.C)\n                 self.D = np.sqrt(np.maximum(self.D, 1e-16))\n                 #self.C = self.B @ np.diag(self.D**2) @ self.B.T\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2702192850832271, 0.6237760105665677, 0.6059795124448955, 0.8511172534995493, 0.6968765035807393, 0.741331075721496, 0.5878590140393193, 0.5775510864139263, 0.6943695214881862, 0.6539213449568626, 0.8491508679128112, 0.9966891259307696, 0.637402344222607, 0.6478413911453949, 0.9024238556712217, 0.7268514441478025, 0.5860857695682942, 0.8274044814086976, 0.35578590029481416, 0.6025237806440973], "operator": "crossover", "theta_sampled": 0.000558302857217121, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "210d7c34-e447-442b-b823-7cd5b7983413", "fitness": 0.6839480598795955, "name": "AdaptiveHybridDECMOOrthogonalRestart", "description": "Integrates DE with CMA-ES using orthogonal sampling and adaptive parameter control, with restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMOOrthogonalRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, restart_trigger=1e-8, orthogonal_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = 0.1  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.restart_trigger = restart_trigger\n        self.orthogonal_trials = orthogonal_trials\n        self.min_sigma = 1e-6\n        self.last_restart = 0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.sigma = max(self.sigma, self.min_sigma) #Prevent sigma from vanishing\n                self.m = self.population[i] # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Orthogonal Design Sampling around best solution\n            if self.budget > 0:\n                eigenvalues, eigenvectors = np.linalg.eigh(self.C)\n                search_directions = eigenvectors  # Use eigenvectors as orthogonal directions\n                \n                for _ in range(min(self.orthogonal_trials, self.budget)): #limit orthogonal trials by budget\n                    random_step = np.random.randn(self.dim)\n                    x_trial = self.x_opt + self.sigma * np.dot(search_directions, random_step)\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.m = self.x_opt.copy()\n            \n            # Restart mechanism\n            if np.abs(self.f_opt) < self.restart_trigger and (generation - self.last_restart) > 100:\n                self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.last_restart = generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridDECMOOrthogonalRestart scored 0.684 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc8a9392-5503-4b2a-9d5a-8f126861fd20"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates DE with CMA-ES using orthogonal sampling and adaptive parameter control, with restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMOOrthogonalRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, restart_trigger=1e-8, orthogonal_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = 0.1  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.restart_trigger = restart_trigger\n        self.orthogonal_trials = orthogonal_trials\n        self.min_sigma = 1e-6\n        self.last_restart = 0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.sigma = max(self.sigma, self.min_sigma) #Prevent sigma from vanishing\n                self.m = self.population[i] # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Orthogonal Design Sampling around best solution\n            if self.budget > 0:\n                eigenvalues, eigenvectors = np.linalg.eigh(self.C)\n                search_directions = eigenvectors  # Use eigenvectors as orthogonal directions\n                \n                for _ in range(min(self.orthogonal_trials, self.budget)): #limit orthogonal trials by budget\n                    random_step = np.random.randn(self.dim)\n                    x_trial = self.x_opt + self.sigma * np.dot(search_directions, random_step)\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.m = self.x_opt.copy()\n            \n            # Restart mechanism\n            if np.abs(self.f_opt) < self.restart_trigger and (generation - self.last_restart) > 100:\n                self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.last_restart = generation\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.330975022837131, 0.6377828172210331, 0.6271905083792613, 0.8761523581004935, 0.7022323645951474, 0.7698409817137144, 0.6265041365381778, 0.629920937466727, 0.7048241168533458, 0.6965364005242638, 0.854785655428671, 0.9984377181836321, 0.6466390695753872, 0.7100170159257264, 0.9123944017283873, 0.7770476574862477, 0.5876227953723709, 0.8242602020424629, 0.2549421407136859, 0.5108548969060436], "operator": "mutation", "theta_sampled": 0.06289089230421079, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "6ed36771-e083-4662-93d4-5b5ffa5c8ec6", "fitness": 0.0, "name": "AdaptiveEvolutionaryLocalSearch", "description": "A population-based algorithm that adaptively switches between exploration and exploitation phases using a combination of differential evolution and a local search operator.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.exploration_prob = 0.7  # Probability of performing differential evolution\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n    def differential_evolution(self, population, func):\n        for i in range(self.pop_size):\n            # Select three distinct individuals\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = population[idxs]\n\n            # Create a trial vector\n            mutation_factor = 0.5\n            crossover_rate = 0.7\n            \n            x_trial = x_r1 + mutation_factor * (x_r2 - x_r3)\n            \n            # Crossover\n            for j in range(self.dim):\n                if np.random.rand() > crossover_rate:\n                    x_trial[j] = population[i, j]\n\n            # Clip to bounds\n            x_trial = np.clip(x_trial, self.lb, self.ub)\n            \n            f_trial = func(x_trial)\n            if f_trial < func(population[i]):\n                population[i] = x_trial\n        return population\n\n    def local_search(self, individual, func):\n        x = individual.copy()\n        for _ in range(self.local_search_iterations):\n            # Generate a small random perturbation\n            perturbation = np.random.normal(0, 0.1, size=self.dim)\n            x_new = x + perturbation\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            if f_new < func(x):\n                x = x_new\n        return x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        population = self.initialize_population()\n        fitness = np.array([func(x) for x in population])\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            if np.random.rand() < self.exploration_prob:\n                # Differential Evolution\n                population = self.differential_evolution(population, func)\n            else:\n                # Local Search\n                for i in range(self.pop_size):\n                    population[i] = self.local_search(population[i], func)\n                    eval_count += self.local_search_iterations\n\n                    if eval_count >= self.budget:\n                        break\n            \n            fitness = np.array([func(x) for x in population])\n            eval_count += self.pop_size if eval_count + self.pop_size <= self.budget else self.budget - eval_count\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            self.exploration_prob = 0.7 * (1 - (eval_count / self.budget)) + 0.3 # reduce exporation as evaluations increase.\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveEvolutionaryLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that adaptively switches between exploration and exploitation phases using a combination of differential evolution and a local search operator.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveEvolutionaryLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.exploration_prob = 0.7  # Probability of performing differential evolution\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n    def differential_evolution(self, population, func):\n        for i in range(self.pop_size):\n            # Select three distinct individuals\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = population[idxs]\n\n            # Create a trial vector\n            mutation_factor = 0.5\n            crossover_rate = 0.7\n            \n            x_trial = x_r1 + mutation_factor * (x_r2 - x_r3)\n            \n            # Crossover\n            for j in range(self.dim):\n                if np.random.rand() > crossover_rate:\n                    x_trial[j] = population[i, j]\n\n            # Clip to bounds\n            x_trial = np.clip(x_trial, self.lb, self.ub)\n            \n            f_trial = func(x_trial)\n            if f_trial < func(population[i]):\n                population[i] = x_trial\n        return population\n\n    def local_search(self, individual, func):\n        x = individual.copy()\n        for _ in range(self.local_search_iterations):\n            # Generate a small random perturbation\n            perturbation = np.random.normal(0, 0.1, size=self.dim)\n            x_new = x + perturbation\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            if f_new < func(x):\n                x = x_new\n        return x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        population = self.initialize_population()\n        fitness = np.array([func(x) for x in population])\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            if np.random.rand() < self.exploration_prob:\n                # Differential Evolution\n                population = self.differential_evolution(population, func)\n            else:\n                # Local Search\n                for i in range(self.pop_size):\n                    population[i] = self.local_search(population[i], func)\n                    eval_count += self.local_search_iterations\n\n                    if eval_count >= self.budget:\n                        break\n            \n            fitness = np.array([func(x) for x in population])\n            eval_count += self.pop_size if eval_count + self.pop_size <= self.budget else self.budget - eval_count\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            self.exploration_prob = 0.7 * (1 - (eval_count / self.budget)) + 0.3 # reduce exporation as evaluations increase.\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.024597576307304914, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "d39846b0-fbf3-4bff-bab4-e9b78e758ef9", "fitness": 0.0, "name": "LevyEnhancedPSO", "description": "Population-based algorithm with Lvy flight dispersal and a self-adaptive step size for exploration and exploitation.", "code": "import numpy as np\n\nclass LevyEnhancedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.levy_exponent = 1.5 # Parameter for Levy flight\n\n    def levy_flight(self, size, beta=1.5):\n        \"\"\"\n        Generate Levy distributed steps.\n        \"\"\"\n        num = np.random.normal(0, 1, size) * np.power(np.abs(np.random.normal(0, 1, size)), 1.0/beta)\n        den = np.power(np.abs(np.random.normal(0, 1, size)), 1.0/beta)\n        sigma = np.power(np.math.gamma(1+beta)*np.sin(np.pi*beta/2)/(np.math.gamma((1+beta)/2)*beta*np.power(2,(beta-1)/2)), 1/beta)\n        step = sigma * (num/den)\n        return step\n    \n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        pbest_positions = population.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        gbest_position = population[global_best_index].copy()\n        gbest_fitness = fitness[global_best_index]\n        \n        # Adaptive step size initialization\n        adaptive_step_size = 0.1 * (self.ub - self.lb)  # Initial step size\n        step_size_reduction_factor = 0.995\n        step_size_increase_factor = 1.005\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (pbest_positions[i] - population[i])\n                social_component = self.c2 * r2 * (gbest_position - population[i])\n                \n                velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Levy flight dispersal (occasionally)\n                if np.random.rand() < 0.05: # 5% probability of Levy flight\n                    levy_steps = self.levy_flight(self.dim) * adaptive_step_size\n                    new_position += levy_steps\n                \n                # Clip positions to bounds\n                new_position = np.clip(new_position, self.lb, self.ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_positions[i] = new_position.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_position = new_position.copy()\n                        adaptive_step_size = min(adaptive_step_size * step_size_increase_factor, (self.ub-self.lb)) #Increase step size if better\n                else:\n                    adaptive_step_size *= step_size_reduction_factor # Reduce step size if not better\n                    \n                population[i] = new_position.copy()\n                \n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                    break\n\n        return gbest_fitness, gbest_position", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with Lvy flight dispersal and a self-adaptive step size for exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass LevyEnhancedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.levy_exponent = 1.5 # Parameter for Levy flight\n\n    def levy_flight(self, size, beta=1.5):\n        \"\"\"\n        Generate Levy distributed steps.\n        \"\"\"\n        num = np.random.normal(0, 1, size) * np.power(np.abs(np.random.normal(0, 1, size)), 1.0/beta)\n        den = np.power(np.abs(np.random.normal(0, 1, size)), 1.0/beta)\n        sigma = np.power(np.math.gamma(1+beta)*np.sin(np.pi*beta/2)/(np.math.gamma((1+beta)/2)*beta*np.power(2,(beta-1)/2)), 1/beta)\n        step = sigma * (num/den)\n        return step\n    \n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        pbest_positions = population.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        gbest_position = population[global_best_index].copy()\n        gbest_fitness = fitness[global_best_index]\n        \n        # Adaptive step size initialization\n        adaptive_step_size = 0.1 * (self.ub - self.lb)  # Initial step size\n        step_size_reduction_factor = 0.995\n        step_size_increase_factor = 1.005\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (pbest_positions[i] - population[i])\n                social_component = self.c2 * r2 * (gbest_position - population[i])\n                \n                velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Levy flight dispersal (occasionally)\n                if np.random.rand() < 0.05: # 5% probability of Levy flight\n                    levy_steps = self.levy_flight(self.dim) * adaptive_step_size\n                    new_position += levy_steps\n                \n                # Clip positions to bounds\n                new_position = np.clip(new_position, self.lb, self.ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness\n                    pbest_positions[i] = new_position.copy()\n                    \n                    if new_fitness < gbest_fitness:\n                        gbest_fitness = new_fitness\n                        gbest_position = new_position.copy()\n                        adaptive_step_size = min(adaptive_step_size * step_size_increase_factor, (self.ub-self.lb)) #Increase step size if better\n                else:\n                    adaptive_step_size *= step_size_reduction_factor # Reduce step size if not better\n                    \n                population[i] = new_position.copy()\n                \n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                    break\n\n        return gbest_fitness, gbest_position\n```", "operator": "random_new", "theta_sampled": 0.1420572735638199, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "6a0cc433-5201-4bb6-9565-0a389750165a", "fitness": 0.0, "name": "AdaptiveKrillHerd", "description": "Exploration-Exploitation using Krill Herd with adaptive step size and Lvy flights for enhanced diversity.", "code": "import numpy as np\n\nclass AdaptiveKrillHerd:\n    def __init__(self, budget=10000, dim=10, N=50, C_n=0.01, C_f=0.01, v_f=0.01, D_max=0.005):\n        self.budget = budget\n        self.dim = dim\n        self.N = N  # Number of krill\n        self.C_n = C_n  # Inertia weight for movement induced\n        self.C_f = C_f  # Foraging influence weight\n        self.v_f = v_f  # Maximum foraging speed\n        self.D_max = D_max  # Maximum diffusion speed\n        self.lb = -5.0\n        self.ub = 5.0\n        self.krill = None\n        self.fitness = None\n        self.best_krill = None\n        self.best_fitness = np.inf\n\n    def initialize(self):\n        self.krill = np.random.uniform(self.lb, self.ub, size=(self.N, self.dim))\n        self.fitness = np.full(self.N, np.inf)\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def calculate_distances(self):\n        distances = np.zeros((self.N, self.N))\n        for i in range(self.N):\n            for j in range(i + 1, self.N):\n                distances[i, j] = np.linalg.norm(self.krill[i] - self.krill[j])\n                distances[j, i] = distances[i, j]\n        return distances\n\n    def move_krill(self, func, distances, t):\n        for i in range(self.N):\n            # Movement induced by other krill\n            alpha_i = np.zeros(self.dim)\n            for j in range(self.N):\n                if i != j:\n                    alpha = self.C_n * np.exp(-distances[i, j] / (2 * np.mean(distances))) * (self.krill[j] - self.krill[i])\n                    alpha_i += alpha\n            \n            # Foraging motion\n            beta_i = self.C_f * (self.best_krill - self.krill[i])\n\n            # Physical diffusion\n            delta_i = self.D_max * (np.random.rand(self.dim) - 0.5) \n\n            # Adaptive step size\n            adaptive_step = 1 - (t / self.budget)  # Linearly decreasing step size\n\n            # Lvy Flight for enhanced exploration\n            levy = self.levy_flight() * adaptive_step\n            \n            new_position = self.krill[i] + adaptive_step * alpha_i + adaptive_step * beta_i + delta_i + levy\n            \n            # Boundary handling\n            new_position = np.clip(new_position, self.lb, self.ub)\n            \n            new_fitness = func(new_position)\n\n            if new_fitness < self.fitness[i]:\n                self.krill[i] = new_position\n                self.fitness[i] = new_fitness\n\n                if new_fitness < self.best_fitness:\n                    self.best_fitness = new_fitness\n                    self.best_krill = new_position.copy()\n\n\n    def __call__(self, func):\n        self.initialize()\n        self.best_fitness = np.inf\n        self.best_krill = None\n        eval_count = 0\n\n        for i in range(self.N):\n            self.fitness[i] = func(self.krill[i])\n            eval_count += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_krill = self.krill[i].copy()\n\n        t = 0\n        while eval_count < self.budget:\n            distances = self.calculate_distances()\n            self.move_krill(func, distances, t)\n\n            eval_count = 0\n            for i in range(self.N):\n                eval_count += 1 # each krill position is evaluated once in move_krill\n            t += 1\n\n        return self.best_fitness, self.best_krill", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Exploration-Exploitation using Krill Herd with adaptive step size and Lvy flights for enhanced diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveKrillHerd:\n    def __init__(self, budget=10000, dim=10, N=50, C_n=0.01, C_f=0.01, v_f=0.01, D_max=0.005):\n        self.budget = budget\n        self.dim = dim\n        self.N = N  # Number of krill\n        self.C_n = C_n  # Inertia weight for movement induced\n        self.C_f = C_f  # Foraging influence weight\n        self.v_f = v_f  # Maximum foraging speed\n        self.D_max = D_max  # Maximum diffusion speed\n        self.lb = -5.0\n        self.ub = 5.0\n        self.krill = None\n        self.fitness = None\n        self.best_krill = None\n        self.best_fitness = np.inf\n\n    def initialize(self):\n        self.krill = np.random.uniform(self.lb, self.ub, size=(self.N, self.dim))\n        self.fitness = np.full(self.N, np.inf)\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def calculate_distances(self):\n        distances = np.zeros((self.N, self.N))\n        for i in range(self.N):\n            for j in range(i + 1, self.N):\n                distances[i, j] = np.linalg.norm(self.krill[i] - self.krill[j])\n                distances[j, i] = distances[i, j]\n        return distances\n\n    def move_krill(self, func, distances, t):\n        for i in range(self.N):\n            # Movement induced by other krill\n            alpha_i = np.zeros(self.dim)\n            for j in range(self.N):\n                if i != j:\n                    alpha = self.C_n * np.exp(-distances[i, j] / (2 * np.mean(distances))) * (self.krill[j] - self.krill[i])\n                    alpha_i += alpha\n            \n            # Foraging motion\n            beta_i = self.C_f * (self.best_krill - self.krill[i])\n\n            # Physical diffusion\n            delta_i = self.D_max * (np.random.rand(self.dim) - 0.5) \n\n            # Adaptive step size\n            adaptive_step = 1 - (t / self.budget)  # Linearly decreasing step size\n\n            # Lvy Flight for enhanced exploration\n            levy = self.levy_flight() * adaptive_step\n            \n            new_position = self.krill[i] + adaptive_step * alpha_i + adaptive_step * beta_i + delta_i + levy\n            \n            # Boundary handling\n            new_position = np.clip(new_position, self.lb, self.ub)\n            \n            new_fitness = func(new_position)\n\n            if new_fitness < self.fitness[i]:\n                self.krill[i] = new_position\n                self.fitness[i] = new_fitness\n\n                if new_fitness < self.best_fitness:\n                    self.best_fitness = new_fitness\n                    self.best_krill = new_position.copy()\n\n\n    def __call__(self, func):\n        self.initialize()\n        self.best_fitness = np.inf\n        self.best_krill = None\n        eval_count = 0\n\n        for i in range(self.N):\n            self.fitness[i] = func(self.krill[i])\n            eval_count += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_krill = self.krill[i].copy()\n\n        t = 0\n        while eval_count < self.budget:\n            distances = self.calculate_distances()\n            self.move_krill(func, distances, t)\n\n            eval_count = 0\n            for i in range(self.N):\n                eval_count += 1 # each krill position is evaluated once in move_krill\n            t += 1\n\n        return self.best_fitness, self.best_krill\n```", "operator": "random_new", "theta_sampled": 0.2782824182092592, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "f4cd1dab-14e9-4121-89b0-6a177280ae3e", "fitness": 0.0, "name": "AdaptiveClampingPSO", "description": "A swarm-based optimization algorithm with adaptive inertia and velocity clamping based on the fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveClampingPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, c1=2.0, c2=2.0, w_max=0.9, w_min=0.4, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.w_max = w_max # Inertia weight maximum\n        self.w_min = w_min # Inertia weight minimum\n        self.v_max_ratio = v_max_ratio\n        self.x = None\n        self.v = None\n        self.pbest_x = None\n        self.pbest_f = None\n        self.gbest_x = None\n        self.gbest_f = np.inf\n        self.eval_count = 0\n        self.bounds = None # will be initialized later\n    \n\n    def initialize_swarm(self, func):\n        self.bounds = func.bounds\n        self.x = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(self.swarm_size, self.dim))\n        self.v = np.random.uniform(-self.v_max, self.v_max, size=(self.swarm_size, self.dim))\n        self.pbest_x = np.copy(self.x)\n        self.pbest_f = np.array([func(x_i) for x_i in self.x])\n        self.eval_count += self.swarm_size\n        self.gbest_x = self.pbest_x[np.argmin(self.pbest_f)]\n        self.gbest_f = np.min(self.pbest_f)\n\n    def __call__(self, func):\n        self.v_max = self.v_max_ratio * (self.bounds.ub - self.bounds.lb)\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (self.pbest_x[i] - self.x[i])\n                social_component = self.c2 * r2 * (self.gbest_x - self.x[i])\n                \n                self.v[i] = w * self.v[i] + cognitive_component + social_component\n\n                # Velocity clamping\n                self.v[i] = np.clip(self.v[i], -self.v_max, self.v_max)\n\n\n                # Update position\n                self.x[i] = self.x[i] + self.v[i]\n\n                # Boundary handling (clamping)\n                self.x[i] = np.clip(self.x[i], self.bounds.lb, self.bounds.ub)\n\n                # Evaluate fitness\n                f = func(self.x[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if f < self.pbest_f[i]:\n                    self.pbest_f[i] = f\n                    self.pbest_x[i] = np.copy(self.x[i])\n\n                    # Update global best\n                    if f < self.gbest_f:\n                        self.gbest_f = f\n                        self.gbest_x = np.copy(self.x[i])\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.gbest_f, self.gbest_x", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: 'NoneType' object has no attribute 'ub'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A swarm-based optimization algorithm with adaptive inertia and velocity clamping based on the fitness landscape.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveClampingPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, c1=2.0, c2=2.0, w_max=0.9, w_min=0.4, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.w_max = w_max # Inertia weight maximum\n        self.w_min = w_min # Inertia weight minimum\n        self.v_max_ratio = v_max_ratio\n        self.x = None\n        self.v = None\n        self.pbest_x = None\n        self.pbest_f = None\n        self.gbest_x = None\n        self.gbest_f = np.inf\n        self.eval_count = 0\n        self.bounds = None # will be initialized later\n    \n\n    def initialize_swarm(self, func):\n        self.bounds = func.bounds\n        self.x = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(self.swarm_size, self.dim))\n        self.v = np.random.uniform(-self.v_max, self.v_max, size=(self.swarm_size, self.dim))\n        self.pbest_x = np.copy(self.x)\n        self.pbest_f = np.array([func(x_i) for x_i in self.x])\n        self.eval_count += self.swarm_size\n        self.gbest_x = self.pbest_x[np.argmin(self.pbest_f)]\n        self.gbest_f = np.min(self.pbest_f)\n\n    def __call__(self, func):\n        self.v_max = self.v_max_ratio * (self.bounds.ub - self.bounds.lb)\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (self.pbest_x[i] - self.x[i])\n                social_component = self.c2 * r2 * (self.gbest_x - self.x[i])\n                \n                self.v[i] = w * self.v[i] + cognitive_component + social_component\n\n                # Velocity clamping\n                self.v[i] = np.clip(self.v[i], -self.v_max, self.v_max)\n\n\n                # Update position\n                self.x[i] = self.x[i] + self.v[i]\n\n                # Boundary handling (clamping)\n                self.x[i] = np.clip(self.x[i], self.bounds.lb, self.bounds.ub)\n\n                # Evaluate fitness\n                f = func(self.x[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if f < self.pbest_f[i]:\n                    self.pbest_f[i] = f\n                    self.pbest_x[i] = np.copy(self.x[i])\n\n                    # Update global best\n                    if f < self.gbest_f:\n                        self.gbest_f = f\n                        self.gbest_x = np.copy(self.x[i])\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.gbest_f, self.gbest_x\n```", "operator": "random_new", "theta_sampled": 0.004801203453104384, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "401dab32-571d-4e07-9dda-69789b2e02c7", "fitness": 0.3632399664860182, "name": "AdaptiveDECMA_Restart", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation and a Restart Mechanism, using a mirrored population to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMA_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1, restart_trigger = 0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.restart_trigger = restart_trigger # Threshold for restarting the population\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        self.mirrored_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) #Mirrored population\n        self.mirrored_fitness = np.array([func(x) for x in self.mirrored_population])\n        self.budget -= self.pop_size #Subtract budget\n\n        restart_counter = 0 # Restart counter\n        while self.budget > 0:\n            \n            combined_population = np.concatenate((self.population, self.mirrored_population))\n            combined_fitness = np.concatenate((self.fitness, self.mirrored_fitness))\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(2 * self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = combined_population[idxs] #Take from combined population\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Mirrored population update\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(2 * self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = combined_population[idxs] #Take from combined population\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.mirrored_population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.mirrored_fitness[i] <= 0 and f_trial <= 0) or (self.mirrored_fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.mirrored_fitness[i]:\n                        self.mirrored_population[i] = x_trial\n                        self.mirrored_fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.mirrored_population[i])\n                            self.archive_fitness.append(self.mirrored_fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.mirrored_fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.mirrored_population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.mirrored_population[i] = x_trial\n                        self.mirrored_fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.mirrored_population[i])\n                            self.archive_fitness.append(self.mirrored_fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.mirrored_fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.mirrored_population[i]\n                                self.archive_fitness[max_archive_index] = self.mirrored_fitness[i]\n\n            # Restart mechanism\n            if self.success_rate < self.restart_trigger:\n                restart_counter += 1\n                if restart_counter > 5 * self.dim:\n                    # Restart population\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.budget -= self.pop_size\n\n                    self.mirrored_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) #Mirrored population\n                    self.mirrored_fitness = np.array([func(x) for x in self.mirrored_population])\n                    self.budget -= self.pop_size #Subtract budget\n\n                    self.m = self.x_opt.copy()\n                    self.sigma = self.sigma0\n                    self.ps = np.zeros(self.dim)\n                    self.success_history = []\n                    restart_counter = 0  # Reset restart counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDECMA_Restart scored 0.363 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e5596f8c-6991-41ed-91fc-75dd80c09d2f"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation and a Restart Mechanism, using a mirrored population to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMA_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1, restart_trigger = 0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.restart_trigger = restart_trigger # Threshold for restarting the population\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        self.mirrored_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) #Mirrored population\n        self.mirrored_fitness = np.array([func(x) for x in self.mirrored_population])\n        self.budget -= self.pop_size #Subtract budget\n\n        restart_counter = 0 # Restart counter\n        while self.budget > 0:\n            \n            combined_population = np.concatenate((self.population, self.mirrored_population))\n            combined_fitness = np.concatenate((self.fitness, self.mirrored_fitness))\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(2 * self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = combined_population[idxs] #Take from combined population\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Mirrored population update\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(2 * self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = combined_population[idxs] #Take from combined population\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.mirrored_population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.mirrored_fitness[i] <= 0 and f_trial <= 0) or (self.mirrored_fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.mirrored_fitness[i]:\n                        self.mirrored_population[i] = x_trial\n                        self.mirrored_fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.mirrored_population[i])\n                            self.archive_fitness.append(self.mirrored_fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.mirrored_fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.mirrored_population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.mirrored_population[i] = x_trial\n                        self.mirrored_fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.mirrored_population[i])\n                            self.archive_fitness.append(self.mirrored_fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.mirrored_fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.mirrored_population[i]\n                                self.archive_fitness[max_archive_index] = self.mirrored_fitness[i]\n\n            # Restart mechanism\n            if self.success_rate < self.restart_trigger:\n                restart_counter += 1\n                if restart_counter > 5 * self.dim:\n                    # Restart population\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.budget -= self.pop_size\n\n                    self.mirrored_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) #Mirrored population\n                    self.mirrored_fitness = np.array([func(x) for x in self.mirrored_population])\n                    self.budget -= self.pop_size #Subtract budget\n\n                    self.m = self.x_opt.copy()\n                    self.sigma = self.sigma0\n                    self.ps = np.zeros(self.dim)\n                    self.success_history = []\n                    restart_counter = 0  # Reset restart counter\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.158952085481342, 0.2913241688634778, 0.34964569253411093, 0.44626226284207005, 0.2717297487460286, 0.35766413123526986, 0.2891826364804936, 0.29346017322134366, 0.2696117031468267, 0.1920767959814189, 0.38763303844393415, 0.9987776246036686, 0.2991430383944569, 0.28374217834485305, 0.7041330328120349, 0.343168524591979, 0.283628261264693, 0.38022683098897647, 0.1839453218246635, 0.4804920799187222], "operator": "mutation", "theta_sampled": 0.16237551070154563, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "dd7a59c1-a606-416b-8646-44951e8cb1a3", "fitness": 0.7100416969344245, "name": "HybridAdaptiveDECMO2", "description": "Hybrid DE with CMA-ES step-size adaptation and covariance matrix learning using success rate and archive.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMO2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm HybridAdaptiveDECMO2 scored 0.710 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea", "e5596f8c-6991-41ed-91fc-75dd80c09d2f"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid DE with CMA-ES step-size adaptation and covariance matrix learning using success rate and archive.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMO2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.31841317435185323, 0.7006261689875546, 0.6469844370769853, 0.8742713090723686, 0.7113308825238195, 0.7844312798805856, 0.6356420332027155, 0.6605784850659501, 0.7116600819700887, 0.6672800508502837, 0.876900109807578, 0.9916207410202444, 0.6493232593517806, 0.732425287769148, 0.9169303732308913, 0.8018546710227745, 0.6351835422367955, 0.8347999993691539, 0.4417591970778121, 0.6088188548201088], "operator": "crossover", "theta_sampled": -0.0019469200097455496, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "35615c3e-5fc8-449a-8e5b-0ba0433e9e14", "fitness": 0.5854870697839908, "name": "AdaptiveDEOrthogonal", "description": "Adaptive Differential Evolution with self-adaptive parameters, orthogonal crossover, and a dynamically updated archive for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, ortho_group_size = 3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9 # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.ortho_group_size = ortho_group_size\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F_i = np.random.normal(self.F, 0.1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n                CR_i = np.random.normal(self.CR, 0.1)\n                CR_i = np.clip(CR_i, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                x_trial = np.copy(self.population[i])\n                \n                num_groups = self.dim // self.ortho_group_size\n                for g in range(num_groups):\n                    start_idx = g * self.ortho_group_size\n                    end_idx = (g + 1) * self.ortho_group_size\n                    \n                    group_indices = np.arange(start_idx, end_idx)\n                    \n                    if np.random.rand() < CR_i:  # Apply crossover to the group\n                        # Orthogonal array design (simplified for demonstration)\n                        # Replace with a proper OA library for better performance\n                        oa = [[-1, -1, -1],\n                              [-1, 1, 1],\n                              [1, -1, 1],\n                              [1, 1, -1]]\n\n                        oa_idx = np.random.randint(0, len(oa))\n                        \n                        for k in range(self.ortho_group_size):\n                            if oa[oa_idx][k] == 1:\n                                x_trial[group_indices[k]] = x_mutated[group_indices[k]]\n\n\n                # Handle remaining dimensions if dim is not a multiple of ortho_group_size\n                remaining_dims = self.dim % self.ortho_group_size\n                if remaining_dims > 0:\n                    start_idx = self.dim - remaining_dims\n                    for j in range(remaining_dims):\n                        if np.random.rand() < CR_i:\n                            x_trial[start_idx + j] = x_mutated[start_idx + j]\n\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEOrthogonal scored 0.585 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d17a6ceb-fe6a-4fa8-bbec-e066fdc30cac"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with self-adaptive parameters, orthogonal crossover, and a dynamically updated archive for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, ortho_group_size = 3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9 # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.ortho_group_size = ortho_group_size\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F_i = np.random.normal(self.F, 0.1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n                CR_i = np.random.normal(self.CR, 0.1)\n                CR_i = np.clip(CR_i, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                x_trial = np.copy(self.population[i])\n                \n                num_groups = self.dim // self.ortho_group_size\n                for g in range(num_groups):\n                    start_idx = g * self.ortho_group_size\n                    end_idx = (g + 1) * self.ortho_group_size\n                    \n                    group_indices = np.arange(start_idx, end_idx)\n                    \n                    if np.random.rand() < CR_i:  # Apply crossover to the group\n                        # Orthogonal array design (simplified for demonstration)\n                        # Replace with a proper OA library for better performance\n                        oa = [[-1, -1, -1],\n                              [-1, 1, 1],\n                              [1, -1, 1],\n                              [1, 1, -1]]\n\n                        oa_idx = np.random.randint(0, len(oa))\n                        \n                        for k in range(self.ortho_group_size):\n                            if oa[oa_idx][k] == 1:\n                                x_trial[group_indices[k]] = x_mutated[group_indices[k]]\n\n\n                # Handle remaining dimensions if dim is not a multiple of ortho_group_size\n                remaining_dims = self.dim % self.ortho_group_size\n                if remaining_dims > 0:\n                    start_idx = self.dim - remaining_dims\n                    for j in range(remaining_dims):\n                        if np.random.rand() < CR_i:\n                            x_trial[start_idx + j] = x_mutated[start_idx + j]\n\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                # Stochastic ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    # Assign random probabilities if fitness values have different signs\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n                        \n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            # Replace the worst archived solution\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2086045116157499, 0.3237115333415267, 0.5410704721890338, 0.8280135666552255, 0.6377573573027262, 0.714682726905683, 0.5849830009810704, 0.5335015138557385, 0.612138854819676, 0.5880610562356736, 0.6539540217080599, 0.9923773702990597, 0.2988595070300084, 0.56033377180676, 0.8211558021671228, 0.7347476198850897, 0.4730666885801418, 0.7812028696777202, 0.30301606899580225, 0.518503081627946], "operator": "mutation", "theta_sampled": 0.18558051672132259, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "4f8a2483-3226-4fbe-8fc9-c6e4a4de09de", "fitness": 0.41946414599425164, "name": "AdaptiveHybridDECMRestart", "description": "Combines Differential Evolution (DE), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and a restart mechanism based on stagnation detection for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n    def initialize_population(self, func):\n         return np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n    def __call__(self, func):\n        self.population = self.initialize_population(func)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.last_improvement = 0\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size (CMA-ES like update)\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() #Important change: use x_trial rather than population[i]\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    self.last_improvement = generation\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n            # Restart mechanism\n            if generation - self.last_improvement > self.restart_trigger:\n                self.population = self.initialize_population(func)\n                self.fitness = np.array([func(x) for x in self.population])\n                self.m = self.x_opt.copy()  # Reset mean to the best individual so far\n                self.C = np.eye(self.dim)  # Reset covariance matrix\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                self.last_improvement = generation # Reset the last improvement\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridDECMRestart scored 0.419 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and a restart mechanism based on stagnation detection for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n    def initialize_population(self, func):\n         return np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n    def __call__(self, func):\n        self.population = self.initialize_population(func)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.last_improvement = 0\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size (CMA-ES like update)\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() #Important change: use x_trial rather than population[i]\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    self.last_improvement = generation\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n            # Restart mechanism\n            if generation - self.last_improvement > self.restart_trigger:\n                self.population = self.initialize_population(func)\n                self.fitness = np.array([func(x) for x in self.population])\n                self.m = self.x_opt.copy()  # Reset mean to the best individual so far\n                self.C = np.eye(self.dim)  # Reset covariance matrix\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                self.last_improvement = generation # Reset the last improvement\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.341996064831665, 0.6690722707235266, 0.6667882484218152, 0], "operator": "mutation", "theta_sampled": 0.13647447188321116, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "70b8b6cc-d364-4944-98a9-efe5c7641eae", "fitness": 0.0, "name": "SOMOptimizer", "description": "Population-based algorithm with self-organizing maps for adapting search direction and step size.", "code": "import numpy as np\nfrom collections import deque\n\nclass SOMOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_size = som_size\n        self.som = None\n        self.learning_rate = 0.9\n        self.sigma = som_size / 2.0\n        self.min_sigma = 0.1\n        self.sigma_decay_rate = 0.99\n        self.lr_decay_rate = 0.99\n        self.archive = deque(maxlen=100)\n\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.archive.extend(population)\n        return population, fitness\n\n\n    def initialize_som(self):\n        self.som = np.random.rand(self.som_size, self.som_size, self.dim)\n        return self.som\n\n\n    def find_best_matching_unit(self, x):\n        distances = np.sum((self.som - x)**2, axis=2)\n        best_unit = np.unravel_index(np.argmin(distances), distances.shape)\n        return best_unit\n\n\n    def update_som(self, x, best_unit):\n        for i in range(self.som_size):\n            for j in range(self.som_size):\n                distance = np.sqrt((i - best_unit[0])**2 + (j - best_unit[1])**2)\n                influence = np.exp(-distance**2 / (2 * self.sigma**2))\n                self.som[i, j] += self.learning_rate * influence * (x - self.som[i, j])\n\n\n    def generate_offspring(self, population, func):\n        offspring = np.copy(population)\n        for i in range(self.pop_size):\n            # Select two parents randomly\n            idx1, idx2 = np.random.choice(self.pop_size, 2, replace=False)\n            parent1 = population[idx1]\n            parent2 = population[idx2]\n\n            # Crossover\n            crossover_mask = np.random.rand(self.dim) < 0.5\n            offspring[i] = np.where(crossover_mask, parent1, parent2)\n\n            # Mutation\n            mutation_mask = np.random.rand(self.dim) < 0.1\n            offspring[i][mutation_mask] += np.random.normal(0, 0.1, size=np.sum(mutation_mask))\n           \n            # Local search around best matching unit\n            bmu = self.find_best_matching_unit(parent1)\n            offspring[i] = 0.5 * offspring[i] + 0.5 * self.som[bmu[0], bmu[1]] + np.random.normal(0, 0.05, self.dim)\n\n            # Clip to bounds\n            offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub)\n        \n        return offspring\n        \n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n\n        self.initialize_som()\n\n        while eval_count < self.budget:\n            offspring = self.generate_offspring(population, func)\n            offspring_fitness = np.array([func(x) for x in offspring])\n            eval_count += self.pop_size\n\n            # Selection: replace parent with offspring if offspring is better\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    population[i] = offspring[i]\n                    fitness[i] = offspring_fitness[i]\n                    self.archive.append(offspring[i])\n            \n\n            # SOM update\n            for x in population:\n                best_unit = self.find_best_matching_unit(x)\n                self.update_som(x, best_unit)\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Annealing\n            self.sigma = max(self.sigma * self.sigma_decay_rate, self.min_sigma)\n            self.learning_rate *= self.lr_decay_rate\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: name 'deque' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with self-organizing maps for adapting search direction and step size.\n# Code: \n```python\nimport numpy as np\nfrom collections import deque\n\nclass SOMOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_size = som_size\n        self.som = None\n        self.learning_rate = 0.9\n        self.sigma = som_size / 2.0\n        self.min_sigma = 0.1\n        self.sigma_decay_rate = 0.99\n        self.lr_decay_rate = 0.99\n        self.archive = deque(maxlen=100)\n\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.archive.extend(population)\n        return population, fitness\n\n\n    def initialize_som(self):\n        self.som = np.random.rand(self.som_size, self.som_size, self.dim)\n        return self.som\n\n\n    def find_best_matching_unit(self, x):\n        distances = np.sum((self.som - x)**2, axis=2)\n        best_unit = np.unravel_index(np.argmin(distances), distances.shape)\n        return best_unit\n\n\n    def update_som(self, x, best_unit):\n        for i in range(self.som_size):\n            for j in range(self.som_size):\n                distance = np.sqrt((i - best_unit[0])**2 + (j - best_unit[1])**2)\n                influence = np.exp(-distance**2 / (2 * self.sigma**2))\n                self.som[i, j] += self.learning_rate * influence * (x - self.som[i, j])\n\n\n    def generate_offspring(self, population, func):\n        offspring = np.copy(population)\n        for i in range(self.pop_size):\n            # Select two parents randomly\n            idx1, idx2 = np.random.choice(self.pop_size, 2, replace=False)\n            parent1 = population[idx1]\n            parent2 = population[idx2]\n\n            # Crossover\n            crossover_mask = np.random.rand(self.dim) < 0.5\n            offspring[i] = np.where(crossover_mask, parent1, parent2)\n\n            # Mutation\n            mutation_mask = np.random.rand(self.dim) < 0.1\n            offspring[i][mutation_mask] += np.random.normal(0, 0.1, size=np.sum(mutation_mask))\n           \n            # Local search around best matching unit\n            bmu = self.find_best_matching_unit(parent1)\n            offspring[i] = 0.5 * offspring[i] + 0.5 * self.som[bmu[0], bmu[1]] + np.random.normal(0, 0.05, self.dim)\n\n            # Clip to bounds\n            offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub)\n        \n        return offspring\n        \n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n\n        self.initialize_som()\n\n        while eval_count < self.budget:\n            offspring = self.generate_offspring(population, func)\n            offspring_fitness = np.array([func(x) for x in offspring])\n            eval_count += self.pop_size\n\n            # Selection: replace parent with offspring if offspring is better\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    population[i] = offspring[i]\n                    fitness[i] = offspring_fitness[i]\n                    self.archive.append(offspring[i])\n            \n\n            # SOM update\n            for x in population:\n                best_unit = self.find_best_matching_unit(x)\n                self.update_som(x, best_unit)\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Annealing\n            self.sigma = max(self.sigma * self.sigma_decay_rate, self.min_sigma)\n            self.learning_rate *= self.lr_decay_rate\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.44952014575421667, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "575c54ce-3f8b-4179-bca7-c061c2a2f68d", "fitness": 0.0, "name": "RankDEPSO", "description": "Population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE), with a selection mechanism based on fitness rank rather than direct comparison, encouraging exploration and exploitation.", "code": "import numpy as np\n\nclass RankDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, pso_weight=0.7, de_cross=0.9, de_mut=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_weight = pso_weight\n        self.de_cross = de_cross\n        self.de_mut = de_mut\n        self.population = None\n        self.fitness = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_pos = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_pos = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_personal_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_pos[i] = self.population[i].copy()\n\n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_pos = self.population[best_index].copy()\n\n    def rank_based_selection(self):\n        ranked_indices = np.argsort(self.fitness)\n        selected_indices = ranked_indices[:self.pop_size // 2]  # Select top half based on rank\n        return self.population[selected_indices]\n\n    def pso_update(self, velocity, func):\n        inertia = self.pso_weight\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = cognitive_coeff * r1 * (self.personal_best_pos - self.population)\n        social_component = social_coeff * r2 * (self.global_best_pos - self.population)\n\n        velocity = inertia * velocity + cognitive_component + social_component\n        new_population = self.population + velocity\n\n        # Clip to bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        new_population = np.clip(new_population, lb, ub)\n        return new_population, velocity\n\n    def de_mutation(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            mutated_population[i] = x_r1 + self.de_mut * (x_r2 - x_r3)\n        return mutated_population\n\n    def de_crossover(self, mutated_population, func):\n        crossed_population = self.population.copy()\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cross:\n                    crossed_population[i, j] = mutated_population[i, j]\n\n        # Clip to bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        crossed_population = np.clip(crossed_population, lb, ub)\n\n        return crossed_population\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        velocity = np.zeros((self.pop_size, self.dim))\n\n        while self.eval_count < self.budget:\n            # PSO component\n            new_population_pso, velocity = self.pso_update(velocity, func)\n            \n            # DE component\n            mutated_population = self.de_mutation()\n            new_population_de = self.de_crossover(mutated_population, func)\n            \n            # Combine PSO and DE populations (e.g., select best from both)\n            combined_population = np.concatenate((new_population_pso, new_population_de, self.population), axis=0)\n            combined_fitness = np.array([func(x) for x in combined_population])\n            self.eval_count += combined_population.shape[0] - self.population.shape[0]\n\n            # Rank based selection to reduce back to original population size\n            ranked_indices = np.argsort(combined_fitness)[:self.pop_size]\n            self.population = combined_population[ranked_indices]\n            self.fitness = combined_fitness[ranked_indices]\n\n            self.update_personal_best()\n            self.update_global_best()\n        \n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm RankDEPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE), with a selection mechanism based on fitness rank rather than direct comparison, encouraging exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass RankDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, pso_weight=0.7, de_cross=0.9, de_mut=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_weight = pso_weight\n        self.de_cross = de_cross\n        self.de_mut = de_mut\n        self.population = None\n        self.fitness = None\n        self.personal_best_pos = None\n        self.personal_best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_pos = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_pos = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_personal_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_pos[i] = self.population[i].copy()\n\n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_pos = self.population[best_index].copy()\n\n    def rank_based_selection(self):\n        ranked_indices = np.argsort(self.fitness)\n        selected_indices = ranked_indices[:self.pop_size // 2]  # Select top half based on rank\n        return self.population[selected_indices]\n\n    def pso_update(self, velocity, func):\n        inertia = self.pso_weight\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = cognitive_coeff * r1 * (self.personal_best_pos - self.population)\n        social_component = social_coeff * r2 * (self.global_best_pos - self.population)\n\n        velocity = inertia * velocity + cognitive_component + social_component\n        new_population = self.population + velocity\n\n        # Clip to bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        new_population = np.clip(new_population, lb, ub)\n        return new_population, velocity\n\n    def de_mutation(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            mutated_population[i] = x_r1 + self.de_mut * (x_r2 - x_r3)\n        return mutated_population\n\n    def de_crossover(self, mutated_population, func):\n        crossed_population = self.population.copy()\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cross:\n                    crossed_population[i, j] = mutated_population[i, j]\n\n        # Clip to bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        crossed_population = np.clip(crossed_population, lb, ub)\n\n        return crossed_population\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        velocity = np.zeros((self.pop_size, self.dim))\n\n        while self.eval_count < self.budget:\n            # PSO component\n            new_population_pso, velocity = self.pso_update(velocity, func)\n            \n            # DE component\n            mutated_population = self.de_mutation()\n            new_population_de = self.de_crossover(mutated_population, func)\n            \n            # Combine PSO and DE populations (e.g., select best from both)\n            combined_population = np.concatenate((new_population_pso, new_population_de, self.population), axis=0)\n            combined_fitness = np.array([func(x) for x in combined_population])\n            self.eval_count += combined_population.shape[0] - self.population.shape[0]\n\n            # Rank based selection to reduce back to original population size\n            ranked_indices = np.argsort(combined_fitness)[:self.pop_size]\n            self.population = combined_population[ranked_indices]\n            self.fitness = combined_fitness[ranked_indices]\n\n            self.update_personal_best()\n            self.update_global_best()\n        \n        return self.global_best_fitness, self.global_best_pos\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.14678276175706412, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "759520d0-f7e2-4b09-aefe-943b77ab5d9b", "fitness": 0.0, "name": "HybridDE_NM", "description": "A population-based algorithm using a combination of global search based on differential evolution and local search based on Nelder-Mead simplex, dynamically adjusting the balance based on performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.7, nm_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.nm_rate = nm_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    a, b, c = np.random.choice(self.pop_size, 3, replace=False)\n                    while a == i or b == i or c == i:\n                        a, b, c = np.random.choice(self.pop_size, 3, replace=False)\n                    \n                    F = 0.8  # Mutation factor\n                    CR = 0.9 # Crossover rate\n\n                    v = self.population[a] + F * (self.population[b] - self.population[c])\n                    v = np.clip(v, self.lb, self.ub)\n                    \n                    u = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < CR or j == j_rand:\n                            u[j] = v[j]\n                    \n                    f_u = func(u)\n                    self.budget -= 1\n                    if f_u < self.fitness[i] and self.budget > 0:\n                        self.population[i] = u\n                        self.fitness[i] = f_u\n            \n            # Nelder-Mead Simplex step (applied to the best individual)\n            if np.random.rand() < self.nm_rate and self.budget > 0:\n                best_index = np.argmin(self.fitness)\n                x_best = self.population[best_index]\n                \n                def obj_fun(x):\n                  val = func(x)\n                  return val\n                \n                res = minimize(obj_fun, x_best, method='Nelder-Mead', bounds=[(self.lb, self.ub)]*self.dim, options={'maxfev': min(self.budget, 50)})\n                \n                if res.fun < self.fitness[best_index]:\n                    self.population[best_index] = res.x\n                    self.fitness[best_index] = res.fun\n                self.budget -= res.nfev\n\n            # Update global best\n            best_fitness = np.min(self.fitness)\n            best_index = np.argmin(self.fitness)\n            if best_fitness < self.f_opt:\n                self.f_opt = best_fitness\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm using a combination of global search based on differential evolution and local search based on Nelder-Mead simplex, dynamically adjusting the balance based on performance.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_rate=0.7, nm_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.nm_rate = nm_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    a, b, c = np.random.choice(self.pop_size, 3, replace=False)\n                    while a == i or b == i or c == i:\n                        a, b, c = np.random.choice(self.pop_size, 3, replace=False)\n                    \n                    F = 0.8  # Mutation factor\n                    CR = 0.9 # Crossover rate\n\n                    v = self.population[a] + F * (self.population[b] - self.population[c])\n                    v = np.clip(v, self.lb, self.ub)\n                    \n                    u = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < CR or j == j_rand:\n                            u[j] = v[j]\n                    \n                    f_u = func(u)\n                    self.budget -= 1\n                    if f_u < self.fitness[i] and self.budget > 0:\n                        self.population[i] = u\n                        self.fitness[i] = f_u\n            \n            # Nelder-Mead Simplex step (applied to the best individual)\n            if np.random.rand() < self.nm_rate and self.budget > 0:\n                best_index = np.argmin(self.fitness)\n                x_best = self.population[best_index]\n                \n                def obj_fun(x):\n                  val = func(x)\n                  return val\n                \n                res = minimize(obj_fun, x_best, method='Nelder-Mead', bounds=[(self.lb, self.ub)]*self.dim, options={'maxfev': min(self.budget, 50)})\n                \n                if res.fun < self.fitness[best_index]:\n                    self.population[best_index] = res.x\n                    self.fitness[best_index] = res.fun\n                self.budget -= res.nfev\n\n            # Update global best\n            best_fitness = np.min(self.fitness)\n            best_index = np.argmin(self.fitness)\n            if best_fitness < self.f_opt:\n                self.f_opt = best_fitness\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.11836904574616797, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "f43aa052-055c-4e9a-8b70-2ed5c0a46a34", "fitness": 0.0, "name": "EnhancedHybridDECMO", "description": "Combines Differential Evolution with CMA-ES-inspired updates and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    basis = np.random.randn(self.dim, self.dim)\n                    Q, _ = np.linalg.qr(basis)  # Orthogonal basis\n                    step_size = np.random.uniform(-0.1, 0.1, self.dim) # smaller stepsize compared to random values, to allow exploitation.\n                    x_orthogonal = x_trial + np.dot(Q, step_size)\n                    x_orthogonal = np.clip(x_orthogonal, func.bounds.lb, func.bounds.ub)\n                    f_orthogonal = func(x_orthogonal)\n                    self.budget -= 1\n\n                    if f_orthogonal < func(x_trial):\n                        x_trial = x_orthogonal.copy()\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridDECMO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dd7a59c1-a606-416b-8646-44951e8cb1a3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution with CMA-ES-inspired updates and orthogonal learning to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    basis = np.random.randn(self.dim, self.dim)\n                    Q, _ = np.linalg.qr(basis)  # Orthogonal basis\n                    step_size = np.random.uniform(-0.1, 0.1, self.dim) # smaller stepsize compared to random values, to allow exploitation.\n                    x_orthogonal = x_trial + np.dot(Q, step_size)\n                    x_orthogonal = np.clip(x_orthogonal, func.bounds.lb, func.bounds.ub)\n                    f_orthogonal = func(x_orthogonal)\n                    self.budget -= 1\n\n                    if f_orthogonal < func(x_trial):\n                        x_trial = x_orthogonal.copy()\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.14157506395731687, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "62381abc-7101-4bc9-8081-5e467acd8f22", "fitness": 0.0, "name": "CMAES_NelderMead", "description": "A novel algorithm that combines a simplified Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a Nelder-Mead simplex search to balance global exploration with local exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CMAES_NelderMead:\n    def __init__(self, budget=10000, dim=10, sigma=0.1, lambda_=None):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.lambda_ = lambda_ if lambda_ is not None else 4 + int(3 * np.log(dim))  # Population size\n        self.mu = self.lambda_ // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        while eval_count < self.budget:\n            # Sampling\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.lambda_)\n            x = mean + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            f = np.array([func(xi) for xi in x])\n            eval_count += self.lambda_\n\n            if np.any(f < self.f_opt):\n                best_idx = np.argmin(f)\n                if f[best_idx] < self.f_opt:\n                    self.f_opt = f[best_idx]\n                    self.x_opt = x[best_idx]\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_sorted = x[idx[:self.mu]]\n            z_sorted = z[idx[:self.mu]]\n\n            mean_new = np.sum(self.weights[:, None] * x_sorted, axis=0)  # Weighted recombination\n            \n            # Cumulation\n            pc_new = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.sum(self.weights[:, None] * z_sorted, axis=0)\n            self.pc = pc_new\n            \n            # Adaptation\n            C_temp = np.sum(self.weights[:, None, None] * z_sorted[:, :, None] * z_sorted[:, None, :], axis=0)\n            self.C = (1 - self.cs) * self.C + self.cs * C_temp\n\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / self.chiN - 1))\n            \n            mean = mean_new\n\n\n            # Nelder-Mead refinement every few iterations (e.g., every 10% of the budget)\n            if eval_count > 0 and eval_count % (self.budget // 10) == 0:\n               \n                nm_budget = min(self.budget - eval_count, self.dim * 10) # Reduced budget for Nelder-Mead\n                \n                if nm_budget > 0:\n                    res = minimize(func, self.x_opt, method='Nelder-Mead', options={'maxfev': nm_budget, 'xatol': 1e-6, 'fatol': 1e-6})\n\n                    eval_count += res.nfev\n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A novel algorithm that combines a simplified Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a Nelder-Mead simplex search to balance global exploration with local exploitation.\n\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass CMAES_NelderMead:\n    def __init__(self, budget=10000, dim=10, sigma=0.1, lambda_=None):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.lambda_ = lambda_ if lambda_ is not None else 4 + int(3 * np.log(dim))  # Population size\n        self.mu = self.lambda_ // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        while eval_count < self.budget:\n            # Sampling\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.lambda_)\n            x = mean + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            f = np.array([func(xi) for xi in x])\n            eval_count += self.lambda_\n\n            if np.any(f < self.f_opt):\n                best_idx = np.argmin(f)\n                if f[best_idx] < self.f_opt:\n                    self.f_opt = f[best_idx]\n                    self.x_opt = x[best_idx]\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_sorted = x[idx[:self.mu]]\n            z_sorted = z[idx[:self.mu]]\n\n            mean_new = np.sum(self.weights[:, None] * x_sorted, axis=0)  # Weighted recombination\n            \n            # Cumulation\n            pc_new = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.sum(self.weights[:, None] * z_sorted, axis=0)\n            self.pc = pc_new\n            \n            # Adaptation\n            C_temp = np.sum(self.weights[:, None, None] * z_sorted[:, :, None] * z_sorted[:, None, :], axis=0)\n            self.C = (1 - self.cs) * self.C + self.cs * C_temp\n\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / self.chiN - 1))\n            \n            mean = mean_new\n\n\n            # Nelder-Mead refinement every few iterations (e.g., every 10% of the budget)\n            if eval_count > 0 and eval_count % (self.budget // 10) == 0:\n               \n                nm_budget = min(self.budget - eval_count, self.dim * 10) # Reduced budget for Nelder-Mead\n                \n                if nm_budget > 0:\n                    res = minimize(func, self.x_opt, method='Nelder-Mead', options={'maxfev': nm_budget, 'xatol': 1e-6, 'fatol': 1e-6})\n\n                    eval_count += res.nfev\n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.42528436275885523, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "fb7dd932-a8c5-4ba2-bf48-9b28c93c98bd", "fitness": 0.4683001893178346, "name": "HybridAdaptiveDECMO3", "description": "Combines DE with CMA-ES, adaptive parameters, archive, and stochastic ranking, focusing on refined step size and covariance matrix adaptation.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMO3:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, c_y_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.c_y_factor = c_y_factor\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * self.c_y_factor * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                    self.F *= (1 + self.adaptation_rate)\n                    self.CR = min(1.0, self.CR * (1 + self.adaptation_rate))\n\n\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                    self.F *= (1 - self.adaptation_rate)\n                    self.CR = max(0.0, self.CR * (1 - self.adaptation_rate))\n                    \n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm HybridAdaptiveDECMO3 scored 0.468 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea", "dd7a59c1-a606-416b-8646-44951e8cb1a3"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines DE with CMA-ES, adaptive parameters, archive, and stochastic ranking, focusing on refined step size and covariance matrix adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMO3:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, c_y_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.c_y_factor = c_y_factor\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * self.c_y_factor * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                    self.F *= (1 + self.adaptation_rate)\n                    self.CR = min(1.0, self.CR * (1 + self.adaptation_rate))\n\n\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                    self.F *= (1 - self.adaptation_rate)\n                    self.CR = max(0.0, self.CR * (1 - self.adaptation_rate))\n                    \n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1550984556259728, 0.21726597942776493, 0.4265109609985249, 0.7484008680226774, 0.34483874932142755, 0.6406000397184113, 0.4917622606949995, 0.46675593396409154, 0.5573401160125434, 0.4410658470650364, 0.4125369640181994, 0.9969856505199032, 0.29102459731079977, 0.31066124526685157, 0.8042908964040784, 0.4043950481909391, 0.31187587461910193, 0.6389760142222145, 0.197238499798432, 0.5083797851547234], "operator": "crossover", "theta_sampled": 0.004330902119583022, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "ec240c8d-0b8c-46b8-9f75-c4e3861cb3c4", "fitness": 0.0, "name": "AdaptivePerturbationPSO", "description": "Population-based algorithm using a simplified particle swarm approach with adaptive inertia and a perturbation mechanism for exploration.", "code": "import numpy as np\n\nclass AdaptivePerturbationPSO:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia_max=0.9, inertia_min=0.4, c1=2, c2=2, perturbation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n        self.perturbation_rate = perturbation_rate\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.velocities = np.zeros_like(self.particles)\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_values = np.array([func(x) for x in self.particles])\n        self.eval_count += self.population_size\n\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_values)].copy()\n        self.global_best_value = np.min(self.personal_best_values)\n\n    def update_velocity(self, i, inertia):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n        social_component = self.c2 * r2 * (self.global_best_position - self.particles[i])\n\n        self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n    def update_position(self, i, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles[i] = self.particles[i] + self.velocities[i]\n\n        # Boundary handling: reflect particles if they exceed the bounds\n        for d in range(self.dim):\n            if self.particles[i, d] < lb:\n                self.particles[i, d] = lb + (lb - self.particles[i, d])\n                self.velocities[i, d] *= -0.5 # Dampen velocity after reflection\n            elif self.particles[i, d] > ub:\n                self.particles[i, d] = ub - (self.particles[i, d] - ub)\n                self.velocities[i, d] *= -0.5 # Dampen velocity after reflection\n\n        # Keep within bounds\n        self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n        f = func(self.particles[i])\n        self.eval_count += 1\n\n        if f < self.personal_best_values[i]:\n            self.personal_best_values[i] = f\n            self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n    def perturb_particle(self, i, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        # Apply small random perturbation\n        for d in range(self.dim):\n            if np.random.rand() < self.perturbation_rate:\n                self.particles[i, d] += np.random.uniform(-0.1*(ub-lb), 0.1*(ub-lb))  #Small perturbation\n\n        self.particles[i] = np.clip(self.particles[i], lb, ub)\n        f = func(self.particles[i])\n        self.eval_count += 1\n\n        if f < self.personal_best_values[i]:\n            self.personal_best_values[i] = f\n            self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n        self.f_opt = self.global_best_value\n        self.x_opt = self.global_best_position\n\n        iteration = 0\n        while self.eval_count < self.budget:\n            # Adaptive Inertia Weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (iteration / (self.budget / self.population_size))\n            \n            for i in range(self.population_size):\n                self.update_velocity(i, inertia)\n                self.update_position(i, func)\n\n                # Perturbation with probability\n                if np.random.rand() < 0.05: # 5% of iterations\n                    self.perturb_particle(i, func)\n\n            if self.global_best_value < self.f_opt:\n                self.f_opt = self.global_best_value\n                self.x_opt = self.global_best_position\n            \n            iteration += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a simplified particle swarm approach with adaptive inertia and a perturbation mechanism for exploration.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePerturbationPSO:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia_max=0.9, inertia_min=0.4, c1=2, c2=2, perturbation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n        self.perturbation_rate = perturbation_rate\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.velocities = np.zeros_like(self.particles)\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_values = np.array([func(x) for x in self.particles])\n        self.eval_count += self.population_size\n\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_values)].copy()\n        self.global_best_value = np.min(self.personal_best_values)\n\n    def update_velocity(self, i, inertia):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n        social_component = self.c2 * r2 * (self.global_best_position - self.particles[i])\n\n        self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n    def update_position(self, i, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles[i] = self.particles[i] + self.velocities[i]\n\n        # Boundary handling: reflect particles if they exceed the bounds\n        for d in range(self.dim):\n            if self.particles[i, d] < lb:\n                self.particles[i, d] = lb + (lb - self.particles[i, d])\n                self.velocities[i, d] *= -0.5 # Dampen velocity after reflection\n            elif self.particles[i, d] > ub:\n                self.particles[i, d] = ub - (self.particles[i, d] - ub)\n                self.velocities[i, d] *= -0.5 # Dampen velocity after reflection\n\n        # Keep within bounds\n        self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n        f = func(self.particles[i])\n        self.eval_count += 1\n\n        if f < self.personal_best_values[i]:\n            self.personal_best_values[i] = f\n            self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n    def perturb_particle(self, i, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        # Apply small random perturbation\n        for d in range(self.dim):\n            if np.random.rand() < self.perturbation_rate:\n                self.particles[i, d] += np.random.uniform(-0.1*(ub-lb), 0.1*(ub-lb))  #Small perturbation\n\n        self.particles[i] = np.clip(self.particles[i], lb, ub)\n        f = func(self.particles[i])\n        self.eval_count += 1\n\n        if f < self.personal_best_values[i]:\n            self.personal_best_values[i] = f\n            self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n        self.f_opt = self.global_best_value\n        self.x_opt = self.global_best_position\n\n        iteration = 0\n        while self.eval_count < self.budget:\n            # Adaptive Inertia Weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (iteration / (self.budget / self.population_size))\n            \n            for i in range(self.population_size):\n                self.update_velocity(i, inertia)\n                self.update_position(i, func)\n\n                # Perturbation with probability\n                if np.random.rand() < 0.05: # 5% of iterations\n                    self.perturb_particle(i, func)\n\n            if self.global_best_value < self.f_opt:\n                self.f_opt = self.global_best_value\n                self.x_opt = self.global_best_position\n            \n            iteration += 1\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.15200098267604764, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "e9b87d4c-ad18-41e6-9059-fb1f7803d109", "fitness": 0.0, "name": "AdaptiveCMAESWithLocalSearch", "description": "An adaptive CMA-ES variant with population size adaptation and a local search step using Nelder-Mead simplex optimization to refine promising solutions.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveCMAESWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, pop_size_multiplier=4):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.pop_size_multiplier = pop_size_multiplier\n\n    def __call__(self, func):\n        # Initialization\n        mu = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim) # Initialize mean at center of bounds\n        sigma = self.initial_sigma\n        pop_size = int(self.pop_size_multiplier * self.dim)\n        \n        C = np.eye(self.dim)  # Covariance matrix\n        p_sigma = np.zeros(self.dim) # Evolution path for sigma\n        p_c = np.zeros(self.dim) # Evolution path for covariance matrix\n        \n        c_sigma = (pop_size + 2) / (self.dim + pop_size + 5)\n        c_c = (4 + self.dim / 3) / (self.dim + 4 + self.dim * 3 / 2)\n        c_cov = 2 / ((self.dim + np.sqrt(2))**2)\n        c_cov_mu = 0.25 # Small increase\n        \n        d_sigma = 1 + 2 * max(0, np.sqrt((pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        \n        f_opt = np.inf\n        x_opt = None\n        eval_count = 0\n        \n        archive_x = []\n        archive_f = []\n\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, pop_size)\n            x = mu[:, np.newaxis] + sigma * np.dot(np.linalg.cholesky(C), z)\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(pop_size)])\n            eval_count += pop_size\n\n            if eval_count > self.budget:\n                f = f[:pop_size - (eval_count - self.budget)]\n                x = x[:, :pop_size - (eval_count - self.budget)]\n                pop_size = x.shape[1]  # dynamically decrease pop size if exceeding budget\n                eval_count = self.budget  # fix eval_count\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n            \n            # Update optimal solution\n            if f[0] < f_opt:\n                f_opt = f[0]\n                x_opt = x[:, 0].copy()\n\n            archive_x.extend(x[:, :pop_size].T.tolist())\n            archive_f.extend(f[:pop_size].tolist())\n            \n            # Update CMA-ES parameters\n            mu_old = mu.copy()\n            mu = np.mean(x[:, :pop_size // 2], axis=1)\n\n            # Rank-one update of evolution paths\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma)) * np.dot(np.linalg.inv(np.linalg.cholesky(C)), (mu - mu_old)) / sigma\n            p_c = (1 - c_c) * p_c + np.sqrt(c_c * (2 - c_c)) * (mu - mu_old) / sigma\n\n            # Covariance matrix adaptation\n            h_sigma = np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - c_sigma)**(2 * eval_count / pop_size)) < (1.4 + 2 / (self.dim + 1)) * np.sqrt(self.dim)\n            \n            dmu = (mu - mu_old)[:, np.newaxis]\n            \n            C = (1 - c_cov) * C + c_cov * (np.outer(p_c, p_c) + (1 - h_sigma) * c_cov_mu * C) + c_cov * c_cov_mu * np.eye(self.dim)\n\n            # Ensure C is positive definite (numerical stability)\n            try:\n                np.linalg.cholesky(C)\n            except np.linalg.LinAlgError:\n                C = C + 1e-6 * np.eye(self.dim)\n            \n            # Adapt step size\n            sigma = sigma * np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            # Adaptive population size (optional, but helps)\n            if eval_count > self.budget / 2:\n                pop_size = max(int(self.pop_size_multiplier * self.dim * (1 - (eval_count / self.budget - 0.5)*2)), 4)  # Linear decrease\n\n            # Local Search (Nelder-Mead on best solution so far)\n            if eval_count % (2 * pop_size) == 0 and eval_count < self.budget * 0.9: # Perform every few iterations\n                def func_to_minimize(x):\n                    return func(x)\n\n                res = minimize(func_to_minimize, x_opt, method='Nelder-Mead', bounds=list(zip(func.bounds.lb*np.ones(self.dim), func.bounds.ub*np.ones(self.dim)), ), options={'maxfev': int(self.budget * 0.05)})  # Limited budget for local search\n                \n                if res.fun < f_opt:\n                    f_opt = res.fun\n                    x_opt = res.x\n                eval_count += res.nfev\n                if eval_count > self.budget: # budget check\n                    eval_count = self.budget\n                    break # stop immediately if budget is hit\n                    \n\n        return f_opt, x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,8) (2,) (2,) ", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive CMA-ES variant with population size adaptation and a local search step using Nelder-Mead simplex optimization to refine promising solutions.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveCMAESWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, pop_size_multiplier=4):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.pop_size_multiplier = pop_size_multiplier\n\n    def __call__(self, func):\n        # Initialization\n        mu = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim) # Initialize mean at center of bounds\n        sigma = self.initial_sigma\n        pop_size = int(self.pop_size_multiplier * self.dim)\n        \n        C = np.eye(self.dim)  # Covariance matrix\n        p_sigma = np.zeros(self.dim) # Evolution path for sigma\n        p_c = np.zeros(self.dim) # Evolution path for covariance matrix\n        \n        c_sigma = (pop_size + 2) / (self.dim + pop_size + 5)\n        c_c = (4 + self.dim / 3) / (self.dim + 4 + self.dim * 3 / 2)\n        c_cov = 2 / ((self.dim + np.sqrt(2))**2)\n        c_cov_mu = 0.25 # Small increase\n        \n        d_sigma = 1 + 2 * max(0, np.sqrt((pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        \n        f_opt = np.inf\n        x_opt = None\n        eval_count = 0\n        \n        archive_x = []\n        archive_f = []\n\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, pop_size)\n            x = mu[:, np.newaxis] + sigma * np.dot(np.linalg.cholesky(C), z)\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(pop_size)])\n            eval_count += pop_size\n\n            if eval_count > self.budget:\n                f = f[:pop_size - (eval_count - self.budget)]\n                x = x[:, :pop_size - (eval_count - self.budget)]\n                pop_size = x.shape[1]  # dynamically decrease pop size if exceeding budget\n                eval_count = self.budget  # fix eval_count\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n            \n            # Update optimal solution\n            if f[0] < f_opt:\n                f_opt = f[0]\n                x_opt = x[:, 0].copy()\n\n            archive_x.extend(x[:, :pop_size].T.tolist())\n            archive_f.extend(f[:pop_size].tolist())\n            \n            # Update CMA-ES parameters\n            mu_old = mu.copy()\n            mu = np.mean(x[:, :pop_size // 2], axis=1)\n\n            # Rank-one update of evolution paths\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma)) * np.dot(np.linalg.inv(np.linalg.cholesky(C)), (mu - mu_old)) / sigma\n            p_c = (1 - c_c) * p_c + np.sqrt(c_c * (2 - c_c)) * (mu - mu_old) / sigma\n\n            # Covariance matrix adaptation\n            h_sigma = np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - c_sigma)**(2 * eval_count / pop_size)) < (1.4 + 2 / (self.dim + 1)) * np.sqrt(self.dim)\n            \n            dmu = (mu - mu_old)[:, np.newaxis]\n            \n            C = (1 - c_cov) * C + c_cov * (np.outer(p_c, p_c) + (1 - h_sigma) * c_cov_mu * C) + c_cov * c_cov_mu * np.eye(self.dim)\n\n            # Ensure C is positive definite (numerical stability)\n            try:\n                np.linalg.cholesky(C)\n            except np.linalg.LinAlgError:\n                C = C + 1e-6 * np.eye(self.dim)\n            \n            # Adapt step size\n            sigma = sigma * np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            # Adaptive population size (optional, but helps)\n            if eval_count > self.budget / 2:\n                pop_size = max(int(self.pop_size_multiplier * self.dim * (1 - (eval_count / self.budget - 0.5)*2)), 4)  # Linear decrease\n\n            # Local Search (Nelder-Mead on best solution so far)\n            if eval_count % (2 * pop_size) == 0 and eval_count < self.budget * 0.9: # Perform every few iterations\n                def func_to_minimize(x):\n                    return func(x)\n\n                res = minimize(func_to_minimize, x_opt, method='Nelder-Mead', bounds=list(zip(func.bounds.lb*np.ones(self.dim), func.bounds.ub*np.ones(self.dim)), ), options={'maxfev': int(self.budget * 0.05)})  # Limited budget for local search\n                \n                if res.fun < f_opt:\n                    f_opt = res.fun\n                    x_opt = res.x\n                eval_count += res.nfev\n                if eval_count > self.budget: # budget check\n                    eval_count = self.budget\n                    break # stop immediately if budget is hit\n                    \n\n        return f_opt, x_opt\n```", "operator": "random_new", "theta_sampled": 0.39159685495974983, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "e21a1a2c-fa1c-4bc3-9032-49a611013a0e", "fitness": 0.0, "name": "EnhancedHybridDECMO", "description": "Combines Differential Evolution with Covariance Matrix Adaptation and a step size adaptation mechanism, utilizing a combined mutation strategy and adaptive parameter control based on success rate, further enhanced with orthogonal learning to improve exploration.", "code": "import numpy as np\n\nclass EnhancedHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, ortho_group_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.ortho_group_size = ortho_group_size\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)  # Eigenvectors of C\n        self.D = np.ones(self.dim)  # Eigenvalues of C\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # Combined Mutation Strategy: DE + CMA-ES\n                z = np.random.normal(0, 1, self.dim)\n                x_mutated_de = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated_cma = self.m + self.sigma * self.B @ (self.D * z)  # CMA-ES mutation\n                x_mutated = 0.5 * x_mutated_de + 0.5 * x_mutated_cma  # Combine both\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning\n                if self.ortho_group_size > 1 and self.dim > 1:\n                    num_groups = self.dim // self.ortho_group_size\n                    for g in range(num_groups):\n                        start_idx = g * self.ortho_group_size\n                        end_idx = (g + 1) * self.ortho_group_size\n                        group_indices = list(range(start_idx, end_idx))\n                        group_indices = [i % self.dim for i in group_indices] # Ensure indices stay within bounds\n\n                        # Generate an orthogonal array (simplified: random orthogonal matrix)\n                        if self.ortho_group_size > 1:\n                            orthogonal_matrix = np.random.randn(self.ortho_group_size, self.ortho_group_size)\n                            q, r = np.linalg.qr(orthogonal_matrix)  # Ensure orthogonality\n\n                            # Apply orthogonal learning within the group\n                            for k in range(self.ortho_group_size):\n                                new_trial = x_trial.copy()\n                                for j in range(self.ortho_group_size):\n                                    new_trial[group_indices[j]] = x_trial[group_indices[j]] + 0.1 * q[k, j]  # Adjust by orthogonal direction\n                                new_trial = np.clip(new_trial, func.bounds.lb, func.bounds.ub) # Clip each coordinate\n\n                                f_new_trial = func(new_trial)\n                                self.budget -= 1\n                                if f_new_trial < func(x_trial): # Compare against x_trial for consistency\n                                    x_trial = new_trial.copy() # Only update x_trial\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n                \n                # Eigen decomposition of C (only every dim iterations)\n                if i % self.dim == 0:\n                    try:\n                        self.D, self.B = np.linalg.eigh(self.C)  # Ensure C is symmetric\n                        self.D = np.sqrt(np.abs(self.D))  # Handle potential negative eigenvalues\n                    except np.linalg.LinAlgError:\n                        self.C = self.C + 1e-6 * np.eye(self.dim)  # Regularize C\n                        self.D, self.B = np.linalg.eigh(self.C)\n                        self.D = np.sqrt(np.abs(self.D))\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridDECMO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dd7a59c1-a606-416b-8646-44951e8cb1a3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution with Covariance Matrix Adaptation and a step size adaptation mechanism, utilizing a combined mutation strategy and adaptive parameter control based on success rate, further enhanced with orthogonal learning to improve exploration.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, ortho_group_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.ortho_group_size = ortho_group_size\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)  # Eigenvectors of C\n        self.D = np.ones(self.dim)  # Eigenvalues of C\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # Combined Mutation Strategy: DE + CMA-ES\n                z = np.random.normal(0, 1, self.dim)\n                x_mutated_de = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated_cma = self.m + self.sigma * self.B @ (self.D * z)  # CMA-ES mutation\n                x_mutated = 0.5 * x_mutated_de + 0.5 * x_mutated_cma  # Combine both\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning\n                if self.ortho_group_size > 1 and self.dim > 1:\n                    num_groups = self.dim // self.ortho_group_size\n                    for g in range(num_groups):\n                        start_idx = g * self.ortho_group_size\n                        end_idx = (g + 1) * self.ortho_group_size\n                        group_indices = list(range(start_idx, end_idx))\n                        group_indices = [i % self.dim for i in group_indices] # Ensure indices stay within bounds\n\n                        # Generate an orthogonal array (simplified: random orthogonal matrix)\n                        if self.ortho_group_size > 1:\n                            orthogonal_matrix = np.random.randn(self.ortho_group_size, self.ortho_group_size)\n                            q, r = np.linalg.qr(orthogonal_matrix)  # Ensure orthogonality\n\n                            # Apply orthogonal learning within the group\n                            for k in range(self.ortho_group_size):\n                                new_trial = x_trial.copy()\n                                for j in range(self.ortho_group_size):\n                                    new_trial[group_indices[j]] = x_trial[group_indices[j]] + 0.1 * q[k, j]  # Adjust by orthogonal direction\n                                new_trial = np.clip(new_trial, func.bounds.lb, func.bounds.ub) # Clip each coordinate\n\n                                f_new_trial = func(new_trial)\n                                self.budget -= 1\n                                if f_new_trial < func(x_trial): # Compare against x_trial for consistency\n                                    x_trial = new_trial.copy() # Only update x_trial\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n                \n                # Eigen decomposition of C (only every dim iterations)\n                if i % self.dim == 0:\n                    try:\n                        self.D, self.B = np.linalg.eigh(self.C)  # Ensure C is symmetric\n                        self.D = np.sqrt(np.abs(self.D))  # Handle potential negative eigenvalues\n                    except np.linalg.LinAlgError:\n                        self.C = self.C + 1e-6 * np.eye(self.dim)  # Regularize C\n                        self.D, self.B = np.linalg.eigh(self.C)\n                        self.D = np.sqrt(np.abs(self.D))\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.3051204636500558, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "083cbcd7-d7ed-4ad3-a654-fbebd51aded3", "fitness": 0.0, "name": "AdaptiveGMMNelderMead", "description": "An adaptive search algorithm that combines a global exploration phase using a Gaussian Mixture Model (GMM) and a local exploitation phase using a gradient-free optimization method (Nelder-Mead) with adaptive probability based on the success of the previous search.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\nfrom scipy.optimize import minimize\n\nclass AdaptiveGMMNelderMead:\n    def __init__(self, budget=10000, dim=10, n_components=5, exploration_prob=0.5, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.exploration_prob = exploration_prob  # Probability of exploration (GMM sampling)\n        self.exploitation_prob = 1 - exploration_prob  # Probability of exploitation (Nelder-Mead)\n        self.step_size = step_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_gmm(self, func, gmm):\n        \"\"\"Samples a point from the GMM within the bounds.\"\"\"\n        while True:\n            index = np.random.choice(len(gmm.means_), p=gmm.weights_)\n            x = np.random.multivariate_normal(gmm.means_[index], gmm.covariances_[index])\n            if np.all(x >= func.bounds.lb) and np.all(x <= func.bounds.ub):\n                return x\n    \n\n    def update_gmm(self, X, weights):\n        \"\"\"Updates the GMM based on the provided samples and their weights.\"\"\"\n        if len(X) < self.n_components: # Not enough data, return random GMM. Should only happen in the beginning\n          means = np.random.uniform(low=-5.0, high=5.0, size=(self.n_components, self.dim))\n          covariances = [np.eye(self.dim) * (self.step_size**2) for _ in range(self.n_components)] # Diagonal covariance matrices\n          weights = np.ones(self.n_components) / self.n_components\n          return type('GMM', (object,), {'means_': means, 'covariances_': covariances, 'weights_': weights})()\n          \n\n        from sklearn.mixture import GaussianMixture\n        gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n        gmm.fit(X, weights)\n        return gmm\n\n    def __call__(self, func):\n        X = []\n        F = []\n        \n        # Initialization: random GMM\n        means = np.random.uniform(low=func.bounds.lb, high=func.bounds.ub, size=(self.n_components, self.dim))\n        covariances = [np.eye(self.dim) * (self.step_size**2) for _ in range(self.n_components)] # Diagonal covariance matrices\n        weights = np.ones(self.n_components) / self.n_components\n        gmm = type('GMM', (object,), {'means_': means, 'covariances_': covariances, 'weights_': weights})()\n\n        \n        success_count = 0\n        total_count = 0\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.exploration_prob:\n                # Exploration: Sample from GMM\n                x = self.sample_gmm(func, gmm)\n                f = func(x)\n                self.eval_count += 1\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    success_count +=1\n\n                X.append(x)\n                F.append(f)\n\n            else:\n                # Exploitation: Nelder-Mead around current best\n                if self.x_opt is None:\n                    x0 = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    x0 = self.x_opt\n                \n                nm_budget = min(self.budget - self.eval_count, 500) # small budget for local search\n                \n                res = minimize(func, x0, method='Nelder-Mead', options={'maxfev': nm_budget, 'xatol': 1e-4, 'fatol': 1e-4})\n                self.eval_count += res.nfev\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    success_count +=1\n                    \n                X.append(res.x)\n                F.append(res.fun)\n            \n            total_count += 1\n\n            # Update GMM based on collected data. Weight more on better solutions\n            if len(X) > self.n_components:\n              normalized_F = np.max(F) - np.array(F) # Rewards better values with higher values\n              weights = normalized_F / np.sum(normalized_F)\n              gmm = self.update_gmm(np.array(X), weights)\n\n            # Adapt exploration probability\n            if total_count > 20:\n                success_rate = success_count / total_count\n                self.exploration_prob = min(0.9, max(0.1, 1.0 - success_rate)) # Higher success -> more exploitation\n                self.exploitation_prob = 1 - self.exploration_prob\n                success_count = 0\n                total_count = 0\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive search algorithm that combines a global exploration phase using a Gaussian Mixture Model (GMM) and a local exploitation phase using a gradient-free optimization method (Nelder-Mead) with adaptive probability based on the success of the previous search.\n# Code: \n```python\nimport numpy as np\nfrom scipy.stats import multivariate_normal\nfrom scipy.optimize import minimize\n\nclass AdaptiveGMMNelderMead:\n    def __init__(self, budget=10000, dim=10, n_components=5, exploration_prob=0.5, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.exploration_prob = exploration_prob  # Probability of exploration (GMM sampling)\n        self.exploitation_prob = 1 - exploration_prob  # Probability of exploitation (Nelder-Mead)\n        self.step_size = step_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_gmm(self, func, gmm):\n        \"\"\"Samples a point from the GMM within the bounds.\"\"\"\n        while True:\n            index = np.random.choice(len(gmm.means_), p=gmm.weights_)\n            x = np.random.multivariate_normal(gmm.means_[index], gmm.covariances_[index])\n            if np.all(x >= func.bounds.lb) and np.all(x <= func.bounds.ub):\n                return x\n    \n\n    def update_gmm(self, X, weights):\n        \"\"\"Updates the GMM based on the provided samples and their weights.\"\"\"\n        if len(X) < self.n_components: # Not enough data, return random GMM. Should only happen in the beginning\n          means = np.random.uniform(low=-5.0, high=5.0, size=(self.n_components, self.dim))\n          covariances = [np.eye(self.dim) * (self.step_size**2) for _ in range(self.n_components)] # Diagonal covariance matrices\n          weights = np.ones(self.n_components) / self.n_components\n          return type('GMM', (object,), {'means_': means, 'covariances_': covariances, 'weights_': weights})()\n          \n\n        from sklearn.mixture import GaussianMixture\n        gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n        gmm.fit(X, weights)\n        return gmm\n\n    def __call__(self, func):\n        X = []\n        F = []\n        \n        # Initialization: random GMM\n        means = np.random.uniform(low=func.bounds.lb, high=func.bounds.ub, size=(self.n_components, self.dim))\n        covariances = [np.eye(self.dim) * (self.step_size**2) for _ in range(self.n_components)] # Diagonal covariance matrices\n        weights = np.ones(self.n_components) / self.n_components\n        gmm = type('GMM', (object,), {'means_': means, 'covariances_': covariances, 'weights_': weights})()\n\n        \n        success_count = 0\n        total_count = 0\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.exploration_prob:\n                # Exploration: Sample from GMM\n                x = self.sample_gmm(func, gmm)\n                f = func(x)\n                self.eval_count += 1\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    success_count +=1\n\n                X.append(x)\n                F.append(f)\n\n            else:\n                # Exploitation: Nelder-Mead around current best\n                if self.x_opt is None:\n                    x0 = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    x0 = self.x_opt\n                \n                nm_budget = min(self.budget - self.eval_count, 500) # small budget for local search\n                \n                res = minimize(func, x0, method='Nelder-Mead', options={'maxfev': nm_budget, 'xatol': 1e-4, 'fatol': 1e-4})\n                self.eval_count += res.nfev\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    success_count +=1\n                    \n                X.append(res.x)\n                F.append(res.fun)\n            \n            total_count += 1\n\n            # Update GMM based on collected data. Weight more on better solutions\n            if len(X) > self.n_components:\n              normalized_F = np.max(F) - np.array(F) # Rewards better values with higher values\n              weights = normalized_F / np.sum(normalized_F)\n              gmm = self.update_gmm(np.array(X), weights)\n\n            # Adapt exploration probability\n            if total_count > 20:\n                success_rate = success_count / total_count\n                self.exploration_prob = min(0.9, max(0.1, 1.0 - success_rate)) # Higher success -> more exploitation\n                self.exploitation_prob = 1 - self.exploration_prob\n                success_count = 0\n                total_count = 0\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.05407304216734032, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "1c7cec44-ee89-4966-b148-20ac1073ebbc", "fitness": 0.0, "name": "AdaptiveDECMA2", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation and a Re-evaluation step for promising solutions, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMA2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1, reevaluation_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.reevaluation_factor = reevaluation_factor\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n                    # Re-evaluate promising solutions\n                    if np.random.rand() < self.reevaluation_factor:\n                        f_reeval = func(self.x_opt)\n                        self.budget -= 1\n                        if f_reeval < self.f_opt:\n                            self.f_opt = f_reeval\n                            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveDECMA2 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e5596f8c-6991-41ed-91fc-75dd80c09d2f"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation and a Re-evaluation step for promising solutions, enhancing exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMA2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1, reevaluation_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.reevaluation_factor = reevaluation_factor\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n                    # Re-evaluate promising solutions\n                    if np.random.rand() < self.reevaluation_factor:\n                        f_reeval = func(self.x_opt)\n                        self.budget -= 1\n                        if f_reeval < self.f_opt:\n                            self.f_opt = f_reeval\n                            \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.23676772867736276, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "46b91f34-2d31-4f81-93e6-f03a99df4528", "fitness": 0.6651756528849555, "name": "AdaptiveHybridDECMARestart", "description": "Hybrid DE with CMA-ES selection, adaptive parameter control, and a restart mechanism when stagnation is detected to promote exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMARestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() #x_trial not population[i] because that's the old value\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.restart(func)\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt\n\n    def restart(self, func):\n        # Option 1: Reinitialize population around the current best\n        self.population = np.random.normal(self.x_opt, self.sigma0, size=(self.pop_size, self.dim))\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub) #Clip to bounds\n        \n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        #Update best\n        if np.min(self.fitness) < self.f_opt:\n             self.f_opt = np.min(self.fitness)\n             self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Reinitialize covariance matrix\n        self.sigma = self.sigma0  # Reinitialize sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # Option 2: Full reinitialization (more exploration)\n        # self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        # self.fitness = np.array([func(x) for x in self.population])\n        # self.budget -= self.pop_size\n\n        # self.f_opt = np.min(self.fitness)\n        # self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        # self.m = self.x_opt.copy()\n        # self.C = np.eye(self.dim)\n        # self.sigma = self.sigma0\n        # self.pc = np.zeros(self.dim)\n        # self.ps = np.zeros(self.dim)", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridDECMARestart scored 0.665 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dd7a59c1-a606-416b-8646-44951e8cb1a3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Hybrid DE with CMA-ES selection, adaptive parameter control, and a restart mechanism when stagnation is detected to promote exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMARestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:]) # added factor 0.1\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() #x_trial not population[i] because that's the old value\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4) # added clip\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.restart(func)\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt\n\n    def restart(self, func):\n        # Option 1: Reinitialize population around the current best\n        self.population = np.random.normal(self.x_opt, self.sigma0, size=(self.pop_size, self.dim))\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub) #Clip to bounds\n        \n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        #Update best\n        if np.min(self.fitness) < self.f_opt:\n             self.f_opt = np.min(self.fitness)\n             self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Reinitialize covariance matrix\n        self.sigma = self.sigma0  # Reinitialize sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # Option 2: Full reinitialization (more exploration)\n        # self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        # self.fitness = np.array([func(x) for x in self.population])\n        # self.budget -= self.pop_size\n\n        # self.f_opt = np.min(self.fitness)\n        # self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        # self.m = self.x_opt.copy()\n        # self.C = np.eye(self.dim)\n        # self.sigma = self.sigma0\n        # self.pc = np.zeros(self.dim)\n        # self.ps = np.zeros(self.dim)\n```", "aucs": [0.20369512549004098, 0.6922250242315613, 0.7042437521924617, 0.8767535281059632, 0.7632029628549075, 0.7896780521590775, 0.40138287790969374, 0.5097820734549128, 0.760868452485097, 0.6669701580059855, 0.8421109259125464, 0.9986085932823722, 0.4834767802803911, 0.717139675338378, 0.9215688298052622, 0.791896309405, 0.6512507972278018, 0.863483486672705, 0], "operator": "mutation", "theta_sampled": 0.03906432951217274, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "fe0f5d6f-e4a9-47a6-b805-385510942eda", "fitness": 0.0, "name": "HybridAdaptiveDECMA_LS", "description": "Combines a self-adaptive Differential Evolution (saDE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and a local search (Nelder-Mead) to improve convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridAdaptiveDECMA_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, ls_prob = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        # saDE parameters\n        self.mutation_strategies = [self._mutation_strategy_1, self._mutation_strategy_2]\n        self.mutation_probs = [0.5, 0.5]\n        self.success_counts = [0, 0]\n        self.failure_counts = [0, 0]\n\n        self.memory_F = np.ones(len(self.mutation_strategies)) * 0.5\n        self.memory_CR = np.ones(len(self.mutation_strategies)) * 0.9\n\n        self.ls_prob = ls_prob\n\n    def _mutation_strategy_1(self, population, i, archive):\n        idxs = np.random.choice(len(population), 3, replace=False)\n        x_r1, x_r2, x_r3 = population[idxs]\n\n        # Add archive member with probability\n        if np.random.rand() < 0.1 and len(archive) > 0:\n            x_r3 = archive[np.random.randint(len(archive))]\n\n        return x_r1 + self.memory_F[0] * (x_r2 - x_r3)\n\n    def _mutation_strategy_2(self, population, i, archive):\n        idxs = np.random.choice(len(population), 4, replace=False)\n        x_r1, x_r2, x_r3, x_r4 = population[idxs]\n\n        # Add archive member with probability\n        if np.random.rand() < 0.1 and len(archive) > 0:\n            x_r4 = archive[np.random.randint(len(archive))]\n\n        return x_r1 + self.memory_F[1] * (x_r2 - x_r3) + self.memory_F[1] * (x_r4 - population[i])\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Choose mutation strategy\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n                # Mutation\n                x_mutated = mutation_strategy(self.population, i, self.archive)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.memory_CR[strategy_index] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.success_counts[strategy_index] += 1\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.failure_counts[strategy_index] +=1\n\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.success_counts[strategy_index] += 1\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.failure_counts[strategy_index] += 1\n\n\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_trial?\n\n                # Local Search (Nelder-Mead)\n                if np.random.rand() < self.ls_prob:\n                    bounds = func.bounds\n                    def func_for_ls(x):\n                        return func(x)\n                    \n                    if self.budget > 10 * self.dim:\n                        ls_result = minimize(func_for_ls, x_trial, method='Nelder-Mead', bounds=list(zip(bounds.lb, bounds.ub)), options={'maxfev': min(self.budget // 10, 500)})  # Limit FE\n                        self.budget -= ls_result.nfev\n                        if ls_result.fun < self.fitness[i]:\n                            self.population[i] = ls_result.x.copy()\n                            self.fitness[i] = ls_result.fun\n                        \n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                \n                # Adaptation of mutation probabilities\n                if (sum(self.success_counts) + sum(self.failure_counts)) % (10 * self.dim) == 0:\n                    for k in range(len(self.mutation_strategies)):\n                        if self.success_counts[k] + self.failure_counts[k] > 0:\n                            self.mutation_probs[k] = self.success_counts[k] / (self.success_counts[k] + self.failure_counts[k])\n                        else:\n                            self.mutation_probs[k] = 1 / len(self.mutation_strategies) #Assign equal probability if no success or failure recorded\n                    self.mutation_probs /= np.sum(self.mutation_probs) #Normalize probabilities to sum to 1\n                    self.success_counts = [0] * len(self.mutation_strategies)\n                    self.failure_counts = [0] * len(self.mutation_strategies)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines a self-adaptive Differential Evolution (saDE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and a local search (Nelder-Mead) to improve convergence.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridAdaptiveDECMA_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, ls_prob = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        # saDE parameters\n        self.mutation_strategies = [self._mutation_strategy_1, self._mutation_strategy_2]\n        self.mutation_probs = [0.5, 0.5]\n        self.success_counts = [0, 0]\n        self.failure_counts = [0, 0]\n\n        self.memory_F = np.ones(len(self.mutation_strategies)) * 0.5\n        self.memory_CR = np.ones(len(self.mutation_strategies)) * 0.9\n\n        self.ls_prob = ls_prob\n\n    def _mutation_strategy_1(self, population, i, archive):\n        idxs = np.random.choice(len(population), 3, replace=False)\n        x_r1, x_r2, x_r3 = population[idxs]\n\n        # Add archive member with probability\n        if np.random.rand() < 0.1 and len(archive) > 0:\n            x_r3 = archive[np.random.randint(len(archive))]\n\n        return x_r1 + self.memory_F[0] * (x_r2 - x_r3)\n\n    def _mutation_strategy_2(self, population, i, archive):\n        idxs = np.random.choice(len(population), 4, replace=False)\n        x_r1, x_r2, x_r3, x_r4 = population[idxs]\n\n        # Add archive member with probability\n        if np.random.rand() < 0.1 and len(archive) > 0:\n            x_r4 = archive[np.random.randint(len(archive))]\n\n        return x_r1 + self.memory_F[1] * (x_r2 - x_r3) + self.memory_F[1] * (x_r4 - population[i])\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Choose mutation strategy\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n                # Mutation\n                x_mutated = mutation_strategy(self.population, i, self.archive)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.memory_CR[strategy_index] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.success_counts[strategy_index] += 1\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.failure_counts[strategy_index] +=1\n\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.success_counts[strategy_index] += 1\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                    else:\n                        self.failure_counts[strategy_index] += 1\n\n\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_trial?\n\n                # Local Search (Nelder-Mead)\n                if np.random.rand() < self.ls_prob:\n                    bounds = func.bounds\n                    def func_for_ls(x):\n                        return func(x)\n                    \n                    if self.budget > 10 * self.dim:\n                        ls_result = minimize(func_for_ls, x_trial, method='Nelder-Mead', bounds=list(zip(bounds.lb, bounds.ub)), options={'maxfev': min(self.budget // 10, 500)})  # Limit FE\n                        self.budget -= ls_result.nfev\n                        if ls_result.fun < self.fitness[i]:\n                            self.population[i] = ls_result.x.copy()\n                            self.fitness[i] = ls_result.fun\n                        \n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                \n                # Adaptation of mutation probabilities\n                if (sum(self.success_counts) + sum(self.failure_counts)) % (10 * self.dim) == 0:\n                    for k in range(len(self.mutation_strategies)):\n                        if self.success_counts[k] + self.failure_counts[k] > 0:\n                            self.mutation_probs[k] = self.success_counts[k] / (self.success_counts[k] + self.failure_counts[k])\n                        else:\n                            self.mutation_probs[k] = 1 / len(self.mutation_strategies) #Assign equal probability if no success or failure recorded\n                    self.mutation_probs /= np.sum(self.mutation_probs) #Normalize probabilities to sum to 1\n                    self.success_counts = [0] * len(self.mutation_strategies)\n                    self.failure_counts = [0] * len(self.mutation_strategies)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.04323519213977525, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "a1892c28-2d4d-418a-8214-ff1454dd1245", "fitness": 0.47478916512218794, "name": "HybridAdaptiveDECMOCombined", "description": "An adaptive Differential Evolution with Covariance Matrix Adaptation, archive, and dynamically adjusted parameters based on success rate.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOCombined:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, c_cov_factor = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.c_cov_factor = c_cov_factor\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            if len(self.archive_fitness) > 0: #Check for empty archive_fitness\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i].copy()\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n                    \n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            if len(self.archive_fitness) > 0: #Check for empty archive_fitness\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i].copy()\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * self.c_cov_factor * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                    self.F *= (1 + self.adaptation_rate)\n                    self.CR = min(1.0, self.CR * (1 + self.adaptation_rate))\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                    self.F *= (1 - self.adaptation_rate)\n                    self.CR = max(0.0, self.CR * (1 - self.adaptation_rate))\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridAdaptiveDECMOCombined scored 0.475 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea", "dd7a59c1-a606-416b-8646-44951e8cb1a3"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution with Covariance Matrix Adaptation, archive, and dynamically adjusted parameters based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOCombined:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, c_cov_factor = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.c_cov_factor = c_cov_factor\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            if len(self.archive_fitness) > 0: #Check for empty archive_fitness\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i].copy()\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n                    \n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            if len(self.archive_fitness) > 0: #Check for empty archive_fitness\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i].copy()\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * self.c_cov_factor * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                    self.F *= (1 + self.adaptation_rate)\n                    self.CR = min(1.0, self.CR * (1 + self.adaptation_rate))\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n                    self.F *= (1 - self.adaptation_rate)\n                    self.CR = max(0.0, self.CR * (1 - self.adaptation_rate))\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.173524533786084, 0.282157117568853, 0.4060353584626808, 0.6898826919877716, 0.5147017905426265, 0.45087985394655716, 0.4763408110254299, 0.47851304125921046, 0.48849010522469893, 0.26685647788418365, 0.44328454916291193, 0.9988345505951965, 0.27323135045363156, 0.38788231493964964, 0.8086821097675896, 0.4374912790162323, 0.44950971328502787, 0.701450393076449, 0.2654858116599864, 0.5025494487989856], "operator": "crossover", "theta_sampled": 0.0016059725891935963, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "a4df075e-ebad-40fc-b393-a014615345ef", "fitness": 0.0, "name": "AdaptiveHybridOptimizer", "description": "An adaptive population-based algorithm that combines aspects of differential evolution, covariance matrix adaptation evolution strategy (CMA-ES), and Nelder-Mead simplex search, dynamically adjusting its search strategy based on performance feedback.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=None, de_cr=0.7, de_f=0.8, cma_sigma=0.1, nm_alpha=1.0, nm_beta=0.5, nm_gamma=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.cma_sigma = cma_sigma\n        self.nm_alpha = nm_alpha\n        self.nm_beta = nm_beta\n        self.nm_gamma = nm_gamma\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.population = None\n        self.fitness = None\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i].copy()\n            else:\n                self.fitness[i] = np.inf\n        return self.fitness\n\n    def differential_evolution(self):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = self.population[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = self.evaluate_solution(func, x_trial)\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = x_trial\n                self.fitness[i] = f_trial\n\n    def cma_es(self, func):\n        # Simplified CMA-ES update (without full covariance matrix adaptation for brevity)\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0)\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            x = np.random.normal(mean, self.cma_sigma * std)\n            x = np.clip(x, self.lb, self.ub)\n            f = self.evaluate_solution(func, x)\n            \n            if f < self.fitness[i]:\n                self.population[i] = x\n                self.fitness[i] = f\n\n    def nelder_mead(self, func):\n        # Implement Nelder-Mead on the best individual\n        x = self.x_opt\n        \n        # Generate a simplex around x\n        simplex = np.zeros((self.dim + 1, self.dim))\n        simplex[0] = x.copy()\n\n        for i in range(1, self.dim + 1):\n            simplex[i] = x.copy()\n            simplex[i][i-1] += 0.1 # Small perturbation\n\n        # Evaluate the simplex points\n        fitness = np.zeros(self.dim + 1)\n        for i in range(self.dim + 1):\n            fitness[i] = self.evaluate_solution(func, simplex[i])\n            \n        # Perform Nelder-Mead iterations (simplified)\n        for _ in range(5): # Limit the number of NM iterations for budget concerns\n          if self.eval_count >= self.budget:\n              break\n\n          # Sort the simplex points by fitness\n          order = np.argsort(fitness)\n          simplex = simplex[order]\n          fitness = fitness[order]\n          \n          # Calculate the centroid of all points except the worst\n          centroid = np.mean(simplex[:-1], axis=0)\n\n          # Reflection\n          x_reflected = centroid + self.nm_alpha * (centroid - simplex[-1])\n          x_reflected = np.clip(x_reflected, self.lb, self.ub)\n          f_reflected = self.evaluate_solution(func, x_reflected)\n\n          if fitness[0] <= f_reflected < fitness[-2]:\n              simplex[-1] = x_reflected\n              fitness[-1] = f_reflected\n          elif f_reflected < fitness[0]:\n              # Expansion\n              x_expanded = centroid + self.nm_gamma * (x_reflected - centroid)\n              x_expanded = np.clip(x_expanded, self.lb, self.ub)\n              f_expanded = self.evaluate_solution(func, x_expanded)\n              if f_expanded < f_reflected:\n                  simplex[-1] = x_expanded\n                  fitness[-1] = f_expanded\n              else:\n                  simplex[-1] = x_reflected\n                  fitness[-1] = f_reflected\n\n          else:\n              # Contraction\n              x_contracted = centroid + self.nm_beta * (simplex[-1] - centroid)\n              x_contracted = np.clip(x_contracted, self.lb, self.ub)\n              f_contracted = self.evaluate_solution(func, x_contracted)\n              if f_contracted < fitness[-1]:\n                  simplex[-1] = x_contracted\n                  fitness[-1] = f_contracted\n              else:\n                  # Shrink\n                  for i in range(1, self.dim + 1):\n                      simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                      fitness[i] = self.evaluate_solution(func, simplex[i])\n          \n          order = np.argsort(fitness)\n          simplex = simplex[order]\n          fitness = fitness[order]\n          self.x_opt = simplex[0]\n          self.f_opt = fitness[0]\n\n    def evaluate_solution(self, func, x):\n        if self.eval_count < self.budget:\n            f = func(x)\n            self.eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n            return f\n        else:\n            return np.inf\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            if self.eval_count < self.budget * 0.6:\n                self.differential_evolution()\n            elif self.eval_count < self.budget * 0.9:\n                self.cma_es(func)\n            else:\n                self.nelder_mead(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that combines aspects of differential evolution, covariance matrix adaptation evolution strategy (CMA-ES), and Nelder-Mead simplex search, dynamically adjusting its search strategy based on performance feedback.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=None, de_cr=0.7, de_f=0.8, cma_sigma=0.1, nm_alpha=1.0, nm_beta=0.5, nm_gamma=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.cma_sigma = cma_sigma\n        self.nm_alpha = nm_alpha\n        self.nm_beta = nm_beta\n        self.nm_gamma = nm_gamma\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.population = None\n        self.fitness = None\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i].copy()\n            else:\n                self.fitness[i] = np.inf\n        return self.fitness\n\n    def differential_evolution(self):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = self.population[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = self.evaluate_solution(func, x_trial)\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = x_trial\n                self.fitness[i] = f_trial\n\n    def cma_es(self, func):\n        # Simplified CMA-ES update (without full covariance matrix adaptation for brevity)\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0)\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            x = np.random.normal(mean, self.cma_sigma * std)\n            x = np.clip(x, self.lb, self.ub)\n            f = self.evaluate_solution(func, x)\n            \n            if f < self.fitness[i]:\n                self.population[i] = x\n                self.fitness[i] = f\n\n    def nelder_mead(self, func):\n        # Implement Nelder-Mead on the best individual\n        x = self.x_opt\n        \n        # Generate a simplex around x\n        simplex = np.zeros((self.dim + 1, self.dim))\n        simplex[0] = x.copy()\n\n        for i in range(1, self.dim + 1):\n            simplex[i] = x.copy()\n            simplex[i][i-1] += 0.1 # Small perturbation\n\n        # Evaluate the simplex points\n        fitness = np.zeros(self.dim + 1)\n        for i in range(self.dim + 1):\n            fitness[i] = self.evaluate_solution(func, simplex[i])\n            \n        # Perform Nelder-Mead iterations (simplified)\n        for _ in range(5): # Limit the number of NM iterations for budget concerns\n          if self.eval_count >= self.budget:\n              break\n\n          # Sort the simplex points by fitness\n          order = np.argsort(fitness)\n          simplex = simplex[order]\n          fitness = fitness[order]\n          \n          # Calculate the centroid of all points except the worst\n          centroid = np.mean(simplex[:-1], axis=0)\n\n          # Reflection\n          x_reflected = centroid + self.nm_alpha * (centroid - simplex[-1])\n          x_reflected = np.clip(x_reflected, self.lb, self.ub)\n          f_reflected = self.evaluate_solution(func, x_reflected)\n\n          if fitness[0] <= f_reflected < fitness[-2]:\n              simplex[-1] = x_reflected\n              fitness[-1] = f_reflected\n          elif f_reflected < fitness[0]:\n              # Expansion\n              x_expanded = centroid + self.nm_gamma * (x_reflected - centroid)\n              x_expanded = np.clip(x_expanded, self.lb, self.ub)\n              f_expanded = self.evaluate_solution(func, x_expanded)\n              if f_expanded < f_reflected:\n                  simplex[-1] = x_expanded\n                  fitness[-1] = f_expanded\n              else:\n                  simplex[-1] = x_reflected\n                  fitness[-1] = f_reflected\n\n          else:\n              # Contraction\n              x_contracted = centroid + self.nm_beta * (simplex[-1] - centroid)\n              x_contracted = np.clip(x_contracted, self.lb, self.ub)\n              f_contracted = self.evaluate_solution(func, x_contracted)\n              if f_contracted < fitness[-1]:\n                  simplex[-1] = x_contracted\n                  fitness[-1] = f_contracted\n              else:\n                  # Shrink\n                  for i in range(1, self.dim + 1):\n                      simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                      fitness[i] = self.evaluate_solution(func, simplex[i])\n          \n          order = np.argsort(fitness)\n          simplex = simplex[order]\n          fitness = fitness[order]\n          self.x_opt = simplex[0]\n          self.f_opt = fitness[0]\n\n    def evaluate_solution(self, func, x):\n        if self.eval_count < self.budget:\n            f = func(x)\n            self.eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n            return f\n        else:\n            return np.inf\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            if self.eval_count < self.budget * 0.6:\n                self.differential_evolution()\n            elif self.eval_count < self.budget * 0.9:\n                self.cma_es(func)\n            else:\n                self.nelder_mead(func)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.14562531770505982, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "8f38a4ff-ef73-4e08-88ef-0e9e71f8ee21", "fitness": 0.706051636155998, "name": "HybridAdaptiveDECMOCombined", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation, archive, and a combined strategy for step size and covariance updates.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOCombined:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size - Use c_sigma from HybridAdaptiveDECMO2\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                # Adaptive Covariance Matrix Adaptation (CMA-ES part) with factor 0.1 from HybridAdaptiveDECMO2\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()  # Update mean with the trial point\n\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                # Adaptation of c_cov and c_sigma\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridAdaptiveDECMOCombined scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea", "dd7a59c1-a606-416b-8646-44951e8cb1a3"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation, archive, and a combined strategy for step size and covariance updates.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOCombined:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size - Use c_sigma from HybridAdaptiveDECMO2\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                # Adaptive Covariance Matrix Adaptation (CMA-ES part) with factor 0.1 from HybridAdaptiveDECMO2\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()  # Update mean with the trial point\n\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                # Adaptation of c_cov and c_sigma\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.34302131993659224, 0.7075398605922498, 0.6228302369044292, 0.8821381401977515, 0.7274038487488708, 0.7948210381286047, 0.6242074790538235, 0.6760229350577556, 0.7422445738914005, 0.6578222926163084, 0.8666467621776439, 0.9870879828102549, 0.6567043848610397, 0.7082194922454891, 0.93278770183386, 0.7678518163993707, 0.6099583032693848, 0.8327683290875925, 0.4603566006002804, 0.5205996247072594], "operator": "crossover", "theta_sampled": 0.0003576581631936775, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "636c98e9-c649-4902-9fd8-845c99e14fd9", "fitness": 0.3569798925512028, "name": "CauchyAnnealingOptimizer", "description": "A population-based algorithm employing a Cauchy mutation operator and a shrinking search space, inspired by simulated annealing principles.", "code": "import numpy as np\n\nclass CauchyAnnealingOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                cauchy_vector = np.random.standard_cauchy(size=self.dim)\n                mutated_individual = population[i] + self.temp * cauchy_vector * (ub - lb) / 2\n                \n                # Clip to bounds.\n                mutated_individual = np.clip(mutated_individual, lb, ub)\n\n                f_mutated = func(mutated_individual)\n                self.budget -= 1 # Update budget\n\n                if f_mutated < fitness[i] or np.random.rand() < np.exp((fitness[i] - f_mutated) / self.temp):\n                    population[i] = mutated_individual\n                    fitness[i] = f_mutated\n\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_individual\n            \n            # Annealing (cooling)\n            self.temp *= self.cooling_rate\n\n            # Shrink bounds (optional, but can improve convergence)\n            center = self.x_opt\n            range_val = (ub - lb) * self.temp #Reduce search space more slowly to allow exploration\n            lb = np.maximum(func.bounds.lb, center - range_val/2)\n            ub = np.minimum(func.bounds.ub, center + range_val/2)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm CauchyAnnealingOptimizer scored 0.357 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm employing a Cauchy mutation operator and a shrinking search space, inspired by simulated annealing principles.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyAnnealingOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                cauchy_vector = np.random.standard_cauchy(size=self.dim)\n                mutated_individual = population[i] + self.temp * cauchy_vector * (ub - lb) / 2\n                \n                # Clip to bounds.\n                mutated_individual = np.clip(mutated_individual, lb, ub)\n\n                f_mutated = func(mutated_individual)\n                self.budget -= 1 # Update budget\n\n                if f_mutated < fitness[i] or np.random.rand() < np.exp((fitness[i] - f_mutated) / self.temp):\n                    population[i] = mutated_individual\n                    fitness[i] = f_mutated\n\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_individual\n            \n            # Annealing (cooling)\n            self.temp *= self.cooling_rate\n\n            # Shrink bounds (optional, but can improve convergence)\n            center = self.x_opt\n            range_val = (ub - lb) * self.temp #Reduce search space more slowly to allow exploration\n            lb = np.maximum(func.bounds.lb, center - range_val/2)\n            ub = np.minimum(func.bounds.ub, center + range_val/2)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1881010708209565, 0.1883936099198923, 0.24250605035632045, 0.401644942558274, 0.24734840290447546, 0.2961123316190769, 0.31314007619457584, 0.2861689992527823, 0.2178017870336354, 0.18935953749704681, 0.40800193268277496, 0.9969254449166447, 0.22673261067506123, 0.2609885128086211, 0.6577612803952428, 0.25868726232513717, 0.2922822898439442, 0.623157901231149, 0.3788109712331813, 0.4656728367552643], "operator": "random_new", "theta_sampled": 0.0924840479322776, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "5b4f46f9-b4d5-46ed-9a86-9acf1cdf72ce", "fitness": 0.0, "name": "RankDistanceAdaptation", "description": "A population-based algorithm with a novel selection and recombination strategy based on fitness rank and distance to the population center, aiming to balance exploration and exploitation.", "code": "import numpy as np\n\nclass RankDistanceAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            # Calculate population center\n            center = np.mean(self.population, axis=0)\n\n            # Calculate distances to the center\n            distances = np.linalg.norm(self.population - center, axis=1)\n\n            # Rank individuals by fitness\n            rank = np.argsort(self.fitness)\n\n            # Selection and Recombination\n            new_population = []\n            for i in range(self.pop_size):\n                # Parent selection: Favor individuals with good rank and distance from center\n                p1_index = self.select_parent(rank, distances)\n                p2_index = self.select_parent(rank, distances)\n\n                # Recombination: Blend parents, introduce mutation based on rank\n                parent1 = self.population[p1_index]\n                parent2 = self.population[p2_index]\n\n                mutation_rate = 0.1 * (1 - rank[i] / self.pop_size)  # Higher mutation for lower-ranked individuals\n\n                new_individual = 0.5 * (parent1 + parent2) + mutation_rate * np.random.uniform(self.lb-new_individual, self.ub-new_individual, size=self.dim)\n\n                # Clip to bounds\n                new_individual = np.clip(new_individual, self.lb, self.ub)\n\n                new_population.append(new_individual)\n\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n\n            # Update population\n            # Elitism: Keep the best individual from the previous generation\n            worst_index = np.argmax(new_fitness)\n            if self.f_opt < new_fitness[worst_index]:\n                new_population[worst_index] = self.x_opt\n                new_fitness[worst_index] = self.f_opt\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update optimal solution\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt\n\n    def select_parent(self, rank, distances):\n        # Probability based on rank and distance\n        probabilities = (1 - rank / self.pop_size) + (distances / np.max(distances))\n        probabilities /= np.sum(probabilities)  # Normalize\n\n        return np.random.choice(self.pop_size, p=probabilities)", "configspace": "", "generation": 10, "feedback": "", "error": "Evaluation error: cannot access local variable 'new_individual' where it is not associated with a value", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with a novel selection and recombination strategy based on fitness rank and distance to the population center, aiming to balance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass RankDistanceAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            # Calculate population center\n            center = np.mean(self.population, axis=0)\n\n            # Calculate distances to the center\n            distances = np.linalg.norm(self.population - center, axis=1)\n\n            # Rank individuals by fitness\n            rank = np.argsort(self.fitness)\n\n            # Selection and Recombination\n            new_population = []\n            for i in range(self.pop_size):\n                # Parent selection: Favor individuals with good rank and distance from center\n                p1_index = self.select_parent(rank, distances)\n                p2_index = self.select_parent(rank, distances)\n\n                # Recombination: Blend parents, introduce mutation based on rank\n                parent1 = self.population[p1_index]\n                parent2 = self.population[p2_index]\n\n                mutation_rate = 0.1 * (1 - rank[i] / self.pop_size)  # Higher mutation for lower-ranked individuals\n\n                new_individual = 0.5 * (parent1 + parent2) + mutation_rate * np.random.uniform(self.lb-new_individual, self.ub-new_individual, size=self.dim)\n\n                # Clip to bounds\n                new_individual = np.clip(new_individual, self.lb, self.ub)\n\n                new_population.append(new_individual)\n\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n\n            # Update population\n            # Elitism: Keep the best individual from the previous generation\n            worst_index = np.argmax(new_fitness)\n            if self.f_opt < new_fitness[worst_index]:\n                new_population[worst_index] = self.x_opt\n                new_fitness[worst_index] = self.f_opt\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update optimal solution\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt\n\n    def select_parent(self, rank, distances):\n        # Probability based on rank and distance\n        probabilities = (1 - rank / self.pop_size) + (distances / np.max(distances))\n        probabilities /= np.sum(probabilities)  # Normalize\n\n        return np.random.choice(self.pop_size, p=probabilities)\n```", "operator": "random_new", "theta_sampled": 0.4539643099241366, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "e932104f-4a26-4e77-96cf-77e645177192", "fitness": 0.3812550146783063, "name": "AdaptiveCovarianceDifferentialEvolution", "description": "A population-based algorithm that evolves solutions using a combination of differential evolution and a covariance matrix adaptation strategy, with self-adaptive parameter control.", "code": "import numpy as np\n\nclass AdaptiveCovarianceDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.5  # Initial crossover rate\n        self.learning_rate = 0.1 #Learning rate for F and CR.\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        # Initialize covariance matrix\n        C = np.eye(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Mutation with covariance adaptation\n                z = np.random.multivariate_normal(np.zeros(self.dim), C)\n\n                mutant = population[i] + self.F * (x_r1 - x_r2) + 0.1 * z #Adding covariance adaptation as noise\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial_vector[j] = mutant[j]\n\n                # Clip to bounds\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    #Update covariance matrix based on successful moves\n                    C = 0.9 * C + 0.1 * np.outer(trial_vector - population[i], trial_vector - population[i]) #Simplified CMA update\n\n                # Update best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Adapt F and CR\n            success_indices = fitness < np.mean(fitness) # Check if a point did better than the mean\n            if np.any(success_indices):\n              self.F = max(0.1, min(0.9, self.F * (1 + self.learning_rate * (np.mean(fitness[success_indices]) - np.mean(fitness))))) #F adaptation\n              self.CR = max(0.1, min(0.9, self.CR * (1 + self.learning_rate * (np.mean(fitness[success_indices]) - np.mean(fitness))))) #CR adaptation\n              \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveCovarianceDifferentialEvolution scored 0.381 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that evolves solutions using a combination of differential evolution and a covariance matrix adaptation strategy, with self-adaptive parameter control.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCovarianceDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.5  # Initial crossover rate\n        self.learning_rate = 0.1 #Learning rate for F and CR.\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        # Initialize covariance matrix\n        C = np.eye(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Mutation with covariance adaptation\n                z = np.random.multivariate_normal(np.zeros(self.dim), C)\n\n                mutant = population[i] + self.F * (x_r1 - x_r2) + 0.1 * z #Adding covariance adaptation as noise\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial_vector[j] = mutant[j]\n\n                # Clip to bounds\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    #Update covariance matrix based on successful moves\n                    C = 0.9 * C + 0.1 * np.outer(trial_vector - population[i], trial_vector - population[i]) #Simplified CMA update\n\n                # Update best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Adapt F and CR\n            success_indices = fitness < np.mean(fitness) # Check if a point did better than the mean\n            if np.any(success_indices):\n              self.F = max(0.1, min(0.9, self.F * (1 + self.learning_rate * (np.mean(fitness[success_indices]) - np.mean(fitness))))) #F adaptation\n              self.CR = max(0.1, min(0.9, self.CR * (1 + self.learning_rate * (np.mean(fitness[success_indices]) - np.mean(fitness))))) #CR adaptation\n              \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14357827525913058, 0.21512749155505906, 0.5304171046504642, 0.37276343315040283, 0.35066633114547485, 0.45925533737224344, 0.230113768084926, 0.3129143055011935, 0.21532812501983667, 0.1834591594205206, 0.2919350072971939, 0.9536639876398998, 0.27189432390348334, 0.2014324945296686, 0.7546473993110636, 0.5182600512022236, 0.3335691445621375, 0.5864451362076378, 0.21487255889859447, 0.48475685885497233], "operator": "random_new", "theta_sampled": 0.26953064663346127, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "f2b21be7-5d7a-45fa-b2f9-386b896d89f9", "fitness": 0.5037121071781343, "name": "AdaptiveGaussianDifferentialEvolution", "description": "A population-based algorithm that uses a combination of Gaussian mutation and differential evolution with a self-adaptive parameter control mechanism based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveGaussianDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.archive = []\n        self.archive_max_size = 10\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                if np.random.rand() < 0.1:\n                    F = np.random.normal(0.5, 0.3)\n                    F = np.clip(F, 0.1, 1.0)\n                else:\n                    F = self.F\n\n                if np.random.rand() < 0.1:\n                    CR = np.random.normal(0.7, 0.1)\n                    CR = np.clip(CR, 0.1, 1.0)\n                else:\n                    CR = self.CR\n\n\n                # Gaussian Mutation\n                if np.random.rand() < 0.5:\n                    mutant = self.population[i] + F * np.random.normal(0, 1, self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                else:\n                    # Differential Evolution Mutation\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = a + F * (b - c)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    self.population[i] = trial\n\n                    # Update Archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_max_size:\n                        self.archive.pop(0)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveGaussianDifferentialEvolution scored 0.504 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of Gaussian mutation and differential evolution with a self-adaptive parameter control mechanism based on fitness improvement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveGaussianDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.archive = []\n        self.archive_max_size = 10\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                if np.random.rand() < 0.1:\n                    F = np.random.normal(0.5, 0.3)\n                    F = np.clip(F, 0.1, 1.0)\n                else:\n                    F = self.F\n\n                if np.random.rand() < 0.1:\n                    CR = np.random.normal(0.7, 0.1)\n                    CR = np.clip(CR, 0.1, 1.0)\n                else:\n                    CR = self.CR\n\n\n                # Gaussian Mutation\n                if np.random.rand() < 0.5:\n                    mutant = self.population[i] + F * np.random.normal(0, 1, self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                else:\n                    # Differential Evolution Mutation\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = a + F * (b - c)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    self.population[i] = trial\n\n                    # Update Archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_max_size:\n                        self.archive.pop(0)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.18730157797868385, 0.29690553776864204, 0.46677944423039597, 0.7151854585203687, 0.4589246730608514, 0.5598684520170507, 0.34809403970417807, 0.44671933190429813, 0.5034665810195601, 0.3561767297194668, 0.6612066069366113, 0.9990797883369807, 0.3579001596933863, 0.4840279053855959, 0.8285950709282723, 0.5976443101642639, 0.38368344679248656, 0.6982549579757868, 0.2241770493823566, 0.5002510220434503], "operator": "random_new", "theta_sampled": 0.09964427199954974, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "4fa79e80-a653-4a97-9fe3-34394185d161", "fitness": 0.0, "name": "GradientInformedPSO_SA", "description": "Gradient-informed Particle Swarm Optimization with Simulated Annealing-based local search to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass GradientInformedPSO_SA:\n    def __init__(self, budget=10000, dim=10, num_particles=30, w=0.7, c1=1.5, c2=1.5, sa_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.sa_prob = sa_prob #Probability of simulated annealing local search\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.num_particles, self.dim))\n        \n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles  # Subtract initial evaluations\n        \n        # Initialize global best position and value\n        global_best_index = np.argmin(personal_best_values)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.num_particles):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (self.w * velocities[i] \n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                \n                # Update particle position\n                particles[i] = particles[i] + velocities[i]\n                \n                # Clip particles to bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate particle\n                f = func(particles[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if f < personal_best_values[i]:\n                    personal_best_values[i] = f\n                    personal_best_positions[i] = particles[i].copy()\n                    \n                    # Update global best\n                    if f < global_best_value:\n                        global_best_value = f\n                        global_best_position = particles[i].copy()\n                        \n                # Simulated Annealing Local Search with gradient information\n                if np.random.rand() < self.sa_prob and self.budget > 0:\n                    # Approximate gradient using finite differences\n                    gradient = np.zeros(self.dim)\n                    delta = 1e-3  # Small perturbation\n                    for j in range(self.dim):\n                        x_plus = particles[i].copy()\n                        x_minus = particles[i].copy()\n                        x_plus[j] += delta\n                        x_minus[j] -= delta\n                        x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)\n                        x_minus[j] = np.clip(x_minus[j], func.bounds.lb, func.bounds.ub)\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        self.budget -= 2  # Account for two function evaluations\n\n                        gradient[j] = (f_plus - f_minus) / (2 * delta) if self.budget > 1 else 0\n                    \n                    # Move in the opposite direction of the gradient (scaled by a temperature-like parameter)\n                    temperature = global_best_value # Use the current best value as a measure of temperature\n\n                    #Normalize Gradient, so that large values do not dominate the step size\n                    norm = np.linalg.norm(gradient)\n                    if norm > 0:\n                        gradient = gradient / norm\n                    \n                    # Apply simulated annealing-like move\n                    new_particle = particles[i] - temperature * gradient\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    \n                    new_f = func(new_particle)\n                    self.budget -= 1\n\n                    # Accept the new particle if it's better or with a probability based on temperature\n                    if new_f < f or np.random.rand() < np.exp(-(new_f - f) / temperature):\n                        particles[i] = new_particle\n                        f = new_f\n                        \n                        # Update personal best\n                        if f < personal_best_values[i]:\n                            personal_best_values[i] = f\n                            personal_best_positions[i] = particles[i].copy()\n                            \n                            # Update global best\n                            if f < global_best_value:\n                                global_best_value = f\n                                global_best_position = particles[i].copy()\n\n                if self.budget <= 0:\n                   break\n\n        return global_best_value, global_best_position", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Gradient-informed Particle Swarm Optimization with Simulated Annealing-based local search to enhance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass GradientInformedPSO_SA:\n    def __init__(self, budget=10000, dim=10, num_particles=30, w=0.7, c1=1.5, c2=1.5, sa_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.sa_prob = sa_prob #Probability of simulated annealing local search\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.num_particles, self.dim))\n        \n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles  # Subtract initial evaluations\n        \n        # Initialize global best position and value\n        global_best_index = np.argmin(personal_best_values)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.num_particles):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (self.w * velocities[i] \n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                \n                # Update particle position\n                particles[i] = particles[i] + velocities[i]\n                \n                # Clip particles to bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate particle\n                f = func(particles[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if f < personal_best_values[i]:\n                    personal_best_values[i] = f\n                    personal_best_positions[i] = particles[i].copy()\n                    \n                    # Update global best\n                    if f < global_best_value:\n                        global_best_value = f\n                        global_best_position = particles[i].copy()\n                        \n                # Simulated Annealing Local Search with gradient information\n                if np.random.rand() < self.sa_prob and self.budget > 0:\n                    # Approximate gradient using finite differences\n                    gradient = np.zeros(self.dim)\n                    delta = 1e-3  # Small perturbation\n                    for j in range(self.dim):\n                        x_plus = particles[i].copy()\n                        x_minus = particles[i].copy()\n                        x_plus[j] += delta\n                        x_minus[j] -= delta\n                        x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)\n                        x_minus[j] = np.clip(x_minus[j], func.bounds.lb, func.bounds.ub)\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        self.budget -= 2  # Account for two function evaluations\n\n                        gradient[j] = (f_plus - f_minus) / (2 * delta) if self.budget > 1 else 0\n                    \n                    # Move in the opposite direction of the gradient (scaled by a temperature-like parameter)\n                    temperature = global_best_value # Use the current best value as a measure of temperature\n\n                    #Normalize Gradient, so that large values do not dominate the step size\n                    norm = np.linalg.norm(gradient)\n                    if norm > 0:\n                        gradient = gradient / norm\n                    \n                    # Apply simulated annealing-like move\n                    new_particle = particles[i] - temperature * gradient\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    \n                    new_f = func(new_particle)\n                    self.budget -= 1\n\n                    # Accept the new particle if it's better or with a probability based on temperature\n                    if new_f < f or np.random.rand() < np.exp(-(new_f - f) / temperature):\n                        particles[i] = new_particle\n                        f = new_f\n                        \n                        # Update personal best\n                        if f < personal_best_values[i]:\n                            personal_best_values[i] = f\n                            personal_best_positions[i] = particles[i].copy()\n                            \n                            # Update global best\n                            if f < global_best_value:\n                                global_best_value = f\n                                global_best_position = particles[i].copy()\n\n                if self.budget <= 0:\n                   break\n\n        return global_best_value, global_best_position\n```", "operator": "random_new", "theta_sampled": 0.13581045123440014, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "0cff02dc-d8dd-4d74-ab09-0a012dd69a46", "fitness": 0.5137648472288765, "name": "HybridAdaptiveDECMA_CRF", "description": "Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and incorporates a success-history based adaptation of the crossover rate (CR) and scaling factor (F) of DE, in addition to step size adaptation, to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMA_CRF:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, cr_adaptation_rate=0.1, f_adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cr_adaptation_rate = cr_adaptation_rate\n        self.f_adaptation_rate = f_adaptation_rate\n        self.cr_success_history = []\n        self.f_success_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() #Using x_trial seems more appropriate.\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n                # Adapt CR and F based on success\n                cr_success = 1 if f_trial < self.fitness[i] else 0\n                self.cr_success_history.append(cr_success)\n                if len(self.cr_success_history) > 10 * self.dim:\n                    self.cr_success_history.pop(0)\n                cr_success_rate = np.mean(self.cr_success_history)\n\n                if cr_success_rate > 0.7:\n                    self.CR = min(1.0, self.CR + self.cr_adaptation_rate)\n                elif cr_success_rate < 0.3:\n                    self.CR = max(0.1, self.CR - self.cr_adaptation_rate)\n\n                f_success = 1 if f_trial < self.fitness[i] else 0\n                self.f_success_history.append(f_success)\n                if len(self.f_success_history) > 10 * self.dim:\n                    self.f_success_history.pop(0)\n                f_success_rate = np.mean(self.f_success_history)\n\n                if f_success_rate > 0.7:\n                    self.F = min(1.0, self.F + self.f_adaptation_rate)\n                elif f_success_rate < 0.3:\n                    self.F = max(0.1, self.F - self.f_adaptation_rate)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridAdaptiveDECMA_CRF scored 0.514 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and incorporates a success-history based adaptation of the crossover rate (CR) and scaling factor (F) of DE, in addition to step size adaptation, to balance exploration and exploitation more effectively.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMA_CRF:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, cr_adaptation_rate=0.1, f_adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cr_adaptation_rate = cr_adaptation_rate\n        self.f_adaptation_rate = f_adaptation_rate\n        self.cr_success_history = []\n        self.f_success_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() #Using x_trial seems more appropriate.\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n                # Adapt CR and F based on success\n                cr_success = 1 if f_trial < self.fitness[i] else 0\n                self.cr_success_history.append(cr_success)\n                if len(self.cr_success_history) > 10 * self.dim:\n                    self.cr_success_history.pop(0)\n                cr_success_rate = np.mean(self.cr_success_history)\n\n                if cr_success_rate > 0.7:\n                    self.CR = min(1.0, self.CR + self.cr_adaptation_rate)\n                elif cr_success_rate < 0.3:\n                    self.CR = max(0.1, self.CR - self.cr_adaptation_rate)\n\n                f_success = 1 if f_trial < self.fitness[i] else 0\n                self.f_success_history.append(f_success)\n                if len(self.f_success_history) > 10 * self.dim:\n                    self.f_success_history.pop(0)\n                f_success_rate = np.mean(self.f_success_history)\n\n                if f_success_rate > 0.7:\n                    self.F = min(1.0, self.F + self.f_adaptation_rate)\n                elif f_success_rate < 0.3:\n                    self.F = max(0.1, self.F - self.f_adaptation_rate)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16590893437766985, 0.28594949770438716, 0.47804122306848706, 0.6409027713493582, 0.5340486218467748, 0.7296054698227594, 0.4766874483865168, 0.46895575310882764, 0.5498607882281901, 0.45805733762911593, 0.4019470968448319, 0.9975002057019727, 0.25930271629940227, 0.3618111361694736, 0.7629172709690659, 0.7531954158116315, 0.42527963089730736, 0.7474100730819859, 0.2652150864598324, 0.5127004668199393], "operator": "mutation", "theta_sampled": 0.22272102376361974, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "83059c9e-6087-4440-9042-a3f4763e10b1", "fitness": 0.7043575649056913, "name": "AdaptiveDECMA2", "description": "An improved Adaptive Differential Evolution with CMA-ES inspired step-size adaptation, archive, and a dynamic F value.", "code": "import numpy as np\n\nclass AdaptiveDECMA2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1, F_initial=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F_initial  # Initial scaling factor, can be adapted\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.F_min = 0.1\n        self.F_max = 1.0\n        self.F_adapt_prob = 0.1 # Probability of adapting F\n        self.p_archive = 0.1\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.p_archive and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                #Potentially adapt F\n                if np.random.rand() < self.F_adapt_prob:\n                    self.F = np.random.uniform(self.F_min, self.F_max)\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDECMA2 scored 0.704 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e5596f8c-6991-41ed-91fc-75dd80c09d2f"], "operator": "mutation", "metadata": {"llm_response": "# Description: An improved Adaptive Differential Evolution with CMA-ES inspired step-size adaptation, archive, and a dynamic F value.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMA2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov = 0.1, F_initial=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F_initial  # Initial scaling factor, can be adapted\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.F_min = 0.1\n        self.F_max = 1.0\n        self.F_adapt_prob = 0.1 # Probability of adapting F\n        self.p_archive = 0.1\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.sigma = self.sigma0 #Init sigma\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.p_archive and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                #Potentially adapt F\n                if np.random.rand() < self.F_adapt_prob:\n                    self.F = np.random.uniform(self.F_min, self.F_max)\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i])\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i]\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * (x_trial - self.m) / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial\n\n                # Adaptive stepsize\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.sigma *= (1 - self.adaptation_rate)\n                self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3828299218117285, 0.7243276754703372, 0.6484069353404351, 0.8378228365040192, 0.7064944713145919, 0.7764063083615389, 0.6772813368295107, 0.6642712352819977, 0.7539808176155323, 0.6667584123814545, 0.8503448249340115, 0.9997403846578578, 0.7024805009904644, 0.7412454802334494, 0.8935489511253372, 0.7644678931578016, 0.6322051427377267, 0.8579587526528247, 0.29618046532261644, 0.5103989513905922], "operator": "mutation", "theta_sampled": 0.030482416253081054, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "c18cfbb3-fa62-456d-bfad-470818341beb", "fitness": 0.40984914266931904, "name": "HybridAdaptiveDECMOCombinedV2", "description": "Combines DE with CMA-ES, adaptive parameter control based on success rate, and a dynamically sized archive to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOCombinedV2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size_factor=2, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = int(archive_size_factor * dim)\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.archive_age = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            \n            old_best_fitness = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    archive_idx = np.random.randint(len(self.archive))\n                    x_r3 = self.archive[archive_idx]\n                    \n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        # Dynamic Archive update with age consideration\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                            self.archive_age.append(0)\n                        else:\n                            #Replace oldest archive member\n                            max_age_index = np.argmax(self.archive_age)\n                            self.archive[max_age_index] = self.population[i].copy()\n                            self.archive_fitness[max_age_index] = self.fitness[i]\n                            self.archive_age[max_age_index] = 0 #reset age\n                        \n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n                        \n                        # Dynamic Archive update with age consideration\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                            self.archive_age.append(0)\n                        else:\n                            #Replace oldest archive member\n                            max_age_index = np.argmax(self.archive_age)\n                            self.archive[max_age_index] = self.population[i].copy()\n                            self.archive_fitness[max_age_index] = self.fitness[i]\n                            self.archive_age[max_age_index] = 0 #reset age\n\n                #Adapt step size - Use c_sigma from HybridAdaptiveDECMO2\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                # Adaptive Covariance Matrix Adaptation (CMA-ES part) with factor 0.1 from HybridAdaptiveDECMO2\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()  # Update mean with the trial point\n\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                # Adaptation of c_cov and c_sigma\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    \n            # Stagnation Detection\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n\n            if len(self.best_fitness_history) == self.stagnation_threshold and np.std(self.best_fitness_history) < 1e-8:\n                self.stagnation_counter += 1\n                # Increase diversity if stagnating by re-initializing a portion of the population\n                num_reinit = int(0.1 * self.pop_size)\n                reinit_indices = np.random.choice(self.pop_size, num_reinit, replace=False)\n                self.population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                self.fitness[reinit_indices] = np.array([func(x) for x in self.population[reinit_indices]])\n                self.budget -= num_reinit\n                \n                self.m = self.x_opt.copy()\n                self.C = np.eye(self.dim)\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n            else:\n                self.stagnation_counter = 0\n            \n            #Age archive\n            for k in range(len(self.archive_age)):\n                self.archive_age[k]+=1\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridAdaptiveDECMOCombinedV2 scored 0.410 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8f38a4ff-ef73-4e08-88ef-0e9e71f8ee21"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines DE with CMA-ES, adaptive parameter control based on success rate, and a dynamically sized archive to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOCombinedV2:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size_factor=2, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = int(archive_size_factor * dim)\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.archive_age = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            \n            old_best_fitness = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    archive_idx = np.random.randint(len(self.archive))\n                    x_r3 = self.archive[archive_idx]\n                    \n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        # Dynamic Archive update with age consideration\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                            self.archive_age.append(0)\n                        else:\n                            #Replace oldest archive member\n                            max_age_index = np.argmax(self.archive_age)\n                            self.archive[max_age_index] = self.population[i].copy()\n                            self.archive_fitness[max_age_index] = self.fitness[i]\n                            self.archive_age[max_age_index] = 0 #reset age\n                        \n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n                        \n                        # Dynamic Archive update with age consideration\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                            self.archive_age.append(0)\n                        else:\n                            #Replace oldest archive member\n                            max_age_index = np.argmax(self.archive_age)\n                            self.archive[max_age_index] = self.population[i].copy()\n                            self.archive_fitness[max_age_index] = self.fitness[i]\n                            self.archive_age[max_age_index] = 0 #reset age\n\n                #Adapt step size - Use c_sigma from HybridAdaptiveDECMO2\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                # Adaptive Covariance Matrix Adaptation (CMA-ES part) with factor 0.1 from HybridAdaptiveDECMO2\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()  # Update mean with the trial point\n\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                # Adaptation of c_cov and c_sigma\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    \n            # Stagnation Detection\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n\n            if len(self.best_fitness_history) == self.stagnation_threshold and np.std(self.best_fitness_history) < 1e-8:\n                self.stagnation_counter += 1\n                # Increase diversity if stagnating by re-initializing a portion of the population\n                num_reinit = int(0.1 * self.pop_size)\n                reinit_indices = np.random.choice(self.pop_size, num_reinit, replace=False)\n                self.population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                self.fitness[reinit_indices] = np.array([func(x) for x in self.population[reinit_indices]])\n                self.budget -= num_reinit\n                \n                self.m = self.x_opt.copy()\n                self.C = np.eye(self.dim)\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n            else:\n                self.stagnation_counter = 0\n            \n            #Age archive\n            for k in range(len(self.archive_age)):\n                self.archive_age[k]+=1\n        return self.f_opt, self.x_opt\n```", "aucs": [0.31279296762119957, 0.674341241714294, 0.6522623613417825, 0], "operator": "mutation", "theta_sampled": 0.04697704367033025, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "7a017b9b-efe5-465f-b385-bd84e62d53d7", "fitness": 0.7164082434844664, "name": "HybridAdaptiveDECMOImproved", "description": "A hybrid Differential Evolution and CMA-ES algorithm with improved archive handling, step size adaptation, and covariance matrix learning, focusing on better exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            #Combine parent and offspring populations\n            combined_population = np.vstack((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Weighted update of the covariance matrix\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridAdaptiveDECMOImproved scored 0.716 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid Differential Evolution and CMA-ES algorithm with improved archive handling, step size adaptation, and covariance matrix learning, focusing on better exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            #Combine parent and offspring populations\n            combined_population = np.vstack((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Weighted update of the covariance matrix\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3438393363489025, 0.706350175289517, 0.6501413743252731, 0.8631240997393157, 0.7897090316997923, 0.7940201967489359, 0.6981672628697289, 0.7119741696831604, 0.7669794639960743, 0.7119555360585033, 0.8695593143372187, 0.9978912053565364, 0.7172636894983045, 0.7329231159614299, 0.8402880707277637, 0.7917346722693784, 0.651166702809469, 0.8501397115332677, 0.3207563230932525, 0.520181417343502], "operator": "mutation", "theta_sampled": 0.008768905297047073, "reward": 0.004951296173146491, "generation": 11}, "task_prompt": ""}
{"id": "d7dfe1a4-7769-4af0-8426-9d9fbe224790", "fitness": 0.0, "name": "HybridAdaptiveDECMOLineSearch", "description": "Combines DE with CMA-ES, adaptive parameter control, and an archive, further incorporating a simplified line search for exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOLineSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, line_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.line_search_prob = line_search_prob\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Line Search\n                if np.random.rand() < self.line_search_prob:\n                    alpha = 0.1\n                    x_ls = x_trial.copy()\n                    f_ls = f_trial\n                    for _ in range(5):\n                        x_new = x_trial + alpha * (x_trial - self.population[i])\n                        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                        f_new = func(x_new)\n                        self.budget -= 1\n                        if f_new < f_ls:\n                            f_ls = f_new\n                            x_ls = x_new.copy()\n                            alpha *= 1.2\n                        else:\n                            alpha *= 0.5\n                    if f_ls < f_trial:\n                        f_trial = f_ls\n                        x_trial = x_ls.copy()\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size - Use c_sigma from HybridAdaptiveDECMO2\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                # Adaptive Covariance Matrix Adaptation (CMA-ES part) with factor 0.1 from HybridAdaptiveDECMO2\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()  # Update mean with the trial point\n\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                # Adaptation of c_cov and c_sigma\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridAdaptiveDECMOLineSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8f38a4ff-ef73-4e08-88ef-0e9e71f8ee21"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines DE with CMA-ES, adaptive parameter control, and an archive, further incorporating a simplified line search for exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOLineSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, F=0.5, CR=0.9, c_sigma=0.1, archive_prob=0.1, line_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Fixed scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = c_sigma\n        self.archive_prob = archive_prob\n        self.line_search_prob = line_search_prob\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < self.archive_prob and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Line Search\n                if np.random.rand() < self.line_search_prob:\n                    alpha = 0.1\n                    x_ls = x_trial.copy()\n                    f_ls = f_trial\n                    for _ in range(5):\n                        x_new = x_trial + alpha * (x_trial - self.population[i])\n                        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                        f_new = func(x_new)\n                        self.budget -= 1\n                        if f_new < f_ls:\n                            f_ls = f_new\n                            x_ls = x_new.copy()\n                            alpha *= 1.2\n                        else:\n                            alpha *= 0.5\n                    if f_ls < f_trial:\n                        f_trial = f_ls\n                        x_trial = x_ls.copy()\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size - Use c_sigma from HybridAdaptiveDECMO2\n                y = x_trial - self.m\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * 1) * y / self.sigma\n                \n                # Adaptive Covariance Matrix Adaptation (CMA-ES part) with factor 0.1 from HybridAdaptiveDECMO2\n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * 0.1 * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy()  # Update mean with the trial point\n\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                # Adaptation of c_cov and c_sigma\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                    self.c_sigma *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                    self.c_sigma *= (1 - self.adaptation_rate)\n\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n                self.c_sigma = np.clip(self.c_sigma, 0.01, 0.4)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.00047506784562946166, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "f73ba069-19b9-44c8-9dbe-c0cdba239407", "fitness": 0.0, "name": "HybridAdaptiveDECMOMirrored", "description": "Combines DE with CMA-ES-like adaptation, employing a mirrored sampling strategy around the mean to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOMirrored:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, mu_c = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.mu_c = mu_c\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Mirrored Sampling: Generate a mirrored point around the mean\n                x_mirrored = self.m + (self.m - x_trial)\n                x_mirrored = np.clip(x_mirrored, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate both trial and mirrored points\n                f_trial = func(x_trial)\n                self.budget -= 1\n                f_mirrored = func(x_mirrored)\n                self.budget -= 1\n\n                # Select the better of trial and mirrored points\n                if f_mirrored < f_trial:\n                    x_best = x_mirrored\n                    f_best = f_mirrored\n                else:\n                    x_best = x_trial\n                    f_best = f_trial\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_best <= 0) or (self.fitness[i] > 0 and f_best > 0):\n                    if f_best < self.fitness[i]:\n                        self.population[i] = x_best.copy()\n                        self.fitness[i] = f_best\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_best = np.random.rand()\n\n                    if p_best < p_i:\n                        self.population[i] = x_best.copy()\n                        self.fitness[i] = f_best\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                # CMA-ES-like adaptation\n                y = x_best - self.m  # Use the best point\n                self.ps = (1 - self.mu_c) * self.ps + np.sqrt(self.mu_c * (2 - self.mu_c) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.mu_c)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.mu_c) * self.pc + hsig * np.sqrt(self.mu_c * (2 - self.mu_c) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.mu_c / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_best?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_best < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_best < self.f_opt:\n                    self.f_opt = f_best\n                    self.x_opt = x_best.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm HybridAdaptiveDECMOMirrored scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines DE with CMA-ES-like adaptation, employing a mirrored sampling strategy around the mean to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOMirrored:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, mu_c = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.mu_c = mu_c\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Mirrored Sampling: Generate a mirrored point around the mean\n                x_mirrored = self.m + (self.m - x_trial)\n                x_mirrored = np.clip(x_mirrored, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate both trial and mirrored points\n                f_trial = func(x_trial)\n                self.budget -= 1\n                f_mirrored = func(x_mirrored)\n                self.budget -= 1\n\n                # Select the better of trial and mirrored points\n                if f_mirrored < f_trial:\n                    x_best = x_mirrored\n                    f_best = f_mirrored\n                else:\n                    x_best = x_trial\n                    f_best = f_trial\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_best <= 0) or (self.fitness[i] > 0 and f_best > 0):\n                    if f_best < self.fitness[i]:\n                        self.population[i] = x_best.copy()\n                        self.fitness[i] = f_best\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_best = np.random.rand()\n\n                    if p_best < p_i:\n                        self.population[i] = x_best.copy()\n                        self.fitness[i] = f_best\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n\n                # CMA-ES-like adaptation\n                y = x_best - self.m  # Use the best point\n                self.ps = (1 - self.mu_c) * self.ps + np.sqrt(self.mu_c * (2 - self.mu_c) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.mu_c)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - self.mu_c) * self.pc + hsig * np.sqrt(self.mu_c * (2 - self.mu_c) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((self.mu_c / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = self.population[i].copy() # or x_best?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_best < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                if f_best < self.f_opt:\n                    self.f_opt = f_best\n                    self.x_opt = x_best.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.0019034362784962414, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "62aa679b-c1cd-4c4d-98a4-fa21d8be4b2e", "fitness": 0.0, "name": "HybridAdaptiveDECMOImprovedRestart", "description": "Integrates a simplified CMA-ES with a self-adaptive differential evolution, where CMA-ES guides the search and DE provides diversity; includes restart mechanism and improved archive management.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOImprovedRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, restart_trigger=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.restart_trigger = restart_trigger # Threshold for restarting based on stagnation\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        self.stagnation_counter = 0\n        self.last_improvement = self.f_opt\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # Adaptive F\n                F_current = self.F * np.random.uniform(0.5, 1.5) # Add some randomness to F\n                x_mutated = x_r1 + F_current * (x_r2 - x_r3)\n\n                # Using CMA-ES to guide the mutation\n                z = np.random.randn(self.dim)\n                x_mutated = self.m + self.sigma * (self.B @ (self.D * z)) # Sampling from CMA-ES distribution\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            #Combine parent and offspring populations\n            combined_population = np.vstack((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Simplified Covariance Matrix Adaptation\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            # Eigenvalue decomposition of C (simplified version)\n            try:\n                self.D, self.B = np.linalg.eigh(self.C) # Using eigh for symmetric C\n                self.D = np.sqrt(np.abs(self.D)) # Ensure positive values and handle potential numerical issues\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.B = np.eye(self.dim)\n                #print(\"linalg error encountered\")\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n                self.stagnation_counter = 0\n                self.last_improvement = self.f_opt\n            else:\n                 self.stagnation_counter += 1\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.restart_trigger * self.budget / self.pop_size: # Trigger restart when stuck\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n                self.m = self.x_opt.copy()\n                self.C = np.eye(self.dim)\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.stagnation_counter = 0\n                #print(\"Restarting\")\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm HybridAdaptiveDECMOImprovedRestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a017b9b-efe5-465f-b385-bd84e62d53d7"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a simplified CMA-ES with a self-adaptive differential evolution, where CMA-ES guides the search and DE provides diversity; includes restart mechanism and improved archive management.\n# Code:\n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOImprovedRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, restart_trigger=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.restart_trigger = restart_trigger # Threshold for restarting based on stagnation\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        self.stagnation_counter = 0\n        self.last_improvement = self.f_opt\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                # Adaptive F\n                F_current = self.F * np.random.uniform(0.5, 1.5) # Add some randomness to F\n                x_mutated = x_r1 + F_current * (x_r2 - x_r3)\n\n                # Using CMA-ES to guide the mutation\n                z = np.random.randn(self.dim)\n                x_mutated = self.m + self.sigma * (self.B @ (self.D * z)) # Sampling from CMA-ES distribution\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            #Combine parent and offspring populations\n            combined_population = np.vstack((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Simplified Covariance Matrix Adaptation\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            # Eigenvalue decomposition of C (simplified version)\n            try:\n                self.D, self.B = np.linalg.eigh(self.C) # Using eigh for symmetric C\n                self.D = np.sqrt(np.abs(self.D)) # Ensure positive values and handle potential numerical issues\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.B = np.eye(self.dim)\n                #print(\"linalg error encountered\")\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n                self.stagnation_counter = 0\n                self.last_improvement = self.f_opt\n            else:\n                 self.stagnation_counter += 1\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.restart_trigger * self.budget / self.pop_size: # Trigger restart when stuck\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n                self.m = self.x_opt.copy()\n                self.C = np.eye(self.dim)\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.stagnation_counter = 0\n                #print(\"Restarting\")\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.0003402039203300277, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "7ef9e57c-9a6d-484b-a8fe-05af2444eaba", "fitness": 0.0, "name": "HybridAdaptiveDECMONMS", "description": "Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and Nelder-Mead Simplex for enhanced exploration and exploitation, incorporating adaptive parameter control and a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMONMS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, nm_prob=0.05, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.nm_prob = nm_prob # Probability of applying Nelder-Mead\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Nelder-Mead Simplex with probability\n                if np.random.rand() < self.nm_prob:\n                    x_trial, f_trial = self.nelder_mead(func, x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                if np.random.rand() >= self.nm_prob: # Ensure NM is not always used, use DE as the default operator\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            #Combine parent and offspring populations\n            combined_population = np.vstack((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Weighted update of the covariance matrix\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            # Stagnation detection and restart\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n                if np.std(self.best_fitness_history) < 1e-8:  #Stagnation detected\n                    self.stagnation_counter += 1\n                    if self.stagnation_counter >= 3: #Restart after 3 consecutive stagnations\n                        self.restart_population(func)\n                        self.stagnation_counter = 0 #Reset counter\n            else:\n                self.stagnation_counter = 0 #Reset if no stagnation this iteration\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n\n        return self.f_opt, self.x_opt\n\n    def nelder_mead(self, func, x0, lb, ub, alpha=1, beta=0.5, gamma=2, max_iter=50): #Reduced max_iter to save budget\n        \"\"\"Nelder-Mead simplex algorithm.\"\"\"\n        n = self.dim\n        simplex = [x0 + 1e-4 * np.random.randn(n) for _ in range(n + 1)]  # Initialize simplex\n        simplex = np.clip(np.array(simplex), lb, ub) #Clip the simplex points\n\n        for i in range(len(simplex)):\n            simplex[i] = self.ensure_bounds(simplex[i], lb, ub)\n            \n        fitness = [func(x) for x in simplex]\n        self.budget -= (n + 1 - len(simplex)) #Substract budget used for initialization\n        \n        for iteration in range(max_iter):\n            # Order the simplex points by fitness\n            fitness_idx = np.argsort(fitness)\n            simplex = simplex[fitness_idx]\n            fitness = np.array(fitness)[fitness_idx]\n            \n            best = simplex[0]\n            worst = simplex[-1]\n            second_worst = simplex[-2]\n            \n            # Calculate centroid of all points except the worst\n            centroid = np.mean(simplex[:-1], axis=0)\n            \n            # Reflection\n            reflected = centroid + alpha * (centroid - worst)\n            reflected = self.ensure_bounds(reflected, lb, ub)\n\n            f_reflected = func(reflected)\n            self.budget -= 1\n            \n            if f_reflected < fitness[0]:\n                # Expansion\n                expanded = centroid + gamma * (reflected - centroid)\n                expanded = self.ensure_bounds(expanded, lb, ub)\n                f_expanded = func(expanded)\n                self.budget -= 1\n                \n                if f_expanded < f_reflected:\n                    simplex[-1] = expanded\n                    fitness[-1] = f_expanded\n                else:\n                    simplex[-1] = reflected\n                    fitness[-1] = f_reflected\n            elif f_reflected < fitness[-2]:\n                simplex[-1] = reflected\n                fitness[-1] = f_reflected\n            else:\n                # Contraction\n                contracted = centroid + beta * (worst - centroid)\n                contracted = self.ensure_bounds(contracted, lb, ub)\n                f_contracted = func(contracted)\n                self.budget -= 1\n                \n                if f_contracted < fitness[-1]:\n                    simplex[-1] = contracted\n                    fitness[-1] = f_contracted\n                else:\n                    # Shrink\n                    for i in range(1, n + 1):\n                        simplex[i] = best + 0.5 * (simplex[i] - best)\n                        simplex[i] = self.ensure_bounds(simplex[i], lb, ub)\n                    fitness = [func(x) for x in simplex]\n                    self.budget -= (n)\n\n\n        best_idx = np.argmin(fitness)\n        return simplex[best_idx], fitness[best_idx]\n\n    def ensure_bounds(self, vec, lb, ub):\n        \"\"\"Ensures that each variable lies within the specified bounds.\"\"\"\n        vec_bounded = np.copy(vec)\n        for i in range(len(vec)):\n            if vec[i] < lb:\n                vec_bounded[i] = lb\n            elif vec[i] > ub:\n                vec_bounded[i] = ub\n        return vec_bounded\n\n    def restart_population(self, func):\n        \"\"\"Restarts the population with new random individuals.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index].copy()\n\n        self.m = self.x_opt.copy()  # Reset mean\n        self.C = np.eye(self.dim)  # Reset covariance matrix\n        self.sigma = self.sigma0 #Reset sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)", "configspace": "", "generation": 12, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": ["7a017b9b-efe5-465f-b385-bd84e62d53d7"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and Nelder-Mead Simplex for enhanced exploration and exploitation, incorporating adaptive parameter control and a restart mechanism when stagnation is detected.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMONMS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, nm_prob=0.05, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.nm_prob = nm_prob # Probability of applying Nelder-Mead\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Nelder-Mead Simplex with probability\n                if np.random.rand() < self.nm_prob:\n                    x_trial, f_trial = self.nelder_mead(func, x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                if np.random.rand() >= self.nm_prob: # Ensure NM is not always used, use DE as the default operator\n                    f_trial = func(x_trial)\n                    self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            #Combine parent and offspring populations\n            combined_population = np.vstack((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Weighted update of the covariance matrix\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            # Stagnation detection and restart\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n                if np.std(self.best_fitness_history) < 1e-8:  #Stagnation detected\n                    self.stagnation_counter += 1\n                    if self.stagnation_counter >= 3: #Restart after 3 consecutive stagnations\n                        self.restart_population(func)\n                        self.stagnation_counter = 0 #Reset counter\n            else:\n                self.stagnation_counter = 0 #Reset if no stagnation this iteration\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n\n        return self.f_opt, self.x_opt\n\n    def nelder_mead(self, func, x0, lb, ub, alpha=1, beta=0.5, gamma=2, max_iter=50): #Reduced max_iter to save budget\n        \"\"\"Nelder-Mead simplex algorithm.\"\"\"\n        n = self.dim\n        simplex = [x0 + 1e-4 * np.random.randn(n) for _ in range(n + 1)]  # Initialize simplex\n        simplex = np.clip(np.array(simplex), lb, ub) #Clip the simplex points\n\n        for i in range(len(simplex)):\n            simplex[i] = self.ensure_bounds(simplex[i], lb, ub)\n            \n        fitness = [func(x) for x in simplex]\n        self.budget -= (n + 1 - len(simplex)) #Substract budget used for initialization\n        \n        for iteration in range(max_iter):\n            # Order the simplex points by fitness\n            fitness_idx = np.argsort(fitness)\n            simplex = simplex[fitness_idx]\n            fitness = np.array(fitness)[fitness_idx]\n            \n            best = simplex[0]\n            worst = simplex[-1]\n            second_worst = simplex[-2]\n            \n            # Calculate centroid of all points except the worst\n            centroid = np.mean(simplex[:-1], axis=0)\n            \n            # Reflection\n            reflected = centroid + alpha * (centroid - worst)\n            reflected = self.ensure_bounds(reflected, lb, ub)\n\n            f_reflected = func(reflected)\n            self.budget -= 1\n            \n            if f_reflected < fitness[0]:\n                # Expansion\n                expanded = centroid + gamma * (reflected - centroid)\n                expanded = self.ensure_bounds(expanded, lb, ub)\n                f_expanded = func(expanded)\n                self.budget -= 1\n                \n                if f_expanded < f_reflected:\n                    simplex[-1] = expanded\n                    fitness[-1] = f_expanded\n                else:\n                    simplex[-1] = reflected\n                    fitness[-1] = f_reflected\n            elif f_reflected < fitness[-2]:\n                simplex[-1] = reflected\n                fitness[-1] = f_reflected\n            else:\n                # Contraction\n                contracted = centroid + beta * (worst - centroid)\n                contracted = self.ensure_bounds(contracted, lb, ub)\n                f_contracted = func(contracted)\n                self.budget -= 1\n                \n                if f_contracted < fitness[-1]:\n                    simplex[-1] = contracted\n                    fitness[-1] = f_contracted\n                else:\n                    # Shrink\n                    for i in range(1, n + 1):\n                        simplex[i] = best + 0.5 * (simplex[i] - best)\n                        simplex[i] = self.ensure_bounds(simplex[i], lb, ub)\n                    fitness = [func(x) for x in simplex]\n                    self.budget -= (n)\n\n\n        best_idx = np.argmin(fitness)\n        return simplex[best_idx], fitness[best_idx]\n\n    def ensure_bounds(self, vec, lb, ub):\n        \"\"\"Ensures that each variable lies within the specified bounds.\"\"\"\n        vec_bounded = np.copy(vec)\n        for i in range(len(vec)):\n            if vec[i] < lb:\n                vec_bounded[i] = lb\n            elif vec[i] > ub:\n                vec_bounded[i] = ub\n        return vec_bounded\n\n    def restart_population(self, func):\n        \"\"\"Restarts the population with new random individuals.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index].copy()\n\n        self.m = self.x_opt.copy()  # Reset mean\n        self.C = np.eye(self.dim)  # Reset covariance matrix\n        self.sigma = self.sigma0 #Reset sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n```", "operator": "mutation", "theta_sampled": 0.0004633732981266692, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "84b84c10-db4b-4eff-87ef-043216c81f8d", "fitness": 0.6690200558074669, "name": "HybridAdaptiveDECMOStochastic", "description": "Combines DE with CMA-ES, adaptive parameters, stochastic ranking, and a dynamic archive for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOStochastic:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, stoch_rank_prob=0.45):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.stoch_rank_prob = stoch_rank_prob\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            # Stochastic ranking and archive update\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and offspring_fitness[i] <= 0) or (self.fitness[i] > 0 and offspring_fitness[i] > 0):\n                    if offspring_fitness[i] < self.fitness[i]:\n                        self.population[i] = offspring[i].copy()\n                        self.fitness[i] = offspring_fitness[i]\n\n                        # Archive update\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    if np.random.rand() < self.stoch_rank_prob:\n                        if offspring_fitness[i] < self.fitness[i]:\n                            self.population[i] = offspring[i].copy()\n                            self.fitness[i] = offspring_fitness[i]\n\n                            # Archive update\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(self.population[i].copy())\n                                self.archive_fitness.append(self.fitness[i])\n                            else:\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i].copy()\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            # Adapt step size (CMA-ES adaptation using best offspring)\n            best_offspring_index = np.argmin(offspring_fitness)\n            y = offspring[best_offspring_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[np.argmin(self.fitness)].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if offspring_fitness[best_offspring_index] < self.f_opt else 0) # Update success based on best offspring\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm HybridAdaptiveDECMOStochastic scored 0.669 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a017b9b-efe5-465f-b385-bd84e62d53d7", "f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines DE with CMA-ES, adaptive parameters, stochastic ranking, and a dynamic archive for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOStochastic:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9, stoch_rank_prob=0.45):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.stoch_rank_prob = stoch_rank_prob\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n\n            # Stochastic ranking and archive update\n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and offspring_fitness[i] <= 0) or (self.fitness[i] > 0 and offspring_fitness[i] > 0):\n                    if offspring_fitness[i] < self.fitness[i]:\n                        self.population[i] = offspring[i].copy()\n                        self.fitness[i] = offspring_fitness[i]\n\n                        # Archive update\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    if np.random.rand() < self.stoch_rank_prob:\n                        if offspring_fitness[i] < self.fitness[i]:\n                            self.population[i] = offspring[i].copy()\n                            self.fitness[i] = offspring_fitness[i]\n\n                            # Archive update\n                            if len(self.archive) < self.archive_size:\n                                self.archive.append(self.population[i].copy())\n                                self.archive_fitness.append(self.fitness[i])\n                            else:\n                                max_archive_index = np.argmax(self.archive_fitness)\n                                if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                    self.archive[max_archive_index] = self.population[i].copy()\n                                    self.archive_fitness[max_archive_index] = self.fitness[i]\n\n            # Adapt step size (CMA-ES adaptation using best offspring)\n            best_offspring_index = np.argmin(offspring_fitness)\n            y = offspring[best_offspring_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[np.argmin(self.fitness)].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if offspring_fitness[best_offspring_index] < self.f_opt else 0) # Update success based on best offspring\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.29401641821672486, 0.6227195230103701, 0.6029069465901549, 0.8506414519341334, 0.7166917487709992, 0.724741940394984, 0.5793694946743229, 0.5971669950535897, 0.6718740163939416, 0.6292439471112721, 0.8244100983486384, 0.9966743402364593, 0.5644853284468122, 0.6942641997144421, 0.9206055712935958, 0.7359533772828432, 0.5788257135488258, 0.7981942509738056, 0.45762977926861603, 0.519985974884807], "operator": "crossover", "theta_sampled": 0.0005955244775989114, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "0b65b061-712e-4ed5-b85a-2b0dba3653ef", "fitness": 0.27651325754405015, "name": "ChargedParticleOptimization", "description": "Population-based algorithm inspired by charged particles interacting with each other, where particles are attracted to better solutions and repelled by worse ones, with adaptive charge and inertia.", "code": "import numpy as np\n\nclass ChargedParticleOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, charge_decay=0.99, inertia_weight=0.7, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.charge_decay = charge_decay\n        self.inertia_weight = inertia_weight\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Initialize velocities\n        velocities = np.zeros((self.pop_size, self.dim))\n        \n        # Initialize charges\n        charges = np.ones(self.pop_size)\n        \n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Update charges based on fitness (better solutions have higher charge)\n            normalized_fitness = (np.max(fitness) - fitness) / (np.max(fitness) - np.min(fitness) + 1e-8)  # Avoid division by zero\n            charges = normalized_fitness\n\n            # Calculate forces between particles\n            forces = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = population[j] - population[i]\n                        magnitude = charges[i] * charges[j] / (np.linalg.norm(distance)**2 + 1e-8) # Add small value to avoid division by zero\n                        forces[i] += magnitude * distance * self.repulsion_factor  # Repulsion between all particles\n\n            # Update velocities and positions\n            velocities = self.inertia_weight * velocities + forces \n            new_population = population + velocities\n            \n            # Handle boundary constraints\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update best solution\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                   population[i] = new_population[i]\n                   fitness[i] = new_fitness[i]\n                   if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_population[i]\n                \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                \n            # Decay charges\n            charges *= self.charge_decay\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm ChargedParticleOptimization scored 0.277 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm inspired by charged particles interacting with each other, where particles are attracted to better solutions and repelled by worse ones, with adaptive charge and inertia.\n# Code:\n```python\nimport numpy as np\n\nclass ChargedParticleOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, charge_decay=0.99, inertia_weight=0.7, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.charge_decay = charge_decay\n        self.inertia_weight = inertia_weight\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Initialize velocities\n        velocities = np.zeros((self.pop_size, self.dim))\n        \n        # Initialize charges\n        charges = np.ones(self.pop_size)\n        \n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Update charges based on fitness (better solutions have higher charge)\n            normalized_fitness = (np.max(fitness) - fitness) / (np.max(fitness) - np.min(fitness) + 1e-8)  # Avoid division by zero\n            charges = normalized_fitness\n\n            # Calculate forces between particles\n            forces = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = population[j] - population[i]\n                        magnitude = charges[i] * charges[j] / (np.linalg.norm(distance)**2 + 1e-8) # Add small value to avoid division by zero\n                        forces[i] += magnitude * distance * self.repulsion_factor  # Repulsion between all particles\n\n            # Update velocities and positions\n            velocities = self.inertia_weight * velocities + forces \n            new_population = population + velocities\n            \n            # Handle boundary constraints\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update best solution\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                   population[i] = new_population[i]\n                   fitness[i] = new_fitness[i]\n                   if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_population[i]\n                \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                \n            # Decay charges\n            charges *= self.charge_decay\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11983490585610357, 0.1862678595713132, 0.27125815406156384, 0.18418446673815025, 0.17848823446736062, 0.20067857803558975, 0.21133667383202326, 0.2115477303328659, 0.21480999587914518, 0.14756655671862662, 0.2193811332941561, 0.9983408028838865, 0.2650445241093441, 0.21424064036169155, 0.5816940719712937, 0.2538894500092015, 0.20779666490861304, 0.3064112140043058, 0.14580626523954854, 0.41168722860621976], "operator": "random_new", "theta_sampled": 0.19238652388638341, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "0b3c0778-e5b8-44cf-90db-f3e12a2543ab", "fitness": 0.6686860431353921, "name": "HybridAdaptiveDECMOCombinedImproved", "description": "Combines improved population handling and archive management from HybridAdaptiveDECMOImproved with stochastic ranking from HybridAdaptiveDECMO, alongside adaptive CMA-ES.", "code": "import numpy as np\n\nclass HybridAdaptiveDECMOCombinedImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection via Stochastic Ranking\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n                \n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and offspring_fitness[i] <= 0) or (self.fitness[i] > 0 and offspring_fitness[i] > 0):\n                    if offspring_fitness[i] < self.fitness[i]:\n                        self.population[i] = offspring[i].copy()\n                        self.fitness[i] = offspring_fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n                    if p_trial < p_i:\n                        self.population[i] = offspring[i].copy()\n                        self.fitness[i] = offspring_fitness[i]\n\n\n            #Combine parent and offspring populations\n            #combined_population = np.vstack((self.population, offspring))\n            #combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            #sorted_indices = np.argsort(combined_fitness)\n            #self.population = combined_population[sorted_indices[:self.pop_size]]\n            #self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Weighted update of the covariance matrix\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm HybridAdaptiveDECMOCombinedImproved scored 0.669 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a017b9b-efe5-465f-b385-bd84e62d53d7", "f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines improved population handling and archive management from HybridAdaptiveDECMOImproved with stochastic ranking from HybridAdaptiveDECMO, alongside adaptive CMA-ES.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDECMOCombinedImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0=0.1, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2 # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) # normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim) #eigenvectors of C\n        self.D = np.ones(self.dim) #eigenvalues of C\n\n        while self.budget > 0:\n            offspring = np.zeros((self.pop_size, self.dim))\n            offspring_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection via Stochastic Ranking\n                f_trial = func(x_trial)\n                self.budget -= 1\n                offspring[i] = x_trial\n                offspring_fitness[i] = f_trial\n                \n            for i in range(self.pop_size):\n                if (self.fitness[i] <= 0 and offspring_fitness[i] <= 0) or (self.fitness[i] > 0 and offspring_fitness[i] > 0):\n                    if offspring_fitness[i] < self.fitness[i]:\n                        self.population[i] = offspring[i].copy()\n                        self.fitness[i] = offspring_fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n                    if p_trial < p_i:\n                        self.population[i] = offspring[i].copy()\n                        self.fitness[i] = offspring_fitness[i]\n\n\n            #Combine parent and offspring populations\n            #combined_population = np.vstack((self.population, offspring))\n            #combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n\n            # Select the best individuals to form the new population\n            #sorted_indices = np.argsort(combined_fitness)\n            #self.population = combined_population[sorted_indices[:self.pop_size]]\n            #self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            best_index = np.argmin(self.fitness)\n            y = self.population[best_index] - self.m\n            self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * self.mueff) * y / self.sigma\n\n            # Weighted update of the covariance matrix\n            oldC = self.C.copy()\n            self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            for k in range(self.mu):\n                 yk = self.population[k] - self.m\n                 self.C += (self.c_cov / self.mueff) * self.weights[k] * (yk[:,None] @ yk[None,:])\n\n            self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.m = self.population[0].copy() # Using the best individual as the new mean\n\n            # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n            self.success_history.append(1 if self.fitness[0] < self.f_opt else 0) # Only update success based on the best in the population\n            if len(self.success_history) > 10 * self.dim:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.7:\n                self.c_cov *= (1 + self.adaptation_rate)\n            elif self.success_rate < 0.3:\n                self.c_cov *= (1 - self.adaptation_rate)\n            self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n\n            # Archive Update: Adding the best individuals to the archive\n            for i in range(min(self.pop_size, self.archive_size)): # Adding at most archive_size individuals\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                else:\n                    max_archive_index = np.argmax(self.archive_fitness)\n                    if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                        self.archive[max_archive_index] = self.population[i].copy()\n                        self.archive_fitness[max_archive_index] = self.fitness[i]\n\n\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2660807238853523, 0.6725604696101866, 0.6356091288654901, 0.8512751526415638, 0.7031963304681998, 0.7521062818975348, 0.5743772998072856, 0.6091518158889333, 0.691153436029637, 0.6158320630963863, 0.8304919354081082, 0.9973738058248448, 0.612890472358067, 0.6849696377838899, 0.8867969430031093, 0.7499822667659505, 0.5897306725102833, 0.81545298330235, 0.26681717979613895, 0.5678722637645308], "operator": "crossover", "theta_sampled": -0.00051004171282722, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "4108326c-c91f-4efd-b591-e38d90fb5c1a", "fitness": 0.37829501923190634, "name": "PSO_DE_Niching", "description": "A population-based algorithm that combines elements of particle swarm optimization and differential evolution, with adaptive parameter control and a niching strategy to maintain diversity.", "code": "import numpy as np\n\nclass PSO_DE_Niching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.8, CR=0.9, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.niche_radius = niche_radius\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_velocity(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (self.w * self.velocities[i] +\n                              self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                              self.c2 * r2 * (self.global_best_position - self.population[i]))\n\n    def differential_evolution_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        return x1 + self.F * (x2 - x3)\n\n    def differential_evolution_crossover(self, mutated_vector, i):\n        trial_vector = self.population[i].copy()\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutated_vector[j]\n        return trial_vector\n\n    def niching_strategy(self, x, func):\n        # Penalize solutions that are too close to each other\n        penalty = 0\n        for other_x in self.population:\n            if np.linalg.norm(x - other_x) < self.niche_radius:\n                penalty += 0.1  # Adjust penalty as needed\n        return func(x) + penalty\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO velocity update\n                self.update_velocity(i)\n\n                # DE mutation\n                mutated_vector = self.differential_evolution_mutation(i)\n\n                # DE crossover\n                trial_vector = self.differential_evolution_crossover(mutated_vector, i)\n\n                # Bound Handling\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Niching and evaluation\n                f_trial = self.niching_strategy(trial_vector, func)\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break # Respect budget\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial_vector.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial_vector.copy()\n\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm PSO_DE_Niching scored 0.378 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of particle swarm optimization and differential evolution, with adaptive parameter control and a niching strategy to maintain diversity.\n# Code:\n```python\nimport numpy as np\n\nclass PSO_DE_Niching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.8, CR=0.9, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.niche_radius = niche_radius\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_velocity(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (self.w * self.velocities[i] +\n                              self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                              self.c2 * r2 * (self.global_best_position - self.population[i]))\n\n    def differential_evolution_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        return x1 + self.F * (x2 - x3)\n\n    def differential_evolution_crossover(self, mutated_vector, i):\n        trial_vector = self.population[i].copy()\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutated_vector[j]\n        return trial_vector\n\n    def niching_strategy(self, x, func):\n        # Penalize solutions that are too close to each other\n        penalty = 0\n        for other_x in self.population:\n            if np.linalg.norm(x - other_x) < self.niche_radius:\n                penalty += 0.1  # Adjust penalty as needed\n        return func(x) + penalty\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO velocity update\n                self.update_velocity(i)\n\n                # DE mutation\n                mutated_vector = self.differential_evolution_mutation(i)\n\n                # DE crossover\n                trial_vector = self.differential_evolution_crossover(mutated_vector, i)\n\n                # Bound Handling\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Niching and evaluation\n                f_trial = self.niching_strategy(trial_vector, func)\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break # Respect budget\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial_vector.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial_vector.copy()\n\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1872961480676113, 0.3038482233781721, 0.3471245526327019, 0.39549774560207984, 0.2734842016696428, 0.3394288042355076, 0.302269895340315, 0.30166657828488264, 0.27320743438707706, 0.26809614779359003, 0.40258281299328347, 0.9899876260170073, 0.37160870260237167, 0.2926700520692156, 0.727425536465738, 0.37395115633969556, 0.30472010228744106, 0.4270317158275049, 0.19192137328143488, 0.4920815753628536], "operator": "random_new", "theta_sampled": 0.15086497771075857, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "6f62b5ed-9526-459a-b348-4d5a48cc6af1", "fitness": 0.4388145713905766, "name": "AdaptiveHybridDECMO", "description": "Combines DE, archive, CMA-ES-like step size adaptation, and a self-adaptive crossover rate based on success history and distance to the best solution.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, cr_adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cr_adapt_rate = cr_adapt_rate\n        self.cr_history = []\n        self.cr_success_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                # Adaptive CR\n                self.cr_history.append(self.CR)\n                self.cr_success_history.append(1 if f_trial < self.fitness[i] else 0)\n\n                if len(self.cr_history) > 10 * self.dim:\n                    self.cr_history.pop(0)\n                    self.cr_success_history.pop(0)\n\n                if np.mean(self.cr_success_history) > 0.5: #adjust CR based on success\n                    self.CR = min(1.0, self.CR + self.cr_adapt_rate)\n                else:\n                    self.CR = max(0.1, self.CR - self.cr_adapt_rate)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveHybridDECMO scored 0.439 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2a6fd6d-7de4-4b23-8433-7b43980425ea"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines DE, archive, CMA-ES-like step size adaptation, and a self-adaptive crossover rate based on success history and distance to the best solution.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, sigma0=0.3, adaptation_rate=0.1, c_cov0 = 0.1, cr_adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.9  # Initial Crossover rate\n        self.archive = []\n        self.archive_fitness = []\n        self.sigma0 = sigma0\n        self.adaptation_rate = adaptation_rate\n        self.success_rate = 0.5\n        self.success_history = []\n        self.c_cov = c_cov0  # CMA-ES learning rate for covariance matrix\n        self.d_sigma = 1.0\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cr_adapt_rate = cr_adapt_rate\n        self.cr_history = []\n        self.cr_success_history = []\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n        self.m = self.x_opt.copy()  # Initialize mean with the best individual\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.sigma = self.sigma0 #Init sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE part)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Add archive member with probability\n                if np.random.rand() < 0.1 and len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Stochastic ranking and archive update (DE part)\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                else:\n                    p_i = np.random.rand()\n                    p_trial = np.random.rand()\n\n                    if p_trial < p_i:\n                        self.population[i] = x_trial.copy()\n                        self.fitness[i] = f_trial\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                            self.archive_fitness.append(self.fitness[i])\n                        else:\n                            max_archive_index = np.argmax(self.archive_fitness)\n                            if self.fitness[i] < self.archive_fitness[max_archive_index]:\n                                self.archive[max_archive_index] = self.population[i].copy()\n                                self.archive_fitness[max_archive_index] = self.fitness[i]\n                #Adapt step size\n                y = x_trial - self.m\n                self.ps = (1 - 0.1) * self.ps + np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n\n                hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - 0.1)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1))\n                \n                self.pc = (1 - 0.1) * self.pc + hsig * np.sqrt(0.1 * (2 - 0.1) * 1) * y / self.sigma\n                \n                self.C = (1-self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * (y[:,None] @ y[None,:])\n\n                self.sigma *= np.exp((0.1 / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n                self.m = x_trial.copy() # or x_trial?\n\n                # Adaptive Covariance Matrix Adaptation (CMA-ES part)\n                self.success_history.append(1 if f_trial < self.f_opt else 0)\n                if len(self.success_history) > 10 * self.dim:\n                    self.success_history.pop(0)\n                self.success_rate = np.mean(self.success_history)\n\n                if self.success_rate > 0.7:\n                    self.c_cov *= (1 + self.adaptation_rate)\n                elif self.success_rate < 0.3:\n                    self.c_cov *= (1 - self.adaptation_rate)\n                self.c_cov = np.clip(self.c_cov, 0.01, 1.0)\n\n                # Adaptive CR\n                self.cr_history.append(self.CR)\n                self.cr_success_history.append(1 if f_trial < self.fitness[i] else 0)\n\n                if len(self.cr_history) > 10 * self.dim:\n                    self.cr_history.pop(0)\n                    self.cr_success_history.pop(0)\n\n                if np.mean(self.cr_success_history) > 0.5: #adjust CR based on success\n                    self.CR = min(1.0, self.CR + self.cr_adapt_rate)\n                else:\n                    self.CR = max(0.1, self.CR - self.cr_adapt_rate)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1337483456275277, 0.23377439804208644, 0.41677055385686634, 0.558472403833791, 0.3265783442197976, 0.6034901940797313, 0.32486989539132916, 0.42678319495115713, 0.46650621683909044, 0.23084111429794973, 0.3553596072279983, 0.990213355604821, 0.26867682491833234, 0.35286662502764543, 0.7627361101591574, 0.6594060579384771, 0.3299439176098775, 0.6369331296766558, 0.2039535280085022, 0.4943676105007364], "operator": "mutation", "theta_sampled": 0.0021419546911079983, "reward": 0.0, "generation": 12}, "task_prompt": ""}
