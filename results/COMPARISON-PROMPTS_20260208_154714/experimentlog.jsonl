{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 4.68714330884082, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.11001371869196722, "pulls": 14}, "crossover": {"count": 2.513454928466129, "mean": 0.004486962373746042, "var": 1.908902157650892e-05, "std": 0.004369098485558424, "theta": 0.009186020466898651, "pulls": 15}, "random_new": {"count": 2.720850090580262, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.3065422171732377, "pulls": 17}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "ac79e3cd-91bb-4e55-8257-ef35d17b015c", "fitness": 0.6269818555820013, "name": "AdaptiveDEPlusPlus", "description": "Combines adaptive F and CR with success-history based adaptation, adaptive population sizing, and restarts for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEPlusPlus:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=4, F_initial=0.5, CR_initial=0.9, stagnation_threshold=1000, archive_size=100):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size_factor (int): Factor to determine initial population size (pop_size = pop_size_factor * dim).\n            F_initial (float): Initial differential weight.\n            CR_initial (float): Initial crossover probability.\n            stagnation_threshold (int): Number of iterations without improvement to trigger a restart.\n            archive_size (int): Size of archive for storing successful F and CR values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_factor * dim  # Population size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.success_rate_threshold = 0.2  # Threshold for adjusting population size\n        self.pop_size_reduction_factor = 0.8 # Reduction factor if success rate is too low\n        self.pop_size_increase_factor = 1.2 # Increase factor if success rate is high\n        self.min_pop_size = 4 * dim # Minimal population size\n        self.max_pop_size = 10 * dim # Maximal population size\n\n        self.archive_F = []  # Archive for storing successful F values\n        self.archive_CR = []  # Archive for storing successful CR values\n        self.archive_size = archive_size\n\n        self.F_mean = 0.5 # Initialize F_mean\n        self.F_std = 0.3 # Initialize F_std\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n            self.stagnation_counter = 0  # Reset stagnation counter\n        else:\n            self.stagnation_counter +=1\n\n        # Main optimization loop\n        while self.eval_count < self.budget:\n            \n            # Store fitness values for success rate calculation\n            old_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Adaptive F: Uses a dynamically adjusted normal distribution\n                if self.stagnation_counter == 0: # If improved: Reduce F_std and F_mean\n                    self.F_mean = max(0.2, self.F_mean * 0.95) # Reduce mean\n                    self.F_std = max(0.1, self.F_std * 0.95) # Reduce std\n\n                else: # Else: Increase F_std and maybe also F_mean\n                    self.F_mean = min(0.8, self.F_mean * 1.05) # Increase mean\n                    self.F_std = min(0.5, self.F_std * 1.05) # Increase std\n\n                self.F = np.random.normal(self.F_mean, self.F_std)  # Mean 0.5, standard deviation 0.3\n                self.F = np.clip(self.F, 0.1, 1.0) # ensure F stays within bounds [0.1, 1]\n\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n\n                # Ensure the mutated vector stays within bounds\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n\n                # Adaptive CR: Sample CR from archive of successful values\n                if self.archive_CR:\n                    CR_index = np.random.randint(len(self.archive_CR))\n                    current_CR = self.archive_CR[CR_index]\n                else:\n                    current_CR = self.CR # Use initial CR if archive is empty\n\n                for j in range(self.dim):\n                    if np.random.rand() < current_CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Store successful F and CR values in archive\n                    self.archive_F.append(self.F)\n                    self.archive_CR.append(current_CR)\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0) # Keep archive size constant\n                    if len(self.archive_CR) > self.archive_size:\n                        self.archive_CR.pop(0) # Keep archive size constant\n\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive population size adjustment based on success rate\n            successful_individuals = np.sum(fitness < old_fitness)\n            success_rate = successful_individuals / self.pop_size\n\n            if success_rate < self.success_rate_threshold:\n                self.pop_size = int(self.pop_size * self.pop_size_reduction_factor)\n                self.pop_size = max(self.pop_size, self.min_pop_size)  # Ensure minimum population size\n            elif success_rate > (1 - self.success_rate_threshold): # High success_rate\n                self.pop_size = int(self.pop_size * self.pop_size_increase_factor)\n                self.pop_size = min(self.pop_size, self.max_pop_size) # Ensure maximal population size\n            \n            # Regenerate population (only the changed part!)\n            if self.pop_size != population.shape[0]:\n                if self.pop_size > population.shape[0]: # Increase population\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - population.shape[0], self.dim))\n                    population = np.vstack((population, new_individuals))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.eval_count += len(new_fitness)\n                    fitness = np.concatenate((fitness, new_fitness))\n\n                else: # Reduce Population\n                    # Remove the worst individuals (high fitness value)\n                    worst_indices = np.argsort(fitness)[self.pop_size:] # Indices of worst individuals\n                    population = np.delete(population, worst_indices, axis=0)\n                    fitness = np.delete(fitness, worst_indices)\n            \n            # Restart mechanism if stagnating\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEPlusPlus scored 0.627 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0197df04-ea20-47c5-bee1-99bf5f5b7c20", "87c78c15-dbc5-43ef-b285-5a2015525591"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive F and CR with success-history based adaptation, adaptive population sizing, and restarts for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEPlusPlus:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=4, F_initial=0.5, CR_initial=0.9, stagnation_threshold=1000, archive_size=100):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size_factor (int): Factor to determine initial population size (pop_size = pop_size_factor * dim).\n            F_initial (float): Initial differential weight.\n            CR_initial (float): Initial crossover probability.\n            stagnation_threshold (int): Number of iterations without improvement to trigger a restart.\n            archive_size (int): Size of archive for storing successful F and CR values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_factor * dim  # Population size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.success_rate_threshold = 0.2  # Threshold for adjusting population size\n        self.pop_size_reduction_factor = 0.8 # Reduction factor if success rate is too low\n        self.pop_size_increase_factor = 1.2 # Increase factor if success rate is high\n        self.min_pop_size = 4 * dim # Minimal population size\n        self.max_pop_size = 10 * dim # Maximal population size\n\n        self.archive_F = []  # Archive for storing successful F values\n        self.archive_CR = []  # Archive for storing successful CR values\n        self.archive_size = archive_size\n\n        self.F_mean = 0.5 # Initialize F_mean\n        self.F_std = 0.3 # Initialize F_std\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n            self.stagnation_counter = 0  # Reset stagnation counter\n        else:\n            self.stagnation_counter +=1\n\n        # Main optimization loop\n        while self.eval_count < self.budget:\n            \n            # Store fitness values for success rate calculation\n            old_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Adaptive F: Uses a dynamically adjusted normal distribution\n                if self.stagnation_counter == 0: # If improved: Reduce F_std and F_mean\n                    self.F_mean = max(0.2, self.F_mean * 0.95) # Reduce mean\n                    self.F_std = max(0.1, self.F_std * 0.95) # Reduce std\n\n                else: # Else: Increase F_std and maybe also F_mean\n                    self.F_mean = min(0.8, self.F_mean * 1.05) # Increase mean\n                    self.F_std = min(0.5, self.F_std * 1.05) # Increase std\n\n                self.F = np.random.normal(self.F_mean, self.F_std)  # Mean 0.5, standard deviation 0.3\n                self.F = np.clip(self.F, 0.1, 1.0) # ensure F stays within bounds [0.1, 1]\n\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n\n                # Ensure the mutated vector stays within bounds\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n\n                # Adaptive CR: Sample CR from archive of successful values\n                if self.archive_CR:\n                    CR_index = np.random.randint(len(self.archive_CR))\n                    current_CR = self.archive_CR[CR_index]\n                else:\n                    current_CR = self.CR # Use initial CR if archive is empty\n\n                for j in range(self.dim):\n                    if np.random.rand() < current_CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Store successful F and CR values in archive\n                    self.archive_F.append(self.F)\n                    self.archive_CR.append(current_CR)\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0) # Keep archive size constant\n                    if len(self.archive_CR) > self.archive_size:\n                        self.archive_CR.pop(0) # Keep archive size constant\n\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive population size adjustment based on success rate\n            successful_individuals = np.sum(fitness < old_fitness)\n            success_rate = successful_individuals / self.pop_size\n\n            if success_rate < self.success_rate_threshold:\n                self.pop_size = int(self.pop_size * self.pop_size_reduction_factor)\n                self.pop_size = max(self.pop_size, self.min_pop_size)  # Ensure minimum population size\n            elif success_rate > (1 - self.success_rate_threshold): # High success_rate\n                self.pop_size = int(self.pop_size * self.pop_size_increase_factor)\n                self.pop_size = min(self.pop_size, self.max_pop_size) # Ensure maximal population size\n            \n            # Regenerate population (only the changed part!)\n            if self.pop_size != population.shape[0]:\n                if self.pop_size > population.shape[0]: # Increase population\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - population.shape[0], self.dim))\n                    population = np.vstack((population, new_individuals))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.eval_count += len(new_fitness)\n                    fitness = np.concatenate((fitness, new_fitness))\n\n                else: # Reduce Population\n                    # Remove the worst individuals (high fitness value)\n                    worst_indices = np.argsort(fitness)[self.pop_size:] # Indices of worst individuals\n                    population = np.delete(population, worst_indices, axis=0)\n                    fitness = np.delete(fitness, worst_indices)\n            \n            # Restart mechanism if stagnating\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23277036258767592, 0.6126088325673156, 0.5630807109851405, 0.8294060348203555, 0.6867554450984776, 0.7345487083688365, 0.42333049752747687, 0.5321080282421204, 0.6312565900608207, 0.595340869892606, 0.8474904783162919, 0.9873815945342467, 0.6000025869317342, 0.5499247673185581, 0.9139538422743939, 0.7259205984352535, 0.5199008091996937, 0.7898895795203329, 0.2627909958795137, 0.5011757790791791], "operator": "crossover", "theta_sampled": 0.003039785615766519, "reward": 0.017730161909644493, "generation": 5}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-0", "seed": 0}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 3.0574794695687624, "mean": 0.008192622071332643, "var": 5.262708452514248e-05, "std": 0.007254452737811618, "theta": 0.004603363463784281, "pulls": 9}, "crossover": {"count": 2.950310278879165, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.31538620144107715, "pulls": 16}, "random_new": {"count": 3.9136585794392857, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.30757895989575157, "pulls": 21}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "f7c32d4f-92bf-4ba7-b741-64ab0d8172a4", "fitness": 0.7300201065490594, "name": "AdaptiveHybridPSO_DE_v3", "description": "Implements an adaptive hybrid PSO-DE algorithm with dynamic parameter adjustments based on population diversity and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init = min(0.9, self.w_init * 1.05) # Ensure w_init does not exceed 0.9\n                self.cr_init = max(0.1, self.cr_init * 0.95)  # Ensure cr_init does not go below 0.1\n                self.f_init = min(0.9, self.f_init * 1.05)  # Ensure f_init does not exceed 0.9\n                self.stagnation_counter = 0 #reset stagnation counter\n                print(\"Stagnation detected, adapting parameters\")\n\n            self.previous_gbest_f = gbest_f\n\n            # Calculate population diversity\n            diversity = np.std(pop)\n            if diversity < self.diversity_threshold:\n                # Restart the population to increase exploration\n                print(\"Low diversity, restarting population\")\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size  # Update budget after restart\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE_v3 scored 0.730 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dd3b8fcf-b733-48a2-959c-0a9aa421da4a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements an adaptive hybrid PSO-DE algorithm with dynamic parameter adjustments based on population diversity and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init = min(0.9, self.w_init * 1.05) # Ensure w_init does not exceed 0.9\n                self.cr_init = max(0.1, self.cr_init * 0.95)  # Ensure cr_init does not go below 0.1\n                self.f_init = min(0.9, self.f_init * 1.05)  # Ensure f_init does not exceed 0.9\n                self.stagnation_counter = 0 #reset stagnation counter\n                print(\"Stagnation detected, adapting parameters\")\n\n            self.previous_gbest_f = gbest_f\n\n            # Calculate population diversity\n            diversity = np.std(pop)\n            if diversity < self.diversity_threshold:\n                # Restart the population to increase exploration\n                print(\"Low diversity, restarting population\")\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size  # Update budget after restart\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23085331642320728, 0.5927806555141326, 0.8464343792370237, 0.9303321280482861, 0.8817467524829654, 0.8954632000461651, 0.35885983466005955, 0.6429511107786456, 0.8827452498907019, 0.8238452686286073, 0.8811148439426826, 0.9982121205507668, 0.3129647795251814, 0.759440132824202, 0.9245485561140223, 0.8996422290640026, 0.5525258400680322, 0.9023911975040474, 0.7840041454556073, 0.4995463902228474], "operator": "mutation", "theta_sampled": 0.18151281957997545, "reward": 0.027833435664832984, "generation": 6}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-1", "seed": 1}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 5.827537740198358, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.13771895645673035, "pulls": 19}, "crossover": {"count": 1.148733724624329, "mean": 0.0072137050654049375, "var": 0.0007299560090055615, "std": 0.027017698070071802, "theta": -0.0069269557056053175, "pulls": 13}, "random_new": {"count": 2.9451768630645256, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.15235368106951794, "pulls": 14}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "162a8d63-dd69-484e-b20c-ca59a99035e3", "fitness": 0.7342799744009025, "name": "AdaptiveHybridPSO_DE", "description": "An adaptive hybrid PSO-DE algorithm with success-based parameter adaptation, archive utilization, and dynamic strategy selection based on performance feedback.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.734 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d", "8922a96f-d9ad-4a5a-82b4-567075f7c6e7"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with success-based parameter adaptation, archive utilization, and dynamic strategy selection based on performance feedback.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.37717489583923547, 0.7485584900826626, 0.7794829481157071, 0.8804095412024632, 0.8215762396500277, 0.8453933883368048, 0.5914048269786178, 0.7577094841970708, 0.8207214412116675, 0.8020313547327237, 0.8964030379046536, 0.9993926563741286, 0.44780283860518744, 0.7747087663335395, 0.9603433732144111, 0.8440558130931847, 0.694529420749078, 0.8984401085311924, 0.2103651453487846, 0.5350957175169124], "operator": "crossover", "theta_sampled": 0.02322416725178006, "reward": 0.17745804387555764, "generation": 2}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-2", "seed": 2}
{"method_name": "EoH", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "EoH", "budget": 50, "kwargs": {"pop_size": 4}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "c180714a-aa84-47fa-ae34-0a540815d859", "fitness": 0.26569, "name": "BlendedDifferenceEvolution", "description": "Evolves a population by blending the best individual with randomly selected individuals, adapting the blending strength based on success.", "code": "import numpy as np\n\nclass BlendedDifferenceEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, blend_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.blend_rate = blend_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        f_opt = np.min(fitness)\n        x_opt = population[np.argmin(fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Find best individual\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                # Select a random individual to blend with\n                random_idx = np.random.randint(0, self.pop_size)\n                while random_idx == i:\n                    random_idx = np.random.randint(0, self.pop_size)\n                random_individual = population[random_idx]\n\n                # Blend the best individual with the random individual\n                blended = self.blend_rate * best_individual + (1 - self.blend_rate) * random_individual\n\n                # Add a difference vector from another random individual\n                diff_idx1 = np.random.randint(0, self.pop_size)\n                while diff_idx1 == i or diff_idx1 == random_idx:\n                    diff_idx1 = np.random.randint(0, self.pop_size)\n                diff_idx2 = np.random.randint(0, self.pop_size)\n                while diff_idx2 == i or diff_idx2 == random_idx or diff_idx2 == diff_idx1:\n                    diff_idx2 = np.random.randint(0, self.pop_size)\n                \n                blended += 0.1 * (population[diff_idx1] - population[diff_idx2])\n                \n                blended = np.clip(blended, self.lb, self.ub)\n\n                # Evaluate the blended individual\n                f = func(blended)\n                evals += 1\n\n                # Update population if the blended individual is better\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = blended\n                    if f < f_opt:\n                        f_opt = f\n                        x_opt = blended\n            self.blend_rate = np.clip(self.blend_rate + np.random.normal(0, 0.01), 0.1, 0.9)\n\n        self.f_opt = f_opt\n        self.x_opt = x_opt\n        return f_opt, x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}, "log_dir": "run-EoH-MA_BBOB-0", "seed": 0}
