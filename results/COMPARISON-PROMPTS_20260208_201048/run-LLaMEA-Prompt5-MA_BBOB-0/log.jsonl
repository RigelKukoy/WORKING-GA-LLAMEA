{"id": "e6ecb842-1906-45d1-a2d1-8d6095425508", "fitness": "-inf", "name": "OrthogonalCMAES", "description": "Population-based algorithm with covariance matrix adaptation and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, dsigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.dsigma = dsigma\n\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((4 + self.mueff / self.dim) / (self.dim + 4)) * (1 - self.cs)\n\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = 0.5  # Initial step size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        evals = 0\n        while evals < self.budget:\n            # Generate population\n            z = np.random.randn(self.dim, self.popsize)\n            try:\n                C_sqrt = np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite matrix (add small identity matrix)\n                self.C += 1e-6 * np.eye(self.dim)\n                C_sqrt = np.linalg.cholesky(self.C)\n            x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(f)\n            f = f[idx]\n            x = x[:, idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            y = xmean - self.mean\n            self.mean = xmean\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (self.cs * (2 - self.cs) * self.mueff)**0.5 * (np.linalg.inv(C_sqrt) @ y) / self.sigma\n            hsig = (np.sum(self.ps**2) / self.dim) < (2 + 4 / (self.dim + 1))\n            self.pc = (1 - self.cc) * self.pc + hsig * (self.cc * (2 - self.cc) * self.mueff)**0.5 * y / self.sigma\n\n            # Update covariance matrix\n            delta = (1 - hsig) * self.cc * (2 - self.cc)**0.5 * (self.pc / (self.sigma))\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])  + self.c_cov * np.sum(self.weights * (y[:, np.newaxis] @ y[np.newaxis, :]) / self.sigma**2, axis=0)\n\n            # Orthogonal Learning: Perturb C using a random orthogonal matrix\n            if np.random.rand() < 0.1: # Apply orthogonal learning with probability 0.1\n                Q = np.random.randn(self.dim, self.dim)\n                Q, _ = np.linalg.qr(Q)\n                self.C = Q @ self.C @ Q.T  # Apply orthogonal transformation\n\n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim) # add a small diagonal matrix\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.dsigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 10)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "db9dbbcf-307a-49b8-806e-130dc25e1a0f", "fitness": 0.40138189417483616, "name": "AdaptivePSO", "description": "A self-adjusting step-size Particle Swarm Optimization algorithm with velocity clamping and inertia weight adaptation based on population diversity.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, c1=2.05, c2=2.05, w_max=0.9, w_min=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.velocity_max = 1.0 # Clamping velocity to prevent explosion\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_max, self.velocity_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n\n        self.pbest_positions = self.particles.copy()\n        self.pbest_fitness = self.fitness.copy()\n\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.particles[self.gbest_index].copy()\n        self.f_opt = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size  # Track function evaluations\n\n        while eval_count < self.budget:\n            # Calculate inertia weight based on population diversity\n            distances = np.linalg.norm(self.particles - self.gbest_position, axis=1)\n            diversity = np.mean(distances)\n\n            #Adaptive inertia weight, the greater the diversity, the smaller the inertia\n            w = self.w_max - (self.w_max - self.w_min) * (diversity / (ub[0] - lb[0]))\n            w = np.clip(w, self.w_min, self.w_max) #clip to range\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * np.random.rand(self.dim) * (self.pbest_positions[i] - self.particles[i]) + \\\n                                     self.c2 * np.random.rand(self.dim) * (self.gbest_position - self.particles[i])\n                \n                # Velocity Clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_max, self.velocity_max)\n                \n                self.particles[i] = self.particles[i] + self.velocities[i]\n\n                # Boundary Handling (Bounce back)\n                oob = (self.particles[i] < lb) | (self.particles[i] > ub)\n                self.velocities[i][oob] *= -0.5  # Dampen velocity after bounce\n                self.particles[i][oob] = np.clip(self.particles[i][oob], lb[oob], ub[oob])\n                                \n                # Evaluate new position\n                f = func(self.particles[i])\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    if f < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f\n                        self.pbest_positions[i] = self.particles[i].copy()\n\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.gbest_position = self.particles[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.gbest_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.401 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19665013623050986, 0.3422153596603661, 0.42672568027073854, 0.1985425594492235, 0.328405218134309, 0.3921112045814934, 0.3158940655090353, 0.33279151768402404, 0.3317936688680524, 0.2188072424482601, 0.47480788859410117, 0.9987125674158427, 0.26405377627950033, 0.3196632249171367, 0.7823755469327301, 0.46952966884645286, 0.34039887098735555, 0.5140649662610287, 0.2746147616548217, 0.5054799587717405]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "017d2a2c-26bd-4b3e-8e8d-49e97b2d2ce9", "fitness": 0.5790039475863862, "name": "AdaptiveVelocityPSO", "description": "A population-based algorithm employing a velocity-based update rule, inspired by Particle Swarm Optimization, enhanced with a self-adaptive learning rate and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, restart_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.restart_threshold = restart_threshold\n        self.learning_rate = 0.1  # Initial learning rate for self-adaptation\n        self.lr_decay = 0.995      # Decay factor for learning rate\n        self.lr_increase = 1.005  # Increase factor for learning rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/10, abs(ub-lb)/10, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Stagnation counter and restart flag\n        stagnation_counter = 0\n        restart = False\n        \n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n\n            # Limit velocities to prevent divergence\n            v_max = abs(ub - lb) / 2\n            velocities = np.clip(velocities, -v_max, v_max)\n            \n            new_population = population + velocities\n            \n            # Handle boundary constraints\n            new_population = np.clip(new_population, lb, ub)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update personal best positions and fitness\n            improved_indices = new_fitness < personal_best_fitness\n            personal_best_positions[improved_indices] = new_population[improved_indices].copy()\n            personal_best_fitness[improved_indices] = new_fitness[improved_indices].copy()\n            \n            # Update global best position and fitness\n            current_global_best_index = np.argmin(new_fitness)\n            if new_fitness[current_global_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_global_best_index]\n                global_best_position = new_population[current_global_best_index].copy()\n                stagnation_counter = 0 # Reset stagnation counter\n            else:\n                stagnation_counter +=1 # Increment stagnation counter\n\n            #Update population\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n\n            # Restart mechanism\n            if stagnation_counter > self.restart_threshold:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                velocities = np.random.uniform(-abs(ub-lb)/10, abs(ub-lb)/10, size=(self.pop_size, self.dim)) #reinitialize velocities\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                improved_indices = fitness < personal_best_fitness\n                personal_best_positions[improved_indices] = population[improved_indices].copy()\n                personal_best_fitness[improved_indices] = fitness[improved_indices].copy()\n\n                current_global_best_index = np.argmin(fitness)\n                if fitness[current_global_best_index] < global_best_fitness:\n                    global_best_fitness = fitness[current_global_best_index]\n                    global_best_position = population[current_global_best_index].copy()\n                \n                stagnation_counter = 0 # Reset stagnation counter\n\n            # Adaptive Learning Rate (optional, can be added back if beneficial)\n            # if global_best_fitness_history and abs(global_best_fitness - global_best_fitness_history[-1]) < 1e-6:\n            #     self.learning_rate *= self.lr_increase\n            # else:\n            #     self.learning_rate *= self.lr_decay\n            # self.learning_rate = np.clip(self.learning_rate, 0.01, 0.5) #limit to a reasonable range\n            # global_best_fitness_history.append(global_best_fitness)\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveVelocityPSO scored 0.579 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1797846658197766, 0.218812854184808, 0.7114360998419007, 0.888872331823777, 0.3673549330731326, 0.8017856882665664, 0.327967913465388, 0.6241932563324337, 0.7568012975426722, 0.23237737687705373, 0.8768251718825419, 0.9942344232715352, 0.22363405838701278, 0.2590002950089283, 0.6687380322062192, 0.7952859647777564, 0.6303371441647878, 0.8534108080033944, 0.6580599804629135, 0.511166656335126]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "018e4a74-c9a4-4df1-86fc-dc9907ecc7cd", "fitness": 0.0, "name": "AdaptiveVelocitySearch", "description": "A population-based algorithm employing a velocity-based search with adaptive step size control and a stochastic local search component.", "code": "import numpy as np\n\nclass AdaptiveVelocitySearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb) # smaller initial velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size  # decrement budget\n\n        # Initialize personal best and global best\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Adaptive step size\n        step_size = (func.bounds.ub - func.bounds.lb) / 10.0\n        step_size_decay = 0.995 # Decay parameter\n\n        while self.budget > 0:\n            # Update velocities and positions\n            inertia = self.inertia_weight * velocities\n            cognitive = self.cognitive_coeff * np.random.rand(self.population_size, self.dim) * (personal_best_positions - population)\n            social = self.social_coeff * np.random.rand(self.population_size, self.dim) * (global_best_position - population)\n\n            velocities = inertia + cognitive + social\n            population = population + velocities * step_size\n\n            # Clip positions to bounds\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            new_fitness = np.array([func(x) for x in population])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n            fitness = np.copy(new_fitness) #update fitness of the population after function calls\n\n            # Update personal best\n            improved = new_fitness < personal_best_fitness\n            personal_best_positions[improved] = population[improved].copy()\n            personal_best_fitness[improved] = new_fitness[improved].copy()\n\n            # Update global best\n            global_best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[global_best_index] < global_best_fitness:\n                global_best_position = personal_best_positions[global_best_index].copy()\n                global_best_fitness = personal_best_fitness[global_best_index]\n\n            # Stochastic Local Search\n            for i in range(self.population_size):\n                if np.random.rand() < self.local_search_prob:\n                    # Perform a small random perturbation around the personal best\n                    perturbation = np.random.normal(0, step_size/5.0, size=self.dim)\n                    new_position = personal_best_positions[i] + perturbation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_val = func(new_position)\n                    self.budget -= 1\n                    if new_fitness_val < personal_best_fitness[i]:\n                         personal_best_positions[i] = new_position\n                         personal_best_fitness[i] = new_fitness_val\n                         if new_fitness_val < global_best_fitness:\n                             global_best_fitness = new_fitness_val\n                             global_best_position = new_position\n\n            # Step size adaptation\n            step_size *= step_size_decay\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveVelocitySearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "1c96d6c1-44df-4842-a3ff-3273a0761225", "fitness": 0.0, "name": "GradientBasedSearch", "description": "A gradient-based optimization algorithm enhanced with a random search component, adaptive step size, and momentum to efficiently explore the search space.", "code": "import numpy as np\n\nclass GradientBasedSearch:\n    def __init__(self, budget=10000, dim=10, learning_rate=0.1, momentum=0.9, random_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.learning_rate = learning_rate\n        self.momentum = momentum\n        self.random_search_prob = random_search_prob\n        self.x = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.velocity = np.zeros(dim)  # Initialize velocity for momentum\n\n    def __call__(self, func):\n        # Initialize position randomly\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.x = np.random.uniform(lb, ub, size=self.dim)\n        evals = 0\n\n        while evals < self.budget:\n            # Random search with small probability\n            if np.random.rand() < self.random_search_prob:\n                x_new = np.random.uniform(lb, ub, size=self.dim)\n                f_new = func(x_new)\n                evals += 1\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                self.x = x_new\n                self.velocity = np.zeros(self.dim) # Reset velocity\n\n            else:\n                # Calculate numerical gradient\n                gradient = self.numerical_gradient(func, self.x)\n                evals += self.dim # Each gradient evaluation calls the function dim times.\n\n                # Update velocity with momentum\n                self.velocity = self.momentum * self.velocity - self.learning_rate * gradient\n\n                # Update position\n                x_new = self.x + self.velocity\n\n                # Clip to bounds\n                x_new = np.clip(x_new, lb, ub)\n\n                # Evaluate new position\n                f_new = func(x_new)\n                evals += 1\n\n                # Update optimal solution\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n\n                # Update current position\n                self.x = x_new\n\n            if evals > self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def numerical_gradient(self, func, x, h=1e-5):\n        grad = np.zeros_like(x)\n        for i in range(len(x)):\n            x_plus_h = x.copy()\n            x_plus_h[i] += h\n            f_plus_h = func(x_plus_h)\n\n            x_minus_h = x.copy()\n            x_minus_h[i] -= h\n            f_minus_h = func(x_minus_h)\n\n            grad[i] = (f_plus_h - f_minus_h) / (2 * h)\n        return grad", "configspace": "", "generation": 1, "feedback": "The algorithm GradientBasedSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e6ecb842-1906-45d1-a2d1-8d6095425508"], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "78fe2ea4-d562-4e7e-ad2b-3c45d9887580", "fitness": 0.0, "name": "AdaptiveVelocitySearch", "description": "An improved Adaptive Velocity Search algorithm with adaptive parameters, orthogonal initialization and restart mechanism to promote exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveVelocitySearch:\n    def __init__(self, budget=10000, dim=10, population_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n\n    def __call__(self, func):\n        # Orthogonal Initialization\n        population = self.orthogonal_initialization(func)\n        velocities = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        inertia_weight = 0.7\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n        step_size = (func.bounds.ub - func.bounds.lb) / 10.0\n        step_size_decay = 0.995\n        local_search_prob = 0.1\n\n        restart_trigger = False\n        no_improvement_counter = 0\n        max_no_improvement = 100 # increased to allow more exploration\n\n        while self.budget > 0:\n            # Adaptive parameter control\n            if restart_trigger:\n                inertia_weight = 0.9\n                cognitive_coeff = 0.5\n                social_coeff = 0.5\n                step_size = (func.bounds.ub - func.bounds.lb) / 5.0\n                restart_trigger = False\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                velocities = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.population_size\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                global_best_index = np.argmin(fitness)\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index]\n                no_improvement_counter = 0\n\n\n            inertia = inertia_weight * velocities\n            cognitive = cognitive_coeff * np.random.rand(self.population_size, self.dim) * (personal_best_positions - population)\n            social = social_coeff * np.random.rand(self.population_size, self.dim) * (global_best_position - population)\n\n            velocities = inertia + cognitive + social\n            population = population + velocities * step_size\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            new_fitness = np.array([func(x) for x in population])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n            fitness = np.copy(new_fitness)\n\n            improved = new_fitness < personal_best_fitness\n            personal_best_positions[improved] = population[improved].copy()\n            personal_best_fitness[improved] = new_fitness[improved].copy()\n\n            global_best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[global_best_index] < global_best_fitness:\n                global_best_position = personal_best_positions[global_best_index].copy()\n                global_best_fitness = personal_best_fitness[global_best_index]\n                no_improvement_counter = 0 # Reset counter if improvement found\n            else:\n                no_improvement_counter += 1\n\n            # Stochastic Local Search - Reduced intensity for faster execution\n            for i in range(self.population_size):\n                if np.random.rand() < local_search_prob / 2.0: # Reduced probability\n                    perturbation = np.random.normal(0, step_size/10.0, size=self.dim) # Reduced step\n                    new_position = personal_best_positions[i] + perturbation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness_val = func(new_position)\n                    self.budget -= 1\n                    if new_fitness_val < personal_best_fitness[i]:\n                         personal_best_positions[i] = new_position\n                         personal_best_fitness[i] = new_fitness_val\n                         if new_fitness_val < global_best_fitness:\n                             global_best_fitness = new_fitness_val\n                             global_best_position = new_position\n                             no_improvement_counter = 0\n\n            step_size *= step_size_decay\n\n            # Restart mechanism\n            if no_improvement_counter > max_no_improvement:\n                restart_trigger = True\n\n        return global_best_fitness, global_best_position\n\n    def orthogonal_initialization(self, func):\n        # Latin Hypercube Sampling for initial population\n        population = np.zeros((self.population_size, self.dim))\n        for i in range(self.dim):\n            population[:, i] = np.random.permutation(self.population_size)\n        population = (population + np.random.rand(self.population_size, self.dim)) / self.population_size\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        return population", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocitySearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["018e4a74-c9a4-4df1-86fc-dc9907ecc7cd"], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "5b55dc0b-9298-4cb4-affc-da6d96769c50", "fitness": 0.3846879440906247, "name": "DynamicSubswarmPSO", "description": "An enhanced Particle Swarm Optimization with dynamic sub-swarms and adaptive mutation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicSubswarmPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, num_subswarms=4, c1=2.05, c2=2.05, w_max=0.9, w_min=0.4, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_subswarms = num_subswarms\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.mutation_rate = mutation_rate\n        self.velocity_max = 1.0\n        self.subswarm_size = pop_size // num_subswarms # Define subswarm size\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_max, self.velocity_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n\n        self.pbest_positions = self.particles.copy()\n        self.pbest_fitness = self.fitness.copy()\n\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.particles[self.gbest_index].copy()\n        self.f_opt = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n\n        # Initialize subswarms\n        self.subswarm_indices = np.array_split(np.random.permutation(self.pop_size), self.num_subswarms) #split and shuffle\n\n        while eval_count < self.budget:\n            # Dynamic Subswarm Adaptation: Periodically re-assign particles to subswarms\n            if eval_count % (self.budget // 10) == 0: # Re-assign every 10% of the budget\n                self.subswarm_indices = np.array_split(np.random.permutation(self.pop_size), self.num_subswarms)\n\n\n            for k in range(self.num_subswarms): #Iterate through subswarms\n\n                subswarm_particles = self.particles[self.subswarm_indices[k]]\n                subswarm_velocities = self.velocities[self.subswarm_indices[k]]\n                subswarm_pbest_positions = self.pbest_positions[self.subswarm_indices[k]]\n                subswarm_pbest_fitness = self.pbest_fitness[self.subswarm_indices[k]]\n                subswarm_fitness = self.fitness[self.subswarm_indices[k]]\n\n                local_gbest_index = np.argmin(subswarm_fitness)\n                local_gbest_position = subswarm_particles[local_gbest_index].copy()\n\n                # Calculate inertia weight based on subswarm diversity\n                distances = np.linalg.norm(subswarm_particles - local_gbest_position, axis=1)\n                diversity = np.mean(distances)\n                w = self.w_max - (self.w_max - self.w_min) * (diversity / (ub[0] - lb[0]))\n                w = np.clip(w, self.w_min, self.w_max)\n\n                # Update velocities and positions within the subswarm\n                for i in range(len(subswarm_particles)):\n                    subswarm_velocities[i] = w * subswarm_velocities[i] + \\\n                                         self.c1 * np.random.rand(self.dim) * (subswarm_pbest_positions[i] - subswarm_particles[i]) + \\\n                                         self.c2 * np.random.rand(self.dim) * (local_gbest_position - subswarm_particles[i])\n\n                    # Velocity Clamping\n                    subswarm_velocities[i] = np.clip(subswarm_velocities[i], -self.velocity_max, self.velocity_max)\n\n                    subswarm_particles[i] = subswarm_particles[i] + subswarm_velocities[i]\n\n                    # Mutation: Apply mutation with a certain probability\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.1 * (ub[0] - lb[0]), 0.1 * (ub[0] - lb[0]), size=self.dim)\n                        subswarm_particles[i] += mutation\n                                  \n                    # Boundary Handling (Bounce back)\n                    oob = (subswarm_particles[i] < lb) | (subswarm_particles[i] > ub)\n                    subswarm_velocities[i][oob] *= -0.5  # Dampen velocity after bounce\n                    subswarm_particles[i][oob] = np.clip(subswarm_particles[i][oob], lb[oob], ub[oob])\n\n                    # Evaluate new position\n                    f = func(subswarm_particles[i])\n                    eval_count += 1\n\n                    if f < subswarm_fitness[i]:\n                        subswarm_fitness[i] = f\n                        if f < subswarm_pbest_fitness[i]:\n                            subswarm_pbest_fitness[i] = f\n                            subswarm_pbest_positions[i] = subswarm_particles[i].copy()\n\n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.gbest_position = subswarm_particles[i].copy()\n\n                    if eval_count >= self.budget:\n                        break\n\n                #Update main particle array with the updated subswarm\n                self.particles[self.subswarm_indices[k]] = subswarm_particles\n                self.velocities[self.subswarm_indices[k]] = subswarm_velocities\n                self.pbest_positions[self.subswarm_indices[k]] = subswarm_pbest_positions\n                self.pbest_fitness[self.subswarm_indices[k]] = subswarm_pbest_fitness\n                self.fitness[self.subswarm_indices[k]] = subswarm_fitness\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.gbest_position", "configspace": "", "generation": 1, "feedback": "The algorithm DynamicSubswarmPSO scored 0.385 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db9dbbcf-307a-49b8-806e-130dc25e1a0f"], "operator": null, "metadata": {"aucs": [0.1539458650685921, 0.34036795042968115, 0.3691636278857727, 0.4454791786635163, 0.31400186759628845, 0.3747099446432296, 0.2866078453825467, 0.3193817654821186, 0.3139028776615823, 0.18992339253233603, 0.4112301392502583, 0.9923372735402394, 0.2544825541510377, 0.30895892871847386, 0.76712357687218, 0.3657156980615094, 0.31297509276356505, 0.4376979989141724, 0.22716961527762902, 0.5085836889177664]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "3e68c832-3d96-47f4-9316-6467b57b9ba5", "fitness": "-inf", "name": "OrthogonalCMAES", "description": "Orthogonal CMA-ES with Coordinate-wise Step-size Adaptation and Restart: Combines covariance matrix adaptation with orthogonal learning and coordinate-wise step-size control, restarting when stagnation is detected to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, dsigma=0.5, ccov_mu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.dsigma = dsigma\n        self.ccov_mu = ccov_mu\n\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * ((4 + self.mueff / self.dim) / (self.dim + 4)) * (1 - self.cs)\n        self.c_cov_mu = self.ccov_mu / self.mueff\n\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = False\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = np.ones(self.dim) * 0.5 # Coordinate-wise step-size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.evals = 0\n        self.best_f_so_far = np.inf\n\n        while self.evals < self.budget:\n            # Generate population\n            z = np.random.randn(self.dim, self.popsize)\n            try:\n                C_sqrt = np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite matrix (add small identity matrix)\n                self.C += 1e-6 * np.eye(self.dim)\n                C_sqrt = np.linalg.cholesky(self.C)\n\n            x = self.mean[:, np.newaxis] + self.sigma[:, np.newaxis] * C_sqrt @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(f)\n            f = f[idx]\n            x = x[:, idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n            \n            #Stagnation check\n            if self.stagnation_counter > self.max_stagnation:\n                self.restart_trigger = True\n                self.stagnation_counter = 0\n\n\n            # Update mean\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            y = xmean - self.mean\n            self.mean = xmean\n\n            # Update evolution paths\n            inv_sqrt_C = np.linalg.inv(C_sqrt)\n            self.ps = (1 - self.cs) * self.ps + (self.cs * (2 - self.cs) * self.mueff)**0.5 * (inv_sqrt_C @ y) / self.sigma\n            hsig = (np.sum(self.ps**2) / self.dim) < (2 + 4 / (self.dim + 1))\n            self.pc = (1 - self.cc) * self.pc + hsig * (self.cc * (2 - self.cc) * self.mueff)**0.5 * y / self.sigma\n\n            # Update covariance matrix\n            delta = (1 - hsig) * self.cc * (2 - self.cc)**0.5 * (self.pc / (self.sigma))\n            \n            \n            artmp = (1/self.sigma)*y\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + self.c_cov * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.c_cov_mu * np.sum(self.weights * (artmp[:, np.newaxis] @ artmp[np.newaxis, :]), axis=0)\n\n            # Orthogonal Learning: Perturb C using a random orthogonal matrix\n            if np.random.rand() < 0.1: # Apply orthogonal learning with probability 0.1\n                Q = np.random.randn(self.dim, self.dim)\n                Q, _ = np.linalg.qr(Q)\n                self.C = Q @ self.C @ Q.T  # Apply orthogonal transformation\n\n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim) # add a small diagonal matrix\n            \n            #Update coordinate-wise step size\n            self.sigma *= np.exp((self.cs / self.dsigma) * (np.abs(self.ps) / self.chiN - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 10)\n            \n            #Restart mechanism\n            if self.restart_trigger:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = np.ones(self.dim) * 0.5  # Reset step size\n                self.C = np.eye(self.dim)  # Reset covariance matrix\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.restart_trigger = False\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) \nOn line: self.C = np.eye(self.dim)  # Reset covariance matrix", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) \nOn line: self.C = np.eye(self.dim)  # Reset covariance matrix", "parent_ids": ["e6ecb842-1906-45d1-a2d1-8d6095425508"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "04461b8a-d37e-45c7-998b-50eeef93c7d1", "fitness": 0.5815854819977042, "name": "TopologyAwarePSO", "description": "An enhanced PSO variant with adaptive exploration-exploitation balance achieved through dynamic inertia weight adjustment based on population diversity and a topology-based local search for finer refinement.", "code": "import numpy as np\n\nclass TopologyAwarePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, topology_size=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.topology_size = topology_size  # Size of the neighborhood for topology\n        self.diversity_threshold = diversity_threshold\n        self.learning_rate = 0.1\n        self.lr_decay = 0.995\n        self.lr_increase = 1.005\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb) / 10, abs(ub - lb) / 10, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Calculate initial diversity\n        initial_diversity = self.calculate_diversity(population)\n        diversity = initial_diversity\n\n        while self.budget > 0:\n            # Adaptive Inertia Weight\n            # Adjust inertia weight based on population diversity\n            if diversity > self.diversity_threshold:\n                inertia_weight = self.inertia_weight  # Exploration\n            else:\n                inertia_weight = 0.4  # Exploitation\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            # Topology-aware social learning\n            social_component = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Find neighborhood\n                distances = np.sum((population - population[i])**2, axis=1)\n                neighborhood_indices = np.argsort(distances)[:self.topology_size]\n                \n                # Find best neighbor\n                best_neighbor_index = neighborhood_indices[np.argmin(fitness[neighborhood_indices])]\n                social_component[i] = population[best_neighbor_index] - population[i]\n\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * social_component)\n\n            # Limit velocities to prevent divergence\n            v_max = abs(ub - lb) / 2\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            new_population = population + velocities\n\n            # Handle boundary constraints\n            new_population = np.clip(new_population, lb, ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update personal best positions and fitness\n            improved_indices = new_fitness < personal_best_fitness\n            personal_best_positions[improved_indices] = new_population[improved_indices].copy()\n            personal_best_fitness[improved_indices] = new_fitness[improved_indices].copy()\n\n            # Update global best position and fitness\n            current_global_best_index = np.argmin(new_fitness)\n            if new_fitness[current_global_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_global_best_index]\n                global_best_position = new_population[current_global_best_index].copy()\n\n            #Update population\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n\n            # Calculate diversity\n            diversity = self.calculate_diversity(population)\n\n        return global_best_fitness, global_best_position\n\n    def calculate_diversity(self, population):\n        # Calculate average pairwise distance\n        distances = np.sum((population[:, None, :] - population[None, :, :])**2, axis=2)**0.5\n        diversity = np.mean(distances)\n        return diversity", "configspace": "", "generation": 1, "feedback": "The algorithm TopologyAwarePSO scored 0.582 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["017d2a2c-26bd-4b3e-8e8d-49e97b2d2ce9"], "operator": null, "metadata": {"aucs": [0.209934130587336, 0.3076007874005777, 0.6200259836749167, 0.7872375510165419, 0.6892474965365485, 0.7544402239135466, 0.4250527564904599, 0.5536250931152418, 0.7360466932270644, 0.4403440990184032, 0.8203879296884469, 0.9925662234573711, 0.29082339035719873, 0.5655168876549277, 0.7535458934268618, 0.5947579753151229, 0.4826231977899481, 0.7550651338053296, 0.340873573717699, 0.5119946197605407]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "ebc24567-e430-4dbf-807e-85da88d102ca", "fitness": 0.0, "name": "AdaptiveVelocitySearch", "description": "A simplified adaptive velocity search algorithm with dynamic inertia and focused local search around the global best.", "code": "import numpy as np\n\nclass AdaptiveVelocitySearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia_weight_start=0.9, inertia_weight_end=0.2, cognitive_coeff=2.0, social_coeff=2.0, local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim)) # smaller initial velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Step size (removed, using velocity directly)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Dynamic inertia weight\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * generation / (self.budget / self.population_size + generation)  # Linearly decreasing\n\n            # Update velocities and positions\n            inertia = inertia_weight * velocities\n            cognitive = self.cognitive_coeff * np.random.rand(self.population_size, self.dim) * (global_best_position - population) # move towards global best\n            social = self.social_coeff * np.random.rand(self.population_size, self.dim) * (population - np.mean(population, axis=0)) # move away from the crowd\n\n            velocities = inertia + cognitive + social\n            population = population + velocities\n\n            # Clip positions to bounds\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            new_fitness = np.array([func(x) for x in population])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n            fitness = np.copy(new_fitness) #update fitness of the population after function calls\n\n\n            # Update global best\n            global_best_index = np.argmin(fitness)\n            if fitness[global_best_index] < global_best_fitness:\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index]\n\n            # Stochastic Local Search - ONLY around global best, less frequent\n            if np.random.rand() < self.local_search_prob:\n                # Perform a small random perturbation around the global best\n                perturbation = np.random.normal(0, 0.05 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                new_position = global_best_position + perturbation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness_val = func(new_position)\n                self.budget -= 1\n                if new_fitness_val < global_best_fitness:\n                    global_best_position = new_position\n                    global_best_fitness = new_fitness_val\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocitySearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["018e4a74-c9a4-4df1-86fc-dc9907ecc7cd"], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "99b2b86f-0e47-4463-b997-57a3c83fbd66", "fitness": 0.0, "name": "AdaptiveVelocityPSO", "description": "Adaptive Particle Swarm Optimization with dynamic inertia and velocity clamping based on fitness variance to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight_initial=0.9, inertia_weight_final=0.4,\n                 cognitive_coeff=2.0, social_coeff=2.0, velocity_clamp_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight_initial = inertia_weight_initial\n        self.inertia_weight_final = inertia_weight_final\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb) * self.velocity_clamp_factor, abs(ub - lb) * self.velocity_clamp_factor,\n                                      size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive Inertia Weight (linearly decreasing)\n            inertia_weight = self.inertia_weight_initial - (self.inertia_weight_initial - self.inertia_weight_final) * (generation / (self.budget / self.pop_size))\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n\n            # Velocity Clamping based on fitness variance\n            fitness_variance = np.var(fitness)\n            v_max = abs(ub - lb) * self.velocity_clamp_factor * (1 + fitness_variance)  # Higher variance allows larger velocities\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            new_population = population + velocities\n\n            # Handle boundary constraints\n            new_population = np.clip(new_population, lb, ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            remaining_budget = min(self.budget, self.pop_size)  # Ensure we don't exceed the budget\n            new_fitness[:remaining_budget] = [func(x) for x in new_population[:remaining_budget]]\n            self.budget -= remaining_budget\n\n            # Update personal best positions and fitness\n            improved_indices = new_fitness < personal_best_fitness\n            personal_best_positions[improved_indices] = new_population[improved_indices].copy()\n            personal_best_fitness[improved_indices] = new_fitness[improved_indices].copy()\n\n            # Update global best position and fitness\n            current_global_best_index = np.argmin(new_fitness)\n            if new_fitness[current_global_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_global_best_index]\n                global_best_position = new_population[current_global_best_index].copy()\n\n            #Update population\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocityPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["017d2a2c-26bd-4b3e-8e8d-49e97b2d2ce9"], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "c182cfd3-7ca7-43fe-9200-9f51e214e15c", "fitness": 0.100361709061022, "name": "AdaptiveGaussianCMA", "description": "An Adaptive Population-Based Search with Gaussian Mutation and Covariance Matrix Adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveGaussianCMA:\n    def __init__(self, budget=10000, dim=10, population_size=20, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.initial_step_size = initial_step_size\n        self.mean = None  # Initialize in __call__\n        self.covariance = None  # Initialize in __call__\n        self.step_size = None # Initialize in __call__\n\n    def __call__(self, func):\n        # Initialization\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.covariance = np.eye(self.dim)  # Identity matrix\n        self.step_size = self.initial_step_size\n\n        best_fitness = float('inf')\n        best_position = None\n\n        # Evolution Loop\n        while self.budget > 0:\n            # Sample population from multivariate Gaussian distribution\n            population = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance, size=self.population_size)\n\n            # Clip to bounds\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            eval_count = len(fitness)\n            self.budget -= eval_count\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < best_fitness:\n                best_fitness = fitness[best_index]\n                best_position = population[best_index].copy()\n\n            # Adaptation (simplified CMA-ES)\n            # 1. Selection: Select the best individuals (e.g., top half)\n            num_selected = self.population_size // 2\n            indices = np.argsort(fitness)[:num_selected]\n            selected_population = population[indices]\n\n            # 2. Update mean: Weighted average of selected individuals\n            self.mean = np.mean(selected_population, axis=0)\n\n            # 3. Update covariance matrix\n            diff = selected_population - self.mean\n            self.covariance = np.cov(diff.T)\n\n            # If covariance becomes singular, regularize\n            if np.linalg.det(self.covariance) < 1e-9:\n                self.covariance += 1e-6 * np.eye(self.dim)\n\n            # 4. Adapt step size (simplified)\n            if np.std(fitness) < 1e-6:  #Stagnation detection\n                self.step_size *= 1.2  # Increase step size if fitness is too similar\n            else:\n                self.step_size *= 0.99 # Reduce step size slowly to fine-tune\n\n        return best_fitness, best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveGaussianCMA scored 0.100 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["018e4a74-c9a4-4df1-86fc-dc9907ecc7cd"], "operator": null, "metadata": {"aucs": [0.025105154455301593, 0.040273565867201766, 0.1452994372497307, 0.12616427887455595, 0.1508903853820388, 0.10960949637403905, 0.09989644122600039, 0.08211668379321724, 0.14297023812078025, 0.06815939446880237, 0.08612177276547173, 0.19342521622713615, 9.999999999998899e-05, 0.09270256030599322, 0.09058760204791594, 0.1528136834243562, 0.10039069597677985, 0.1028963970888408, 0.07386163252701039, 0.12384954504526813]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "bdc1e881-6044-4853-a4bb-f16bd1a3bbde", "fitness": "-inf", "name": "AdaptiveCovariancePSO", "description": "A novel adaptive PSO variant with a covariance-based mutation operator and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCovariancePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, mutation_rate=0.1, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb) / 10, abs(ub - lb) / 10, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n\n            # Limit velocities to prevent divergence\n            v_max = abs(ub - lb) / 2\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            new_population = population + velocities\n\n            # Handle boundary constraints\n            new_population = np.clip(new_population, lb, ub)\n\n            # Covariance-based Mutation\n            if np.random.rand() < self.mutation_rate:\n                covariance = np.cov(population.T)\n                for i in range(self.pop_size):\n                    new_population[i] += np.random.multivariate_normal(np.zeros(self.dim), covariance, 1).flatten()\n                    new_population[i] = np.clip(new_population[i], lb, ub) # Clip again after mutation\n\n\n            # Orthogonal Learning\n            if np.random.rand() < self.orthogonal_learning_rate:\n                for i in range(self.pop_size):\n                    # Select two random dimensions\n                    d1, d2 = np.random.choice(self.dim, 2, replace=False)\n\n                    # Create an orthogonal array of strength 2\n                    oa = np.array([[1, 1], [-1, 1]])\n\n                    # Generate two new candidate solutions\n                    candidate1 = new_population[i].copy()\n                    candidate2 = new_population[i].copy()\n\n                    candidate1[d1] = new_population[i, d1] + oa[0, 0] * (ub - lb) * 0.01\n                    candidate1[d2] = new_population[i, d2] + oa[0, 1] * (ub - lb) * 0.01\n                    candidate1 = np.clip(candidate1, lb, ub)\n\n                    candidate2[d1] = new_population[i, d1] + oa[1, 0] * (ub - lb) * 0.01\n                    candidate2[d2] = new_population[i, d2] + oa[1, 1] * (ub - lb) * 0.01\n                    candidate2 = np.clip(candidate2, lb, ub)\n\n                    # Evaluate candidates\n                    fitness1 = func(candidate1)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                      break\n                    fitness2 = func(candidate2)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                      break\n                    \n                    # Select the best solution\n                    if fitness1 < fitness2 and fitness1 < func(new_population[i]):\n                        new_population[i] = candidate1\n                    elif fitness2 < fitness1 and fitness2 < func(new_population[i]):\n                        new_population[i] = candidate2\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update personal best positions and fitness\n            improved_indices = new_fitness < personal_best_fitness\n            personal_best_positions[improved_indices] = new_population[improved_indices].copy()\n            personal_best_fitness[improved_indices] = new_fitness[improved_indices].copy()\n\n            # Update global best position and fitness\n            current_global_best_index = np.argmin(new_fitness)\n            if new_fitness[current_global_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_global_best_index]\n                global_best_position = new_population[current_global_best_index].copy()\n\n            #Update population\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "In the code, line 74, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: candidate1[d1] = new_population[i, d1] + oa[0, 0] * (ub - lb) * 0.01", "error": "In the code, line 74, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: candidate1[d1] = new_population[i, d1] + oa[0, 0] * (ub - lb) * 0.01", "parent_ids": ["04461b8a-d37e-45c7-998b-50eeef93c7d1"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "8d9b59a1-c80a-4149-8436-e0b3cd1a71c9", "fitness": 0.46554053820824076, "name": "EnhancedPSO", "description": "A simplified and enhanced PSO with adaptive inertia and velocity clamping, combined with a Cauchy mutation operator for escaping local optima.", "code": "import numpy as np\n\nclass EnhancedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, c1=2.0, c2=2.0, w_max=0.9, w_min=0.4, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.mutation_rate = mutation_rate\n        self.velocity_max = 0.5  # Reduced velocity max\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_max, self.velocity_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count = self.pop_size\n\n        self.pbest_positions = self.particles.copy()\n        self.pbest_fitness = self.fitness.copy()\n\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.particles[self.gbest_index].copy()\n        self.f_opt = self.fitness[self.gbest_index]\n\n        while self.eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                self.velocities[i] = w * self.velocities[i] + \\\n                                 self.c1 * np.random.rand(self.dim) * (self.pbest_positions[i] - self.particles[i]) + \\\n                                 self.c2 * np.random.rand(self.dim) * (self.gbest_position - self.particles[i])\n\n                # Velocity Clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_max, self.velocity_max)\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n\n                # Boundary Handling (clip)\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n                # Cauchy Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.standard_cauchy(size=self.dim) * 0.05 * (ub - lb)  # Scale Cauchy\n                    self.particles[i] += mutation\n                    self.particles[i] = np.clip(self.particles[i], lb, ub)  # Re-clip after mutation\n\n                # Evaluation\n                f = func(self.particles[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if f < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = f\n                    self.pbest_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.gbest_position = self.particles[i].copy()\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.gbest_position", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedPSO scored 0.466 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b55dc0b-9298-4cb4-affc-da6d96769c50"], "operator": null, "metadata": {"aucs": [0.1400969753875052, 0.34521600412903464, 0.4513448505700599, 0.7739256357340568, 0.4038831742335497, 0.4799770511412228, 0.3121650861245808, 0.3896736759610542, 0.41267583359697024, 0.19432957033880016, 0.797738887874111, 0.9927606185719479, 0.274262468723664, 0.39414365245126004, 0.7100206132113921, 0.5113736957720466, 0.4139980942892578, 0.5844067345166901, 0.26350099567587526, 0.465317145861737]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "e9d2a4d2-7d0a-40c2-a4db-84eba57db39b", "fitness": 0.4835683788202423, "name": "SimplifiedAdaptivePSO", "description": "A simplified Adaptive PSO with linearly decreasing inertia and velocity clamping, incorporating a perturbation mechanism to escape local optima and improve exploration.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=30, c1=2.0, c2=2.0, w_start=0.9, w_end=0.4, perturb_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_start = w_start\n        self.w_end = w_end\n        self.perturb_prob = perturb_prob\n        self.velocity_max = 1.0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_max, self.velocity_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n\n        self.pbest_positions = self.particles.copy()\n        self.pbest_fitness = self.fitness.copy()\n\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.particles[self.gbest_index].copy()\n        self.f_opt = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Linearly decreasing inertia weight\n            w = self.w_start - (self.w_start - self.w_end) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update velocities\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * np.random.rand(self.dim) * (self.pbest_positions[i] - self.particles[i]) + \\\n                                     self.c2 * np.random.rand(self.dim) * (self.gbest_position - self.particles[i])\n\n                # Velocity Clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_max, self.velocity_max)\n\n                # Update positions\n                self.particles[i] = self.particles[i] + self.velocities[i]\n\n                # Boundary Handling (Clip)\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n                \n                # Perturbation mechanism\n                if np.random.rand() < self.perturb_prob:\n                    self.particles[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[i] = np.random.uniform(-self.velocity_max, self.velocity_max, size=self.dim)\n\n                # Evaluate new position\n                f = func(self.particles[i])\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    if f < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f\n                        self.pbest_positions[i] = self.particles[i].copy()\n\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.gbest_position = self.particles[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.gbest_position", "configspace": "", "generation": 2, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.484 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db9dbbcf-307a-49b8-806e-130dc25e1a0f"], "operator": null, "metadata": {"aucs": [0.2212029621927627, 0.4130595076292869, 0.45983874786695766, 0.7380261450918588, 0.4325884574983545, 0.5141342831382902, 0.31037913459717215, 0.3970813787575619, 0.4015962165014473, 0.2272622228542912, 0.759735146458793, 0.9998287990266915, 0.29200647619438036, 0.3507611743224547, 0.7513451865694585, 0.49741731985279625, 0.37533721321532176, 0.6545470843506049, 0.35999311366800824, 0.5152270066183526]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "cb7e4ce6-a029-447a-90ef-0ae708255fd5", "fitness": 0.3252456045425509, "name": "NichedAdaptiveVelocityPSO", "description": "A novel PSO variant that combines velocity adaptation with a niching strategy based on fitness similarity to promote exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass NichedAdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, restart_threshold=100, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.restart_threshold = restart_threshold\n        self.niche_radius = niche_radius\n        self.learning_rate = 0.1  # Initial learning rate for self-adaptation\n        self.lr_decay = 0.995      # Decay factor for learning rate\n        self.lr_increase = 1.005  # Increase factor for learning rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/10, abs(ub-lb)/10, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Stagnation counter and restart flag\n        stagnation_counter = 0\n        \n        while self.budget > 0:\n            # Calculate fitness similarity matrix\n            fitness_diff = np.abs(fitness[:, np.newaxis] - fitness)\n            similarity_matrix = (fitness_diff < self.niche_radius).astype(int)\n            \n            # Identify niches\n            niches = []\n            for i in range(self.pop_size):\n                niche_members = np.where(similarity_matrix[i] == 1)[0]\n                niches.append(niche_members)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            for i in range(self.pop_size):\n                # Select a social guide based on niche\n                if len(niches[i]) > 1:\n                    # Select a different member from the niche\n                    niche_member_index = np.random.choice(niches[i][niches[i] != i])\n                    social_guide = population[niche_member_index]\n                else:\n                    social_guide = global_best_position #if niche is singleton, use global best.\n\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                  self.cognitive_coeff * r1[i] * (personal_best_positions[i] - population[i]) +\n                                  self.social_coeff * r2[i] * (social_guide - population[i]))\n\n            # Limit velocities to prevent divergence\n            v_max = abs(ub - lb) / 2\n            velocities = np.clip(velocities, -v_max, v_max)\n            \n            new_population = population + velocities\n            \n            # Handle boundary constraints\n            new_population = np.clip(new_population, lb, ub)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update personal best positions and fitness\n            improved_indices = new_fitness < personal_best_fitness\n            personal_best_positions[improved_indices] = new_population[improved_indices].copy()\n            personal_best_fitness[improved_indices] = new_fitness[improved_indices].copy()\n            \n            # Update global best position and fitness\n            current_global_best_index = np.argmin(new_fitness)\n            if new_fitness[current_global_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_global_best_index]\n                global_best_position = new_population[current_global_best_index].copy()\n                stagnation_counter = 0 # Reset stagnation counter\n            else:\n                stagnation_counter +=1 # Increment stagnation counter\n\n            #Update population\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n\n            # Restart mechanism\n            if stagnation_counter > self.restart_threshold:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                velocities = np.random.uniform(-abs(ub-lb)/10, abs(ub-lb)/10, size=(self.pop_size, self.dim)) #reinitialize velocities\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                improved_indices = fitness < personal_best_fitness\n                personal_best_positions[improved_indices] = population[improved_indices].copy()\n                personal_best_fitness[improved_indices] = fitness[improved_indices].copy()\n\n                current_global_best_index = np.argmin(fitness)\n                if fitness[current_global_best_index] < global_best_fitness:\n                    global_best_fitness = fitness[current_global_best_index]\n                    global_best_position = population[current_global_best_index].copy()\n                \n                stagnation_counter = 0 # Reset stagnation counter\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm NichedAdaptiveVelocityPSO scored 0.325 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["017d2a2c-26bd-4b3e-8e8d-49e97b2d2ce9"], "operator": null, "metadata": {"aucs": [0.16066103553387712, 0.22734694343176676, 0.28708293432064347, 0.26223106964457266, 0.24420180295431837, 0.27968567899501917, 0.2629609465820578, 0.25943578837633496, 0.24131130245672694, 0.21060763794136317, 0.2969911097425484, 0.9961587452478436, 0.29995685762079216, 0.2721119385013925, 0.685702913896274, 0.29588165485636997, 0.24810323569435, 0.3315638084281529, 0.17028532614325065, 0.4726313604833635]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
{"id": "0058d122-c2fc-45c5-8a79-e62f9971ddef", "fitness": "-inf", "name": "RingTopologyAdaptivePSO", "description": "A multi-swarm PSO with a ring topology and adaptive velocity scaling based on success rate and a periodic subswarm recombination strategy.", "code": "import numpy as np\n\nclass RingTopologyAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, num_swarms=4, c1=2.05, c2=2.05, w_max=0.9, w_min=0.4, mutation_rate=0.05, velocity_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_swarms = num_swarms\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.mutation_rate = mutation_rate\n        self.velocity_scale_factor = velocity_scale_factor\n        self.velocity_max = 1.0\n        self.swarm_size = pop_size // num_swarms # Define swarm size\n        self.success_rates = np.zeros(num_swarms)\n        self.success_history_length = 10\n        self.success_history = [[] for _ in range(num_swarms)]\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_max, self.velocity_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n\n        self.pbest_positions = self.particles.copy()\n        self.pbest_fitness = self.fitness.copy()\n\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.particles[self.gbest_index].copy()\n        self.f_opt = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n\n        # Initialize swarms\n        self.swarm_indices = np.array_split(np.random.permutation(self.pop_size), self.num_swarms)\n\n        while eval_count < self.budget:\n            # Periodic Swarm Recombination: Periodically swap particles between adjacent swarms\n            if eval_count % (self.budget // 5) == 0:\n                for k in range(self.num_swarms):\n                    next_swarm_index = (k + 1) % self.num_swarms\n                    # Swap a portion of particles between adjacent swarms\n                    swap_size = self.swarm_size // 4\n                    indices_to_swap = np.random.choice(self.swarm_size, swap_size, replace=False)\n                    temp_particles = self.particles[self.swarm_indices[k][indices_to_swap]].copy()\n                    self.particles[self.swarm_indices[k][indices_to_swap]] = self.particles[self.swarm_indices[next_swarm_index][indices_to_swap]].copy()\n                    self.particles[self.swarm_indices[next_swarm_index][indices_to_swap]] = temp_particles\n\n                    temp_velocities = self.velocities[self.swarm_indices[k][indices_to_swap]].copy()\n                    self.velocities[self.swarm_indices[k][indices_to_swap]] = self.velocities[self.swarm_indices[next_swarm_index][indices_to_swap]].copy()\n                    self.velocities[self.swarm_indices[next_swarm_index][indices_to_swap]] = temp_velocities\n\n            for k in range(self.num_swarms):\n                swarm_particles = self.particles[self.swarm_indices[k]]\n                swarm_velocities = self.velocities[self.swarm_indices[k]]\n                swarm_pbest_positions = self.pbest_positions[self.swarm_indices[k]]\n                swarm_pbest_fitness = self.pbest_fitness[self.swarm_indices[k]]\n                swarm_fitness = self.fitness[self.swarm_indices[k]]\n\n                local_gbest_index = np.argmin(swarm_fitness)\n                local_gbest_position = swarm_particles[local_gbest_index].copy()\n\n                # Calculate inertia weight based on swarm diversity\n                distances = np.linalg.norm(swarm_particles - local_gbest_position, axis=1)\n                diversity = np.mean(distances)\n                w = self.w_max - (self.w_max - self.w_min) * (diversity / (ub[0] - lb[0]))\n                w = np.clip(w, self.w_min, self.w_max)\n\n                # Adaptive Velocity Scaling\n                velocity_scale = 1.0 + self.velocity_scale_factor * self.success_rates[k]\n\n                # Update velocities and positions within the swarm\n                for i in range(len(swarm_particles)):\n                    swarm_velocities[i] = w * swarm_velocities[i] + \\\n                                         self.c1 * np.random.rand(self.dim) * (swarm_pbest_positions[i] - swarm_particles[i]) + \\\n                                         self.c2 * np.random.rand(self.dim) * (local_gbest_position - swarm_particles[i])\n\n                    # Velocity Clamping\n                    swarm_velocities[i] = np.clip(swarm_velocities[i], -self.velocity_max * velocity_scale, self.velocity_max * velocity_scale)\n\n                    swarm_particles[i] = swarm_particles[i] + swarm_velocities[i]\n\n                    # Mutation: Apply mutation with a certain probability\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.1 * (ub[0] - lb[0]), 0.1 * (ub[0] - lb[0]), size=self.dim)\n                        swarm_particles[i] += mutation\n\n                    # Boundary Handling (Bounce back)\n                    oob = (swarm_particles[i] < lb) | (swarm_particles[i] > ub)\n                    swarm_velocities[i][oob] *= -0.5  # Dampen velocity after bounce\n                    swarm_particles[i][oob] = np.clip(swarm_particles[i][oob], lb[oob], ub[oob])\n\n                    # Evaluate new position\n                    f = func(swarm_particles[i])\n                    eval_count += 1\n\n                    if f < swarm_fitness[i]:\n                        # Success! Update success rate\n                        self.success_history[k].append(1)\n                        swarm_fitness[i] = f\n                        if f < swarm_pbest_fitness[i]:\n                            swarm_pbest_fitness[i] = f\n                            swarm_pbest_positions[i] = swarm_particles[i].copy()\n\n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.gbest_position = swarm_particles[i].copy()\n                    else:\n                        self.success_history[k].append(0)\n\n                    if len(self.success_history[k]) > self.success_history_length:\n                        self.success_history[k].pop(0)\n\n                    self.success_rates[k] = np.mean(self.success_history[k]) if self.success_history[k] else 0.0\n\n\n                    if eval_count >= self.budget:\n                        break\n\n                # Update main particle array with the updated swarm\n                self.particles[self.swarm_indices[k]] = swarm_particles\n                self.velocities[self.swarm_indices[k]] = swarm_velocities\n                self.pbest_positions[self.swarm_indices[k]] = swarm_pbest_positions\n                self.pbest_fitness[self.swarm_indices[k]] = swarm_pbest_fitness\n                self.fitness[self.swarm_indices[k]] = swarm_fitness\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.gbest_position", "configspace": "", "generation": 2, "feedback": "Evaluation failed without an exception.", "error": "Evaluation failed without an exception.", "parent_ids": ["5b55dc0b-9298-4cb4-affc-da6d96769c50"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}
