[
     {
          "id": "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5",
          "parents": [
               "d21343ec-7567-464d-8e7c-b48aed862c53"
          ],
          "algorithm": "# Description: An algorithm employing a differential evolution strategy with adaptive scaling factors and crossover probabilities to balance exploration and exploitation.\n# Code:\n```",
          "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Adapt parameters (simple adaptation - can be improved)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt",
          "objective": -0.75329,
          "other_inf": null
     },
     {
          "id": "243d013f-c3f7-47ab-b3ad-51547b5b8efd",
          "parents": [],
          "algorithm": "Adaptive Differential Evolution with dynamic parameter tuning and population size reduction for improved exploration and exploitation.",
          "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            # Adaptive F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n            #Population Size Reduction\n            if eval_count > self.budget * 0.75 and self.pop_size > 10:\n               worst_index = np.argmax(self.fitness)\n               self.population = np.delete(self.population, worst_index, axis = 0)\n               self.fitness = np.delete(self.fitness, worst_index)\n               self.pop_size -= 1\n\n\n        return self.f_opt, self.x_opt",
          "objective": -0.70495,
          "other_inf": null
     },
     {
          "id": "a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d",
          "parents": [],
          "algorithm": "Adaptive Differential Evolution with dynamic parameter adaptation based on past success and restart mechanism.",
          "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n        self.archive_size = 10\n        self.restart_iter = budget // 10\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def update_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.CR = np.mean(self.success_CR)\n        else:\n            self.F = 0.5\n            self.CR = 0.9\n        \n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        iter_count = 0\n        while self.evals < self.budget:\n            iter_count += 1\n            if iter_count % self.restart_iter == 0:\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.update_parameters()\n                continue\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, i)\n                trial = self.crossover(mutant, self.population[i])\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f)\n\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n            \n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n            self.update_parameters()\n        return self.f_opt, self.x_opt",
          "objective": -0.65441,
          "other_inf": null
     },
     {
          "id": "aeb21e49-113b-44b9-8099-59d61d6f0a88",
          "parents": [],
          "algorithm": "Adaptive Differential Evolution with dynamic parameter adaptation based on successful iterations and a restart strategy when stagnation is detected.",
          "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, stagnation_threshold=0.001, stagnation_iter=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iter = stagnation_iter\n        self.best_history = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.f_vals = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.f_vals)\n        self.x_opt = self.population[np.argmin(self.f_vals)]\n        self.eval_count = self.pop_size #Initial population evaluation\n        \n        self.best_history.append(self.f_opt)\n        \n        iter_since_last_improvement = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                if f_trial < self.f_vals[i]:\n                    self.population[i] = trial_vector\n                    self.f_vals[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        iter_since_last_improvement = 0\n                    \n                        # Adaptive CR and F: If improvement found, modify params\n                        self.CR = np.random.normal(0.7, 0.1) \n                        self.F = np.random.normal(0.5, 0.1)\n                        self.CR = np.clip(self.CR, 0.0, 1.0)\n                        self.F = np.clip(self.F, 0.1, 1.0)\n                else:\n                    iter_since_last_improvement += 1\n                    \n                    # If parameters are stuck and aren't improving, modify params more aggressively\n                    if iter_since_last_improvement > 200:\n                         self.CR = np.random.rand()\n                         self.F = np.random.uniform(0.1, 0.9)\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            # Stagnation check\n            if iter_since_last_improvement > self.stagnation_iter:\n                # Restart strategy\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.f_vals = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(self.f_vals)\n                \n                if self.f_vals[best_index] < self.f_opt:\n                    self.f_opt = self.f_vals[best_index]\n                    self.x_opt = self.population[best_index]\n                \n                iter_since_last_improvement = 0\n                # Reset the CR and F too.\n                self.CR = np.random.normal(0.7, 0.1) \n                self.F = np.random.normal(0.5, 0.1)\n                self.CR = np.clip(self.CR, 0.0, 1.0)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                    \n\n        return self.f_opt, self.x_opt",
          "objective": -0.56571,
          "other_inf": null
     }
]