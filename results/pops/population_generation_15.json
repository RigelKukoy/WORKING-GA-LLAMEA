[
     {
          "id": "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc",
          "parents": [
               "0c74a561-8ecd-45c7-86c8-305448e13008"
          ],
          "algorithm": "This algorithm uses a self-adaptive Differential Evolution (SaDE) strategy to dynamically adjust the mutation and crossover parameters based on the success rate of previous generations, promoting a balance between exploration and exploitation.",
          "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0,\n                 num_strategies=4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.num_strategies = num_strategies\n        self.mutation_factors = np.random.uniform(0.5, 1.0, size=num_strategies)\n        self.crossover_rates = np.random.uniform(0.5, 1.0, size=num_strategies)\n        self.success_rates_F = np.ones(num_strategies) / num_strategies\n        self.success_rates_CR = np.ones(num_strategies) / num_strategies\n        self.memory_F = np.zeros(num_strategies)\n        self.memory_CR = np.zeros(num_strategies)\n        self.memory_p = 0.1\n        self.archive_size = int(self.pop_size / 2)\n        self.archive = []\n    \n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(self.num_strategies, p=self.success_rates_F / np.sum(self.success_rates_F))\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.mutation_factors[strategy_index] * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rates[strategy_index] or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update success rates\n                    self.success_rates_F[strategy_index] = (1 - self.memory_p) * self.success_rates_F[strategy_index] + self.memory_p\n                    self.success_rates_CR[strategy_index] = (1 - self.memory_p) * self.success_rates_CR[strategy_index] + self.memory_p\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                     self.success_rates_F[strategy_index] = (1 - self.memory_p) * self.success_rates_F[strategy_index]\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt",
          "objective": -0.76931,
          "other_inf": null
     },
     {
          "id": "0182a2fa-1d0f-49fa-86f9-a932145446c3",
          "parents": [
               "0c74a561-8ecd-45c7-86c8-305448e13008"
          ],
          "algorithm": "This algorithm uses a self-adaptive Differential Evolution (SaDE) approach where mutation and crossover strategies are probabilistically selected and adapted based on their past success, promoting exploration and exploitation.",
          "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.num_strategies = 4\n        self.probabilities = np.ones(self.num_strategies) / self.num_strategies\n        self.memory_size = 10\n        self.success_memory = [[] for _ in range(self.num_strategies)]\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                strategy_index = np.random.choice(self.num_strategies, p=self.probabilities)\n\n                if strategy_index == 0: # DE/rand/1\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = population[np.random.choice(idxs)] + 0.5 * (b - c)\n                elif strategy_index == 1: # DE/best/1\n                    best = population[np.argmin(fitness)]\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = best + 0.5 * (b - c)\n                elif strategy_index == 2: # DE/rand/2\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c, d, e = population[np.random.choice(idxs, 5, replace=False)]\n                    mutant = population[np.random.choice(idxs)] + 0.5 * (b - c) + 0.5 * (d - e)\n                else: # DE/current-to-best/1\n                    best = population[np.argmin(fitness)]\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = population[i] + 0.5 * (best - population[i]) + 0.5 * (b - c)\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                CR = 0.9\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f_trial\n                    self.success_memory[strategy_index].append(1)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_memory[strategy_index].append(0)\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if len(self.success_memory[strategy_index]) > self.memory_size:\n                    self.success_memory[strategy_index].pop(0)\n            \n            population = new_population\n            fitness = new_fitness\n\n            # Update probabilities\n            success_rates = [np.mean(s) if s else 0 for s in self.success_memory]\n            sum_success = np.sum(success_rates)\n            if sum_success > 0:\n                self.probabilities = success_rates / sum_success\n            else:\n                self.probabilities = np.ones(self.num_strategies) / self.num_strategies\n\n        return self.f_opt, self.x_opt",
          "objective": -0.76696,
          "other_inf": null
     },
     {
          "id": "0c74a561-8ecd-45c7-86c8-305448e13008",
          "parents": [
               "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"
          ],
          "algorithm": "This algorithm combines differential evolution with a covariance matrix adaptation strategy (CMA-ES) to adapt the mutation and crossover parameters based on the population's covariance structure, aiming for faster convergence and better exploration.",
          "code": "import numpy as np\n\nclass AdaptiveCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.sigma = sigma # Step size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.C = np.eye(dim)  # Covariance matrix\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Update covariance matrix (simplified CMA-ES update)\n            weights = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size + 1))\n            weights /= np.sum(weights)\n            \n            mean = np.sum(population * weights[:, None], axis=0)\n            \n            C_update = np.zeros_like(self.C)\n            for i in range(self.pop_size):\n                diff = population[i] - mean\n                C_update += weights[i] * np.outer(diff, diff)\n            \n            self.C = (1 - 0.1) * self.C + 0.1 * C_update  # Learning rate\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Sample mutation vector from multivariate normal distribution\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                mutant = a + self.F * (b - c) + self.sigma * z\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt",
          "objective": -0.74681,
          "other_inf": null
     },
     {
          "id": "8c2c1861-da75-4736-b974-fd2e2be3e680",
          "parents": [
               "9cfb8793-40b9-45af-b745-e861ab9fe03c"
          ],
          "algorithm": "This algorithm uses a differential evolution strategy with a population-based approach and adaptive parameter tuning to explore the search space efficiently.",
          "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            trial = self.population[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f = func(trial)\n            self.budget -= 1\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.population[i] = trial\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial.copy()\n                    \n            # Adaptive F and Cr (optional, but can improve performance)\n            if np.random.rand() < 0.1:\n                self.F = np.random.uniform(0.1, 0.9)\n                self.Cr = np.random.uniform(0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n        return self.f_opt, self.x_opt",
          "objective": -0.72314,
          "other_inf": null
     }
]