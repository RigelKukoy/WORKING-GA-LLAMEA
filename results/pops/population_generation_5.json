[
     {
          "id": "851876e6-2776-4345-966a-ecfb1e540613",
          "parents": [
               "a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"
          ],
          "algorithm": "A self-adaptive Differential Evolution algorithm with a smaller population size, aggressive parameter adaptation, and periodic local search using Nelder-Mead simplex method.}\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n        self.archive_size = 10\n        self.adaptation_rate = 0.1\n        self.local_search_interval = budget // 20\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def update_parameters(self):\n        if self.success_F:\n            mean_F = np.mean(self.success_F)\n            mean_CR = np.mean(self.success_CR)\n\n            self.F = (1 - self.adaptation_rate) * self.F + self.adaptation_rate * mean_F\n            self.CR = (1 - self.adaptation_rate) * self.CR + self.adaptation_rate * mean_CR\n        else:\n            self.F = 0.5\n            self.CR = 0.9\n        \n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            x0 = self.population[i].copy()\n            bounds = [(self.lb, self.ub)] * self.dim\n            res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(self.budget - self.evals, 50)",
          "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n        self.archive_size = 10\n        self.adaptation_rate = 0.1\n        self.local_search_interval = budget // 20\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def update_parameters(self):\n        if self.success_F:\n            mean_F = np.mean(self.success_F)\n            mean_CR = np.mean(self.success_CR)\n\n            self.F = (1 - self.adaptation_rate) * self.F + self.adaptation_rate * mean_F\n            self.CR = (1 - self.adaptation_rate) * self.CR + self.adaptation_rate * mean_CR\n        else:\n            self.F = 0.5\n            self.CR = 0.9\n        \n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            x0 = self.population[i].copy()\n            bounds = [(self.lb, self.ub)] * self.dim\n            res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(self.budget - self.evals, 50)})\n\n            if res.fun < self.fitness[i]:\n                self.population[i] = res.x\n                self.fitness[i] = res.fun\n                self.evals += res.nfev\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        iter_count = 0\n        while self.evals < self.budget:\n            iter_count += 1\n\n            if iter_count % self.local_search_interval == 0:\n                self.local_search(func)\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                  new_population.append(self.population[i])\n                  new_fitness.append(self.fitness[i])\n                  continue\n\n                mutant = self.mutate(self.population, i)\n                trial = self.crossover(mutant, self.population[i])\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f)\n\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n            \n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n            self.update_parameters()\n        return self.f_opt, self.x_opt",
          "objective": -0.76561,
          "other_inf": null
     },
     {
          "id": "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5",
          "parents": [
               "d21343ec-7567-464d-8e7c-b48aed862c53"
          ],
          "algorithm": "# Description: An algorithm employing a differential evolution strategy with adaptive scaling factors and crossover probabilities to balance exploration and exploitation.\n# Code:\n```",
          "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Adapt parameters (simple adaptation - can be improved)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt",
          "objective": -0.75329,
          "other_inf": null
     },
     {
          "id": "137d9a07-0ec0-4f54-8667-75ec1b71d11d",
          "parents": [
               "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"
          ],
          "algorithm": "# Description: An enhanced differential evolution algorithm incorporating a restart mechanism and dynamic parameter adaptation based on population diversity to escape local optima and maintain exploration.\n# Code:\n```",
          "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.restart_trigger = restart_trigger  # Percentage of budget used before considering a restart\n        self.initial_F = F\n        self.initial_CR = CR\n        self.restart_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        initial_budget = self.budget + self.pop_size # to compute restart threshold\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Adapt parameters based on population diversity\n            diversity = np.std(population)\n            self.F = np.clip(self.initial_F + np.random.normal(0, 0.01 * diversity), 0.1, 0.9)\n            self.CR = np.clip(self.initial_CR + np.random.normal(0, 0.01 * diversity), 0.1, 0.9)\n\n            # Restart mechanism\n            if (initial_budget - self.budget) / initial_budget > self.restart_trigger:\n                if diversity < 0.01:  # If population has converged\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                    self.F = self.initial_F  # Reset parameters\n                    self.CR = self.initial_CR\n                    self.restart_count += 1\n        return self.f_opt, self.x_opt",
          "objective": -0.74433,
          "other_inf": null
     },
     {
          "id": "14b1fe56-3093-4a53-9c2c-e31902aaad85",
          "parents": [
               "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"
          ],
          "algorithm": "# Description: An enhanced differential evolution algorithm that incorporates a restart mechanism based on stagnation detection and dynamically adjusts the population size based on performance.\n# Code:\n```",
          "code": "import numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, stagnation_threshold=500, pop_resize_freq=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.pop_resize_freq = pop_resize_freq\n        self.last_improvement = 0\n        self.initial_pop_size = pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        generation = 0\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                self.stagnation_counter = 0\n                self.last_improvement = generation\n            else:\n                self.stagnation_counter += 1\n\n            # Adapt parameters (simple adaptation - can be improved)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n            \n            # Stagnation check and restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Restart the population\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                self.stagnation_counter = 0\n                self.last_improvement = generation\n\n            # Dynamic population size adjustment\n            if generation > 0 and generation % self.pop_resize_freq == 0:\n                improvement_ratio = (generation - self.last_improvement) / self.pop_resize_freq\n                if improvement_ratio < 0.2:  # Example threshold\n                    self.pop_size = max(10, int(self.pop_size * 0.8))  # Reduce population size\n                    # Reinitialize population (smaller)\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size  # Account for new evals\n                    best_index = np.argmin(fitness)\n                    if fitness[best_index] < self.f_opt:\n                        self.f_opt = fitness[best_index]\n                        self.x_opt = population[best_index].copy()\n\n                elif improvement_ratio > 0.5:  # Example threshold\n                    self.pop_size = min(self.initial_pop_size, int(self.pop_size * 1.2)) # Increase population size\n                    # Reinitialize population (larger)\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size # Account for new evals\n                    best_index = np.argmin(fitness)\n                    if fitness[best_index] < self.f_opt:\n                        self.f_opt = fitness[best_index]\n                        self.x_opt = population[best_index].copy()\n            generation += 1\n        return self.f_opt, self.x_opt",
          "objective": -0.73532,
          "other_inf": null
     }
]