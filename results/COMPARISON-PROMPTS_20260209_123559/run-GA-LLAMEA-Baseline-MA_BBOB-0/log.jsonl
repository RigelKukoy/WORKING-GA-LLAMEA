{"id": "6b3a7bc8-91c4-4016-8019-fe61db8cf365", "fitness": "-inf", "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with population diversity maintenance and restart strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_trigger = 100  # Number of iterations without improvement to trigger restart\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.fitness[i] == np.inf:\n                if self.eval_count < self.budget:\n                    self.fitness[i] = func(self.population[i])\n                    self.eval_count += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    break\n\n    def mutate(self):\n        mutated_vectors = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[idxs]\n            mutated_vectors[i] = a + self.F * (b - c)\n            mutated_vectors[i] = np.clip(mutated_vectors[i], self.lb, self.ub)\n        return mutated_vectors\n\n    def crossover(self, mutated_vectors):\n        trial_vectors = np.copy(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == np.random.randint(self.dim):  # Ensure at least one parameter changes\n                    trial_vectors[i, j] = mutated_vectors[i, j]\n        return trial_vectors\n    \n    def selection(self, func, trial_vectors):\n        improved = False\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_trial = func(trial_vectors[i])\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vectors[i]\n                    self.fitness[i] = f_trial\n                    improved = True\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vectors[i]\n        return improved\n\n    def diversity(self):\n        # Calculate average pairwise distance in the population\n        distances = np.sum((self.population[:, None, :] - self.population[None, :, :])**2, axis=2)**0.5\n        diversity_metric = np.mean(distances)\n        return diversity_metric\n\n    def restart_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.initialize_population()\n        self.evaluate_population(func)\n        \n        no_improvement_count = 0\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate()\n            trial = self.crossover(mutated)\n            improved = self.selection(func, trial)\n\n            if not improved:\n                no_improvement_count +=1\n            else:\n                no_improvement_count = 0\n\n            if no_improvement_count > self.restart_trigger:\n                 if self.diversity() < 0.1 * (self.ub - self.lb):  #Restart if diversity is too low\n                    self.restart_population()\n                    self.evaluate_population(func)\n                    no_improvement_count = 0 # Reset counter after restart\n            \n            # Adaptive adjustment of F and Cr (optional)\n            # self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0) # Example adaptive F\n            # self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0) # Example adaptive CR\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with population diversity maintenance and restart strategy.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_trigger = 100  # Number of iterations without improvement to trigger restart\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.fitness[i] == np.inf:\n                if self.eval_count < self.budget:\n                    self.fitness[i] = func(self.population[i])\n                    self.eval_count += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    break\n\n    def mutate(self):\n        mutated_vectors = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[idxs]\n            mutated_vectors[i] = a + self.F * (b - c)\n            mutated_vectors[i] = np.clip(mutated_vectors[i], self.lb, self.ub)\n        return mutated_vectors\n\n    def crossover(self, mutated_vectors):\n        trial_vectors = np.copy(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == np.random.randint(self.dim):  # Ensure at least one parameter changes\n                    trial_vectors[i, j] = mutated_vectors[i, j]\n        return trial_vectors\n    \n    def selection(self, func, trial_vectors):\n        improved = False\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_trial = func(trial_vectors[i])\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vectors[i]\n                    self.fitness[i] = f_trial\n                    improved = True\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vectors[i]\n        return improved\n\n    def diversity(self):\n        # Calculate average pairwise distance in the population\n        distances = np.sum((self.population[:, None, :] - self.population[None, :, :])**2, axis=2)**0.5\n        diversity_metric = np.mean(distances)\n        return diversity_metric\n\n    def restart_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.initialize_population()\n        self.evaluate_population(func)\n        \n        no_improvement_count = 0\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate()\n            trial = self.crossover(mutated)\n            improved = self.selection(func, trial)\n\n            if not improved:\n                no_improvement_count +=1\n            else:\n                no_improvement_count = 0\n\n            if no_improvement_count > self.restart_trigger:\n                 if self.diversity() < 0.1 * (self.ub - self.lb):  #Restart if diversity is too low\n                    self.restart_population()\n                    self.evaluate_population(func)\n                    no_improvement_count = 0 # Reset counter after restart\n            \n            # Adaptive adjustment of F and Cr (optional)\n            # self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0) # Example adaptive F\n            # self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0) # Example adaptive CR\n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "3593d576-a641-42ba-b00c-fc1f5e062643", "fitness": "-inf", "name": "APGEENS", "description": "Adaptive Population-based Gradient Estimation with Elite Archive and Neighborhood Search.", "code": "import numpy as np\n\nclass APGEENS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.exploration_rate = exploration_rate\n        self.population = None\n        self.fitness = None\n        self.archive_x = None\n        self.archive_f = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func, eval_count):\n        for i in range(self.pop_size):\n            if self.fitness[i] == np.inf and eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i].copy()\n        return eval_count\n\n    def update_archive(self):\n        if self.archive_x is None:\n            self.archive_x = self.population.copy()\n            self.archive_f = self.fitness.copy()\n        else:\n            self.archive_x = np.concatenate((self.archive_x, self.population), axis=0)\n            self.archive_f = np.concatenate((self.archive_f, self.fitness))\n            \n            idx = np.argsort(self.archive_f)[:self.archive_size]\n            self.archive_x = self.archive_x[idx]\n            self.archive_f = self.archive_f[idx]\n\n    def estimate_gradient(self, idx):\n        # Estimate gradient using a central difference approach with random perturbation\n        gradient = np.zeros(self.dim)\n        h = np.random.uniform(0.001, 0.01)  # Adaptive step size, could also be decreased over time\n\n        x_plus = self.population[idx].copy()\n        x_minus = self.population[idx].copy()\n\n        rand_dim = np.random.randint(0, self.dim) # Choose one dimension randomly\n\n        x_plus[rand_dim] = np.clip(x_plus[rand_dim] + h, self.lb, self.ub)\n        x_minus[rand_dim] = np.clip(x_minus[rand_dim] - h, self.lb, self.ub)\n\n        f_plus = np.inf\n        f_minus = np.inf\n        \n        return x_plus, x_minus, rand_dim, h\n    \n    def __call__(self, func):\n        eval_count = 0\n        self.initialize_population()\n        eval_count = self.evaluate_population(func, eval_count)\n\n        while eval_count < self.budget:\n            self.update_archive()\n\n            for i in range(self.pop_size):\n                # Gradient-based update with archive guidance\n                \n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random restart\n                    self.population[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = np.inf # Mark for re-evaluation\n                    continue\n\n                x_plus, x_minus, rand_dim, h = self.estimate_gradient(i)\n                \n                if eval_count + 2 <= self.budget:\n                    f_plus = func(x_plus)\n                    eval_count +=1\n                    f_minus = func(x_minus)\n                    eval_count +=1\n                    \n                    gradient_estimate = (f_plus - f_minus) / (2*h)\n                    \n                    self.population[i, rand_dim] = np.clip(self.population[i, rand_dim] - 0.1 * gradient_estimate, self.lb, self.ub) # Step size 0.1\n                    self.fitness[i] = np.inf\n                    \n                    if f_plus < self.f_opt:\n                        self.f_opt = f_plus\n                        self.x_opt = x_plus.copy()\n                        \n                    if f_minus < self.f_opt:\n                        self.f_opt = f_minus\n                        self.x_opt = x_minus.copy()\n                else:\n                    # If almost out of budget perform random exploration\n                    self.population[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = np.inf\n\n            eval_count = self.evaluate_population(func, eval_count)\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Population-based Gradient Estimation with Elite Archive and Neighborhood Search.\n# Code:\n```python\nimport numpy as np\n\nclass APGEENS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.exploration_rate = exploration_rate\n        self.population = None\n        self.fitness = None\n        self.archive_x = None\n        self.archive_f = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func, eval_count):\n        for i in range(self.pop_size):\n            if self.fitness[i] == np.inf and eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i].copy()\n        return eval_count\n\n    def update_archive(self):\n        if self.archive_x is None:\n            self.archive_x = self.population.copy()\n            self.archive_f = self.fitness.copy()\n        else:\n            self.archive_x = np.concatenate((self.archive_x, self.population), axis=0)\n            self.archive_f = np.concatenate((self.archive_f, self.fitness))\n            \n            idx = np.argsort(self.archive_f)[:self.archive_size]\n            self.archive_x = self.archive_x[idx]\n            self.archive_f = self.archive_f[idx]\n\n    def estimate_gradient(self, idx):\n        # Estimate gradient using a central difference approach with random perturbation\n        gradient = np.zeros(self.dim)\n        h = np.random.uniform(0.001, 0.01)  # Adaptive step size, could also be decreased over time\n\n        x_plus = self.population[idx].copy()\n        x_minus = self.population[idx].copy()\n\n        rand_dim = np.random.randint(0, self.dim) # Choose one dimension randomly\n\n        x_plus[rand_dim] = np.clip(x_plus[rand_dim] + h, self.lb, self.ub)\n        x_minus[rand_dim] = np.clip(x_minus[rand_dim] - h, self.lb, self.ub)\n\n        f_plus = np.inf\n        f_minus = np.inf\n        \n        return x_plus, x_minus, rand_dim, h\n    \n    def __call__(self, func):\n        eval_count = 0\n        self.initialize_population()\n        eval_count = self.evaluate_population(func, eval_count)\n\n        while eval_count < self.budget:\n            self.update_archive()\n\n            for i in range(self.pop_size):\n                # Gradient-based update with archive guidance\n                \n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random restart\n                    self.population[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = np.inf # Mark for re-evaluation\n                    continue\n\n                x_plus, x_minus, rand_dim, h = self.estimate_gradient(i)\n                \n                if eval_count + 2 <= self.budget:\n                    f_plus = func(x_plus)\n                    eval_count +=1\n                    f_minus = func(x_minus)\n                    eval_count +=1\n                    \n                    gradient_estimate = (f_plus - f_minus) / (2*h)\n                    \n                    self.population[i, rand_dim] = np.clip(self.population[i, rand_dim] - 0.1 * gradient_estimate, self.lb, self.ub) # Step size 0.1\n                    self.fitness[i] = np.inf\n                    \n                    if f_plus < self.f_opt:\n                        self.f_opt = f_plus\n                        self.x_opt = x_plus.copy()\n                        \n                    if f_minus < self.f_opt:\n                        self.f_opt = f_minus\n                        self.x_opt = x_minus.copy()\n                else:\n                    # If almost out of budget perform random exploration\n                    self.population[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = np.inf\n\n            eval_count = self.evaluate_population(func, eval_count)\n            \n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "4a39388d-fd36-4e01-93ca-8df1d52bcec3", "fitness": "-inf", "name": "AdaptiveDECM", "description": "A population-based algorithm that combines elements of differential evolution and covariance matrix adaptation, adapting both the search direction and step size using information from the population's diversity and objective function values.", "code": "import numpy as np\n\nclass AdaptiveDECM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Reasonable default\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.mean = None\n        self.C = None\n        self.D = None\n        self.eigenspace_learning_rate = 0.1\n        self.step_size_adaptation_rate = 0.5\n\n    def __call__(self, func):\n        # Initialization\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        population = np.random.uniform(bounds_lb, bounds_ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update the remaining budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.mean = np.mean(population, axis=0)\n        self.C = np.eye(self.dim)  # Initial Covariance matrix\n        self.D = np.ones(self.dim)  # Step sizes\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # 1. Mutation (DE part, but using current population's covariance information)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Incorporate CMA-ES-like step size and direction\n                z = np.random.normal(0, 1, self.dim)\n                mutated = population[i] + self.mutation_factor * (x_r1 - x_r2) + 0.1 * self.D * np.dot(self.C, z)\n\n                # 2. Crossover\n                crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n                trial_vector = np.where(crossover_mask, mutated, population[i])\n                trial_vector = np.clip(trial_vector, bounds_lb, bounds_ub)  # Keep within bounds\n\n                # 3. Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # CMA-ES Adaptation\n            old_mean = self.mean.copy()\n            self.mean = np.mean(population, axis=0)\n\n            # Update covariance matrix C\n            diff = self.mean - old_mean\n            self.C = (1 - self.eigenspace_learning_rate) * self.C + self.eigenspace_learning_rate * np.outer(diff / self.D, diff / self.D)\n            \n            # Keep C positive definite\n            try:\n                w, V = np.linalg.eigh(self.C) # Use eigh for symmetric matrices\n                w = np.maximum(w, 1e-8)\n                self.C = V @ np.diag(w) @ V.T\n            except np.linalg.LinAlgError:\n                # If the covariance matrix becomes singular, reset it.\n                self.C = np.eye(self.dim)\n\n            # Adapt step sizes D\n            norm_diff = np.linalg.norm(diff)\n            self.D = self.D * np.exp(self.step_size_adaptation_rate * (norm_diff / np.linalg.norm(self.D) - 1))\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of differential evolution and covariance matrix adaptation, adapting both the search direction and step size using information from the population's diversity and objective function values.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDECM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Reasonable default\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.mean = None\n        self.C = None\n        self.D = None\n        self.eigenspace_learning_rate = 0.1\n        self.step_size_adaptation_rate = 0.5\n\n    def __call__(self, func):\n        # Initialization\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        population = np.random.uniform(bounds_lb, bounds_ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update the remaining budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.mean = np.mean(population, axis=0)\n        self.C = np.eye(self.dim)  # Initial Covariance matrix\n        self.D = np.ones(self.dim)  # Step sizes\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # 1. Mutation (DE part, but using current population's covariance information)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Incorporate CMA-ES-like step size and direction\n                z = np.random.normal(0, 1, self.dim)\n                mutated = population[i] + self.mutation_factor * (x_r1 - x_r2) + 0.1 * self.D * np.dot(self.C, z)\n\n                # 2. Crossover\n                crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n                trial_vector = np.where(crossover_mask, mutated, population[i])\n                trial_vector = np.clip(trial_vector, bounds_lb, bounds_ub)  # Keep within bounds\n\n                # 3. Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # CMA-ES Adaptation\n            old_mean = self.mean.copy()\n            self.mean = np.mean(population, axis=0)\n\n            # Update covariance matrix C\n            diff = self.mean - old_mean\n            self.C = (1 - self.eigenspace_learning_rate) * self.C + self.eigenspace_learning_rate * np.outer(diff / self.D, diff / self.D)\n            \n            # Keep C positive definite\n            try:\n                w, V = np.linalg.eigh(self.C) # Use eigh for symmetric matrices\n                w = np.maximum(w, 1e-8)\n                self.C = V @ np.diag(w) @ V.T\n            except np.linalg.LinAlgError:\n                # If the covariance matrix becomes singular, reset it.\n                self.C = np.eye(self.dim)\n\n            # Adapt step sizes D\n            norm_diff = np.linalg.norm(diff)\n            self.D = self.D * np.exp(self.step_size_adaptation_rate * (norm_diff / np.linalg.norm(self.D) - 1))\n\n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "05e8f151-2451-4260-b017-c4e933896596", "fitness": 0.0, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Archive and Stochastic Ranking. This algorithm utilizes a population-based approach, differential mutation, an archive to store promising solutions, and stochastic ranking to handle constraints (implicitly by comparing function values directly). The adaptation adjusts the mutation and crossover rates based on the success of previous generations.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_history = []\n        self.CR_history = []\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = x_1 + self.F * (x_2 - x_3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial_vector)\n                        self.archive_fitness.append(f_trial)\n                    else:\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if f_trial < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = trial_vector\n                            self.archive_fitness[max_archive_index] = f_trial\n\n\n                # Update optimal solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Adaptive F and CR (simple averaging based on success - can be improved)\n            successful_F = []\n            successful_CR = []\n\n            for i in range(self.pop_size):\n                 if self.fitness[i] < func(self.population[i]):  # crude definition of success\n                     successful_F.append(self.F)  # Placeholder\n                     successful_CR.append(self.CR) # Placeholder - assumes CR was successful if the individual's fitness improved.\n\n\n            if successful_F:\n                self.F = np.mean(successful_F)\n            else:\n                self.F = 0.5 # reset if no success\n\n            if successful_CR:\n                self.CR = np.mean(successful_CR)\n            else:\n                self.CR = 0.7 # reset if no success\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Archive and Stochastic Ranking. This algorithm utilizes a population-based approach, differential mutation, an archive to store promising solutions, and stochastic ranking to handle constraints (implicitly by comparing function values directly). The adaptation adjusts the mutation and crossover rates based on the success of previous generations.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_history = []\n        self.CR_history = []\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = x_1 + self.F * (x_2 - x_3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial_vector)\n                        self.archive_fitness.append(f_trial)\n                    else:\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if f_trial < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = trial_vector\n                            self.archive_fitness[max_archive_index] = f_trial\n\n\n                # Update optimal solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Adaptive F and CR (simple averaging based on success - can be improved)\n            successful_F = []\n            successful_CR = []\n\n            for i in range(self.pop_size):\n                 if self.fitness[i] < func(self.population[i]):  # crude definition of success\n                     successful_F.append(self.F)  # Placeholder\n                     successful_CR.append(self.CR) # Placeholder - assumes CR was successful if the individual's fitness improved.\n\n\n            if successful_F:\n                self.F = np.mean(successful_F)\n            else:\n                self.F = 0.5 # reset if no success\n\n            if successful_CR:\n                self.CR = np.mean(successful_CR)\n            else:\n                self.CR = 0.7 # reset if no success\n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0]}, "task_prompt": ""}
{"id": "bd98ccbe-9c54-46e0-8d7e-9d5d16b31348", "fitness": 0.633196826071228, "name": "MirroredDifferentialEvolution", "description": "A population-based algorithm that combines global exploration with local exploitation using a mirrored sampling strategy to enhance boundary exploration and solution refinement.", "code": "import numpy as np\n\nclass MirroredDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population within the bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Mirrored sampling to handle out-of-bounds individuals\n                for k in range(self.dim):\n                    if mutant[k] < func.bounds.lb[k]:\n                        mutant[k] = func.bounds.lb[k] + np.random.rand() * (population[a][k] - func.bounds.lb[k]) \n                    elif mutant[k] > func.bounds.ub[k]:\n                        mutant[k] = func.bounds.ub[k] - np.random.rand() * (func.bounds.ub[k] - population[a][k])\n\n                # Crossover\n                trial = population[i].copy()\n                for k in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[k] = mutant[k]\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm MirroredDifferentialEvolution scored 0.633 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines global exploration with local exploitation using a mirrored sampling strategy to enhance boundary exploration and solution refinement.\n# Code: \n```python\nimport numpy as np\n\nclass MirroredDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population within the bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Mirrored sampling to handle out-of-bounds individuals\n                for k in range(self.dim):\n                    if mutant[k] < func.bounds.lb[k]:\n                        mutant[k] = func.bounds.lb[k] + np.random.rand() * (population[a][k] - func.bounds.lb[k]) \n                    elif mutant[k] > func.bounds.ub[k]:\n                        mutant[k] = func.bounds.ub[k] - np.random.rand() * (func.bounds.ub[k] - population[a][k])\n\n                # Crossover\n                trial = population[i].copy()\n                for k in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[k] = mutant[k]\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.5315236062972752, "generation": 1, "aucs": [0.21572375495985918, 0.39259537344322915, 0.6216620505218088, 0.8222959640171312, 0.7080532206488402, 0.7642836472053867, 0.590824316413701, 0.5819962056134431, 0.713988861039742, 0.6217792881332341, 0.8156633453067194, 0.9985766950087186, 0.3632170072264498, 0.6797480518180246, 0.8520137838961965, 0.7709224235292718, 0.5060808809063686, 0.812432376139657, 0.30523682533918006, 0.5268424502575974]}, "task_prompt": ""}
{"id": "fa5b7cbb-eaaf-49e7-b69d-838558e2ba92", "fitness": 0.0, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution with a simplified parameter adaptation mechanism and a probabilistic archive usage for mutation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, p_archive=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.p_archive = p_archive\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_1, x_2 = self.population[idxs]\n\n                if np.random.rand() < self.p_archive and self.archive:\n                    x_3 = self.archive[np.random.randint(len(self.archive))]\n                else:\n                    idx3 = np.random.choice(self.pop_size, 1, replace=False)[0]\n                    x_3 = self.population[idx3]\n\n\n                mutant = x_1 + self.F * (x_2 - x_3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial_vector)\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = trial_vector  # Replace random archive member\n\n                # Update optimal solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Simplified Adaptation of F and CR\n            success_indices = self.fitness < np.array([func(x) for x in self.population]) # more efficient than within the loop\n\n            if np.any(success_indices): # only adapt F and CR if there was a success\n              self.F = 0.5 * (self.F + np.random.rand()) # adapt F\n              self.CR = 0.5 * (self.CR + np.random.rand()) # adapt CR\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["05e8f151-2451-4260-b017-c4e933896596"], "operator": "simplify", "metadata": {"llm_response": "# Description: An adaptive differential evolution with a simplified parameter adaptation mechanism and a probabilistic archive usage for mutation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, p_archive=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.p_archive = p_archive\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_1, x_2 = self.population[idxs]\n\n                if np.random.rand() < self.p_archive and self.archive:\n                    x_3 = self.archive[np.random.randint(len(self.archive))]\n                else:\n                    idx3 = np.random.choice(self.pop_size, 1, replace=False)[0]\n                    x_3 = self.population[idx3]\n\n\n                mutant = x_1 + self.F * (x_2 - x_3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial_vector)\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = trial_vector  # Replace random archive member\n\n                # Update optimal solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Simplified Adaptation of F and CR\n            success_indices = self.fitness < np.array([func(x) for x in self.population]) # more efficient than within the loop\n\n            if np.any(success_indices): # only adapt F and CR if there was a success\n              self.F = 0.5 * (self.F + np.random.rand()) # adapt F\n              self.CR = 0.5 * (self.CR + np.random.rand()) # adapt CR\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.04379568473753731, "generation": 1, "aucs": [0]}, "task_prompt": ""}
{"id": "8ab76ae1-2555-4149-a335-3f49eb9e526f", "fitness": "-inf", "name": "PSO_DE", "description": "Population-based algorithm that combines Particle Swarm Optimization (PSO) with a mutation operator inspired by Differential Evolution (DE) to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = population + velocities\n            \n            # Apply bounds constraints\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n            \n            # Apply DE mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < self.mutation_rate:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutation_vector = x_r1 + 0.5 * (x_r2 - x_r3)\n                    \n                    # Crossover with current particle\n                    crossover_mask = np.random.rand(self.dim) < 0.1  # Low crossover rate\n                    population[i] = np.where(crossover_mask, mutation_vector, population[i])\n                    population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in population])\n            num_evals = len(new_fitness)\n            self.budget -= num_evals\n\n            # Update personal best positions and fitness\n            improved_indices = new_fitness < personal_best_fitness\n            personal_best_positions[improved_indices] = population[improved_indices].copy()\n            personal_best_fitness[improved_indices] = new_fitness[improved_indices].copy()\n            \n            # Update global best position and fitness\n            current_best_index = np.argmin(new_fitness)\n            if new_fitness[current_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_best_index]\n                global_best_position = population[current_best_index].copy()\n        \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines Particle Swarm Optimization (PSO) with a mutation operator inspired by Differential Evolution (DE) to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = population + velocities\n            \n            # Apply bounds constraints\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n            \n            # Apply DE mutation\n            for i in range(self.pop_size):\n                if np.random.rand() < self.mutation_rate:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutation_vector = x_r1 + 0.5 * (x_r2 - x_r3)\n                    \n                    # Crossover with current particle\n                    crossover_mask = np.random.rand(self.dim) < 0.1  # Low crossover rate\n                    population[i] = np.where(crossover_mask, mutation_vector, population[i])\n                    population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in population])\n            num_evals = len(new_fitness)\n            self.budget -= num_evals\n\n            # Update personal best positions and fitness\n            improved_indices = new_fitness < personal_best_fitness\n            personal_best_positions[improved_indices] = population[improved_indices].copy()\n            personal_best_fitness[improved_indices] = new_fitness[improved_indices].copy()\n            \n            # Update global best position and fitness\n            current_best_index = np.argmin(new_fitness)\n            if new_fitness[current_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_best_index]\n                global_best_position = population[current_best_index].copy()\n        \n        return global_best_fitness, global_best_position\n```", "operator": "random_new", "theta_sampled": 0.3271918585174956, "generation": 1}, "task_prompt": ""}
{"id": "706d9931-8cf9-47f5-a993-7478d9c5cf54", "fitness": 0.4650366342568759, "name": "ShrinkingPSO", "description": "A population-based algorithm that combines Particle Swarm Optimization (PSO) with a shrinking search space.", "code": "import numpy as np\n\nclass ShrinkingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/5, abs(ub-lb)/5, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find personal best positions and global best position\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index].copy()\n        \n        shrink_factor = 0.995\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + self.c1 * r1 * (pbest_pop[i] - pop[i]) + self.c2 * r2 * (gbest_pos - pop[i])\n                pop[i] = pop[i] + velocities[i]\n\n                # Clip positions to bounds\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            # Evaluate updated population\n            new_fitness = np.array([func(x) for x in pop])\n            self.budget -= self.pop_size\n\n            # Update personal best positions\n            improved_indices = new_fitness < pbest_fitness\n            pbest_pop[improved_indices] = pop[improved_indices].copy()\n            pbest_fitness[improved_indices] = new_fitness[improved_indices].copy()\n\n            # Update global best position\n            new_gbest_index = np.argmin(new_fitness)\n            if new_fitness[new_gbest_index] < gbest_fitness:\n                gbest_pos = pop[new_gbest_index].copy()\n                gbest_fitness = new_fitness[new_gbest_index].copy()\n\n            # Shrink search space\n            center = gbest_pos\n            width = (ub - lb) * shrink_factor\n            lb = np.maximum(lb, center - width/2)\n            ub = np.minimum(ub, center + width/2)\n        \n\n        return gbest_fitness, gbest_pos", "configspace": "", "generation": 1, "feedback": "The algorithm ShrinkingPSO scored 0.465 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines Particle Swarm Optimization (PSO) with a shrinking search space.\n# Code:\n```python\nimport numpy as np\n\nclass ShrinkingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/5, abs(ub-lb)/5, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Find personal best positions and global best position\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_pos = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index].copy()\n        \n        shrink_factor = 0.995\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + self.c1 * r1 * (pbest_pop[i] - pop[i]) + self.c2 * r2 * (gbest_pos - pop[i])\n                pop[i] = pop[i] + velocities[i]\n\n                # Clip positions to bounds\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            # Evaluate updated population\n            new_fitness = np.array([func(x) for x in pop])\n            self.budget -= self.pop_size\n\n            # Update personal best positions\n            improved_indices = new_fitness < pbest_fitness\n            pbest_pop[improved_indices] = pop[improved_indices].copy()\n            pbest_fitness[improved_indices] = new_fitness[improved_indices].copy()\n\n            # Update global best position\n            new_gbest_index = np.argmin(new_fitness)\n            if new_fitness[new_gbest_index] < gbest_fitness:\n                gbest_pos = pop[new_gbest_index].copy()\n                gbest_fitness = new_fitness[new_gbest_index].copy()\n\n            # Shrink search space\n            center = gbest_pos\n            width = (ub - lb) * shrink_factor\n            lb = np.maximum(lb, center - width/2)\n            ub = np.minimum(ub, center + width/2)\n        \n\n        return gbest_fitness, gbest_pos\n```", "operator": "random_new", "theta_sampled": 0.29274324197232915, "generation": 1, "aucs": [0.19269417880169126, 0.1720447514157487, 0.7236260663772978, 0.9228695884250824, 0.2842628393408899, 0.2879700071186151, 0.2890440149998398, 0.6789712783790559, 0.757769895842115, 0.23885899919012765, 0.3587954725714674, 0.9983884645128382, 0.22601955883242952, 0.2561194150117805, 0.6483169677704756, 0.7805115021600895, 0.2859619456722259, 0.3785207868791378, 0.36387801947935605, 0.45610893235725536]}, "task_prompt": ""}
{"id": "94744d96-6c3f-4605-a9d4-c9f0ed13152b", "fitness": 0.6221670438803769, "name": "ImprovedAdaptiveDE", "description": "Simplified Adaptive Differential Evolution with improved parameter adaptation based on fitness improvement ratios and a mirroring boundary handling strategy.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = x_1 + self.F * (x_2 - x_3)\n\n                # Boundary Handling (Mirroring)\n                mutant = np.where(mutant < self.lb, 2 * self.lb - mutant, mutant)\n                mutant = np.where(mutant > self.ub, 2 * self.ub - mutant, mutant)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    delta_fitness = self.fitness[i] - f_trial #fitness improvement\n                    improvement_ratio = delta_fitness / (abs(self.fitness[i]) + 1e-9) #Relative improvement\n\n                    #Adaptive parameter updates\n                    self.F = 0.5 * self.F + 0.5 * np.random.normal(0.5, 0.1) # F adaptation\n                    self.CR = 0.5 * self.CR + 0.5 * np.random.normal(0.7, 0.1) # CR adaptation\n                    self.F = np.clip(self.F, 0.1, 1.0)  # Keep F within reasonable bounds\n                    self.CR = np.clip(self.CR, 0.1, 1.0)  # Keep CR within reasonable bounds\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm ImprovedAdaptiveDE scored 0.622 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["05e8f151-2451-4260-b017-c4e933896596"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with improved parameter adaptation based on fitness improvement ratios and a mirroring boundary handling strategy.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = x_1 + self.F * (x_2 - x_3)\n\n                # Boundary Handling (Mirroring)\n                mutant = np.where(mutant < self.lb, 2 * self.lb - mutant, mutant)\n                mutant = np.where(mutant > self.ub, 2 * self.ub - mutant, mutant)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    delta_fitness = self.fitness[i] - f_trial #fitness improvement\n                    improvement_ratio = delta_fitness / (abs(self.fitness[i]) + 1e-9) #Relative improvement\n\n                    #Adaptive parameter updates\n                    self.F = 0.5 * self.F + 0.5 * np.random.normal(0.5, 0.1) # F adaptation\n                    self.CR = 0.5 * self.CR + 0.5 * np.random.normal(0.7, 0.1) # CR adaptation\n                    self.F = np.clip(self.F, 0.1, 1.0)  # Keep F within reasonable bounds\n                    self.CR = np.clip(self.CR, 0.1, 1.0)  # Keep CR within reasonable bounds\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.22322543290626207, "generation": 1, "aucs": [0.20840450600928662, 0.43529999140971565, 0.6003726294569702, 0.8599954224000357, 0.6959362800910512, 0.7599927060499425, 0.5423350451827178, 0.5841252579288497, 0.7140612547173892, 0.5756720528738808, 0.8093783793156397, 0.9935184794080774, 0.3242964547045909, 0.6557535546508209, 0.8926214293509948, 0.7560341640314558, 0.5117114452959964, 0.8121625700211682, 0.19025504461461062, 0.5214142100943434]}, "task_prompt": ""}
{"id": "7712549c-0ef8-4536-bcd7-dd0b28cb2954", "fitness": 0.4071738798794756, "name": "VelocityEnhancedLocalSearch", "description": "A population-based algorithm employing a velocity update mechanism inspired by Particle Swarm Optimization, combined with a local search strategy to refine promising solutions.", "code": "import numpy as np\n\nclass VelocityEnhancedLocalSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia_weight=0.7, cognitive_coeff=1.4, social_coeff=1.4, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_radius = local_search_radius\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.population_size, self.dim))  # Smaller initial velocities\n\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n\n        while self.budget > 0:\n            for i in range(self.population_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.cognitive_coeff * r1 * (global_best_position - population[i])\n                social_component = self.social_coeff * r2 * (global_best_position - population[i]) # Swarm towards the best\n                velocities[i] = self.inertia_weight * velocities[i] + cognitive_component + social_component\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Local search around the current position with a few steps\n                for _ in range(3): \n                    if self.budget <= 0:\n                        break\n                    \n                    perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    local_position = np.clip(population[i] + perturbation, lb, ub)\n\n                    local_fitness = func(local_position)\n                    self.budget -= 1\n                    \n                    if local_fitness < fitness[i]:\n                        fitness[i] = local_fitness\n                        population[i] = local_position.copy()\n\n                if self.budget <= 0:\n                    break;\n\n                # Evaluate fitness\n                #fitness[i] = func(population[i]) # moved to local search\n                #self.budget -= 1\n\n                # Update global best\n                if fitness[i] < global_best_fitness:\n                    global_best_fitness = fitness[i]\n                    global_best_position = population[i].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm VelocityEnhancedLocalSearch scored 0.407 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm employing a velocity update mechanism inspired by Particle Swarm Optimization, combined with a local search strategy to refine promising solutions.\n\n# Code: \n```python\nimport numpy as np\n\nclass VelocityEnhancedLocalSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia_weight=0.7, cognitive_coeff=1.4, social_coeff=1.4, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_radius = local_search_radius\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.population_size, self.dim))  # Smaller initial velocities\n\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n\n        while self.budget > 0:\n            for i in range(self.population_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.cognitive_coeff * r1 * (global_best_position - population[i])\n                social_component = self.social_coeff * r2 * (global_best_position - population[i]) # Swarm towards the best\n                velocities[i] = self.inertia_weight * velocities[i] + cognitive_component + social_component\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Local search around the current position with a few steps\n                for _ in range(3): \n                    if self.budget <= 0:\n                        break\n                    \n                    perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    local_position = np.clip(population[i] + perturbation, lb, ub)\n\n                    local_fitness = func(local_position)\n                    self.budget -= 1\n                    \n                    if local_fitness < fitness[i]:\n                        fitness[i] = local_fitness\n                        population[i] = local_position.copy()\n\n                if self.budget <= 0:\n                    break;\n\n                # Evaluate fitness\n                #fitness[i] = func(population[i]) # moved to local search\n                #self.budget -= 1\n\n                # Update global best\n                if fitness[i] < global_best_fitness:\n                    global_best_fitness = fitness[i]\n                    global_best_position = population[i].copy()\n\n        return global_best_fitness, global_best_position\n```", "operator": "random_new", "theta_sampled": 0.30873558887525343, "generation": 1, "aucs": [0.10700022961881372, 0.20062710364719716, 0.42101764172528067, 0.8247556846807756, 0.38106666826947877, 0.4621998493565883, 0.3065326675471933, 0.22646749759538642, 0.32626974326015656, 0.18352650875009258, 0.6569349185709775, 0.9979488643429621, 0.2716499071126538, 0.2690508705647632, 0.5877817381497368, 0.488041109356677, 0.24618336358647153, 0.5713918724190274, 0.16622557261909932, 0.4488057864161794]}, "task_prompt": ""}
{"id": "d5981f3f-c144-45df-828d-bdfe62346342", "fitness": 0.0, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with archive and per-dimension adaptation of mutation factor F.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = np.full(dim, 0.5)  # Initial mutation factor (per dimension)\n        self.CR = 0.7 # Initial crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = x_1 + self.F * (x_2 - x_3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial_vector)\n                        self.archive_fitness.append(f_trial)\n                    else:\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if f_trial < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = trial_vector\n                            self.archive_fitness[max_archive_index] = f_trial\n\n\n                # Update optimal solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Adaptive F (per dimension, simple average based on success)\n            for d in range(self.dim):\n                successful_F_d = []\n                for i in range(self.pop_size):\n                    if self.fitness[i] < func(self.population[i]):  # crude definition of success\n                        successful_F_d.append(self.F[d])\n\n                if successful_F_d:\n                    self.F[d] = np.mean(successful_F_d)\n                else:\n                    self.F[d] = 0.5  # reset if no success\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["05e8f151-2451-4260-b017-c4e933896596", "05e8f151-2451-4260-b017-c4e933896596"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with archive and per-dimension adaptation of mutation factor F.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = np.full(dim, 0.5)  # Initial mutation factor (per dimension)\n        self.CR = 0.7 # Initial crossover rate\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.n_evals = self.pop_size\n\n        while self.n_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = x_1 + self.F * (x_2 - x_3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.n_evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial_vector)\n                        self.archive_fitness.append(f_trial)\n                    else:\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if f_trial < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = trial_vector\n                            self.archive_fitness[max_archive_index] = f_trial\n\n\n                # Update optimal solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            # Adaptive F (per dimension, simple average based on success)\n            for d in range(self.dim):\n                successful_F_d = []\n                for i in range(self.pop_size):\n                    if self.fitness[i] < func(self.population[i]):  # crude definition of success\n                        successful_F_d.append(self.F[d])\n\n                if successful_F_d:\n                    self.F[d] = np.mean(successful_F_d)\n                else:\n                    self.F[d] = 0.5  # reset if no success\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.5954467696665287, "generation": 1, "aucs": [0]}, "task_prompt": ""}
{"id": "f4ce8d4d-bab6-4fe9-83d4-d11dc4580872", "fitness": 0.45560034141849837, "name": "HybridDEPSO", "description": "A population-based algorithm that combines elements of differential evolution and particle swarm optimization, with adaptive parameter control.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution mutation factor\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.pbest_fitness = None\n        self.pbest_position = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.pbest_position = self.pop.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            # Adaptive Parameter Control\n            self.F = 0.5 + 0.5 * np.random.rand()\n            self.CR = 0.6 + 0.3 * np.random.rand()\n            self.w = 0.4 + 0.5 * np.random.rand()\n            self.c1 = 1.0 + 1.0 * np.random.rand()\n            self.c2 = 1.0 + 1.0 * np.random.rand()\n                \n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = self.pop[i] + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # PSO Velocity Update\n                velocity = self.w * (self.pbest_position[i] - self.pop[i]) + self.c1 * np.random.rand() * (self.pbest_position[i] - self.pop[i]) + self.c2 * np.random.rand() * (self.best_position - self.pop[i])\n                trial = self.pop[i] + velocity\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        trial[j] = self.pop[i, j]\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial.copy()\n\n                    if f_trial < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f_trial\n                        self.pbest_position[i] = trial.copy()\n                        \n                        if f_trial < self.best_fitness:\n                            self.best_fitness = f_trial\n                            self.best_position = trial.copy()\n\n                if eval_count >= self.budget:\n                    break\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDEPSO scored 0.456 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of differential evolution and particle swarm optimization, with adaptive parameter control.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution mutation factor\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.pbest_fitness = None\n        self.pbest_position = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.pbest_position = self.pop.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            # Adaptive Parameter Control\n            self.F = 0.5 + 0.5 * np.random.rand()\n            self.CR = 0.6 + 0.3 * np.random.rand()\n            self.w = 0.4 + 0.5 * np.random.rand()\n            self.c1 = 1.0 + 1.0 * np.random.rand()\n            self.c2 = 1.0 + 1.0 * np.random.rand()\n                \n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = self.pop[i] + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # PSO Velocity Update\n                velocity = self.w * (self.pbest_position[i] - self.pop[i]) + self.c1 * np.random.rand() * (self.pbest_position[i] - self.pop[i]) + self.c2 * np.random.rand() * (self.best_position - self.pop[i])\n                trial = self.pop[i] + velocity\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        trial[j] = self.pop[i, j]\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial.copy()\n\n                    if f_trial < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f_trial\n                        self.pbest_position[i] = trial.copy()\n                        \n                        if f_trial < self.best_fitness:\n                            self.best_fitness = f_trial\n                            self.best_position = trial.copy()\n\n                if eval_count >= self.budget:\n                    break\n\n\n        return self.best_fitness, self.best_position\n```", "operator": "random_new", "theta_sampled": 0.5726493721969885, "generation": 1, "aucs": [0.14836451106065596, 0.18568816350521578, 0.6891060875436911, 0.9677705876374505, 0.26958776646452554, 0.6660148687871028, 0.33192919915656127, 0.4909017414690662, 0.2952108626347453, 0.17791535400729552, 0.3952210868917787, 0.9983345010666681, 0.3342528928687203, 0.3398376975640036, 0.5872374798590222, 0.33477383892714097, 0.2745795474896737, 0.9479991257923235, 0.19788622231765507, 0.4793952933266713]}, "task_prompt": ""}
{"id": "ee1804f1-1d49-4d23-b933-a2c9d7157e24", "fitness": "-inf", "name": "SelfOrganizingSearch", "description": "A self-organizing algorithm that adapts step sizes based on local gradient estimates and population diversity.", "code": "import numpy as np\n\nclass SelfOrganizingSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for step size adaptation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        step_sizes = np.ones(self.dim) * (ub - lb) / 10.0 # Initial step sizes\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Estimate local gradient using finite differences\n                gradient_estimate = np.zeros(self.dim)\n                for j in range(self.dim):\n                    x_plus = population[i].copy()\n                    x_minus = population[i].copy()\n                    \n                    #Ensure boundaries are not violated\n                    x_plus[j] = min(ub, x_plus[j] + step_sizes[j] / 2.0)\n                    x_minus[j] = max(lb, x_minus[j] - step_sizes[j] / 2.0)\n                    \n                    f_plus = func(x_plus)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n                    \n                    f_minus = func(x_minus)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n                    \n                    gradient_estimate[j] = (f_plus - f_minus) / (x_plus[j] - x_minus[j])\n\n                # Update position based on gradient estimate\n                new_x = population[i] - self.lr * step_sizes * gradient_estimate\n                new_x = np.clip(new_x, lb, ub)  # Clip to bounds\n                \n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                # Update population and fitness if better\n                if new_f < fitness[i]:\n                    population[i] = new_x\n                    fitness[i] = new_f\n\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n\n            # Adapt step sizes based on population diversity\n            for j in range(self.dim):\n                std_dev = np.std(population[:, j])\n                step_sizes[j] = min(ub - lb, max(1e-6, std_dev)) #Ensure a minimum and maximum stepsize\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "In the code, line 33, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: x_plus[j] = min(ub, x_plus[j] + step_sizes[j] / 2.0)", "error": "In the code, line 33, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: x_plus[j] = min(ub, x_plus[j] + step_sizes[j] / 2.0)", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-organizing algorithm that adapts step sizes based on local gradient estimates and population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass SelfOrganizingSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for step size adaptation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        step_sizes = np.ones(self.dim) * (ub - lb) / 10.0 # Initial step sizes\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Estimate local gradient using finite differences\n                gradient_estimate = np.zeros(self.dim)\n                for j in range(self.dim):\n                    x_plus = population[i].copy()\n                    x_minus = population[i].copy()\n                    \n                    #Ensure boundaries are not violated\n                    x_plus[j] = min(ub, x_plus[j] + step_sizes[j] / 2.0)\n                    x_minus[j] = max(lb, x_minus[j] - step_sizes[j] / 2.0)\n                    \n                    f_plus = func(x_plus)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n                    \n                    f_minus = func(x_minus)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n                    \n                    gradient_estimate[j] = (f_plus - f_minus) / (x_plus[j] - x_minus[j])\n\n                # Update position based on gradient estimate\n                new_x = population[i] - self.lr * step_sizes * gradient_estimate\n                new_x = np.clip(new_x, lb, ub)  # Clip to bounds\n                \n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                # Update population and fitness if better\n                if new_f < fitness[i]:\n                    population[i] = new_x\n                    fitness[i] = new_f\n\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n\n            # Adapt step sizes based on population diversity\n            for j in range(self.dim):\n                std_dev = np.std(population[:, j])\n                step_sizes[j] = min(ub - lb, max(1e-6, std_dev)) #Ensure a minimum and maximum stepsize\n        \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.407475769232687, "generation": 2}, "task_prompt": ""}
{"id": "3f96b111-8dd7-4e79-9b64-cc29acf6ac6b", "fitness": 0.0, "name": "AdaptiveArchiveDE", "description": "Adaptive Differential Evolution with archive and stochastic ranking for constraint handling.", "code": "import numpy as np\n\nclass AdaptiveArchiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.archive_size = archive_size\n        self.archive = None\n\n    def __call__(self, func):\n        # Initialize population within the bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Initialize archive\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        archive_fitness = np.array([func(x) for x in self.archive])\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n\n                # Incorporate archive individuals into mutation\n                if np.random.rand() < 0.1 and self.archive is not None and len(self.archive) > 0:\n                     c_idx = np.random.randint(0, len(self.archive))\n                     mutant = population[a] + self.F * (population[b] - self.archive[c_idx])\n                else:\n                     c = np.random.choice(indices, 1, replace=False)[0] #avoid modifying indices list\n                     mutant = population[a] + self.F * (population[b] - population[c])\n\n\n                # Clip to bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                   cross_points[np.random.randint(0, self.dim)] = True\n                trial[cross_points] = mutant[cross_points]\n\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n                    # Update archive (stochastic ranking)\n                    if self.archive is not None and len(self.archive) > 0:\n                        worst_archive_idx = np.argmax(archive_fitness)\n                        if f < archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = trial\n                            archive_fitness[worst_archive_idx] = f\n\n\n\n                if evals >= self.budget:\n                    break\n\n            #Adaptive F and CR\n            self.F = 0.5 + 0.4*np.random.rand()\n            self.CR = 0.9*self.CR + 0.1*np.random.rand()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveArchiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bd98ccbe-9c54-46e0-8d7e-9d5d16b31348"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with archive and stochastic ranking for constraint handling.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveArchiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.archive_size = archive_size\n        self.archive = None\n\n    def __call__(self, func):\n        # Initialize population within the bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Initialize archive\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        archive_fitness = np.array([func(x) for x in self.archive])\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n\n                # Incorporate archive individuals into mutation\n                if np.random.rand() < 0.1 and self.archive is not None and len(self.archive) > 0:\n                     c_idx = np.random.randint(0, len(self.archive))\n                     mutant = population[a] + self.F * (population[b] - self.archive[c_idx])\n                else:\n                     c = np.random.choice(indices, 1, replace=False)[0] #avoid modifying indices list\n                     mutant = population[a] + self.F * (population[b] - population[c])\n\n\n                # Clip to bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                   cross_points[np.random.randint(0, self.dim)] = True\n                trial[cross_points] = mutant[cross_points]\n\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n                    # Update archive (stochastic ranking)\n                    if self.archive is not None and len(self.archive) > 0:\n                        worst_archive_idx = np.argmax(archive_fitness)\n                        if f < archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = trial\n                            archive_fitness[worst_archive_idx] = f\n\n\n\n                if evals >= self.budget:\n                    break\n\n            #Adaptive F and CR\n            self.F = 0.5 + 0.4*np.random.rand()\n            self.CR = 0.9*self.CR + 0.1*np.random.rand()\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.36491111442253965, "generation": 2, "aucs": [0]}, "task_prompt": ""}
{"id": "0ac28686-cd2d-4afe-9750-1f207153e127", "fitness": "-inf", "name": "AdaptiveRankDE", "description": "An adaptive population-based algorithm that combines aspects of Differential Evolution with a stochastic ranking selection mechanism to handle constraints implicitly and adaptively tunes its parameters.", "code": "import numpy as np\n\nclass AdaptiveRankDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive for past solutions\n        self.archive_size = 10\n        self.success_F = []\n        self.success_CR = []\n        self.memory_F = np.full(10, self.F)\n        self.memory_CR = np.full(10, self.CR)\n        self.memory_idx = 0\n        self.tau1 = 0.1\n        self.tau2 = 0.1\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        mutated = np.copy(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[idxs]\n            mutated[i] = pop[i] + F * (x_r2 - x_r3)\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        crossed = np.copy(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < CR or j == np.random.randint(self.dim):\n                    crossed[i, j] = mutated[i, j]\n        return crossed\n    \n    def repair(self, arr, lb, ub):\n        arr = np.clip(arr, lb, ub)\n        return arr\n    \n    def stochastic_ranking(self, fitness, trial_fitness):\n      P_f = 0.45\n      ranked_indices = np.argsort(np.where(fitness < 0, fitness, np.random.rand(len(fitness)) * np.max(fitness)))\n\n      trial_ranked_indices = np.argsort(np.where(trial_fitness < 0, trial_fitness, np.random.rand(len(trial_fitness)) * np.max(trial_fitness)))\n      \n      return ranked_indices, trial_ranked_indices\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive F and CR\n            self.memory_idx = (self.memory_idx + 1) % 10\n\n            F = self.memory_F[self.memory_idx] + self.tau1 * np.random.normal(0, 0.1)\n            CR = self.memory_CR[self.memory_idx] + self.tau2 * np.random.normal(0, 0.1)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.clip(CR, 0.1, 1.0)\n\n\n            mutated = self.mutate(self.population, F)\n            mutated = self.repair(mutated, func.bounds.lb, func.bounds.ub)\n            crossed = self.crossover(self.population, mutated, CR)\n            crossed = self.repair(crossed, func.bounds.lb, func.bounds.ub)\n\n            trial_fitness = np.array([func(x) for x in crossed])\n            self.budget -= self.pop_size\n            \n            ranked_indices, trial_ranked_indices = self.stochastic_ranking(self.fitness, trial_fitness)\n\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            successful_F = []\n            successful_CR = []\n            for i in range(self.pop_size):\n                if trial_fitness[i] < self.fitness[i]:\n                    new_population[i] = crossed[i]\n                    new_fitness[i] = trial_fitness[i]\n                    successful_F.append(F)\n                    successful_CR.append(CR)\n                else:\n                    pass # Keep the old\n            \n            self.population = new_population\n            self.fitness = new_fitness\n\n            if len(successful_F) > 0:\n              self.memory_F[self.memory_idx] = np.mean(successful_F)\n              self.memory_CR[self.memory_idx] = np.mean(successful_CR)\n\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "Evaluation failed without an exception.", "error": "Evaluation failed without an exception.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that combines aspects of Differential Evolution with a stochastic ranking selection mechanism to handle constraints implicitly and adaptively tunes its parameters.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveRankDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive for past solutions\n        self.archive_size = 10\n        self.success_F = []\n        self.success_CR = []\n        self.memory_F = np.full(10, self.F)\n        self.memory_CR = np.full(10, self.CR)\n        self.memory_idx = 0\n        self.tau1 = 0.1\n        self.tau2 = 0.1\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        mutated = np.copy(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[idxs]\n            mutated[i] = pop[i] + F * (x_r2 - x_r3)\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        crossed = np.copy(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < CR or j == np.random.randint(self.dim):\n                    crossed[i, j] = mutated[i, j]\n        return crossed\n    \n    def repair(self, arr, lb, ub):\n        arr = np.clip(arr, lb, ub)\n        return arr\n    \n    def stochastic_ranking(self, fitness, trial_fitness):\n      P_f = 0.45\n      ranked_indices = np.argsort(np.where(fitness < 0, fitness, np.random.rand(len(fitness)) * np.max(fitness)))\n\n      trial_ranked_indices = np.argsort(np.where(trial_fitness < 0, trial_fitness, np.random.rand(len(trial_fitness)) * np.max(trial_fitness)))\n      \n      return ranked_indices, trial_ranked_indices\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive F and CR\n            self.memory_idx = (self.memory_idx + 1) % 10\n\n            F = self.memory_F[self.memory_idx] + self.tau1 * np.random.normal(0, 0.1)\n            CR = self.memory_CR[self.memory_idx] + self.tau2 * np.random.normal(0, 0.1)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.clip(CR, 0.1, 1.0)\n\n\n            mutated = self.mutate(self.population, F)\n            mutated = self.repair(mutated, func.bounds.lb, func.bounds.ub)\n            crossed = self.crossover(self.population, mutated, CR)\n            crossed = self.repair(crossed, func.bounds.lb, func.bounds.ub)\n\n            trial_fitness = np.array([func(x) for x in crossed])\n            self.budget -= self.pop_size\n            \n            ranked_indices, trial_ranked_indices = self.stochastic_ranking(self.fitness, trial_fitness)\n\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            successful_F = []\n            successful_CR = []\n            for i in range(self.pop_size):\n                if trial_fitness[i] < self.fitness[i]:\n                    new_population[i] = crossed[i]\n                    new_fitness[i] = trial_fitness[i]\n                    successful_F.append(F)\n                    successful_CR.append(CR)\n                else:\n                    pass # Keep the old\n            \n            self.population = new_population\n            self.fitness = new_fitness\n\n            if len(successful_F) > 0:\n              self.memory_F[self.memory_idx] = np.mean(successful_F)\n              self.memory_CR[self.memory_idx] = np.mean(successful_CR)\n\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.37319321725259635, "generation": 2}, "task_prompt": ""}